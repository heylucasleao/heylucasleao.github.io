---
{"dg-publish":true,"permalink":"/digital-garden/meu-modelo-conforme/text/4-previsao-conforme/"}
---

# Previs√£o Conforme

A melhor descri√ß√£o que encontrei sobre o tema encontra-se no artigo [Theoretical Foundations of Conformal Prediction](https://arxiv.org/abs/2411.11824), que descreve como:

> A previs√£o conforme √© uma abordagem estat√≠stica para quantifica√ß√£o de incerteza onde as previs√µes do modelo s√£o acompanhadas por um **intervalo **ou **conjunto**, comunicando o grau de confiabilidade em qualquer previs√£o, sem depender de pressupostos sobre a certeza do modelo.

Portanto, √© um framework de aprendizagem de m√°quina que permite quantificar incertezas e criar intervalos de predi√ß√£o. Isso possibilita melhores interpreta√ß√µes do modelo, maior seguran√ßa e garantias de probabilidade emp√≠rica nos resultados.

Suas vantagens s√£o:

- **Cobertura Garantida**: As regi√µes de previs√£o oferecem garantias de cobertura para o resultado final.
- **Agnosticismo de Modelo**: √â compat√≠vel com qualquer modelo ou √°rea de Machine Learning.
- **Independ√™ncia de Distribui√ß√£o**: As previs√µes conformes n√£o pressup√µem uma distribui√ß√£o de probabilidade espec√≠fica (Gaussiana, Gama, Poisson etc.), ampliando sua aplicabilidade.
- **Aus√™ncia de Retreino**: N√£o √© necess√°rio reestimar o modelo ap√≥s a previs√£o inicial.
- **Predi√ß√£o Probabil√≠stica**: Oferece previs√µes com medidas de confian√ßa, permitindo controlar o n√≠vel de garantia do pr√≥prio modelo.
- **Flexibilidade de Tamanho de Dados**: A validade das previs√µes √© mantida independentemente do tamanho do conjunto de dados. Contudo, um conjunto de dados pequeno para calibra√ß√£o gera menos valor se comparado a uma volumetria maior.
- **Efici√™ncia Computacional**: As previs√µes mant√™m a efici√™ncia computacional, sendo ideais para aplica√ß√µes em tempo real e grandes conjuntos de dados.

Existem dois tipos de categorias: Transductive Conformal Prediction (TCP) e Inductive Conformal Prediction (ICP). 

**Transductive Conformal Prediction (TCP):**
O TCP foi o m√©todo **original** de Previs√£o Conforme. Sua caracter√≠stica principal √© que, para cada novo ponto de dados, o modelo √© treinado inteiramente para **cada** resultado poss√≠vel. Por exemplo, em um modelo bin√°rio de classifica√ß√£o, o modelo ser√° treinado uma vez para o valor 0 e outra para o valor 1, calculando um score de n√£o conformidade para cada caso. 

> [!tip] üí°
> Ou seja, o modelo ir√° ser treinado para cada r√≥tulo e para cada ponto novo a ser testado!

Esse processo garante alta precis√£o, pois considera toda a informa√ß√£o dispon√≠vel para cada previs√£o. Este processo se assimila na t√©cnica Jacknife, que faz uma √© um processo de leave-one-out para estima√ß√£o de vari√¢ncia e vi√©s , aonde:

1. Remove de forma **n√£o **aleat√≥ria uma observa√ß√£o por vez do conjunto de dados
2. Calcula a estat√≠stica de interesse com as observa√ß√µes restantes
3. Utiliza essas estimativas para avaliar o vari√¢ncia e vi√©s do estimador

No contexto da Previs√£o Conforme, esta abordagem tem como objetivo as estimativas de incerteza, embora‚Å†, em contra partida pode ser computacionalmente ineficiente dependendo da quantidade de dados tanto de treinamento, como para teste. 

**Inductive Conformal Prediction (ICP):**
O ICP foi desenvolvido como uma alternativa mais eficiente ao TCP. Nele treinamos uma √∫nica vez utilizando dados **separados** ao do treinamento do nosso modelo base. Com esse conjunto de dados de calibra√ß√£o, geramos um intervalo que s√£o aplicados a novos dados para previs√£o.

Embora o TCP ofere√ßa potencialmente maior precis√£o, o ICP √© geralmente preferido em aplica√ß√µes pr√°ticas devido √† sua efici√™ncia computacional, especialmente em cen√°rios com a necessidade de previs√µes em tempo real.

Uma explica√ß√£o visual sobre a diferen√ßa de ambos pode ser vista por aqui:

[Uncertainty Quantification (3): From Full to Split Conformal Methods](https://youtu.be/YigGJfsCjDk?si=GdeR7xnGCZCZeOhk)

Logo, para este projeto, farei apenas o m√©todo ICP.

## Cobertura Garantida

Para compreender a garantia de cobertura, vamos analisar duas express√µes matem√°ticas fundamentais:

$$
P(Y_{n+1} \in C(X_{n+1})) \geq 1 - \alpha
$$

Ela que a probabilidade do pr√≥ximo valor Y estar contido no conjunto de predi√ß√£o C(Xn+1) √© de pelo menos 1-Œ±, onde Œ± representa nossa taxa de erro desejada.

$$
C(X_{n+1}) = \{y \in Y : s(X_{n+1}, y) \leq \hat{q}\}
$$

Esta segunda express√£o define o conjunto de predi√ß√£o utilizando um score de n√£o-conformidade. Este score, calculado a partir de novos dados, √© comparado com o quantil conforme (qÃÇ), que estabelece nosso limiar para dados conformes. Em termos pr√°ticos, isso cria um conjunto de predi√ß√£o onde temos uma garantia probabil√≠stica de 1-Œ± de que o pr√≥ximo valor Y estar√° contido.

Para que isso seja respeitado, devemos assumir que os dados respeitem a permutabilidase e que sejam dados independentes e identicamente distribu√≠dos (i.i.d.), assegurando a validade estat√≠stica da cobertura.

## Permutabilidade

O termo se refere √† propriedade de uma sequ√™ncia de vari√°veis aleat√≥rias em que a ordem de aparecimento n√£o afeta sua distribui√ß√£o de probabilidade conjunta.

Em termos mais simples, significa que os elementos de uma sequ√™ncia podem ser reorganizados sem afetar suas propriedades probabil√≠sticas fundamentais. Por exemplo:

Imagine uma urna com 3 bolas coloridas (vermelha, azul e verde) das quais voc√™ vai retirar uma a uma. Considere as seguintes sequ√™ncias poss√≠veis:

- Sequ√™ncia 1: (Vermelha, Azul, Verde)
- Sequ√™ncia 2: (Verde, Vermelha, Azul)
- Sequ√™ncia 3: (Azul, Verde, Vermelha)

Se as bolas s√£o retiradas aleatoriamente e recolocadas, a probabilidade de obter qualquer uma dessas sequ√™ncias √© id√™ntica. Isso demonstra que a sequ√™ncia √© permut√°vel ‚Äî voc√™ pode reorganizar os elementos e a distribui√ß√£o de probabilidade permanece inalterada.

Em resumo, para que a previs√£o conforme funcione adequadamente, os dados de calibra√ß√£o **devem** seguir a mesma distribui√ß√£o dos dados que ser√£o preditos no dia a dia. Podemos validar isso atrav√©s de diferentes m√©todos: an√°lise de cobertura emp√≠rica, que abordarei posteriormente, teste t de Student ou teste de Kolmogorov-Smirnov.

