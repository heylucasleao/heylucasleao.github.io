---
{"dg-publish":true,"permalink":"/digital-garden/meu-modelo-conforme/text/2-antes-de-comecarmos/"}
---

# Antes de começarmos...

## A Importância da Incerteza

Antes de mais nada, queria compartilhar uma reflexão importante. Minha jornada com ciência de dados me fez perceber algo interessante: quanto mais me aprofundava nesse campo, mais distante ficava do pensamento estatístico tradicional. A razão? A estatística trabalha fundamentalmente com a ótica da incerteza e nossa compreensão das limitações dos resultados.

Segundo o artigo [Importance of being uncertain](https://www.nature.com/articles/nmeth.2613):

> A estatística nos ajuda a responder esta questão. Ela nos fornece uma maneira de modelar quantitativamente o papel do acaso em nossos experimentos e representar dados não como medições precisas, mas como estimativas com erro. Também nos mostra como o erro em valores de entrada se propaga através dos cálculos. A aplicação prática deste framework teórico é associar incerteza ao resultado dos experimentos e atribuir níveis de confiança a afirmações que generalizam além das observações.

Percebi que estava sempre focando no acerto, e não no erro! Pode parecer uma reflexão simples, mas isso muda totalmente nosso paradigma diário: devemos buscar estar menos errados, não mais certos. É preciso aceitar viver sob a incerteza, reconhecendo o papel do erro. Altay Souza enfatiza esse conceito frequentemente em suas aulas de Estatística Aplicada à Psicobiologia, pela UNIFESP. Para entender mais esse entendimento, recomendo suas [oito primeiras aulas](https://youtube.com/playlist?list=PLZjaOxYREinvactJNtUHibf5GDW2JsPFL&si=pvKB7PXG1WP8o-tr) — serão úteis para a vida inteira, prometo.

### De volta aos Princípios

Andrey Kolmogorov, matemático nascido no século XX, foi crucial para o desenvolvimento da ciência moderna. Suas contribuições inestimáveis abrangem desde a biologia, topologia e geologia até a **teoria da probabilidade**. Ele revolucionou nossa compreensão científica de tal forma que, sem suas descobertas, este artigo possivelmente nem existiria. Kolmogorov estabeleceu não apenas a definição matemática da probabilidade por meio de seus axiomas, mas também descreveu o Teorema Central do Limite. Seus axiomas não são meras construções matemáticas — são padrões fundamentais observados na natureza, comparáveis às leis da física como a gravidade. Assim como podemos observar e comprovar a gravidade empiricamente, os axiomas probabilísticos se manifestam em fenômenos naturais, da genética à mecânica quântica, demonstrando sua validade universal.

A teoria da probabilidade de Kolmogorov marcou a matemática moderna ao estabelecer uma base axiomática rigorosa para seu estudo. Até seu trabalho em 1933, a teoria carecia de fundamento matemático formal. Com sua obra "Fundamentos da Teoria da Probabilidade", ele unificou diferentes interpretações da probabilidade em uma única estrutura matemática coerente.

Sua abordagem revolucionária combinou a teoria dos conjuntos com a teoria da medida para definir probabilidade de forma matematicamente precisa. Essa formalização estabeleceu a teoria da probabilidade como um campo independente da matemática, permitindo representar eventos probabilísticos através de funções.

Sua contribuição vai além da formalização matemática — oferece um framework que permite modelar fenômenos aleatórios em diversos campos científicos, da física quântica à biologia molecular, economia e ciência da computação.

Para fundamentar isso, ele estabeleceu três axiomas da teoria da probabilidade:

1. **Não-negatividade:** A probabilidade de qualquer evento deve ser maior ou igual a zero.
$$
P(A) ∈ ℝ+
$$
2. **Normalização:** A probabilidade do espaço amostral total (Ω) é igual a 1.
$$
P(Ω) = 1
$$
3. **Aditividade:** Para eventos mutuamente exclusivos, a probabilidade da união é igual à soma das probabilidades individuais.
$$
P(A ∪ B) = P(A) + P(B)
$$

> [!note] 
> 
> Estes axiomas são importantes porque:
> 
> - Fornecem uma base matemática rigorosa para o cálculo de probabilidades
> - Permitem derivar todas as outras regras e teoremas de probabilidade
> - São fundamentais para entender o Teorema Central do Limite

Com base nesses axiomas, ele enunciou o Teorema do Limite Central, que demonstra:

4. Ao coletar múltiplas amostras de uma população e calcular suas médias, a distribuição dessas médias amostrais tende a uma distribuição normal, independentemente da distribuição original dos dados (sendo necessárias no mínimo 30 amostras para esta convergência, conforme seu experimento).
5. A média dessas médias amostrais converge consistentemente para a verdadeira média populacional.

Isso nos permite utilizar **amostras** para estimar parâmetros populacionais, eliminando a necessidade de dados censitários.

Para ver a prova visual do TLC, basta clicar no link abaixo. Você perceberá que quanto mais amostras forem coletadas, mais a distribuição da amostra tenderá a uma normal, com sua média convergindo para a média da população.

[Probability Distributions](https://seeing-theory.brown.edu/probability-distributions/index.html#section3)

Este conceito é um dos pilares para a inferências sobre populações a partir de amostras. Com isso, conseguimos criar **intervalos de confiança.**

Caso queira saber mais sobre Kolmogorov, sugiro [esse link.](https://medium.com/@valeman/andrey-kolmogorov-one-of-the-greatest-mathematicians-of-the-xxst-century-4167ad02d10)

## Intervalo de Confiança

Desenvolvido por Jerzy Neyman em 1937, como parte de sua teoria de estimação por intervalos. Esta contribuição ofereceu uma alternativa mais robusta às estimativas pontuais.

Neyman propôs que, ao invés de tentar adivinhar o valor exato de um parâmetro populacional, seria mais útil estabelecer um intervalo de valores prováveis, junto com um nível de confiança associado. Esta abordagem reconhece explicitamente a incerteza inerente à inferência estatística.

> [!tip] 
> A interpretação correta de um intervalo de confiança de 95% é:
> Se repetíssemos o processo de amostragem muitas vezes e calculássemos o intervalo de confiança para cada amostra, aproximadamente 95% desses intervalos conteriam o verdadeiro parâmetro populacional.

Esta interpretação frequentista é crucial para entender que o intervalo de confiança não nos diz a probabilidade de que o parâmetro populacional esteja dentro do intervalo calculado, mas sim a confiabilidade do método de construção do intervalo ao longo de múltiplas amostras. Uma boa representação visual do intervalo de confiança pode ser vista por [aqui](https://rpsychologist.com/d3/ci/).

![1000000033.png|Intervalo de Confiança da Média de Idade de Pacientes com Câncer Cervical](/img/user/digital-garden/meu-modelo-conforme/assets/1000000033.png)
[Intervalo de Confiança da Média de Idade de Pacientes com Câncer Cervical](https://github.com/HeyLucasLeao/bootstrapping-intervals)

É importante termos uma noção sobre os temas demonstrados pois são cruciais para a entendermos a Previsão Conforme. Nele, iremos quantificar a incerteza, melhorarmos nossa confiabilidade e interpretabilidade do modelo.
