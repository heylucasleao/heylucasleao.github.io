---
{"dg-publish":true,"permalink":"/digital-garden/path-for-the-true-and-brave/text/13-gen-ai/"}
---

# GenAI

É importante salientar alguns pontos. Modelos de Large Language Models (LLMs) não capturam, por si só, relações de causalidade. Há desafios conhecidos de reasoning em modelos **não** determinísticos e, para inferência causal, esses modelos não substituem os conceitos e frameworks consolidados da econometria.

Ainda assim, LLMs podem ser usados como ferramenta de suporte, como por exemplo, para gerar hipóteses, explorar possíveis variáveis instrumentais ou identificar potenciais confundidores — porém sempre com muita cautela. O artigo [Mining Causality: AI-Assisted Search for Instrumental Variables](https://arxiv.org/abs/2409.14202) propõe um agente que auxilia na busca por variáveis instrumentais por meio de etapas de prompt e validações. Outra alternativa que complementa essa abordagem é a biblioteca [PyWhyLLM](https://github.com/py-why/pywhyllm), que ajuda a encontrar relações (IVs, confundidores) que conectam tratamento ao desfecho.

Essas ferramentas não devem ser usadas para terceirizar decisões nem para substituir conhecimento de domínio ou regras de negócio. Seu uso exige criticidade, documentação cuidadosa e submissão à revisão por pares humanos. A interpretação dos resultados e a atribuição de efeitos causais devem ser feitas por pesquisadores qualificados. Lembre-se interpretações equivocadas são responsabilidade dos autores — como comentado por Fisher. Quanto maior for o impacto ou a criticidade do trabalho, mais rigorosas devem ser as análises.