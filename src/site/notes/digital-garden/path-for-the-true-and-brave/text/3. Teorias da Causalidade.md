---
{"dg-publish":true,"permalink":"/digital-garden/path-for-the-true-and-brave/text/3-teorias-da-causalidade/"}
---

# Teorias da Causalidade

A causalidade é um conceito complexo, abordado por pensadores como Aristóteles, David Hume, e Kant, com contribuições mais recentes de economistas como Angus Deaton e estatísticos. Em diversas áreas, há uma variabilidade de definições dela.

Para o contexto da estatística e da modelagem de dados, a abordagem mais relevante é a Causalidade Regular (diferente da Causalidade Estrita de Descartes, que se baseia em leis naturais). A Causalidade Regular foca em eventos probabilísticos em vez de determinísticos, dando um foco grande em probabilidade condicional. Essa linha de pensamento foi inicialmente influenciada por ideias de Hans Reichenbach e John Stuart Mill, evoluindo para o que é hoje reconhecido como a moderna teoria da inferência causal, impulsionada por Judea Pearl e seu trabalho com Modelos Gráficos Acíclicos Direcionados (DAGs). Outros nomes, como Susan Haack e Deborah Mayo, também trouxeram contribuições importantes para a filosofia da causalidade e da estatística.

Neste modelo, a causalidade é definida por três aspectos principais:

- **Direcionalidade:** A relação de causa e efeito é estruturada graficamente, indicando que o evento **A** causa o evento **B** ($A \rightarrow B$).
- **Temporalidade:** A causalidade é expressa em termos de **probabilidades condicionais** – a probabilidade de um evento, dado que o outro já ocorreu. No entanto, o conceito estatístico fundamental aqui é a probabilidade de a causa **A** ocorrer, dado o efeito **B**, **se e somente se A for a causa**. Em termos de probabilidades condicionais, o que é crucial é a **comparação** entre $P(B | A)$ e $P(B | \neg A)$ (a probabilidade do efeito B ocorrer na presença da causa A versus na sua ausência).
- **Reprodutibilidade (ou Invariância):** Para ser considerada causal, a relação observada entre os eventos deve ser **invariante**, ou seja, consistentemente reproduzida sob as mesmas condições e em diferentes contextos relevantes.

> [!tip] 
> A Independência Condicional é a chave da inferência causal. Ela permite distinguir relações causais genuínas de simples associações estatísticas, identificando se a relação entre dois eventos desaparece ao condicionar uma terceira variável (a variável de confusão).

> [!tip]
> As variáveis de confusão (ou variáveis confundidoras, ou confounders) são variáveis que exercem influência tanto na causa quanto no efeito em estudo.
> É crucial identificar e controlar essas variáveis, pois a sua presença afeta diretamente a validade da inferência causal, levando a estimativas enviesadas do verdadeiro efeito, causando o que chamamos de associação espúria.

# Definição de Causalidade, Causação e Associação

Como falei, existe uma definição ampla sobre causalidade, a qual varia conforme a área de atuação. Essa pluralidade de conceitos é bem representada no artigo [The Representation of Causality and Causation with Ontologies: A Systematic Literature Review](https://www.researchgate.net/publication/363691336_The_Representation_of_Causality_and_Causation_with_Ontologies_A_Systematic_Literature_Review), que demonstra como as definições mudam ao longo da literatura. Para o escopo probabilístico em que atuaremos, adotaremos uma perspectiva mais próxima à de Judea Pearl.

Causalidade é a relação direcional de causa e efeito entre entidades, variáveis ou eventos. Já a causação refere-se ao mecanismo ou ação pela qual a causa produz o efeito. Ambos os conceitos envolvem direcionalidade, temporalidade e influência — a ideia de que um elemento efetivamente gera uma alteração no outro.

Em contraste, a associação é a mera relação estatística entre duas variáveis. É fundamental não confundirmos com causalidade. Por definição, a associação **pode** incluir vieses, enquanto a causação busca **isolar** relações diretas. Assim, duas variáveis podem não ter influência direta entre si, mas parecerem relacionadas por serem influenciadas por uma variável externa não mapeada (lembremos da **relação espúria**). Nesses casos, há associação, mas não há nexo causal direto.

> [!tip]
> *Causal inference is the science of inferring causation from association and understanding when and why they differ. - Matheus Facure*

# Terminologia Comum

Para facilitar entendimento, deixarei algumas notações e os termos usados ao longo dos textos para evitar ambiguidade.

- Unidade
    - $i$: unidade de análise (indivíduo, evento, parcela, etc.). Notação alternativa: $U_i$.
    
- Variável de tratamento
    - $D_i \in {0,1}$: indicador binário de tratamento para a unidade $i$ (1 = tratada, 0 = controle).
    - Para tratamentos contínuos ou multivalorados use $T_i$ ou $D_i \in \mathbb{R}$ / ${0,1,2,\dots}$ e declare explicitamente.
    
- Covariáveis
    - $X_i$: vetor de covariáveis pré‑tratamento (potenciais confundidores, moderadores). Veja [[digital-garden/path-for-the-true-and-brave/text/6. DAG\|6. DAG]] para identificar quais $X$ devem ser condicionadas.

- Outcomes e potenciais outcomes
    - $Y_i(1),; Y_i(0)$: potenciais outcomes de $i$ sob tratamento e controle, respectivamente.
    - Outcome observado: 
    $$Y_i = Y_i(1) \cdot D_i + Y_i(0) \cdot(1 - D_i)$$

- Estimandos Comuns
    - Efeito Médio de Tratamento (ATE): 
    $$\text{ATE} = \mathbb{E}[Y_i(1) - Y_i(0)].$$
    
    - Efeito Médio no Tratado (ATT / ATET): 
    $$\text{ATT} = \mathbb{E}[Y_i(1) - Y_i(0) \mid D_i = 1].$$

# Problema Fundamental da Inferência Causal

O Problema Fundamental da Inferência Causal reside na impossibilidade de observar simultaneamente, na mesma unidade, o resultado factual e o resultado contrafactual .

Para quantificar o efeito causal de um tratamento, seria necessário calcular a diferença entre esses dois resultados. No entanto, uma única unidade (seja um indivíduo, evento ou variável) só pode existir em um único estado (tratado ou não tratado) em um dado momento.

Em essência, a quantificação exata exigiria um universo paralelo onde a unidade pudesse ser observada em condições idênticas, mas sob estados de tratamento opostos. Dado que isso é logisticamente impossível, o problema é considerado o obstáculo central da inferência causal.

# Definição Formal

$$
E[Y|T=1] - E[Y|T=0] = \underbrace{E[Y_1 - Y_0|T=1]}_{ATT} + \underbrace{\{ E[Y_0|T=1] - E[Y_0|T=0] \}}_{BIAS}
$$

Associação é igual ao efeito de tratamentos no grupo tratado mais o viés, que por sua vez é dado por como o grupo tratado e controlado diferem antes do tratamento, no caso de ambos de nenhum deles receberem o tratamento. Nela haverá causalidade se não houver viés, isto é, que em outras palavras, ocorrerá causação somente se o grupo tratado e o controlado são iguais ou comparáveis, exceto pelo seu tratamento quando o resultado do não tratado é igual ao contrafactual do tratado.

$$
E[Y_0|T=0]=E[Y_0|T=1]
$$
