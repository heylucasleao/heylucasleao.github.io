---
{"dg-publish":true,"permalink":"/digital-garden/path-for-the-true-and-brave/text/12-double-machine-learning/"}
---

# Double Machine Learning

![dml_1.png](/img/user/digital-garden/path-for-the-true-and-brave/assets/dml_1.png)
[Double ML: Causal Inference based on ML](https://docs.doubleml.org/tutorial/stable/slides/part1/Lect1_uai_Introduction_to_DML.html#14)

Agora, iremos adentrar um pouco na inferência causal moderna. Relembramos o uso do Teorema FWL para "desviesamento". Ele demonstra que, em uma regressão linear, podemos "remover" o efeito das covariáveis $X$ através de resíduos e então estimar o efeito de $D$ (tratamento) sobre $Y$.

O Double Machine Learning (DML) generaliza essa ideia usando Machine Learning para estimar os componentes que dependem de $X$ e, em seguida, "partializa" (remove a influência de) $X$ em $Y$ e $D$.

O método se destaca por quatro pilares fundamentais:

1. Framework não paramétrico
     Permite usar quaisquer modelo, como Random Forests e Gradient Boosting para modelar as variáveis de confusão ($X$). Isso captura relações complexas e não-lineares automaticamente.
        
2. Redução de viés
    Modelos de Machine Learning usam regularização (ex.: Lasso ou profundidade de árvores) para evitar overfitting, o que "encolhe" as previsões, distorcendo as estimativas de efeito causal. O DML resolve isso separando a estimação do ruído da estimação do efeito.
        
3. Intervalos de confiança válidos
    É matematicamente inviável calcular p-valores precisos diretamente de uma "caixa preta" como uma Rede Neural. O DML transforma o problema final numa regressão linear simples sobre resíduos, permitindo recuperar a teoria estatística clássica para calcular significância estatística.
        
4. Eficiência
    Significa que o erro da estimativa diminui rapidamente à medida que a amostra ($n$) cresce, comportando-se tão bem quanto uma regressão linear simples, mesmo utilizando modelos de ML complexos (que normalmente convergem mais devagar) para limpar os dados.


Sua ideia é utilizar dois modelos preditivos separados: um para o potencial outcome e outro para o tratamento. O processo ocorre nos seguintes passos:

1. **Estimar o outcome $Y$:** Usamos um modelo de ML flexível ($q(X)$) para prever $Y$ com base nas características $X$.
    
2. **Estimar o tratamento $D$:** Usamos outro modelo de ML flexível ($g(X)$) para prever o tratamento $D$ com base nas características $X$ (similar a um Propensity Score).

3. **Obtemos os resíduos:**
    
    - Resíduo do outcome: $\tilde{Y} = Y - \hat{q}(X)$
        
    - Resíduo do tratamento: $\tilde{D} = D - \hat{g}(X)$

> [!tip] Lembrete
	>Utilizamos o resíduo justamente para isolarmos os efeitos exógenos! Queremos apenas saber o Impacto do outcome sob os tratamentos, eliminando as variáveis de confusão.

4. Fazemos a regressão dos resíduos:
    
    $$\tilde{Y} = \tau \tilde{D} + \epsilon$$
    
    Onde $\tau$ é o parâmetro causal (ATE). Esse processo é feito dinamicamente utilizando [Cross-Fitting](https://www.youtube.com/watch?v=BMAr27rp4uA), que comentarei posteriormente.

# Regressão Parcialmente Linear e Ortogonalização

Vamos olhar para a **Regressão Parcialmente Linear (PLR)**.

Assumimos que o mundo gerador dos dados segue:

$$Y = D\theta + g(X) + U$$

$$D = m(X) + V$$

Onde $\theta$ é o nosso alvo (efeito causal) e $g(X)$ é uma função complexa e desconhecida dos confoundings.

Se tentarmos estimar $\theta$ diretamente com ML, o erro na estimativa de $g(X)$ contamina $\theta$. A solução é a **Ortogonalização**:

1. Calculamos a esperança condicional de $Y$ dado $X$:
    
    $$E[Y|X] = E[D|X]\theta + g(X)$$
    
    Chamamos $E[Y|X]$ de $\hat{Y}$ e $E[D|X]$ de $\hat{D}$.
    
2. Subtraímos essa esperança da equação original:
    
    $$Y - E[Y|X] = (D - E[D|X])\theta + (g(X) - g(X)) + U$$
    
3. Note a mágica: o termo complexo $g(X)$ se cancela! Ficamos apenas com os resíduos:
    
    $$(Y - \hat{Y}) = (D - \hat{D})\theta + U$$
    
    Ou seja:
    
    $$\tilde{Y} = \theta \tilde{D} + U$$
    

Agora, o erro na estimativa de $g(X)$ é **ortogonal** (não correlacionado) ao tratamento residual, permitindo que o OLS isole o $\theta$ "limpo".


> [!tip] Premissas Importantes
> 
> É fundamental refrisar que esse método não é  "bala de prata". A validade causal ainda depende das premissas anteriores:
> 
> - **Ignorabilidade:** $Y(d) \perp D | X$. Ou seja, todas as variáveis de confusão relevantes foram incluídas em $X$. É importante refrisarmos isso que é assumido que foi capturando todos os confounders relevantes. Na prática, não temos como saber por exato, mas uma boa construção é importante.
> - **Domínio sob regra de negócio**: Para toda a inferência causal, aqui não muda. Por mais complexo que nosso modelo possa ser, ele sempre será limitado relativo a tomada de decisão às escolhas de variáveis. Um bom DAG construído ainda é necessário, para evitar qualquer viés sob o resultado.
> - **Qualidade de dados**: por mais que o DoubleML é focado para estudos observacionais, aonde não controlamos variáveis de confusão e não temos uma randomização controlada, ele ainda pode sofrer com dados ruins. Se a extração tiver algum viés forte, problemas com campos, o resultado dele vai ser ineficiente para estimar causalidade.
> - **Positividade:** Para valores de $X$ relevantes, deve haver variação no tratamento (a probabilidade de tratamento $P(D|X)$ não deve ser nem 0 nem 1 estritos, como também valores extremos).
> - **Regularidade:** Os estimadores de ML devem convergir suficientemente rápido. O uso de **Cross-Fitting** é crucial para evitar viés de overfitting e garantir a validade assintótica.
>

# O Perigo no Overfitting

Vale ressaltar que a flexibilidade dos modelos de Machine Learning traz o risco de overfitting. Se o modelo entende demais os dados de treino, ele absorve ruídos como se fossem padrões reais, tornando os resíduos enviesados em direção a zero, eliminando a variação necessária para encontrarmos o efeito causal.

Por conta disso, a prática padrão é utilizar o [Cross-Fitting](https://www.youtube.com/watch?v=BMAr27rp4uA):
1. Selecionamos $K$ possíveis folds.
2. No $K1$, separamos os dados por exemplo em "Treino" e "Hold-out".
3. O modelo é treinado apenas na base de **Treino**, e utilizamos os dados para calcular o resíduo do **Hold-Out**.
4. Agora, retreinamos o modelo com outro $K$ fold, até que todos os dados tenham seus resíduos calculados.
    
Assim, mesmo que o modelo aprenda nos dados de treino, ele não terá "visto" os dados de hold-out. Isso garante que os resíduos mantenham um ruído real e a variabilidade honesta necessária.

![cross_fitting.png](/img/user/digital-garden/path-for-the-true-and-brave/assets/cross_fitting.png)
[Double Machine Learning for Causal Inference: A Practical Guide | by Mohamed Hmamouch | Medium](https://medium.com/@med.hmamouch99/double-machine-learning-for-causal-inference-a-practical-guide-5d85b77aa586)

### Implementação Prática: Calculando ATE e CATE com Python

Vamos utilizar a biblioteca `DoubleML` para aplicar os conceitos acima.
#### 1. Calculando o ATE

Para o ATE, assumimos um efeito constante e usamos o modelo **Partial Linear Regression (PLR)**.


```python
import numpy as np
import pandas as pd
from doubleml import DoubleMLData, DoubleMLPLR
from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier

# --- Configuração dos Dados ---
# Suponha que temos um DataFrame 'df' com:
# 'y': Outcome, 'd': Tratamento binário, 'X1'...'X5': Covariáveis
data_dml = DoubleMLData(df,
                        y_col='y',
                        d_cols='d',
                        x_cols=[f'X{i}' for i in range(5)])

# --- Definindo os Modelos (Learners) ---
# Modelo para prever Y (Outcome)
ml_l = RandomForestRegressor(n_estimators=100, max_depth=5)
# Modelo para prever D (Propensity Score)
ml_m = RandomForestClassifier(n_estimators=100, max_depth=5)

# --- Estimando ATE com Cross-Fitting ---
dml_plr = DoubleMLPLR(data_dml,
                      ml_l=ml_l,
                      ml_m=ml_m,
                      n_folds=3) # 3-fold Cross-Fitting

dml_plr.fit()
print(dml_plr.summary)
```

_O resultado `coef` no sumário será o nosso $\tau$ (ATE), livre do viés das covariáveis._

#### 2. Calculando o CATE 

Se quisermos saber como o efeito varia de acordo com as características da pessoa ($X$), usamos o **Interactive Regression Model (IRM)**. Em vez de calcular um número único, projetamos o efeito causal nas covariáveis usando um Preditor Linear (BLP).

```python
from doubleml import DoubleMLIRM

# --- Usando IRM para permitir interações ---
# ml_g prevê E[Y|X, D] e ml_m prevê E[D|X]
ml_g = RandomForestRegressor(n_estimators=100, max_depth=5)
ml_m = RandomForestClassifier(n_estimators=100, max_depth=5)

dml_irm = DoubleMLIRM(data_dml,
                      ml_g=ml_g,
                      ml_m=ml_m,
                      n_folds=3)

dml_irm.fit()

# --- Projetando a Heterogeneidade (CATE) ---
# "Como o efeito causal varia linearmente com as features X?"
cate_res = dml_irm.cate(basis=df[[f'X{i}' for i in range(5)]])

print(cate_res)
```

**Interpretando o CATE:** Se no resultado do `cate_res` o coeficiente de uma variável (ex: `X1: Idade`) for positivo e significante, indica que o tratamento é mais eficaz quanto maior for a idade do indivíduo.

>[!tip]
>PLR: Assume que o efeito do tratamento ($\theta$) entra de forma aditiva e linear (não interage complexamente com $X$ na equação estrutural). É ideal para **tratamentos contínuos** (ex: preço, dosagem).
>
>IRM: É desenhado especificamente para tratamentos binários. Ele permite interações completas entre o tratamento e as covariáveis, sendo mais robusto para heterogeneidade. Ele utiliza o estimador _AIPW (Augmented Inverse Probability Weighting)_ por trás dos panos, que possui a propriedade de **Dupla Robustez** (Doubly Robust).

![dml_2.png](/img/user/digital-garden/path-for-the-true-and-brave/assets/dml_2.png)
[Introduction to Causal Machine Learning with DoubleML for Python](https://docs.doubleml.org/tutorial/stable/lectures/L1/introduction_part2_models_package.html#/introduction-to-double-machine-learning-1)
#### 3. Calculando o GATE (Group Average Treatment Effect)

Enquanto o CATE busca o efeito individual (que pode possuir alto ruído estatístico), o **GATE** busca o efeito médio em um **subgrupo** específico.

A biblioteca `DoubleML` oferece um método dedicado `.gate()` para cada grupo. Para utilizá-lo, precisamos passar um DataFrame onde as colunas representam os grupos (indicadores binários/dummies).


>[!tip]
>Podemos calcular o GATE agregando as estimativas do CATE. Filtramos as unidades que pertencem ao grupo de interesse e tiramos a média dos seus efeitos causais estimados ($\hat{\tau}(x)$).

Matematicamente:

$$\tau_{GATE} = E[\hat{\tau}(x) \mid x \in \text{Grupo}]$$

```python
# --- Passo 1: Definir os Grupos de Interesse ---
# Vamos criar, por exemplo, dois grupos baseados na variável X1 (ex: Idade normalizada)
# Grupo 0: X1 <= 0.5
# Grupo 1: X1 > 0.5
groups = pd.DataFrame({
    'Grupo_Baixo_X1': df['X1'] <= 0.5,
    'Grupo_Alto_X1':  df['X1'] > 0.5
})

# --- Passo 2: Calcular o GATE via DoubleML ---
# O método gate() ajusta uma regressão linear dos resíduos contra essas variáveis de grupo
gate_res = dml_irm.gate(groups=groups)

print(gate_res)

# --- Passo 3: Analisar os Intervalos de Confiança ---
# Verificamos se o intervalo de 95% cruza o zero ou se os grupos se sobrepõem
print(gate_res.confint())
```

Essa abordagem é poderosa para decisões de negócio estratégicas, onde não podemos personalizar para cada indivíduo, mas podemos criar políticas para segmentos (ex: Região Norte vs. Sul).

| **Característica**           | **CATE (Conditional Average Treatment Effect)**                                             | **GATE (Group Average Treatment Effect)**                                                              |
| ---------------------------- | ------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------ |
| **Definição**                | Efeito do tratamento para um indivíduo (ou unidade) com características exatas $X$.         | Média dos efeitos de tratamento para um **subgrupo** específico da população.                          |
| **Nível de Granularidade**   | **Micro** (Individual / Personalizado).                                                     | **Macro** (Segmento / Cluster).                                                                        |
| **Notação Matemática**       | $\tau(x) = E[Y(1) - Y(0) \mid X=x]$                                                         | $\tau_{GATE} = E[\tau(x) \mid x \in \text{Grupo}]$                                                     |
| **Pergunta de Negócio**      | "Qual desconto devo dar para **este cliente específico** agora?"                            | "A campanha funciona melhor na **Região Sul** ou na **Região Norte**?"                                 |
| **Estabilidade Estatística** | **Baixa**. Sofre com alta variância e ruído, pois $n=1$ (ou muito pequeno) para aquele $X$. | **Alta**. O ruído individual tende a se cancelar na média do grupo, gerando estimativas mais robustas. |
| **No DoubleML**              | Resultado da projeção do efeito nas features (via `dml_irm.cate()` ou BLP).                 | Calculado tirando a média das predições do CATE filtradas por um subconjunto do DataFrame.             |
| **Aplicação Principal**      | Personalização de produto, Medicina de precisão, Recomendação dinâmica.                     | Definição de estratégia, Política pública, Decisão de portfólio.                                       |

# DoubleML com Variáveis Instrumentais (IV)

Diferente do DoubleML padrão (que limpa $X$ apenas de $Y$ e $D$), no cenário com Variável Instrumental nós precisamos limpar a influência das covariáveis ($X$) de **três** lugares: do Resultado ($Y$), do Tratamento ($D$) e do Instrumento ($Z$).

Simulando o `DoubleMLPIV` para ter uma ideia, o processo envolve 3 modelos de Machine Learning  e uma regressão IV 2SLS final.

## Premissas

1. **$Y$** depende de $X, D, U$.
2. **$D$** depende de $X, Z, U$.
3. **$Z$** depende de $X$
    
#### 1. Previsão

Primeiro, usamos ML para prever $Y$, $D$ e $Z$ usando apenas as covariáveis $X$. O objetivo é capturar toda a variação explicada por variáveis de confusão.

- Modelo 1 ($q(X)$): Prever $Y$ usando $X$.
- Modelo 2 ($m(X)$): Prever $D$ usando $X$.
- Modelo 3 ($r(X)$): Prever $Z$ usando $X$.
    
#### 2.  Ortogonalização Tripla

Subtraímos as previsões dos valores reais.

- $\tilde{Y} = Y - \hat{Y}_{ML}$ (Variação no outcome não explicada por $X$)
- $\tilde{D} = D - \hat{D}_{ML}$ (Variação no tratamento não explicada por $X$)
- $\tilde{Z} = Z - \hat{Z}_{ML}$ (Variação no instrumento não explicada por $X$)
    

#### 3. Estágio Final (2SLS nos Resíduos)

 Usamos os **resíduos do instrumento** ($\tilde{Z}$) para instrumentar os **resíduos do tratamento** ($\tilde{D}$) e explicar os **resíduos do resultado** ($\tilde{Y}$).


```python
import numpy as np
import pandas as pd
import statsmodels.api as sm
from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier

# --- 1. Gerando Dados Fictícios (Endógenos) ---
np.random.seed(42)
n = 1000
# X afeta tudo (confusão)
X = np.random.normal(0, 1, (n, 3)) 
# Z (instrumento) afeta D, mas também depende de X
Z = 0.5*X[:,0] + np.random.normal(0, 1, n) 
# U (não observado) afeta D e Y
U = np.random.normal(0, 1, n) 
# D (tratamento) depende de X, Z e U (viés)
D = 0.5*Z + 0.5*X[:,0] + U + np.random.normal(0, 0.5, n)
# Y (outcome) depende de D, X e U. Efeito real de D é 2.0
Y = 2.0*D + X[:,0] + U + np.random.normal(0, 0.5, n) 

df = pd.DataFrame({'Y': Y, 'D': D, 'Z': Z})
X_cols = pd.DataFrame(X, columns=['X1', 'X2', 'X3'])

# --- 2. Fase de Machine Learning ---
# Treinamos modelos para capturar a influência de X em Y, D e Z

# a) Prever Y dado X
model_y = RandomForestRegressor(max_depth=5).fit(X_cols, df['Y'])
y_hat = model_y.predict(X_cols)
y_res = df['Y'] - y_hat  # Resíduo Y (Ortogonalizado)

# b) Prever D dado X
model_d = RandomForestRegressor(max_depth=5).fit(X_cols, df['D'])
d_hat = model_d.predict(X_cols)
d_res = df['D'] - d_hat  # Resíduo D (Ortogonalizado)

# c) Prever Z dado X (Essencial para DoubleMLPIV!)
model_z = RandomForestRegressor(max_depth=5).fit(X_cols, df['Z'])
z_hat = model_z.predict(X_cols)
z_res = df['Z'] - z_hat  # Resíduo Z (Ortogonalizado)

# --- 3. 2SLS clássico ---
# y_res ~ beta * d_res (instrumentado por z_res)

# 1º Estágio Manual: Regredir d_res contra z_res
stage1 = sm.OLS(d_res, sm.add_constant(z_res)).fit()
d_res_hat = stage1.predict() # Variação de D limpa de X e induzida por Z limpo

# 2º Estágio Manual: Regredir y_res contra o predito do 1º estágio
stage2 = sm.OLS(y_res, sm.add_constant(d_res_hat)).fit()
```



