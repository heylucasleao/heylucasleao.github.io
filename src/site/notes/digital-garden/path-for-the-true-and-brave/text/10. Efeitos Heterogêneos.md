---
{"dg-publish":true,"permalink":"/digital-garden/path-for-the-true-and-brave/text/10-efeitos-heterogeneos/"}
---

 # Efeitos Heterogêneos

Nas análises de inferência causal demonstradas anteriormente, exploramos o ATE sob uma perspectiva populacional. No entanto, em muitos cenários, o interesse reside em entender como diferentes subgrupos reagem ao tratamento, identificando quem apresenta impactos maiores ou menores. Para capturar essa variabilidade, utilizamos o Efeito Médio de Tratamento Condicional (CATE), que nos permite observar os chamados efeitos heterogêneos.

O objetivo do CATE é permitir que a tomada de decisão seja fundamentada nas características específicas ($X$) de cada unidade. Em vez de perguntar apenas se "o tratamento funciona", passamos a questionar: "para quem o tratamento funciona melhor?"**.

Matematicamente, definimos o CATE como:

$$\tau(x) = \mathbb{E}[Y_i(1) - Y_i(0) \mid X_i=x]$$

Onde buscamos a diferença esperada entre os outcomes potenciais ($Y_1$ e $Y_0$), condicionada a um conjunto de covariáveis $X$.
# Regressão Linear

Uma regressão linear simples estima apenas o coeficiente médio do tratamento. Para identificar efeitos heterogêneos, introduzimos **termos de interação** entre a variável de tratamento ($T$) e as características das unidades ($X$). Essa abordagem torna o modelo flexível, permitindo que a "inclinação" (o efeito do tratamento) varie conforme o perfil da unidade.


A equação assume a forma:

$$y_i = \beta_0 + \beta_1 D_i + \beta_2 X_i + \beta_3 (D_i \times X_i) + \epsilon_i.$$

### Derivação do Efeito

Para isolar o efeito do tratamento em um modelo com interações, utilizamos a derivada parcial da variável de resultado ($y$) em relação ao tratamento ($D$).

Considere o modelo:

$$y_i = \beta_0 + \beta_1 D_i + \beta_2 X_i + \beta_3 (D_i \times X_i) + \epsilon_i$$

A variação de $y$ para uma mudança infinitesimal em $t$ é dada por:

$$\frac{\partial y_i}{\partial D_i} = \beta_1 + \beta_3 X_i$$

Isso nos mostra que o efeito do tratamento não é constante: ele depende diretamente dos valores das covariáveis $X_i$ de cada indivíduo.
### Aproximação por Diferença Finitas

Na prática, como o modelo é linear, essa derivada pode ser calculada exatamente através da diferença entre duas predições. Usamos a definição de derivada onde o incremento ($\epsilon$) é igual a 1 unidade:

$$\frac{\delta y}{\delta D} \approx \hat{y}(D + 1) - \hat{y}(t)$$

Onde:

- $\hat{y}(D + 1)$ é a predição do modelo incrementando o tratamento original em uma unidade.
- $\hat{y}(D)$ é a predição do modelo com os dados originais.

### Exemplo ([Causal Inference in Python: Applying Causal Inference in the Tech Industry](https://github.com/matheusfacure/causal-inference-in-python-code/blob/main/causal-inference-in-python/06-Effect-Heterogeneity.ipynb)

```python

import statsmodels.formula.api as smf

# 1. Definição das covariáveis (características que podem causar heterogeneidade)
X = ["C(month)", "C(weekday)", "is_holiday", "competitors_price"]

# 2. Especificação do modelo com Interação # A sintaxe 'discounts * (X)'
# Isso permite que o efeito do desconto mude conforme o mês, feriado ou preço do concorrente.
regr_cate = smf.ols(f"sales ~ discounts*({'+'.join(X)})",
                    data=data).fit()

# 3. Estimativa do CATE (Efeito Médio de Tratamento Condicional) 
# Calculamos a diferença entre duas realidades hipotéticas para cada unidade: 
# Realidade A: O desconto atual + 1 unidade 
# Realidade B: O desconto atual 
# A diferença entre as predições isola o efeito marginal do desconto naquele contexto específico.
ols_cate_pred = (
    regr_cate.predict(data.assign(discounts=data["discounts"]+1)) 
    -regr_cate.predict(data)
)
```


# Avaliação

A ideia central de criar modelos CATE surge da necessidade de ordenar as unidades das mais sensíveis às menos sensíveis ao tratamento, visando a personalização. Como não podemos observar o efeito individual real para validar essa ordenação, avaliamos grupos definidos pela predição do modelo. Diferentemente de um modelo tradicional de machine learning, focamos em verificar o quão bem o modelo está em relação a essa segmentação para efeito causal médio condicional. Não irei abordar a fundo, novamente aconselho a ler o [livro do Matheus Facure](https://www.amazon.com.br/Causal-Inference-Python-Applying-Industry/dp/1098140257) pois há uma explicação muito boa sobre. Pontuarei apenas as três formar em que ele comenta como métodos.

Outro ponto a ressaltar, é que se encontra exemplos bons da aplicação aberta via o jupyter notebook exemplar do livro. [Causal Inference in Python: Applying Causal Inference in the Tech Industry](https://github.com/matheusfacure/causal-inference-in-python-code/blob/main/causal-inference-in-python/06-Effect-Heterogeneity.ipynb).

## Efeito por Quantil

A abordagem consiste em segmentar os dados em quantis baseados na predição do modelo e estimar o efeito dentro de cada partição. Se o efeito estimado em cada quantil estiver ordenado (por exemplo, do maior para o menor), isso indica que o modelo é eficaz em ordenar o CATE verdadeiro. [Visualmente](https://github.com/matheusfacure/causal-inference-in-python-code/blob/main/causal-inference-in-python/06-Effect-Heterogeneity.ipynb), quanto maior for o efeito "escada" no gráfico de efeito por quantil, melhor o modelo distingue os efeitos altos dos baixos.

## Curva de Efeito Cumulativo

Seguindo a lógica anterior, a Curva de Efeito Cumulativo não estima o efeito por grupos isolados, mas sim acumulando um grupo sobre o outro. O processo envolve ordenar os dados pelo score do modelo (predição CATE) e estimar o efeito ordenado de um valor N, depois do valor N + 1, e assim sucessivamente.

Embora essa curva permita resumir a qualidade do modelo calculando a área entre a curva e o ATE, ela apresenta uma desvantagem: o início da curva possui uma amostra pequeno, o que nos trás maior incerteza devido ao tamanho reduzido da amostra acumulada naquele ponto.

## Curva de Ganho Cumulativo (Cumulative Gain)

Para corrigir a questão da variância no início da curva de efeito cumulativo, utiliza-se a Curva de Ganho Cumulativo. A lógica é a mesma, porém multiplicamos cada ponto da curva de efeito pela proporção da amostra acumulada ($N_{cum}/N$).

O modelo que apresentar a maior área entre a curva e a linha tracejada (representando o ATE) — ou a maior soma dos valores da curva normalizada — é considerado o melhor em termos de ordenação do CATE. Por conta disso, podemos tirar o AUC e utilizarmos para avaliar o modelo desse resultado.
