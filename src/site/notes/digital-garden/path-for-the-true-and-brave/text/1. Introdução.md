---
{"dg-publish":true,"permalink":"/digital-garden/path-for-the-true-and-brave/text/1-introducao/"}
---

# Introdução

E cá estamos Dezembro de 2025, semana de natal. Faz um tempo que não escrevo nada publicamente — na verdade até estava, concentrado em refinar o [Tinyshift](https://github.com/heylucasleao/tinyshift). O projeto cresceu bastante e estou bem feliz com o rumo que tomou, embora sei que ainda há muito o que fazer nele.

Neste meio caminho, em epifanias, percebi algo. Quanto mais tempo trabalho em ciência de dados, mais certeza só tenho de uma coisa: eu sei absolutamente **nada.** Depois de tanto tempo estudando sob diversos temas, novamente senti que estava batendo em outro teto. 

Em diversas pesquisas, para justificarmos uma tomada de ação, acabávamos nos defendendo utilizando apenas dados observacionais. Seja uma ação de marketing, uma recomendação de produto, ou investimento em nova tecnologia. Mas e se os dados estiverem errados? E se não se concretizar o ROI mapeado pelo meu time, utilizando dados históricos meus ou dos concorrentes? Ou pior, e se der o efeito rebote e na verdade acabarmos perdendo dinheiro com isso? Fiquei me questionando se a forma como eu modelava, para esses contextos, fazia sentido. Perguntas de negócio, de impacto causa e efeito — isto é, se a ação $X$ causaria $Y$ — ainda faria sentido serem respondidas da forma como eu fazia.

Neste contexto, se você veio como eu de um universo de modelagem preditiva, ficamos habituados a um escopo: associação. Baseado nos dados que tenho, há um padrão, linear ou não, da variável $X$ com $Y$. Em geral, isso é suficiente. Entretanto, isso pode resultar em dois problemas:

O primeiro é que estamos sempre falando de padrões. Comportamentos de fraude, spam, itens comprados juntos. Isso é natural: nosso cérebro é feito para reconhecer padrões, desde a Era da Pedra. Para nossa sobrevivência, sempre ficamos habituados a isso. Mas padrões não são causa e efeito. Em alguns cenários, isto já é suficiente, como fraude e spam. Em outros, isso pode ser nocivo.

Imagine o cenário (alunos do Altay de Souza vão reconhecer essa analogia): você trabalha para uma prefeitura e quer entender um aumento de ataques de tubarão e como preveni-los. Uma das variáveis que você observou é a quantidade de vendas de sorvete. Ao observar a relação entre as duas, você fica surpreso, pois há **associações** fortes entre uma e outra. Seria sensato proibir o consumo de sorvetes ao redor das praias? Seus dados dizem que sim, seu raciocínio como ser humano, não. Relutante, você conversa com um colega que leu sobre inferência causal, e ele alerta que isso pode ser uma correlação espúria — ambas as variáveis podem ser influenciadas por um terceiro fator, uma causa comum: temperatura. Olhando mais a fundo, você vê que isto faz sentido. No verão, as pessoas vão mais à praia e compram mais sorvete — assim como há mais chance de ataques. Por mais que você diga "mas isto é óbvio!", em diversos outros cenários, não são. Na realidade, podem ser até contraintuitivos. Por isso, é importante seguirmos premissas, frameworks e sermos céticos, pois o mantra vale: associação não implica causalidade.

A segunda questão é prática: um modelo de Machine Learning tradicional frequentemente entrega apenas uma probabilidade. Nós, humanos, tomamos decisões com base nesse número. Mas se nosso objetivo é orientar ações — por exemplo, reduzir churn —, não basta saber quem tem maior probabilidade de churn; precisamos saber qual é o impacto de uma ação (uma promoção, atendimento diferenciado, cross-sell) sobre o churn. Quais ações causam mais impacto para diferentes perfis de cliente? ([Facure fala exatamente disso no podcast do Aleksander Molak](https://youtu.be/y59_XLOnmgI?si=jbp2Cy8AX_iuzrEB)). Em vez de modelar apenas a probabilidade, quero saber qual intervenção impacta mais e por quanto — ou seja, modelar as regras de negócio, não só fazer previsão.

Modelos preditivos podem induzir a decisões equivocadas quando o objetivo é neste escopo. O propósito final de um modelo de ML é resolver um problema de negócio. Por isso, comecei a estudar formas de modelagem que foquem tomada de decisão: entender relações de causa e efeito para orientar intervenções eficazes. 

Estas anotações são o registro da minha jornada nessa selva que conheço tão pouco. Elas não são e nunca vão ser um guia prático, mas achei que seria bom disponibilizá-las para ajudar quem também gostaria de começar a ler ou discutir sobre o tema.

**Aqui**, escreverei apenas tópicos que me interessam, focando em estudos transversais e efeitos heterogêneos. Inferência Causal é gigante, então espere por lacunas nesse conteúdo. Mais importante: vamos ter um pouco de [humildade epistêmica](https://pt.wikipedia.org/wiki/Humildade_epist%C3%AAmica) aqui.

> [!tip] 
> Este documento não tem a pretensão de ser um ponto focal de ensinar, mas sim um registro pessoal de aprendizado. Escrever me ajuda a fixar o conteúdo e, ao torná-lo público, espero facilitar o caminho de quem também quer desbravar este tema, mas se sente perdido no início.
> 
> Como ponto de partida, criei o [[digital-garden/path-for-the-true-and-brave/text/0. Roadmap\|0. Roadmap]] detalhando o caminho que **eu** percorri. Como referências essenciais, recomendo acompanhar [Robson Tigre](https://www.google.com/search?q=LINK) e [Matheus Facure](https://www.google.com/search?q=LINK) — seus respectivos livros são excelentes e complementares.
> 
> Note que alguns assuntos no roadmap se repetem ou são revisitados. Isso é intencional. Acredito que a fixação do conhecimento acontece através da:
> 
> 1. **Síntese:** Criar anotações próprias e explicar o assunto;
> 2. **Prática:** Aplicar o que foi estudado;
> 3. **Diversidade:** Consumir o mesmo tema por diferentes fontes e perspectivas.

