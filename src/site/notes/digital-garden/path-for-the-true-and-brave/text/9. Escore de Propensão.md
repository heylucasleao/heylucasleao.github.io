---
{"dg-publish":true,"permalink":"/digital-garden/path-for-the-true-and-brave/text/9-escore-de-propensao/"}
---

# Escore de Propensão

Em inferência causal distinguimos dois cenários: estudos experimentais, nos quais o pesquisador controla o mecanismo de atribuição - por exemplo, usando RCT - e conhece as probabilidades de receber o tratamento; e estudos observacionais, nos quais a alocação não é controlada e pode haver vieses por confusão. Em estudos observacionais precisamos, de certa forma, “simular” a randomização para reduzir vieses decorrentes de diferenças nas covariáveis pré‑tratamento entre tratados e controles.

A definição formal é:

$$
e(X) = P(D=1 | X)
$$

Onde $D$ é a variável de tratamento e $X$ covariáveis.

Ao condicionarmos nas covariáveis, o escore de propensão controla as variáveis de confusão, ajudando a alcançarmos a independência condicional — o tratamento $D$ torna-se independente do resultado potencial, desde que se condicione no escore de propensão, ${Y(0),Y(1)} ⟂ D | e(X)$.

> [!tip]  Cenários comuns 
> - **Viés de Seleção:** Pessoas que escolhem receber um tratamento são fundamentalmente diferentes daquelas que não o recebem.
> 	- Exemplo: Indivíduos mais saudáveis ou mais ricos podem ter maior acesso ou propensão a um novo medicamento. 
>- **Noncompliance:** Mesmo em ensaios clínicos, se houver falta de adesão total ao tratamento, o efeito causal (como o ATE ou ATT) calculado diretamente pode estar enviesado, comprometendo os resultados e sua interpretabilidade.

> [!tip] Nota
> O conceito do Escore de Propensão é estritamente aplicado a tratamentos binários (discretizados ou dicotômicos: Sim/Não). Para tratamentos contínuos, um método utilizado é o Generalized Propensity Score (GPS), aonde modela envolta a densidade condicional, ao invés da probabilidade condicional.

Importante destacar, que ainda sim, precisamos que as premissas de ignorabilidade, positividade e SUTVA devem ser respeitadas antes de aplicar. Relembrando que comentei sobre esse tema em [[digital-garden/path-for-the-true-and-brave/text/5. Design de Experimentos\|5. Design de Experimentos]].

Para utilizarmos o score de propensão, basta regredirmos a intervenção com suas covariáveis em modelo probabilístico, como a regressão logística. Seu resultado, final, seria a probabilidade de uma unidade receber o tratamento condicional dado às covariáveis pré‑tratamento $X$.
### Exemplo ([Causal Inference in Python: Applying Causal Inference in the Tech Industry](https://github.com/matheusfacure/causal-inference-in-python-code/blob/main/causal-inference-in-python/05-Propensity-Score.ipynb))

```python
import statsmodels.formula.api as smf

# 1. Estimar o Escore de Propensão 
ps_model = smf.logit("""intervention ~ 
tenure + last_engagement_score + department_score
+ C(n_of_reports) + C(gender) + C(role)""", data=df).fit(disp=0)

# 2. Adicionar o Escore de Propensão como nova coluna
data_ps = df.assign(
    propensity_score = ps_model.predict(df),
)

data_ps[["intervention", "engagement_score", "propensity_score"]].head()

# 3. Estimar o Efeito Causal usando o Escore de Propensão como covariável
model = smf.ols("engagement_score ~ intervention + propensity_score",
                data=data_ps).fit()

# O coeficiente 'intervention' neste modelo representa o ATE ajustado pelo escore de propensão
print("ATE Ajustado por Escore de Propensão:", model.params["intervention"])
```
# Ponderação por Escore de Propensão Inverso

Uma vez tendo esse score, podemos estimar o efeito médio de tratamento. Uma das formas que podemos é por Ponderação por Score de Propensão Inverso (IPW).

A ideia de IPW é reponderar a sua amostra para criar uma pseudo-população onde a distribuição das variáveis de confusão $X$ é a mesma nos grupos de tratamento $D=1$ e controle $D=0$. Isto imita as condições de um ensaio aleatório. O peso $\mathbf{W}$ atribuído a cada indivíduo é o inverso da probabilidade de o indivíduo ter recebido o tratamento que realmente recebeu. Essa probabilidade é o Escore de Propensão $\hat{e}(\mathbf{x})$. Utilizando desta forma, estimamos um ATE em uma população observacional e você quiser criar uma pseudo‑população em que o tratamento é independente das covariáveis observadas. 

> [!tip] Exemplo
> **Unidades Incomuns (Alto Peso):**
> - Unidades que receberam um tratamento **improvável** (e.g., alto risco de rotatividade, mas **não** receberam o treino) recebem um **peso alto**.
>     - Isso os torna mais **representativos** da população em geral, essencialmente forçando um balanceamento da amostra.
> 
> **Unidades Comuns (Baixo Peso):**
> 
> - Unidades que receberam um tratamento provável recebem um peso baixo.

O peso para cada unidade $\mathbf{W}_i$ é calculado da seguinte forma, onde $\mathbf{D}_i$ é o tratamento real recebido:

$$
\mathbf{W}_i = \frac{1}{\mathbf{P}(\mathbf{D}_i | \mathbf{X}_i)} = \begin{cases} \frac{1}{\hat{e}(\mathbf{x}_i)} & \text{se } \mathbf{D}_i = 1 \\ \frac{1}{1 - \hat{e}(\mathbf{x}_i)} & \text{se } \mathbf{D}_i = 0 \end{cases}
$$

> [!tip] Nota
> Ao dar um peso alto a unidades tratadas que parecem unidades de controle, e unidades de controle que parecem unidades tratadas, o método garante que o grupo de tratamento e o grupo de controle na pseudo-população sejam comparáveis.

### Exemplos ([Causal Inference in Python: Applying Causal Inference in the Tech Industry](https://github.com/matheusfacure/causal-inference-in-python-code/blob/main/causal-inference-in-python/05-Propensity-Score.ipynb))

$$
\text{Efeito Causal} = \left(\begin{array}{c}\text{Média ponderada do resultado} \\ \text{se todos fossem tratados}\end{array}\right) - \left(\begin{array}{c}\text{Média ponderada do resultado} \\ \text{se ninguém fosse tratado}\end{array}\right)
$$

```python
# 1. Calcular os pesos IPW para cada grupo
weight_t = 1 / data_ps.query("intervention == 1")["propensity_score"]
weight_nt = 1 / (1 - data_ps.query("intervention == 0")["propensity_score"])

# 2. Obter os resultados (engagement_score) por grupo
t1 = data_ps.query("intervention == 1")["engagement_score"] 
t0 = data_ps.query("intervention == 0")["engagement_score"] 

# 3. Estimar o Resultado Potencial Médio (E[Y^t])
y1_num = sum(t1 * weight_t)  # Numerador: Somatório (Y * W) para T=1
y1_den = sum(weight_t)        # Denominador: Somatório (W) para T=1
y1 = y1_num / y1_den

y0_num = sum(t0 * weight_nt)  # Numerador: Somatório (Y * W) para T=0
y0_den = sum(weight_nt)       # Denominador: Somatório (W) para T=0
y0 = y0_num / y0_den

print("E[Y1] (Tratado):", y1)
print("E[Y0] (Controle):", y0)
print("ATE:", y1 - y0)
```
# Estimador Duplamente Robusto

O Escore de Propensão $\mathbf{e}(\mathbf{X})$ e a Ponderação por Escore de Propensão Inverso (IPW) são ferramentas para controlar variáveis de confusão e simular a randomização em dados observacionais. O IPW, em particular, é um estimador baseado em design que se foca em balancear os grupos.
Entretanto, uma preocupação comum em inferência causal é a especificação incorreta dos modelos. E se o modelo que usamos para calcular o Escore de Propensão estiver errado? Isso nos leva à busca por estimadores mais resilientes.

## **O Conceito "Duplamente Robusto"**

Um estimador é considerado Duplamente Robusto (Double Robust - DR) se a estimativa do efeito causal for consistente (ou seja, convergirá para o verdadeiro efeito causal) se:

1. O modelo para o Escore de Propensão estiver corretamente especificado.
**OU**
2. O modelo para o outcome potencial que estima estiver corretamente especificado.

Em outras palavras, o estimador DR **c**onverge para o modelo que estiver correto. Isso confere uma vantagem e aumenta a confiança na estimativa final, pois você só precisa acertar em um dos dois modelos. A ideia central é que o estimador utiliza ambos os modelos - por exemplo, IPW + Regressão Logística - para construir um estimador para o resultado potencial.

Um estimador DR popular para o resultado potencial médio sob tratamento pode ser escrito como:

$$
\mu_t^{DR}(\hat{\mu}, \hat{e}) = \frac{1}{N} \sum_{i=1}^{N} \left[ \hat{\mu}_t(\mathbf{X}_i) + \frac{\mathbf{D}_i - \hat{e}(\mathbf{X}_i)}{\hat{e}(\mathbf{X}_i)} \left( \mathbf{Y}_i - \hat{\mu}_t(\mathbf{X}_i) \right) \right]
$$

Onde:

- $\mathbf{Y}_i$ é o resultado observado.
- $\mathbf{D}_i$ é a variável de tratamento.
- $\hat{\mu}_t(\mathbf{X}_i)$  é a previsão do resultado $\mathbf{Y}$ pelo modelo, assumindo o tratamento $t$
- $\hat{e}(\mathbf{X}_i)$ é o **Escore de Propensão**.

Se o Escore de Propensão estiver correto:

O termo $\frac{\mathbf{D}_i - \hat{e}(\mathbf{X}_i)}{\hat{e}(\mathbf{X}_i)}$ tenderá a zero na média, e o segundo termo todo se anulará.

Isto deixa apenas o primeiro termo, $\frac{1}{N} \sum_{i=1}^{N} \hat{\mu}_t(\mathbf{X}_i)$, que converge para a estimativa do resultado do modelo. Neste caso, a estimativa DR se comporta como um estimador *design-based*.

Se o modelo estiver correto:

O segundo termo, $\left( \mathbf{Y}_i - \hat{\mu}_t(\mathbf{X}_i) \right)$, tenderá a zero na média, pois $\hat{\mu}_t(\mathbf{X}_i)$ é uma previsão precisa de $\mathbf{Y}_i$.

A estimativa DR converge para um estimador *outcome-based* que se baseia primariamente no modelo.


