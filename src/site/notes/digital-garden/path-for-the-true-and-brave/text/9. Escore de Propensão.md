---
{"dg-publish":true,"permalink":"/digital-garden/path-for-the-true-and-brave/text/9-escore-de-propensao/"}
---

# Escore de Propensão

Em inferência causal distinguimos dois cenários: estudos experimentais, nos quais o pesquisador controla o mecanismo de atribuição - por exemplo, usando RCT - e conhece as probabilidades de receber o tratamento; e estudos observacionais, nos quais a alocação não é controlada e pode haver vieses por confusão. Em estudos observacionais precisamos, de certa forma, “simular” a randomização para reduzir vieses decorrentes de diferenças nas covariáveis pré‑tratamento entre tratados e controles.

A definição formal é:

$$
e(X) = P(D=1 | X)
$$

Onde $D$ é a variável de tratamento e $X$ covariáveis.

Ao condicionarmos nas covariáveis, o escore de propensão controla as variáveis de confusão, ajudando a alcançarmos a independência condicional — o tratamento $D$ torna-se independente do resultado potencial, desde que se condicione no escore de propensão, ${Y(0),Y(1)} ⟂ D | e(X)$. Importante pontuar que o conceito do Escore de Propensão é estritamente aplicado a tratamentos binários (discretizados ou dicotômicos: Sim/Não). Para tratamentos contínuos, um método utilizado é o Generalized Propensity Score (GPS), aonde observamos a densidade condicional, ao invés da probabilidade condicional. Este tópico não irei abordar.

> [!tip]  Cenários comuns 
> - **Viés de Seleção:** Pessoas que escolhem receber um tratamento são fundamentalmente diferentes daquelas que não o recebem.
> 	- Exemplo: Indivíduos mais saudáveis ou mais ricos podem ter maior acesso ou propensão a um novo medicamento. 
>- **Noncompliance:** Mesmo em ensaios clínicos, se houver falta de adesão total ao tratamento, o efeito causal (como o ATE ou ATT) calculado diretamente pode estar enviesado, comprometendo os resultados e sua interpretabilidade.

Importante destacar, que ainda sim, precisamos que as premissas de ignorabilidade, positividade e SUTVA devem ser respeitadas antes de aplicar. Relembrando que comentei sobre esse tema em [[digital-garden/path-for-the-true-and-brave/text/5. Design de Experimentos\|5. Design de Experimentos]].

Para utilizarmos o score de propensão, basta regredirmos a intervenção com suas covariáveis em modelo probabilístico, como a regressão logística. Seu resultado, final, seria a probabilidade de uma unidade receber o tratamento condicional dado às covariáveis pré‑tratamento $X$.
### Exemplo ([Causal Inference in Python: Applying Causal Inference in the Tech Industry](https://github.com/matheusfacure/causal-inference-in-python-code/blob/main/causal-inference-in-python/05-Propensity-Score.ipynb))

```python
import statsmodels.formula.api as smf

# 1. Estimar o Escore de Propensão 
ps_model = smf.logit("""intervention ~ 
tenure + last_engagement_score + department_score
+ C(n_of_reports) + C(gender) + C(role)""", data=df).fit(disp=0)

# 2. Adicionar o Escore de Propensão como nova coluna
data_ps = df.assign(
    propensity_score = ps_model.predict(df),
)

data_ps[["intervention", "engagement_score", "propensity_score"]].head()

# 3. Estimar o Efeito Causal usando o Escore de Propensão como covariável
model = smf.ols("engagement_score ~ intervention + propensity_score",
                data=data_ps).fit()

# O coeficiente 'intervention' neste modelo representa o ATE ajustado pelo escore de propensão
print("ATE Ajustado por Escore de Propensão:", model.params["intervention"])
```


>[!tip] Avaliação de Viés
> Caso haja suspeita de que a base de dados avaliada sofre de algum viés, podemos utilizar o escore de propensão para verificar quão "previsível" é a designação do tratamento. Em um experimento aleatório, o **AUC** do modelo de propensão deve ser próximo de **0.50**, indicando que o tratamento foi atribuído ao acaso. Se o AUC for elevado a isto, isso sugere um indício de viés de seleção e falta de sobreposição entre os grupos, sugerindo que tratados e controles são tão diferentes que a comparação pode ser inviável.
# Ponderação por Escore de Propensão Inverso (IPW)

Uma vez estimado o escore, podemos utilizá-lo para calcular o efeito médio de tratamento via **IPW**. A ideia central é reponderar a amostra original para criar uma pseudo-população onde a distribuição das covariáveis $X$ seja idêntica entre os grupos de tratamento e controle, simulando as condições de um experimento aleatório.

O peso $W_i$ atribuído a cada indivíduo é o inverso da probabilidade de ele ter recebido o tratamento que de fato recebeu:

$$
\mathbf{W}_i = \frac{1}{\mathbf{P}(\mathbf{D}_i | \mathbf{X}_i)} = \begin{cases} \frac{1}{\hat{e}(\mathbf{x}_i)} & \text{se } \mathbf{D}_i = 1 \\ \frac{1}{1 - \hat{e}(\mathbf{x}_i)} & \text{se } \mathbf{D}_i = 0 \end{cases}
$$

Na intuição, queremos dar mais peso para observações "raras" ou "improváveis":
- Indivíduo Tratado com baixo escore: Ele se parece com o grupo de controle, mas recebeu o tratamento. Damos a ele um peso alta para que ele represente a parcela da população que "deveria" estar no grupo de controle, mas foi tratada.

- Indivíduo de Controle com alto escore: Ele se parece com o grupo de tratamento, mas não foi tratado. Também recebe peso alta para equilibrar a balança.

Isso cria uma distribuição balanceada entre grupo de controle e tratamento, como se tivéssemos feito um experimento aleatório, utilizando o peso de cada observação usando o Escore de Propensão $\hat{e}(\mathbf{x})$. Desta forma, o método garante que o grupo de tratamento e o grupo de controle na pseudo-população sejam comparáveis. assim, conseguimos estimar um efeito causal em uma população observacional de a partir de uma pseudo-população em que o tratamento é independente das covariáveis observadas. 

> [!tip] Exemplos de uso
> **Unidades Incomuns (Alto Peso):**
> - Unidades que receberam um tratamento **improvável** (e.g., alto risco de rotatividade, mas **não** receberam o treino) recebem um **peso alto**.
>     - Isso os torna mais **representativos** da população em geral, essencialmente forçando um balanceamento da amostra.
> 
> **Unidades Comuns (Baixo Peso):**
> 
> - Unidades que receberam um tratamento provável recebem um peso baixo.

Para validar se a reponderação foi bem-sucedida, podemos verificar a somatória dos pesos: se a soma de $W_1$ e a soma de $W_0$ se aproximarem, cada uma, do tamanho total da amostra original ($N$), a ponderação é considerada estável. Se esses valores divergirem drasticamente, isso indica a presença de pesos extremos, o que pode tornar a estimativa do ATE pouco confiável. Outra forma de avaliarmos é plotarmos a distribuição de cada grupo: em tese, ambos deveriam estar aproximadas. Isto pode ser observado nos [exemplos](https://github.com/matheusfacure/causal-inference-in-python-code/blob/main/causal-inference-in-python/05-Propensity-Score.ipynb) do livro do Facure.
### Exemplos ([Causal Inference in Python: Applying Causal Inference in the Tech Industry](https://github.com/matheusfacure/causal-inference-in-python-code/blob/main/causal-inference-in-python/05-Propensity-Score.ipynb))

$$
\text{Efeito Causal} = \left(\begin{array}{c}\text{Média ponderada do resultado} \\ \text{se todos fossem tratados}\end{array}\right) - \left(\begin{array}{c}\text{Média ponderada do resultado} \\ \text{se ninguém fosse tratado}\end{array}\right)
$$

```python
# 1. Calcular os pesos IPW para cada grupo
weight_t = 1 / data_ps.query("intervention == 1")["propensity_score"]
weight_nt = 1 / (1 - data_ps.query("intervention == 0")["propensity_score"])

# 2. Obter os resultados (engagement_score) por grupo
t1 = data_ps.query("intervention == 1")["engagement_score"] 
t0 = data_ps.query("intervention == 0")["engagement_score"] 

# 3. Estimar o Resultado Potencial Médio (E[Y^t])
y1_num = sum(t1 * weight_t)  # Numerador: Somatório (Y * W) para T=1
y1_den = sum(weight_t)        # Denominador: Somatório (W) para T=1
y1 = y1_num / y1_den

y0_num = sum(t0 * weight_nt)  # Numerador: Somatório (Y * W) para T=0
y0_den = sum(weight_nt)       # Denominador: Somatório (W) para T=0
y0 = y0_num / y0_den

print("E[Y1] (Tratado):", y1)
print("E[Y0] (Controle):", y0)
print("ATE:", y1 - y0)
```
# Estimador Duplamente Robusto

O Escore de Propensão $\mathbf{e}(\mathbf{X})$ e a Ponderação por Escore de Propensão Inverso (IPW) são ferramentas para controlar variáveis de confusão e simular a randomização em dados observacionais. O IPW, em particular, é um estimador baseado em design que se foca em balancear os grupos.
Entretanto, uma preocupação comum em inferência causal é a especificação incorreta dos modelos. E se o modelo que usamos para calcular o Escore de Propensão estiver errado? Isso nos leva à busca por estimadores mais resilientes.

## **O Conceito "Duplamente Robusto"**

Um estimador é considerado Duplamente Robusto (Double Robust - DR) se a estimativa do efeito causal for consistente (ou seja, convergirá para o verdadeiro efeito causal) se:

1. O modelo para o Escore de Propensão estiver corretamente especificado.
**OU**
2. O modelo para o outcome potencial que estima estiver corretamente especificado.

Em outras palavras, o estimador DR **c**onverge para o modelo que estiver correto. Isso confere uma vantagem e aumenta a confiança na estimativa final, pois você só precisa acertar em um dos dois modelos. A ideia central é que o estimador utiliza ambos os modelos - por exemplo, IPW + Regressão Logística - para construir um estimador para o resultado potencial.

Um estimador DR popular para o resultado potencial médio sob tratamento pode ser escrito como:

$$
\mu_t^{DR}(\hat{\mu}, \hat{e}) = \frac{1}{N} \sum_{i=1}^{N} \left[ \hat{\mu}_t(\mathbf{X}_i) + \frac{\mathbf{D}_i - \hat{e}(\mathbf{X}_i)}{\hat{e}(\mathbf{X}_i)} \left( \mathbf{Y}_i - \hat{\mu}_t(\mathbf{X}_i) \right) \right]
$$

Onde:

- $\mathbf{Y}_i$ é o resultado observado.
- $\mathbf{D}_i$ é a variável de tratamento.
- $\hat{\mu}_t(\mathbf{X}_i)$  é a previsão do resultado $\mathbf{Y}$ pelo modelo, assumindo o tratamento $t$
- $\hat{e}(\mathbf{X}_i)$ é o **Escore de Propensão**.

Se o Escore de Propensão estiver correto:

O termo $\frac{\mathbf{D}_i - \hat{e}(\mathbf{X}_i)}{\hat{e}(\mathbf{X}_i)}$ tenderá a zero na média, e o segundo termo todo se anulará.

Isto deixa apenas o primeiro termo, $\frac{1}{N} \sum_{i=1}^{N} \hat{\mu}_t(\mathbf{X}_i)$, que converge para a estimativa do resultado do modelo. Neste caso, a estimativa DR se comporta como um estimador *design-based*.

Se o modelo estiver correto:

O segundo termo, $\left( \mathbf{Y}_i - \hat{\mu}_t(\mathbf{X}_i) \right)$, tenderá a zero na média, pois $\hat{\mu}_t(\mathbf{X}_i)$ é uma previsão precisa de $\mathbf{Y}_i$.

A estimativa DR converge para um estimador *outcome-based* que se baseia primariamente no modelo.


