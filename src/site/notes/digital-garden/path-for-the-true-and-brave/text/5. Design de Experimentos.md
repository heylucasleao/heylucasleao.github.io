---
{"dg-publish":true,"permalink":"/digital-garden/path-for-the-true-and-brave/text/5-design-de-experimentos/"}
---

# Design de Experimentos

Na introdução ao seu trabalho [The Design of Experiments](https://home.iitk.ac.in/~shalab/anova/DOE-RAF.pdf), Ronald Fisher demonstrou preocupação com a falta de clareza e rigor metodológico em experimentos. Ele notou que a ausência de um design experimental robusto poderia levar a:

- **Dificuldade de Interpretação:** O leitor e, por vezes, o próprio cientista, poderiam ter interpretações diferentes sobre os resultados, levando a conclusões não suportadas pelos dados ou que poderiam ter ocorrido **por acaso** (chance), mesmo que a hipótese fosse falsa.
- **Carência Estrutural (Design):** Falhas lógicas e estruturais tornam o experimento **fundamentalmente incorreto**, muitas vezes devido a controles inadequados ou à ausência de uma comparação válida.

Fisher propôs um método rigoroso que visa trazer **facilidade** e **confiança** ao cientista no tópico de experimentação, desde o planejamento (_design_) até o desenvolvimento e a análise.

Conceitos Chave de Fisher:
- **Randomização:** Para garantir que as características não observáveis se distribuam igualmente entre os grupos.
- **Controle:** Para isolar o efeito do tratamento de outros fatores externos.
- **Replicação:** Para reduzir o erro experimental e aumentar a precisão da estimativa.

# Experimentos Aleatorizados

Para contornar o Problema Fundamental da Inferência Causal, suprir a carência de design de experimentos e controlar o viés de variável omitida, recorre-se a métodos de pesquisa como o Experimento Aleatorizado.

O experimento aleatorizado, ou ensaio clínico randomizado (RCT), é um procedimento no qual as unidades de uma amostra populacional são alocadas de forma aleatória (randomizada) ao grupo de tratamento ou ao grupo de controle.

A randomização é crucial, pois:
- Elimina vieses de seleção e confusão.
- Cria grupos estatisticamente comparáveis (balanceados).

Ao garantir que a única diferença sistemática esperada entre os grupos seja a aplicação do tratamento, a randomização permite que a **diferença observacional** nos resultados seja interpretada como uma **estimativa válida do efeito causal** médio do tratamento na população.
# Premissas

[Molak, em conversa com Thanos Vlontzos](https://www.youtube.com/watch?v=ofAtKK6O2dE&list=TLGGKVDHELD0i-YzMDEyMjAyNQ&t=6s) enfatiza que nunca nos livramos totalmente das premissas. Todo modelo, causal ou não, repousa sobre suposições; o objetivo não é eliminá‑las, mas escolher aquelas com as quais podemos conviver e torná‑las explícitas. Segundo ele, o problema não é ter premissas iniciais, e sim esquecê‑las: uma suposição negligenciada pode fazer um projeto parecer perfeito na superfície, mas esconder uma "mancha enorme" que, mais tarde, causará problemas. Isso vale tanto para estudos experimentais quanto especialmente para estudos observacionais. As premissas que devemos respeitar são:

- **SUTVA (Stable Unit Treatment Value Assumption)**
     	- Consistência: O tratamento é bem definido; o outcome observado para uma unidade sob o tratamento $D$ é igual ao resultado potencial $Y(D)$.
		- Sem interferência: O tratamento de uma unidade não afeta o resultado de outra (sem _spillovers_/efeitos indiretos).
- **Ignorabilidade / Unconfoundedness / Exchangeability**
    	- Os resultados potenciais são independentes da atribuição do tratamento, condicional às covariáveis observadas: $\{Y(0), Y(1)\} \perp D | X$. Em RCTs ideais, a randomização garante ignorabilidade por definição.
- **Positividade / Overlap**
    	- Para todo valor de $X$ considerado, há probabilidade estritamente positiva de receber cada condição: $0 < P(T=1 | X) < 1$. Sem positividade, não é possível comparar contrafactuais em certas subpopulações.
- **Controle de confundidores**
    	- _Em estudos observacionais:_ Medir e ajustar os confundidores (regressão, _propensity scores_, IPW, etc.).
    	- _Em RCTs:_ Projetar estratificação quando necessário para garantir balanceamento e ajustar para covariáveis na análise para melhorar a precisão (redução de variância).
- **Ameaças pós-randomização**
    	- Não-adesão (_noncompliance_), perda amostral diferencial (_attrition_), contaminação e mediadores induzidos pelo tratamento podem reintroduzir viés de seleção.

> [!tip] Checagens práticas recomendadas
> - Verificar balanceamento de covariáveis pré-tratamento (tabelas de estatísticas descritivas e testes de hipótese; _love plot_).
> - Conferir _overlap_/_propensity score distributions_ e excluir regiões sem suporte comum (em análises condicionais).
> - Monitorar rigorosamente as taxas de adesão e perda amostral.

![rct_1.png](/img/user/digital-garden/path-for-the-true-and-brave/assets/rct_1.png)
[Lecture 3 – The Magic of Randomized Control Trials](https://stanford-causal-inference-class.github.io/materials/lecture-slides/Unit1_Lecture1.pptx)

![rct_2.png](/img/user/digital-garden/path-for-the-true-and-brave/assets/rct_2.png)
[Lecture 3 – The Magic of Randomized Control Trials](https://stanford-causal-inference-class.github.io/materials/lecture-slides/Unit1_Lecture1.pptx)

> [!tip] Leitura Recomendada
> Um bom artigo que podemos observar o carinho de um bom design de experimento e aleatorizada, é o artigo [The impact of computer usage on academic performance: Evidence from a randomized trial at the United States Military Academy](https://www.sciencedirect.com/science/article/abs/pii/S0272775716303454).
## Pontos de Atenção

- **Validade Interna:**
	- **Definição**: Refere-se à confiança de que o efeito observado no resultado é **causado** unicamente pela manipulação do tratamento (variável independente) e não por fatores externos, vieses ou erros de condução. Um experimento tem alta validade interna se pudermos afirmar com certeza que o tratamento causou a mudança no resultado.
    - **Ameaças:** Seleção dos participantes, mudanças naturais ao longo do tempo, eventos externos durante o experimento e mortalidade/perda amostral.
	      
- **Validação Externa:** Trata-se da capacidade de generalizar os resultados do experimento para a população mais ampla ou para outros ambientes e contextos. Se os resultados só se aplicam à amostra específica estudada, a validade externa é baixa.
    - **Ameaças:** Interação entre seleção e tratamento (o efeito só existe no grupo específico selecionado) e efeitos de laboratório (condições artificiais que não refletem o mundo real).
	    
- **Validade de Construto**
    - **Definição:** Refere-se à adequação das medidas. Garante que as variáveis operacionais (como você mede ou manipula algo) realmente representam os construtos teóricos (os conceitos abstratos estudados).
    - **Em outras palavras:** É a certeza de que o experimento está medindo aquilo que se propôs a medir.
	    
    - **Ponto de Atenção:**
        - Deve-se garantir que as métricas realmente capturem a essência dos conceitos (ex: satisfação do cliente, motivação).
        - **Ameaças Comuns:**
            - Sub-representação do Construto: A métrica é incompleta e não captura a totalidade do conceito.
            - Variância de Métodos Irrelevantes: A medição é contaminada por fatores alheios ao conceito de interesse.
	            
- **Efeito Spillover (Violação da SUTVA):**
    - Ocorre quando o tratamento aplicado ao Grupo de Tratamento afeta, indiretamente, o Grupo de Controle (ou vice-versa). O tratamento "vaza" ou a informação/benefício se espalha.
        - **Exemplos:**
            - Um participante do controle **aprende** sobre a nova funcionalidade com um amigo do tratamento.
            - Um participante do grupo de controle **aprende** sobre a nova funcionalidade com um amigo do grupo de tratamento (contaminação).
            - A mudança de preço em uma loja (tratamento) altera a **demanda** de uma loja vizinha (controle).
            - Em experimentos geográficos, a intervenção em uma área afeta a área contígua.
	            
        - **Implicação:** Se houver _spillover_, o grupo de controle deixa de ser uma linha de base pura, comprometendo a validade interna. A estimativa do efeito será enviesada.
		        
        - **Mitigação:** Usar clusters/agrupamentos distantes (geográfica ou socialmente) ou implementar cegamento rigoroso.
				
## Problemas com Experimentos Aleatorizados

Em um RCT, os participantes são distribuídos aleatoriamente para o grupo de tratamento ou controle. Essa randomização visa equilibrar todas as variáveis de confusão (tanto as conhecidas quanto as desconhecidas) entre os grupos, permitindo que qualquer diferença observada no resultado seja atribuída, com alta confiança, à intervenção (causa).

Embora seja o padrão de ouro na metodologia experimental, ele não oferece uma garantia absoluta de causalidade, pois a randomização inicial é apenas o primeiro passo. A causalidade pode ser comprometida por **vieses pós-randomização** que surgem durante a execução do estudo. Problemas como a desigualdade de características entre os participantes, perda ou até abandono podem prejudicar o resultado para uma generalização dos resultados.

Além das limitações metodológicas na condução do estudo, o RCT é inviável ou antiético em inúmeros cenários de pesquisa causal. Existem fenômenos de interesse (como o efeito de eventos raros, exposições de longuíssimo prazo, ou variáveis não manipuláveis, como o *status* socioeconômico) onde a aleatoriedade é inatingível. Mais gravemente, a randomização é antiética em exposições que são sabidamente prejudiciais. Por exemplo, seria moralmente inaceitável randomizar uma população para forçar um grupo a fumar a fim de analisar as chances de câncer de pulmão.

Portanto, em contextos onde a intervenção não pode ser controlada por um RCT devido a impedimentos éticos ou práticos, os pesquisadores devem recorrer a outras ferramentas, como também é possível aplicar outros tipos de amostragens. 

## Experimentos Condicionalmente Aleatórios

Em amostras de tamanho limitado ou dependendo de cenários específicos, a aleatorização simples pode, por acaso, resultar em um desequilíbrio em covariáveis entre os grupos. Esse desequilíbrio pode levar a um viés de seleção e comprometer a validade interna do experimento. Para mitigar esse risco e equilibrar as características importantes na amostra, podemos utilizar métodos de Aleatorização Condicional. Um método mais simples e comumente utilizado, é a estratificação por covariáveis, isto é, dividir a população em subgrupos com base em que cada proporção e características sejam divididas entre o grupo de controle e tratamento. Ainda sim, há diversos outros meios.

## Elementos do Poder Estatístico

![hypothesis_test_1.png](/img/user/digital-garden/path-for-the-true-and-brave/assets/hypothesis_test_1.png)

No contexto de estudos experimentai, ainda estaremos trabalhando com testes de hipóteses, pois de fato estamos atuando com cenários nas quais queremos estudar. Isto implica que estamos ainda sujeitos a cometer erros estatísticos ao tomar uma decisão sobre a hipótese nula $H_0$.

### Erros do Tipo I e Tipo II

![hypothesis_test_2.png](/img/user/digital-garden/path-for-the-true-and-brave/assets/hypothesis_test_2.png)

**Erro do Tipo I (Falso Positivo)**:

Ocorre quando rejeitamos a $H_0$ quando ela é, na verdade, verdadeira. A probabilidade de cometer um Erro Tipo I é controlada pelo **nível de significância** $\alpha$.  Comumente o valor de $\alpha$ é utilizado em 0,05, o que significa que aceitamos 5% de chance de concluir erroneamente que há um efeito.


> [!tip]
> Neste contexto, seria concluir que o tratamento teve um efeito quando, na realidade, a diferença observada foi devida puramente ao acaso.

**Erro do Tipo II (Falso Negativo)**:

Ocorre quando falhamos em rejeitar a $H_0$ quando ela é, na verdade, falsa. A probabilidade de cometer um Erro Tipo II é controlado pelo poder de teste, $1 - \beta$.

> [!tip]
> Neste contexto, seria concluir que o tratamento não teve um efeito (ou que não houve diferença significativa) quando, na realidade, ele teve um efeito real na população.

### Análise de Poder Estatístico

É fundamental que façamos uma análise do poder, pois permite determinar o tamanho de amostra necessário para detectar um efeito de determinado tamanho com uma probabilidade aceitável. Os quatro termos inter-relacionados nesta análise são:

1. Tamanho da Amostra: O número de observações incluídas no estudo. Um aumento na amostra geralmente aumenta o Poder do Teste.
	
2. Nível de Significância $\alpha$: Se for **diminuído** (ex: de 0,05 para 0,01), a chance de um Falso Positivo diminui, mas a exigência para rejeitar $H_0$ é maior, o que, por sua vez, diminuindo a sensibilidade do Poder do Teste (aumentando $\beta$). 
	
3. Poder do Teste (**$1 - \beta$**): O poder de teste é a **sensibilidade** do estudo. Geralmente, o poder do teste é fixado em 0,80 (ou 80%), o que significa que se um efeito real existir, o estudo tem 80% de chance de detectá-lo.
	
4. Tamanho do Efeito (Effect Size - Cohen’s D) ou Efeito Mínimo Detectável (Minimum Detectable Effect - MDE): O Tamanho do Efeito é a magnitude da diferença ou relacionamento de interesse na população. O MDE é o menor tamanho de efeito que o estudo está equipado para detectar com as configurações de amostra, nível de significância e Poder do teste.
		
    - **Relação com o MDE**:
        - Se o MDE for muito alto (ex: 15%), o estudo é muito "grosseiro" e pode falhar em detectar efeitos menores, mas clinicamente ou economicamente relevantes (ex: 2%), resultando em um aumento da probabilidade do Erro Tipo II.
        - Para **reduzir o MDE** e, assim, aumentar a sensibilidade do estudo a efeitos menores, é necessário **aumentar o Tamanho da Amostra N.
	
	
 O MDE não deve ser um número arbitrário; ele deve ser o menor efeito que é economicamente ou clinicamente relevante para a sua área.  A Análise de Poder a Priori deve usar este MDE junto com o Poder e o Alpha para calcular o tamanho de amostra mínimo necessário. Se o tamanho da amostra for inviável para o MDE de interesse, o estudo deve ser repensado.

> [!tip]
> Segundo Ron Kovahi, se o MDE for menor que 5%, dificilmente você irá detectá-lo com confiança, junto ao fato da quantidade de amostras necessárias para verificar. O ideal será entre 5% a 10%. 

# Mecanismo de Atribuição

>[!tip] Quote
I think it's wrong to think any causality comes only in the modeling part. It comes in the entire system building process:
>
>- From the data collection (thinking about which parameters come into play);
>- Obviously the data modeling;
>- And then to actually **making it robust** and serving it to the **End Customer**.
>
>So this is, for example, a very crucial point: Gathering correct data, especially in the medical field, is extremely hard and extremely crucial. - [Thanos Vlontzos](https://www.youtube.com/watch?v=ofAtKK6O2dE)

O mecanismo de atribuição é o processo (conhecido ou desconhecido) que determina quais unidades recebem o tratamento e quais recebem o controle. Formalmente, ele descreve a lei de probabilidade condicional $P(W | X, Y(0), Y(1))$ que governa a alocação do tratamento $W$.

Em um RCT, este mecanismo é controlado e conhecido (ex: moeda, sorteio). Em estudos observacionais, ele é desconhecido e precisa ser estimado. Essa estimativa é justamente o cálculo da probabilidade de receber o tratamento $P(W=1|X)$, valor que chamamos de Escore de Propensão, ao qual nos permite rebalancear os grupos e validar se as premissas de identificação foram respeitadas. 