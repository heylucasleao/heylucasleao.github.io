---
{"dg-publish":true,"permalink":"/path-for-the-true-and-brave/causalidade/11-variavel-instrumental/"}
---

Existem cenários em que é inviável controlar totalmente o viés de variável omitida $U$. Nestes casos, problemas comuns incluem:

- A impossibilidade de coletar ou mensurar todas as variáveis de confusão.
    
- A impossibilidade de garantir que todos os indivíduos designados ao grupo de tratamento efetivamente recebam ou utilizem o tratamento. Isso caracteriza uma violação do perfect compliance (adesão perfeita).
    
> [!tip]
> 
> Compliance refere-se à taxa de adesão, ou seja, o percentual de indivíduos que efetivamente utilizaram o tratamento conforme designado.

Nestes cenários, a variável não observada $U$ exerce influência tanto sobre o tratamento $D$ quanto sobre o resultado $Y$, enviesando as estimativas causais:

$$D \leftarrow U \rightarrow Y$$

Uma solução para contornar a falta de controle sobre $U$ é utilizar uma Variável Instrumental $Z$, que antecede $D$:

$$ Z \rightarrow D \leftarrow U \rightarrow Y$$

Essa abordagem isola a variação em $D$ que é induzida por $Z$, "limpando" a influência de $U$. Para que isso funcione, as seguintes premissas devem ser atendidas:

- **Relevância:** A relação entre o instrumento $Z$ e o tratamento $D$ deve ser forte.
    
    - _Prática:_ Regredir $Z$ em $D$ e verificar se o R² e a Estatística F (p-valor) são significativos.
        
- **Restrição de Exclusão:** O instrumento $Z$ deve afetar o resultado $Y$ **apenas** através de $D$, sem caminhos diretos.
    
- **Exogeneidade (Independência):** O instrumento deve ser não correlacionado com o termo de erro ou variáveis omitidas ($Cov(Z, U) = 0$).
    
- **Monotonicidade:** O instrumento deve afetar o tratamento numa única direção.
    

A Variável Instrumental (IV) pode ser aplicada em dois contextos principais:

1. **Correção de Experimentos (RCTs):** Para lidar com falhas de adesão (_imperfect compliance_). Por exemplo, quando $Z$ é a oferta do tratamento e $D$ é o uso efetivo. Nem todos os ofertados usam, mas a oferta ($Z$) é aleatória.
    
2. **Estudos Observacionais:** Quando não houve randomização e suspeita-se que variáveis de confusão desconhecidas ($U$) afetem a escolha do tratamento. Aqui, o instrumento funciona como um "experimento natural", introduzindo uma aleatoriedade na atribuição de $D$ que o pesquisador não pôde controlar manualmente.
    

O instrumento provoca um **choque exógeno** na variável $D$, gerando uma variação no tratamento que é independente das características não observadas $U$.

# Estágios

Para calcular o efeito causal via IV, podemos decompor a análise em duas regressões simples e uma divisão. 

1. Primeiro Estágio (Impacto no Tratamento):
    
    Regredimos o tratamento $D$ em relação ao instrumento $Z$.
    - Verificamos a premissa de **Relevância**. O coeficiente ($\pi$) nos diz o quanto o instrumento aumenta a probabilidade ou intensidade do tratamento.$$D = \alpha_1 + \pi Z + e_1$$
        
1. Forma Reduzida (Intenção de Tratar - ITTE):
    Regredimos o resultado $Y$ diretamente em relação ao instrumento $Z$, ignorando o tratamento $D$ por enquanto.
    
    - Como $Z$ é aleatório/exógeno, esse coeficiente ($\gamma$) mostra o efeito causal da _atribuição_ do instrumento sobre o resultado.
    $$Y = \alpha_2 + \gamma Z + e_2$$
        
2. Cálculo do LATE:
    O efeito causal final ($\beta_{IV}$) é a razão entre esses dois coeficientes. Ou seja, ajustamos o efeito total ($\gamma$) pela proporção de pessoas que realmente aderiram ao tratamento ($\pi$).
    
    $$\beta_{IV} = \frac{\text{Efeito de Z em Y (Forma Reduzida)}}{\text{Efeito de Z em D (Primeiro Estágio)}} = \frac{\gamma}{\pi}$$


```python
import statsmodels.formula.api as smf


# 1. Primeiro Estágio: Efeito de Z em D
# O coeficiente de Z aqui é a taxa de adesão
first_stage = smf.ols('D ~ Z', data=df).fit()
den = first_stage.params['Z']


# 2. Forma Reduzida: Efeito de Z em Y
# O coeficiente de Z aqui é o ITTE
reduced_form = smf.ols('Y ~ Z', data=df).fit()
num = reduced_form.params['Z']

# Cálculo do Wald, ou LATE
wald_estimator_sm = num / den

print(f"Numerador (ITTE): {num}")
print(f"Denominador (Compliance): {den}")
print(f"Efeito Causal (Wald): {wald_estimator_sm}")
```

# Mínimos Quadrados em Dois Estágios (2SLS)

Enquanto o cálculo do LATE via razão é intuitivo para um único instrumento, o método 2SLS  permite a inclusão de múltiplas variáveis de controle e múltiplos instrumentos.

1. Primeiro Estágio (Purificação de $D$):
    
    Regride-se o tratamento $D$ contra o instrumento $Z$ (e demais controles). O objetivo não é analisar o coeficiente, mas sim obter os valores preditos ($\hat{D}$).
    
    $$\hat{D} = \hat{\alpha} + \hat{\pi} Z$$
    
2. Segundo Estágio (Estimação Causal):
    
    Substitui-se a variável de tratamento original ($D$) pelos valores preditos calculados no passo anterior ($\hat{D}$) e realiza-se a regressão do resultado $Y$ sobre essa nova variável.
    
    $$Y = \beta_0 + \beta_{2SLS} \hat{D} + \varepsilon$$

A intuição aqui é a **decomposição da variância**. A variável de tratamento original $D$ possui dois componentes de variação:

1. Uma parte **endógena**, correlacionada com $U$
2. Uma parte **exógena**, induzida pelo instrumento $Z$

Ao rodarmos o primeiro estágio e calcularmos $\hat{D}$, estamos isolando apenas a variação em $D$ que é explicada por $Z$. Como $Z$ é não correlacionado com $U$, $\hat{D}$ também será independente de $U$.

Portanto, o segundo estágio utiliza uma versão "limpa" do tratamento. Ao regredir $Y$ em $\hat{D}$, eliminamos a contaminação do viés de seleção, permitindo que o OLS estime o efeito causal verdadeiro.

```python
from linearmodels.iv import IV2SLS

# Fórmula: Y ~ Controles + [Endogeno ~ Instrumento]
# O "1" representa a constante (intercepto)
formula = 'Y ~ 1 + X + [D ~ Z]'

model = IV2SLS.from_formula(formula, df)
result = model.fit()

print(result)
```

>[!tip]  2SLS vs. DoubleML (DML)
>O método 2SLS tradicional assume que as relações entre as variáveis de controle (covariáveis) e o resultado são **lineares**. Caso sejam não lineares, o 2SLS pode falhar em remover todo o viés. É aqui que podemos utilizar o método de Double Machine Learning (DML) com uso de IV.
