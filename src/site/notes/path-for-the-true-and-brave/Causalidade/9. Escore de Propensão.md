---
{"dg-publish":true,"permalink":"/path-for-the-true-and-brave/causalidade/9-escore-de-propensao/"}
---

# Escore de Propens√£o

No contexto de infer√™ncia causal, podemos ter dois cen√°rios: estudos experimentais, onde h√° controle da randomiza√ß√£o por meio de RCTs e, por consequ√™ncia, melhor controle dos confundidores; e estudos observacionais, onde n√£o controlamos como os dados foram obtidos, podendo haver vi√©s(es). Para esse √∫ltimo contexto, devemos, de alguma forma, simular a randomiza√ß√£o. Em outras palavras, controlar vieses que possam prejudicar o estudo. Um dos m√©todos que podemos utilizar,  o escore de propens√£o (Propensity Score), que serve para aproximar condi√ß√µes de randomiza√ß√£o em estudos observacionais, nos quais a aloca√ß√£o do tratamento n√£o √© aleat√≥ria e os dados j√° foram coletados. Nesse cen√°rio n√£o h√° controle das diferen√ßas entre os grupos de tratamento e controle, o que pode gerar vi√©s por vari√°veis de confus√£o. 

> [!tip]
> Exemplos comuns para utilizarmos o escore de propens√£o:
> - **Vi√©s de Sele√ß√£o:** Pessoas que escolhem receber um tratamento s√£o fundamentalmente diferentes daquelas que n√£o o recebem.
> 	- Exemplo: Indiv√≠duos mais saud√°veis ou mais ricos podem ter maior acesso ou propens√£o a um novo medicamento. 
>- **Noncompliance:** Mesmo em ensaios cl√≠nicos, se houver falta de ades√£o total ao tratamento, o efeito causal (como o ATE ou ATT) calculado diretamente pode estar enviesado, comprometendo os resultados e sua interpretabilidade.

A defini√ß√£o formal √©:

$$
e(X) = P(T=1 | X)
$$

Onde $T$ √© a vari√°vel de tratamento e $X$ covari√°veis.

Ao condicionarmos nas covari√°veis, o escore de propens√£o controla as vari√°veis de confus√£o, ajudando a alcan√ßarmos a independ√™ncia condicional ‚Äî o tratamento T torna-se independente do resultado potencial, desde que se condicione no escore de propens√£o, $T \perp Y^t | e(X)$.

> [!tip] üí°
> O Escore de Propens√£o √© uma ferramenta tamb√©m conhecida para redu√ß√£o de dimensionalidade. Em vez de ter que controlar dezenas de covari√°veis $X$ diretamente na an√°lise de resultado, podemos simplesmente controlar o escore $e(X)$.

> [!tip] üí°
> O conceito do Escore de Propens√£o √© estritamente aplicado a tratamentos bin√°rios (discretizados ou dicot√¥micos: Sim/N√£o). Para tratamentos cont√≠nuos, um m√©todo utilizado √© o Generalized Propensity Score (GPS), aonde modela envolta a densidade condicional, ao inv√©s da probabilidade condicional.

Importante destacar, que ainda sim, precisamos que as premissas de ignorabilidade, positividade e SUTVA devem ser respeitadas antes de aplicar. Relembrando que comentei sobre esse tema em [[path-for-the-true-and-brave/Causalidade/5. Design de Experimentos\|5. Design de Experimentos]].

Para utilizarmos o score de propens√£o, basta regredirmos a interven√ß√£o com suas covari√°veis em uma regress√£o log√≠stica. Seu resultado, final, seria a probabilidade de uma unidade receber o tratamento condicional √†s covari√°veis pr√©‚Äëtratamento X.
### Exemplo ([Causal Inference in Python: Applying Causal Inference in the Tech Industry](https://github.com/matheusfacure/causal-inference-in-python-code/blob/main/causal-inference-in-python/05-Propensity-Score.ipynb)

```python
import statsmodels.formula.api as smf

# 1. Estimar o Escore de Propens√£o 
ps_model = smf.logit("""intervention ~ 
tenure + last_engagement_score + department_score
+ C(n_of_reports) + C(gender) + C(role)""", data=df).fit(disp=0)

# 2. Adicionar o Escore de Propens√£o como nova coluna
data_ps = df.assign(
    propensity_score = ps_model.predict(df),
)

data_ps[["intervention", "engagement_score", "propensity_score"]].head()

# 3. Estimar o Efeito Causal usando o Escore de Propens√£o como covari√°vel
model = smf.ols("engagement_score ~ intervention + propensity_score",
                data=data_ps).fit()

# O coeficiente 'intervention' neste modelo representa o ATE ajustado pelo escore de propens√£o
print("ATE Ajustado por Escore de Propens√£o:", model.params["intervention"])
```
# Pondera√ß√£o por Escore de Propens√£o Inverso

Uma vez tendo esse score, podemos estimar o efeito m√©dio de tratamento. Uma das formas que podemos √© por Pondera√ß√£o por Score de Propens√£o Inverso (IPW).

A ideia de IPW √© reponderar a sua amostra para criar uma pseudo-popula√ß√£o onde a distribui√ß√£o das vari√°veis de confus√£o $X$ √© a mesma nos grupos de tratamento $T=1$ e controle $T=0$. Isto imita as condi√ß√µes de um ensaio aleat√≥rio. O peso $\mathbf{W}$ atribu√≠do a cada indiv√≠duo √© o inverso da probabilidade de o indiv√≠duo ter recebido o tratamento que realmente recebeu. Essa probabilidade √© o Escore de Propens√£o $\hat{e}(\mathbf{x})$. Utilizando desta forma, estimamos um ATE em uma popula√ß√£o observacional e voc√™ quiser criar uma pseudo‚Äëpopula√ß√£o em que o tratamento √© independente das covari√°veis observadas. 

> [!tip] 
> **Unidades Incomuns (Alto Peso):**
> - Unidades que receberam um tratamento **improv√°vel** (e.g., alto risco de rotatividade, mas **n√£o** receberam o treino) recebem um **peso alto**.
>     - Isso os torna mais **representativos** da popula√ß√£o em geral, essencialmente for√ßando um balanceamento da amostra.
> 
> **Unidades Comuns (Baixo Peso):**
> 
> - Unidades que receberam um tratamento prov√°vel recebem um peso baixo.

O peso para cada unidade $\mathbf{W}_i$ √© calculado da seguinte forma, onde $\mathbf{T}_i$ √© o tratamento real recebido:

$$
\mathbf{W}_i = \frac{1}{\mathbf{P}(\mathbf{T}_i | \mathbf{X}_i)} = \begin{cases} \frac{1}{\hat{e}(\mathbf{x}_i)} & \text{se } \mathbf{T}_i = 1 \\ \frac{1}{1 - \hat{e}(\mathbf{x}_i)} & \text{se } \mathbf{T}_i = 0 \end{cases}
$$

> [!tip] üí°
> Ao dar um peso alto a unidades tratadas que parecem unidades de controle, e unidades de controle que parecem unidades tratadas, o m√©todo garante que o grupo de tratamento e o grupo de controle na pseudo-popula√ß√£o sejam compar√°veis.

### Exemplo ([Causal Inference in Python: Applying Causal Inference in the Tech Industry](https://github.com/matheusfacure/causal-inference-in-python-code/blob/main/causal-inference-in-python/05-Propensity-Score.ipynb)

$$
\text{Efeito Causal} = \left(\begin{array}{c}\text{M√©dia ponderada do resultado} \\ \text{se todos fossem tratados}\end{array}\right) - \left(\begin{array}{c}\text{M√©dia ponderada do resultado} \\ \text{se ningu√©m fosse tratado}\end{array}\right)
$$

```python
# 1. Calcular os pesos IPW para cada grupo
weight_t = 1 / data_ps.query("intervention == 1")["propensity_score"]
weight_nt = 1 / (1 - data_ps.query("intervention == 0")["propensity_score"])

# 2. Obter os resultados (engagement_score) por grupo
t1 = data_ps.query("intervention == 1")["engagement_score"] 
t0 = data_ps.query("intervention == 0")["engagement_score"] 

# 3. Estimar o Resultado Potencial M√©dio (E[Y^t])
y1_num = sum(t1 * weight_t)  # Numerador: Somat√≥rio (Y * W) para T=1
y1_den = sum(weight_t)        # Denominador: Somat√≥rio (W) para T=1
y1 = y1_num / y1_den

y0_num = sum(t0 * weight_nt)  # Numerador: Somat√≥rio (Y * W) para T=0
y0_den = sum(weight_nt)       # Denominador: Somat√≥rio (W) para T=0
y0 = y0_num / y0_den

print("E[Y1] (Tratado):", y1)
print("E[Y0] (Controle):", y0)
print("ATE:", y1 - y0)
```
# Estimativa Duplamente Robusta

O Escore de Propens√£o $\mathbf{e}(\mathbf{X})$ e a Pondera√ß√£o por Escore de Propens√£o Inverso (IPW) s√£o ferramentas para controlar vari√°veis de confus√£o e simular a randomiza√ß√£o em dados observacionais. O IPW, em particular, √© um estimador baseado em design que se foca em balancear os grupos.
Entretanto, uma preocupa√ß√£o comum em infer√™ncia causal √© a especifica√ß√£o incorreta dos modelos. E se o modelo que usamos para calcular o Escore de Propens√£o estiver errado? Isso nos leva √† busca por estimadores mais resilientes.

## **O Conceito "Duplamente Robusto"**

Um estimador √© considerado Duplamente Robusto (Double Robust - DR) se a estimativa do efeito causal for consistente (ou seja, convergir√° para o verdadeiro efeito causal) se:

1. O modelo para o Escore de Propens√£o estiver corretamente especificado.
**OU**
2. O modelo para o outcome potencial que estima estiver corretamente especificado.

Em outras palavras, o estimador DR **c**onverge para o modelo que estiver correto. Isso confere uma vantagem e aumenta a confian√ßa na estimativa final, pois voc√™ s√≥ precisa acertar em um dos dois modelos. A ideia central √© que o estimador utiliza ambos os modelos - por exemplo, IPW + Regress√£o Log√≠stica - para construir um estimador para o resultado potencial.

Um estimador DR popular para o resultado potencial m√©dio sob tratamento pode ser escrito como:

$$
\mu_t^{DR}(\hat{\mu}, \hat{e}) = \frac{1}{N} \sum_{i=1}^{N} \left[ \hat{\mu}_t(\mathbf{X}_i) + \frac{\mathbf{T}_i - \hat{e}(\mathbf{X}_i)}{\hat{e}(\mathbf{X}_i)} \left( \mathbf{Y}_i - \hat{\mu}_t(\mathbf{X}_i) \right) \right]
$$

Onde:

- $\mathbf{Y}_i$ √© o resultado observado.
- $\mathbf{T}_i$ √© a vari√°vel de tratamento.
- $\hat{\mu}_t(\mathbf{X}_i)$  √© a previs√£o do resultado $\mathbf{Y}$ pelo modelo, assumindo o tratamento $t$
- $\hat{e}(\mathbf{X}_i)$ √© o **Escore de Propens√£o**.

Se o Escore de Propens√£o estiver correto:

O termo $\frac{\mathbf{T}_i - \hat{e}(\mathbf{X}_i)}{\hat{e}(\mathbf{X}_i)}$ tender√° a zero na m√©dia, e o segundo termo todo se anular√°.

Isto deixa apenas o primeiro termo, $\frac{1}{N} \sum_{i=1}^{N} \hat{\mu}_t(\mathbf{X}_i)$, que converge para a estimativa do resultado do modelo. Neste caso, a estimativa DR se comporta como um estimador *design-based*.

Se o modelo estiver correto:

O segundo termo, $\left( \mathbf{Y}_i - \hat{\mu}_t(\mathbf{X}_i) \right)$, tender√° a zero na m√©dia, pois $\hat{\mu}_t(\mathbf{X}_i)$ √© uma previs√£o precisa de $\mathbf{Y}_i$.

A estimativa DR converge para um estimador *outcome-based* que se baseia primariamente no modelo.


