[
{
		"title": "Digital Garden Home",
		"date":"Thu Dec 25 2025 18:15:37 GMT+0000 (Coordinated Universal Time)",
		"url":"/",
		"content": "<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/digital-garden/path-for-the-true-and-brave/text/inferencia-causal/\">Infer√™ncia Causal</a>\n<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/digital-garden/meu-modelo-conforme/text/meu-modelo-conforme/\">Meu Modelo Conforme</a>",
		"tags": [ "note","gardenEntry"]
},

{
		"title": "1. Introdu√ß√£o",
		"date":"Thu Dec 25 2025 18:15:37 GMT+0000 (Coordinated Universal Time)",
		"url":"/digital-garden/meu-modelo-conforme/text/1-introducao/",
		"content": "Introdu√ß√£o\n\n[!note]\n&quot;The true measure of a man is not his intelligence or how high he rises in this freak establishment. No, the true measure of a man is this: how quickly can he respond to the needs of others and how much of himself he can give&quot; ‚Äî Philip K. Dick\n\nOl√°! Se voc√™ encontrou este documento, significa que ou foi tapeado ou me conhece... De qualquer forma, seja bem-vindo!\nMeu nome √© Lucas Le√£o, sou Cientista de Dados ‚Äî ou pelo menos tento ser. Se voc√™, assim como eu, j√° se sentiu estagnado e desejava se aperfei√ßoar em alguma tecnologia ou teoria que s√≥ ouvia falar, saiba que estamos no mesmo barco.\nDurante minha jornada criando modelos de Machine Learning, uma d√∫vida persistia: como posso ter mais confian√ßa nos meus modelos? N√£o me entenda mal! Confio nas minhas habilidades, mas busco uma garantia extra na modelagem para evitar futuras dores de cabe√ßa, tendo melhor no√ß√£o sobre as incertezas das predi√ß√µes.\nSegundo o artigo Is there a role for statistics in artificial intelligence?, a quantifica√ß√£o de incerteza √© frequentemente negligenciada em aplica√ß√µes de intelig√™ncia artificial por dois motivos principais:\n\nFalsa cren√ßa de que &quot;Big Data&quot; automaticamente garante resultados exatos\nComplexidade dos m√©todos dificulta a cria√ß√£o de regi√µes de incerteza estatisticamente v√°lidas\n\nNos √∫ltimos anos, surgiram diversas propostas para quantificar incerteza em modelos de Machine Learning e Deep Learning. No entanto, apenas o m√©todo de Previs√£o Conforme teve sua validade te√≥rica comprovada, demonstrando intervalos de previs√£o que fornecem cobertura emp√≠rica efetiva para dados futuros ‚Äî ou seja, um intervalo de previs√£o que de fato cobre valores futuros em (1 - Œ±) das vezes.\nEste documento √© um di√°rio dessa jornada para explorar tanto a quantifica√ß√£o de incerteza quanto novos m√©todos de balanceamento de modelo. Nele, desenvolvi duas camadas adicionais ao modelo de RandomForestClassifier, atrelado ao meu objetivo de estudo. Se encontrar qualquer erro ou tiver sugest√µes de melhoria, por favor, mande-me um e-mail sem receio. Ficarei grato em revisar. Se estiver pensando em aplicar essa metodologia a outro problema, n√£o hesite em me contatar. Valeu!\nGithub\n\nhttps://github.com/heylucasleao/tinycp",
		"tags": [ "note"]
},

{
		"title": "10. Classificador Conforme",
		"date":"Thu Dec 25 2025 18:15:37 GMT+0000 (Coordinated Universal Time)",
		"url":"/digital-garden/meu-modelo-conforme/text/10-classificador-conforme/",
		"content": "Classificador Conforme\nParab√©ns por chegar a este t√≥pico. Agora, vamos explorar a s√≠ntese de todos os conceitos discutidos anteriormente e apresentar uma vis√£o detalhada do modelo que criei. Certamente, pode haver conflitos conceituais. Caso ocorra, n√£o tenha medo de me comunicar. Objetivo desse di√°rio √© demonstrar minha linha de pensamento, e como cheguei at√© aqui.\nO objetivo era desenvolver um modelo com alta adaptabilidade, flexibilidade e caracter√≠sticas espec√≠ficas oferecidas pelo RandomForest, incluindo:\n\nCapacidade de processar dados de alta dimensionalidade e extrair correla√ß√µes complexas.\nHabilidade de treinar modelos com dados de baixa frequ√™ncia.\nRobustez no tratamento de conjuntos de dados desbalanceados.\nEfici√™ncia computacional, permitindo treinamento e infer√™ncia r√°pidas.\n\nAo incorporar a calibra√ß√£o conformal (Venn-Abers), o modelo alcan√ßa:\n\nRegula√ß√£o precisa do score, transformando-o em uma medida verdadeiramente probabil√≠stica e mitigando riscos de overfitting.\nMaior confiabilidade nas previs√µes, essencial para aplica√ß√µes cr√≠ticas.\n\nA implementa√ß√£o da Previs√£o Conforme proporciona:\n\nAprimoramento significativo na interpretabilidade dos resultados do modelo.\nEstabelecimento de uma garantia de cobertura, permitindo controle preciso sobre a confian√ßa do modelo.\nFlexibilidade na modelagem do intervalo de predi√ß√£o, adapt√°vel a diferentes cen√°rios.\nCapacidade de quantificar a incerteza das previs√µes.\n\nA integra√ß√£o de propriedades de Aprendizado Sens√≠vel ao Custo oferece:\n\nVersatilidade para lidar com diversos tipos de distribui√ß√µes de dados.\nCalibra√ß√£o baseada no custo de erro e n√£o somente performance.\nCapacidade de ajustar o modelo para minimizar custos em cen√°rios assim√©tricos de erro.\n\nClassificador Conforme Bin√°rio\nUm diferencial que n√£o mencionei √© a utiliza√ß√£o de uma ideia baseada nos artigos Venn Prediction for Survival Analysis e Efficient Venn predictors using random forests. Nessa abordagem, os dados n√£o utilizados no treinamento de cada √°rvore, conhecidos como amostras OOB (Out-of-Bag), s√£o empregados para gerar nossa cobertura. A ideia √© que teremos uma representatividade populacional de cada arvore de decis√£o. Em teoria, isso elimina a necessidade de uma base de calibra√ß√£o separada. No entanto, neste caso, utilizo esses dados para outro prop√≥sito.\n√â importante ressaltar tamb√©m que transformo o conjunto de predi√ß√µes em uma √∫nica resposta: se o modelo tem certeza de que h√° apenas o r√≥tulo verdadeiro ou n√£o. Isso compromete a interpretabilidade do conjunto de predi√ß√µes do modelo. Conceitualmente, reconhe√ßo que isso pode ser question√°vel, mas o fa√ßo para obter flexibilidade na utiliza√ß√£o do Aprendizado Sens√≠vel a Custo. Vale notar que internamente ainda √© poss√≠vel recuperar essa informa√ß√£o.\nCalibra√ß√£o do Valor Œ±\nAp√≥s a cria√ß√£o do modelo conforme, ainda n√£o h√° uma defini√ß√£o clara do valor Œ±. Para determin√°-lo, calibro para o melhor resultado da acur√°cia balanceada em um intervalo de 0.01 a 0.10. O objetivo √© encontrar a melhor cobertura que permita ao modelo obter o menor custo de erro com uma garantia m√≠nima de 90%. Haver√° situa√ß√µes em que n√£o h√° raz√£o para reduzir Œ±, possibilitando seu estreitamento, enquanto em outras, o modelo poder√° ter uma efici√™ncia melhor com um aumento desse valor.\n\n[!tip] üí°\nAo unir os tr√™s t√≥picos e calibrar o Œ±, estabelecemos um n√≠vel de signific√¢ncia que equilibra o custo entre falsos positivos e falsos negativos, evita overfitting e mant√©m uma distribui√ß√£o representativa para a cobertura.\n\nAvalia√ß√£o de Performance\nPara certificar que tudo ocorreu bem com o modelo, verifico seu performance com dados de valida√ß√£o utilizando uma fun√ß√£o chamada evaluate. As m√©tricas que ele retorna s√£o:\n- &quot;total&quot;: A quantidade total de dados utilizados para avalia√ß√£o.\n- &quot;alpha&quot;: O n√≠vel de signific√¢ncia estabelecido da cobertura.\n- &quot;empirical_coverage&quot;: A cobertura emp√≠rica dos conjuntos da Previs√£o Conforme.\n- &quot;one_c&quot;: A propor√ß√£o de conjuntos de predi√ß√£o contendo exatamente um elemento.\n- &quot;avg_c&quot;: O tamanho m√©dio dos conjuntos de predi√ß√£o.\n- &quot;empty&quot;: A propor√ß√£o de conjuntos de predi√ß√£o vazios.\n- &quot;error&quot;: A taxa de erro de classifica√ß√£o.\n- &quot;log_loss&quot;: A perda logar√≠tmica das predi√ß√µes.\n- &quot;ece&quot;: O erro de calibra√ß√£o esperado.\n- &quot;bm&quot;: O √≠ndice de informa√ß√£o do bookmaker.\n- &quot;mcc&quot;: O coeficiente de correla√ß√£o de Matthews.\n- &quot;f1&quot;: O F1-Score\n- &quot;fpr&quot;: A taxa de falsos positivos.\n\nDistribui√ß√£o Beta\n\nA distribui√ß√£o Beta √© uma distribui√ß√£o de probabilidade cont√≠nua no intervalo [0, 1], ideal para observar e quantificar a incerteza na probabilidade do modelo. Sua fun√ß√£o de densidade de probabilidade √© definida por dois par√¢metros Œ± e Œ≤, que controlam a forma da distribui√ß√£o e permitem modelar diferentes tipos de incerteza probabil√≠stica. √â importante destacar que, devido ao rigor da Previs√£o Conforme, a cobertura segue naturalmente essa distribui√ß√£o, assegurando a confiabilidade do modelo. Embora n√£o seja estritamente necess√°rio analisar a Beta especificamente para este fim, n√£o discrimino o uso para an√°lises posteriores, como nos testes A/B.\nRefer√™ncia de meu Projeto\nhttps://github.com/HeyLucasLeao/cp-study/blob/master/cp.ipynb",
		"tags": [ "note"]
},

{
		"title": "11. Refer√™ncias",
		"date":"Thu Dec 25 2025 18:15:37 GMT+0000 (Coordinated Universal Time)",
		"url":"/digital-garden/meu-modelo-conforme/text/11-referencias/",
		"content": "Refer√™ncias\n\nInterpretable Uncertainty\nUnlocking Reliable Machine Learning: Conformal Prediction by Valery Manokhin\nDistribution-Free Uncertainty Quantification\nUncertainty Quantification: Enter Conformal Predictors\nUnderstanding, Generating, and Evaluating Prediction Intervals\nIntroduction To Conformal Prediction With Python: A Short Guide For Quantifying Uncertainty Of Machine Learning Models\nA Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification\nPractical Guide to Applied Conformal Prediction in Python: Learn and apply the best uncertainty frameworks to your industry applications\nUma Introdu√ß√£o Pr√°tica √† Previs√£o Conforme\nCalibrando Modelos de Classifica√ß√£o Bin√°ria com Previs√£o Conforme\nAplicando Previs√£o Conforme em Modelos de Classifica√ß√£o\nHow to calibrate your classifier in an intelligent way using Venn-Abers Conformal Prediction\nWeek #4: Overview Of Conformal Predictors\nWeek #2: Intuition Behind Conformal Prediction\nWeek #1: Getting Started With Conformal Prediction For Classification\nConformal Prediction: Prediction with guaranteed performance\nIsotonic Regression : Another Level of Regression Method\nExpected Calibration Error (ECE): A Step-by-Step Visual Explanation\nConformal prediction for classification",
		"tags": ["4", "2", "1", "note"]
},

{
		"title": "12. Regress√£o",
		"date":"Thu Dec 25 2025 18:15:37 GMT+0000 (Coordinated Universal Time)",
		"url":"/digital-garden/meu-modelo-conforme/text/12-regressao/",
		"content": "Regress√£o\n\nNa predi√ß√£o, estimamos resultados com base em dados hist√≥ricos, assumindo que padr√µes passados podem nos ajudar a prever o futuro ‚Äî sempre considerando um grau de incerteza. Na regress√£o, buscamos estimar um ponto espec√≠fico. Por exemplo, na regress√£o linear, projetamos uma linha baseada em valores m√©dios para obter o resultado desejado. Por√©m, estatisticamente, isso nos diz pouco: qual √© o n√≠vel de incerteza do modelo? Que garantia temos de que minha casa realmente vale R$535.295?\nEm 1937, Jerzy Neyman introduziu o conceito de intervalos de confian√ßa, argumentando que determinar um valor exato para um par√¢metro populacional baseado em amostras tem utilidade limitada. √â mais valioso estabelecer um intervalo de valores poss√≠veis, com um n√≠vel de confian√ßa definido de que o valor real esteja contido nele. Assim, podemos avaliar o grau de incerteza ao estimar um par√¢metro. No contexto de previs√£o, este conceito √© bastante relevante. A variabilidade e incerteza, sejam aleat√≥rias ou epist√™micas, frequentemente dificultam a representa√ß√£o de todos os cen√°rios poss√≠veis. Por isso, quantificar a incerteza do modelo pode ser mais √∫til do que simplesmente fornecer um ponto m√©dio. √â aqui que entra a regress√£o quant√≠lica: em vez de estimar um ponto m√©dio, ela estima via quantil ‚Äî o que √© mais representativo para distribui√ß√µes adversas de dados no dia a dia ‚Äî permitindo-nos estimar duas previs√µes e utiliz√°-las como intervalo.\n\nEntretanto, a regress√£o quant√≠lica n√£o oferece garantia estat√≠stica de cobertura da previs√£o. Embora seja mais informativa, falta essa garantia formal. √â nesse contexto que a previs√£o conforme se torna valiosa. Por exemplo, em vez de afirmar que minha casa vale R$535.295, posso apresentar um intervalo com 95% de confian√ßa: entre R$515.629 e R$545.800. Mesmo sem um valor exato, tenho uma margem confi√°vel do poss√≠vel valor da casa e sei em qual faixa o modelo est√° seguro. Considere outro cen√°rio: e se o intervalo fosse de R$480.000 a R$800.000? Tal amplitude indicaria claramente um problema no resultado. Seriam as caracter√≠sticas da minha casa que dificultam a previs√£o? A regi√£o onde moro influencia os pre√ßos? Ou o modelo est√° simplesmente incorreto? Todas essas an√°lises se tornam poss√≠veis ao examinar a amplitude do intervalo ‚Äî algo que um valor pontual estimado jamais nos permitiria.\nAp√≥s a cria√ß√£o do m√©todo de Previs√£o Conforme para classifica√ß√£o na minha biblioteca, aprendi muito sobre o m√©todo e o tema em geral. Com isso, decidi expandir o projeto, oferecendo suporte cont√≠nuo √† biblioteca. Para aprofundar meu entendimento, implementei dois m√©todos de regress√£o usando ICP simples via divis√£o de dados de treino e calibra√ß√£o: o ConformalizedRegression e o ConformalizedQuantileRegression.\n\nA diferen√ßa maior √© que ConformalizedRegression aceita um modelo de regress√£o normal baseado no scikit-learn , e o ConformalizedQuantileRegression(CQR), que aceita modelos que preditam intervalos quant√≠licos, baseado no quantile-forest . A raz√£o disso √© que originalmente, a regress√£o conforme foi introduzida criando intervalos com a previs√£o estimada do modelo. O √∫nico problema que devido a forma desse treino, √© que o modelo original n√£o √© capaz de ser t√£o adaptivo com a distribui√ß√£o dos dados, tornando o intervalo da previs√£o menos abrangente. Para sanar isso, o ConformalizedQuantileRegressor se torna melhor para essas previs√µes, devido ao modelo utiliza ser um modelo quantil que predita um intervalo de previs√£o, identificando intervalos mais adaptativos entre os dados. E sim, ambos aceitam gera√ß√£o da cobertura baseado em Out-Of-Bag (OOB).",
		"tags": [ "note"]
},

{
		"title": "2. Antes de Come√ßarmos‚Ä¶",
		"date":"Thu Dec 25 2025 18:15:37 GMT+0000 (Coordinated Universal Time)",
		"url":"/digital-garden/meu-modelo-conforme/text/2-antes-de-comecarmos/",
		"content": "Antes de come√ßarmos...\nA Import√¢ncia da Incerteza\nAntes de mais nada, queria compartilhar uma reflex√£o importante. Minha jornada com ci√™ncia de dados me fez perceber algo interessante: quanto mais me aprofundava nesse campo, mais distante ficava do pensamento estat√≠stico tradicional. A raz√£o? A estat√≠stica trabalha fundamentalmente com a √≥tica da incerteza e nossa compreens√£o das limita√ß√µes dos resultados.\nSegundo o artigo Importance of being uncertain:\n\nA estat√≠stica nos ajuda a responder esta quest√£o. Ela nos fornece uma maneira de modelar quantitativamente o papel do acaso em nossos experimentos e representar dados n√£o como medi√ß√µes precisas, mas como estimativas com erro. Tamb√©m nos mostra como o erro em valores de entrada se propaga atrav√©s dos c√°lculos. A aplica√ß√£o pr√°tica deste framework te√≥rico √© associar incerteza ao resultado dos experimentos e atribuir n√≠veis de confian√ßa a afirma√ß√µes que generalizam al√©m das observa√ß√µes.\n\nPercebi que estava sempre focando no acerto, e n√£o no erro! Pode parecer uma reflex√£o simples, mas isso muda totalmente nosso paradigma di√°rio: devemos buscar estar menos errados, n√£o mais certos. √â preciso aceitar viver sob a incerteza, reconhecendo o papel do erro. Altay Souza enfatiza esse conceito frequentemente em suas aulas de Estat√≠stica Aplicada √† Psicobiologia, pela UNIFESP. Para entender mais esse entendimento, recomendo suas oito primeiras aulas ‚Äî ser√£o √∫teis para a vida inteira, prometo.\nDe volta aos Princ√≠pios\nAndrey Kolmogorov, matem√°tico nascido no s√©culo XX, foi crucial para o desenvolvimento da ci√™ncia moderna. Suas contribui√ß√µes inestim√°veis abrangem desde a biologia, topologia e geologia at√© a teoria da probabilidade. Ele revolucionou nossa compreens√£o cient√≠fica de tal forma que, sem suas descobertas, este artigo possivelmente nem existiria. Kolmogorov estabeleceu n√£o apenas a defini√ß√£o matem√°tica da probabilidade por meio de seus axiomas, mas tamb√©m descreveu o Teorema Central do Limite. Seus axiomas n√£o s√£o meras constru√ß√µes matem√°ticas ‚Äî s√£o padr√µes fundamentais observados na natureza, compar√°veis √†s leis da f√≠sica como a gravidade. Assim como podemos observar e comprovar a gravidade empiricamente, os axiomas probabil√≠sticos se manifestam em fen√¥menos naturais, da gen√©tica √† mec√¢nica qu√¢ntica, demonstrando sua validade universal.\nA teoria da probabilidade de Kolmogorov marcou a matem√°tica moderna ao estabelecer uma base axiom√°tica rigorosa para seu estudo. At√© seu trabalho em 1933, a teoria carecia de fundamento matem√°tico formal. Com sua obra &quot;Fundamentos da Teoria da Probabilidade&quot;, ele unificou diferentes interpreta√ß√µes da probabilidade em uma √∫nica estrutura matem√°tica coerente.\nSua abordagem revolucion√°ria combinou a teoria dos conjuntos com a teoria da medida para definir probabilidade de forma matematicamente precisa. Essa formaliza√ß√£o estabeleceu a teoria da probabilidade como um campo independente da matem√°tica, permitindo representar eventos probabil√≠sticos atrav√©s de fun√ß√µes.\nSua contribui√ß√£o vai al√©m da formaliza√ß√£o matem√°tica ‚Äî oferece um framework que permite modelar fen√¥menos aleat√≥rios em diversos campos cient√≠ficos, da f√≠sica qu√¢ntica √† biologia molecular, economia e ci√™ncia da computa√ß√£o.\nPara fundamentar isso, ele estabeleceu tr√™s axiomas da teoria da probabilidade:\n\nN√£o-negatividade: A probabilidade de qualquer evento deve ser maior ou igual a zero.\n\nP(A)‚àà‚Ñù+\nNormaliza√ß√£o: A probabilidade do espa√ßo amostral total (Œ©) √© igual a 1.\n\nP(Œ©)=1\nAditividade: Para eventos mutuamente exclusivos, a probabilidade da uni√£o √© igual √† soma das probabilidades individuais.\n\nP(A‚à™B)=P(A)+P(B)\n[!note] üìå\nEstes axiomas s√£o importantes porque:\n\nFornecem uma base matem√°tica rigorosa para o c√°lculo de probabilidades\nPermitem derivar todas as outras regras e teoremas de probabilidade\nS√£o fundamentais para entender o Teorema Central do Limite\n\nCom base nesses axiomas, ele enunciou o Teorema do Limite Central, que demonstra:\n\nAo coletar m√∫ltiplas amostras de uma popula√ß√£o e calcular suas m√©dias, a distribui√ß√£o dessas m√©dias amostrais tende a uma distribui√ß√£o normal, independentemente da distribui√ß√£o original dos dados (sendo necess√°rias no m√≠nimo 30 amostras para esta converg√™ncia, conforme seu experimento).\nA m√©dia dessas m√©dias amostrais converge consistentemente para a verdadeira m√©dia populacional.\n\nIsso nos permite utilizar amostras para estimar par√¢metros populacionais, eliminando a necessidade de dados censit√°rios.\nPara ver a prova visual do TLC, basta clicar no link abaixo. Voc√™ perceber√° que quanto mais amostras forem coletadas, mais a distribui√ß√£o da amostra tender√° a uma normal, com sua m√©dia convergindo para a m√©dia da popula√ß√£o.\nProbability Distributions\nEste conceito √© um dos pilares para a infer√™ncias sobre popula√ß√µes a partir de amostras. Com isso, conseguimos criar intervalos de confian√ßa.\nCaso queira saber mais sobre Kolmogorov, sugiro esse link.\nIntervalo de Confian√ßa\nDesenvolvido por Jerzy Neyman em 1937, como parte de sua teoria de estima√ß√£o por intervalos. Esta contribui√ß√£o ofereceu uma alternativa mais robusta √†s estimativas pontuais.\nNeyman prop√¥s que, ao inv√©s de tentar adivinhar o valor exato de um par√¢metro populacional, seria mais √∫til estabelecer um intervalo de valores prov√°veis, junto com um n√≠vel de confian√ßa associado. Esta abordagem reconhece explicitamente a incerteza inerente √† infer√™ncia estat√≠stica.\n\n[!tip] üí°\nA interpreta√ß√£o correta de um intervalo de confian√ßa de 95% √©:\nSe repet√≠ssemos o processo de amostragem muitas vezes e calcul√°ssemos o intervalo de confian√ßa para cada amostra, aproximadamente 95% desses intervalos conteriam o verdadeiro par√¢metro populacional.\n\nEsta interpreta√ß√£o frequentista √© crucial para entender que o intervalo de confian√ßa n√£o nos diz a probabilidade de que o par√¢metro populacional esteja dentro do intervalo calculado, mas sim a confiabilidade do m√©todo de constru√ß√£o do intervalo ao longo de m√∫ltiplas amostras. Uma boa representa√ß√£o visual do intervalo de confian√ßa pode ser vista por aqui.\n\n√â importante termos uma no√ß√£o sobre os temas demonstrados pois s√£o cruciais para a entendermos a Previs√£o Conforme. Nele, iremos quantificar a incerteza, melhorarmos nossa confiabilidade e interpretabilidade do modelo.",
		"tags": [ "note"]
},

{
		"title": "3. Probabilidade e Calibra√ß√£o de Modelo",
		"date":"Thu Dec 25 2025 18:15:37 GMT+0000 (Coordinated Universal Time)",
		"url":"/digital-garden/meu-modelo-conforme/text/3-probabilidade-e-calibracao-de-modelo/",
		"content": "Probabilidade e Calibra√ß√£o de Modelo\nA probabilidade do modelo √© um conceito crucial na aprendizagem de m√°quina. Ela representa a confian√ßa do modelo em suas previs√µes, oferecendo insights sobre seu desempenho e confiabilidade.\nA ideia em geral √© que essa probabilidade, seja emp√≠rica, ou seja, refletindo que dados similares caem nesse percentual.\nImagine um modelo de vis√£o computacional que verifica se as cerejas do caf√© est√£o maduras o suficiente para colheita. Se separarmos todas as cerejas √†s quais o modelo atribuiu um score probabil√≠stico de 0.80 e, manualmente, verificarmos que 40% delas est√£o realmente maduras, logo que o modelo est√° descalibrado. Isso poder√° trazer risco a colheita, dando falsas expectativas e sendo imprevisivel seus resultados, demonstrando uma alta confian√ßa. Em contra partida, a calibra√ß√£o quando bem feita oferece maior seguran√ßa de que o modelo se comportar√° adequadamente em um ambiente de produ√ß√£o, al√©m de fornecer informa√ß√µes importantes sobre as incertezas do modelo, proporcionando previsibilidade para os stakeholders.\nIsto √© bem exemplificado no artigo Calibration: the Achilles heel of predictiveanalytics:\n\nSe o algoritmo √© usado para informar pacientes, estimativas de risco mal calibradas levam a falsas expectativas tanto para pacientes quanto para profissionais de sa√∫de. Os pacientes podem tomar decis√µes pessoais antecipando um evento, ou sua aus√™ncia, que na verdade eram equivocadas. Por exemplo, considere um modelo de predi√ß√£o que prev√™ a chance de um tratamento de fertiliza√ß√£o in vitro (FIV) resultar em um nascimento [14]. Independentemente do qu√£o bem os modelos possam discriminar entre tratamentos que resultam em nascimento versus aqueles que n√£o resultam, √© claro que uma super ou subestima√ß√£o da chance de nascimento torna os algoritmos clinicamente inaceit√°veis. Por exemplo, uma forte superestima√ß√£o da chance de nascimento ap√≥s FIV daria falsas esperan√ßas a casais que j√° est√£o passando por uma experi√™ncia estressante e emocional. Tratar um casal que, na realidade, tem um progn√≥stico favor√°vel exp√µe a mulher desnecessariamente a poss√≠veis efeitos colaterais prejudiciais, como a s√≠ndrome de hiperestimula√ß√£o ovariana.\n\nProbability Calibration : Data Science Concepts\nN√£o √© um problema novo\nGlenn W. Brier, meteorologista, enfrentou um problema similar em meados do s√©culo 20 com previs√µes do tempo. Como poderia avaliar a precis√£o de suas estimativas em rela√ß√£o ao que realmente acontecia? Foi assim que desenvolveu o &quot;Brier Score&quot;, uma m√©trica que avalia a precis√£o das previs√µes probabil√≠sticas, comparando as probabilidades previstas com os resultados observados. Um score menor indica previs√µes mais precisas. At√© os dias de hoje, √© uma m√©trica essencial para entendermos o comportamento de nossas previs√µes.\nThe Brier Score Explained | Model Calibration\nOutra m√©trica utilizada nesse contexto √© o Log Loss, que quantifica a incerteza na probabilidade das predi√ß√µes do modelo, comparando-as com os resultados reais. Utilizar essas duas m√©tricas pode fornecer perspectivas diferentes sobre o desempenho do modelo.\nEm geral, modelos de ML n√£o garantem boa calibra√ß√£o, ou seja, seu score probabil√≠stico pode n√£o representar realmente uma probabilidade. Isso √© evidenciado na palestra de Guillaume Lemaitre, que tamb√©m demonstra como t√©cnicas populares de balanceamento podem prejudicar bastante essa calibra√ß√£o.\nUma forma de observar isso √© atrav√©s da curva de confiabilidade, que compara as probabilidades previstas pelo modelo com as frequ√™ncias reais observadas dos eventos. Ela demonstra se o modelo est√° bem calibrado, confiante demais ou n√£o. Para compara√ß√£o, √© criada uma linha diagonal perfeita que representa um modelo perfeitamente calibrado, onde as probabilidades previstas correspondem exatamente √†s frequ√™ncias observadas. Se a curva de predi√ß√£o ficar abaixo da linha diagonal, significa que o modelo est√° confiante demais, prevendo probabilidades mais altas do que deveria em rela√ß√£o ao percentual real de ocorr√™ncias. Caso a curva fique acima da linha diagonal, sugere que o modelo est√° subestimando suas previs√µes, sendo menos confiante do que deveria.\n\nTendo isso em mente, vamos considerar um cen√°rio: voc√™ est√° desenvolvendo um modelo de predi√ß√£o para identificar quando seu pedido no iFood pode resultar em uma experi√™ncia ruim. Para isso, voc√™ coletou 10 caracter√≠sticas de 100.000 pedidos (sim, voc√™ adora pedir comida!) ao longo de 5 anos. Ao analisar os dados, voc√™ percebeu que a distribui√ß√£o √© desbalanceada ‚Äî apenas 20% dos registros indicam uma experi√™ncia negativa. Isso √© um bom sinal, mas como seu modelo se comportaria com esse desbalanceamento? Voc√™ decide, ent√£o, experimentar quatro tipos de modelos:\n\nRandomForestClassifier (RF) sem nenhum tratamento nos dados\nBalancedRandomForestClassifier\nRF utilizando a t√©cnica de Random Under-Sampling (RUS)\nRF utilizando a t√©cnica de Synthetic Minority Over-sampling Technique (SMOTE)\nhttps://github.com/HeyLucasLeao/cp-study/blob/master/calibration_demo.ipynb\n\nFeito esses quatro modelos, se depara com isso:\nCurva de Confiabilidade\n\nO modelo sem tratamento do desbalanceamento de dados √©, na verdade, melhor calibrado do que aqueles que utilizaram t√©cnicas de reamostragem, como SMOTE, ROS ou RUS. Isto tamb√©m √© evidenciado em diversos, artigo, como por exemplo:\n\nThe harm of class imbalance corrections for risk prediction models: illustration and simulation using logistic regression\nThe harms of class imbalance corrections for machine learning based prediction models: a simulation study\nStop Oversampling for Class Imbalance Learning: A Critical Review\n\nAl√©m disso, observa-se que alguns modelos s√£o naturalmente descalibrados ap√≥s seu treinamento, independentemente do tratamento de dados. Conforme demonstrado no artigo Probabilistic Prediction in scikit-learn, √© necess√°rio adicionar um m√©todo de calibra√ß√£o para melhorar as estimativas.\nVenn-Abers\nNesse contexto, utilizo o Venn-Abers, um modelo de calibra√ß√£o que fornece um intervalo de probabilidade, auxiliando na interpreta√ß√£o e quantifica√ß√£o da incerteza na previs√£o de um modelo. Para obter as probabilidades, o m√©todo usa regress√£o isot√¥nica para calibrar as previs√µes, aplicando-a duas vezes: primeiro assumindo que o r√≥tulo verdadeiro √© 0, depois assumindo que √© 1. Esse processo gera duas fun√ß√µes de calibra√ß√£o, f0 e f1, que calculam os intervalos de probabilidade e representam os limites inferior e superior da probabilidade do r√≥tulo ser 1. √â poss√≠vel tamb√©m trabalhar com uma √∫nica probabilidade como resultado, que √© o que faremos neste projeto. O artigo original sugere a f√≥rmula:\np=p11‚àíp0+p1Reamostragem\nConsiderando que a reamostragem prejudica a calibra√ß√£o do modelo, decidi abordar o problema das classes de outra maneira, preservando a distribui√ß√£o original dos dados. √â importante ressaltar tamb√©m que o desbalanceamento por si s√≥ nem sempre prejudica o modelo ‚Äî h√° arquiteturas pensadas nestes cen√°rios, regularizando o vi√©s. Durante anos, existiu uma concep√ß√£o de que √°rvores de decis√£o, quando aplicadas em dados desbalanceados, inevitavelmente produziriam modelos enviesados para a classe majorit√°ria. Entretanto, existem evid√™ncias de que √°rvores de decis√£o s√£o capazes de lidar com esse cen√°rio e, em algumas situa√ß√µes, podem at√© desenvolver uma tend√™ncia favor√°vel √† classe minorit√°ria, com ajustes espec√≠ficos. No caso do RandomForestClassifier, por exemplo, ajustamos o crit√©rio do modelo com base na propor√ß√£o das classes, o que auxilia na generaliza√ß√£o. Para um entendimento mais profundo, sugiro a leitura do artigo Towards understanding the bias in decision trees.",
		"tags": [ "note"]
},

{
		"title": "4. Previs√£o Conforme",
		"date":"Thu Dec 25 2025 18:15:37 GMT+0000 (Coordinated Universal Time)",
		"url":"/digital-garden/meu-modelo-conforme/text/4-previsao-conforme/",
		"content": "Previs√£o Conforme\nA melhor descri√ß√£o que encontrei sobre o tema encontra-se no artigo Theoretical Foundations of Conformal Prediction, que descreve como:\n\nA previs√£o conforme √© uma abordagem estat√≠stica para quantifica√ß√£o de incerteza onde as previs√µes do modelo s√£o acompanhadas por um **intervalo **ou conjunto, comunicando o grau de confiabilidade em qualquer previs√£o, sem depender de pressupostos sobre a certeza do modelo.\n\nPortanto, √© um framework de aprendizagem de m√°quina que permite quantificar incertezas e criar intervalos de predi√ß√£o. Isso possibilita melhores interpreta√ß√µes do modelo, maior seguran√ßa e garantias de probabilidade emp√≠rica nos resultados.\nSuas vantagens s√£o:\n\nCobertura Garantida: As regi√µes de previs√£o oferecem garantias de cobertura para o resultado final.\nAgnosticismo de Modelo: √â compat√≠vel com qualquer modelo ou √°rea de Machine Learning.\nIndepend√™ncia de Distribui√ß√£o: As previs√µes conformes n√£o pressup√µem uma distribui√ß√£o de probabilidade espec√≠fica (Gaussiana, Gama, Poisson etc.), ampliando sua aplicabilidade.\nAus√™ncia de Retreino: N√£o √© necess√°rio reestimar o modelo ap√≥s a previs√£o inicial.\nPredi√ß√£o Probabil√≠stica: Oferece previs√µes com medidas de confian√ßa, permitindo controlar o n√≠vel de garantia do pr√≥prio modelo.\nFlexibilidade de Tamanho de Dados: A validade das previs√µes √© mantida independentemente do tamanho do conjunto de dados. Contudo, um conjunto de dados pequeno para calibra√ß√£o gera menos valor se comparado a uma volumetria maior.\nEfici√™ncia Computacional: As previs√µes mant√™m a efici√™ncia computacional, sendo ideais para aplica√ß√µes em tempo real e grandes conjuntos de dados.\n\nExistem dois tipos de categorias: Transductive Conformal Prediction (TCP) e Inductive Conformal Prediction (ICP).\nTransductive Conformal Prediction (TCP):\nO TCP foi o m√©todo original de Previs√£o Conforme. Sua caracter√≠stica principal √© que, para cada novo ponto de dados, o modelo √© treinado inteiramente para cada resultado poss√≠vel. Por exemplo, em um modelo bin√°rio de classifica√ß√£o, o modelo ser√° treinado uma vez para o valor 0 e outra para o valor 1, calculando um score de n√£o conformidade para cada caso.\n\n[!tip] üí°\nOu seja, o modelo ir√° ser treinado para cada r√≥tulo e para cada ponto novo a ser testado!\n\nEsse processo garante alta precis√£o, pois considera toda a informa√ß√£o dispon√≠vel para cada previs√£o. Este processo se assimila na t√©cnica Jacknife, que faz uma √© um processo de leave-one-out para estima√ß√£o de vari√¢ncia e vi√©s , aonde:\n\nRemove de forma **n√£o **aleat√≥ria uma observa√ß√£o por vez do conjunto de dados\nCalcula a estat√≠stica de interesse com as observa√ß√µes restantes\nUtiliza essas estimativas para avaliar o vari√¢ncia e vi√©s do estimador\n\nNo contexto da Previs√£o Conforme, esta abordagem tem como objetivo as estimativas de incerteza, embora‚Å†, em contra partida pode ser computacionalmente ineficiente dependendo da quantidade de dados tanto de treinamento, como para teste.\nInductive Conformal Prediction (ICP):\nO ICP foi desenvolvido como uma alternativa mais eficiente ao TCP. Nele treinamos uma √∫nica vez utilizando dados separados ao do treinamento do nosso modelo base. Com esse conjunto de dados de calibra√ß√£o, geramos um intervalo que s√£o aplicados a novos dados para previs√£o.\nEmbora o TCP ofere√ßa potencialmente maior precis√£o, o ICP √© geralmente preferido em aplica√ß√µes pr√°ticas devido √† sua efici√™ncia computacional, especialmente em cen√°rios com a necessidade de previs√µes em tempo real.\nUma explica√ß√£o visual sobre a diferen√ßa de ambos pode ser vista por aqui:\nUncertainty Quantification (3): From Full to Split Conformal Methods\nLogo, para este projeto, farei apenas o m√©todo ICP.\nCobertura Garantida\nPara compreender a garantia de cobertura, vamos analisar duas express√µes matem√°ticas fundamentais:\nP(Yn+1‚ààC(Xn+1))‚â•1‚àíŒ±Ela que a probabilidade do pr√≥ximo valor Y estar contido no conjunto de predi√ß√£o C(Xn+1) √© de pelo menos 1-Œ±, onde Œ± representa nossa taxa de erro desejada.\nC(Xn+1)={y‚ààY:s(Xn+1,y)‚â§q^}Esta segunda express√£o define o conjunto de predi√ß√£o utilizando um score de n√£o-conformidade. Este score, calculado a partir de novos dados, √© comparado com o quantil conforme (qÃÇ), que estabelece nosso limiar para dados conformes. Em termos pr√°ticos, isso cria um conjunto de predi√ß√£o onde temos uma garantia probabil√≠stica de 1-Œ± de que o pr√≥ximo valor Y estar√° contido.\nPara que isso seja respeitado, devemos assumir que os dados respeitem a permutabilidase e que sejam dados independentes e identicamente distribu√≠dos (i.i.d.), assegurando a validade estat√≠stica da cobertura.\nPermutabilidade\nO termo se refere √† propriedade de uma sequ√™ncia de vari√°veis aleat√≥rias em que a ordem de aparecimento n√£o afeta sua distribui√ß√£o de probabilidade conjunta.\nEm termos mais simples, significa que os elementos de uma sequ√™ncia podem ser reorganizados sem afetar suas propriedades probabil√≠sticas fundamentais. Por exemplo:\nImagine uma urna com 3 bolas coloridas (vermelha, azul e verde) das quais voc√™ vai retirar uma a uma. Considere as seguintes sequ√™ncias poss√≠veis:\n\nSequ√™ncia 1: (Vermelha, Azul, Verde)\nSequ√™ncia 2: (Verde, Vermelha, Azul)\nSequ√™ncia 3: (Azul, Verde, Vermelha)\n\nSe as bolas s√£o retiradas aleatoriamente e recolocadas, a probabilidade de obter qualquer uma dessas sequ√™ncias √© id√™ntica. Isso demonstra que a sequ√™ncia √© permut√°vel ‚Äî voc√™ pode reorganizar os elementos e a distribui√ß√£o de probabilidade permanece inalterada.\nEm resumo, para que a previs√£o conforme funcione adequadamente, os dados de calibra√ß√£o devem seguir a mesma distribui√ß√£o dos dados que ser√£o preditos no dia a dia. Podemos validar isso atrav√©s de diferentes m√©todos: an√°lise de cobertura emp√≠rica, que abordarei posteriormente, teste t de Student ou teste de Kolmogorov-Smirnov.",
		"tags": [ "note"]
},

{
		"title": "5. Treinamento",
		"date":"Thu Dec 25 2025 18:15:37 GMT+0000 (Coordinated Universal Time)",
		"url":"/digital-garden/meu-modelo-conforme/text/5-treinamento/",
		"content": "Treinamento\nNos meus projetos iniciais de carreira, como o de ansiedade e pandemia em √©poca de Covid-19 ou o balan√ßo sobre os dados e previsibilidade sobre a pandemia na regi√£o do Amazonas, eu acreditava que apenas gerar o F1 Score ou analisar o ROC-AUC resolveria todos os meus problemas. Por√©m, quando me deparava com novos dados, eu n√£o sabia o que estava acontecendo. Percebi, tarde demais, que o modelo n√£o estava calibrado!\n\nPara resolver esse problema, uma op√ß√£o √© transformar nosso modelo em um modelo conforme, que descrevi anteriormente. Eu at√© poderia ter parado apenas na camada de calibra√ß√£o Venn-Abers, que por si s√≥ j√° transforma nosso modelo em um conforme, mas a gera√ß√£o de cobertura nos d√° outras interpretabilidades e possibilidades, que irei comentar no pr√≥ximos t√≥picos.\n\n[!tip] üí°\nN√£o h√° necessidade de termos uma modelo de calibra√ß√£o se quiser calibrar fazendo uma cobertura de previs√£o conforme. Apenas fa√ßo para melhorar integridade das probabilidades.\n\nDivis√£o de Dados\nVamos seguir este processo:\n\nDurante o treinamento, dividiremos os dados em tr√™s partes: dados de treinamento, calibra√ß√£o e valida√ß√£o.\n\nPor motivos de vi√©s, n√£o utilizamos a mesma massa de dados de treinamento do modelo para gerar o nosso ponto de corte para cobertura de dados conformes.\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\nX_train, X_calib, y_train, y_calib = train_test_split(X_train, y_train, test_size=0.25, random_state=42)\n\nPor conta de meu projeto, vou permanecer com RandomForestClassifier, mas pode ser qualquer um. A fim de simplicidade, deixarei tamb√©m para termos apenas 2 classes de previs√£o.\n\nrf = RandomForestClassifier(random_state=42, n_jobs=-1)\nrf.fit(X_train, y_train)\n\nGrau de Incerteza\nPrecisamos tornar esse modelo conforme. Para isso, vamos estabelecer um limite m√°ximo de incerteza do modelo para determinar se a classe predita √© provavelmente a verdadeira.\nEsse grau de incerteza √© chamado de score de n√£o-conformidade. Existem v√°rias maneiras de calcul√°-lo, mas para simplificar, usaremos o Hinge Loss, tamb√©m conhecido como probabilidade inversa. Este score √© calculado como 1 ‚àí P(y), onde P(y) √© a predi√ß√£o do seu modelo. Podemos interpret√°-lo como a dist√¢ncia entre a previs√£o do nosso modelo e a label verdadeira. Quanto mais pr√≥ximo de 1, mais incerto √© o resultado; quanto mais pr√≥ximo de 0, mais certo.\nCobertura\nDurante o treinamento utilizamos esse score apenas para as probabilidades das classes verdadeiras, a fim de gerar um ponto de corte. Esse ponto separa novos dados que podem conter cada uma das classes em potencial. Chamamos isso de cobertura, pois garante com um grau de confiabilidade que a label verdadeira estar√° dentro do conjunto de predi√ß√£o. Abordaremos esse conceito com mais detalhes posteriormente.\n# Total de Dados\nn = len(X_calib)\n\n# Score do Modelo\ny_prob = model.predict_proba(X_calib)\n\n# Filtramos apenas para as probabilidades das labels verdadeiras\ny_prob = y_prob[np.arange(n),y_calib]\n\n# Hinge Loss\nnon_conformity_score = 1 - y_prob\n\nUma vez gerado, criaremos o qÃÇ , que √© um ponto de corte baseado em medida de posi√ß√£o. Para todos os scores de n√£o-conformidade, ordenamos seus valores do maior para o menor. Isso nos permite tra√ßar um quantil baseado no n√≠vel de confian√ßa, garantindo um percentual de cobertura.\nRecapitulando, o processo envolve:\n\nDefinir nosso n√≠vel de confian√ßa Œ±.\nGerar o qÃÇ, que ser√° o quantil (1 - Œ±) desse score ordenado, do maior para o menor. Esse √© o percentual de garantia. Por exemplo: com um Œ± de 0.10, teremos um ponto de corte com 90% de garantia.\n\nn = len(nonconformity_score)\nalpha = 0.1\nq_level = np.ceil((n + 1) * (1 - alpha)) / n\nqhat = np.quantile(nonconformity_score, q_level, method=&quot;higher&quot;)\n\n[!tip] üí°\n\nO q_level √© necess√°rio para ajustar a posi√ß√£o do quantil dentro do conjunto de dados finito, distribuindo adequadamente as posi√ß√µes dos quantis.\n\nCom todos os elementos gerados, podemos plotar o resultado. √â importante lembrar que tudo abaixo desse qÃÇ tem cobertura garantida. Dessa forma, os 90% de cobertura significam que h√° a garantia de 90% para a classe verdadeira estar contida no conjunto de predi√ß√£o. √â por essa raz√£o que se utiliza o termo &quot;incerteza rigorosa&quot; para Previs√£o Conforme ‚Äî existe uma probabilidade emp√≠rica por tr√°s disso!\nfig = px.histogram(\nnonconformity_score,\ntitle=&quot;Score de N√£o Conformidade&quot;,\ncolor_discrete_sequence=[&quot;grey&quot;, &quot;orange&quot;],\nwidth=800,\nheight=400)\nfig.update_yaxes(title_text=&quot;Total&quot;)\nfig.update_xaxes(title_text=&quot;Score&quot;)\nfig.update_layout(legend=dict(title=&quot;Label&quot;))\nfig.add_vline(x=qhat, line_dash=&quot;dash&quot;, line_color=&quot;black&quot;, annotation_text=&quot;qhat&quot;, annotation_position=&quot;top&quot;)",
		"tags": [ "note"]
},

{
		"title": "6. Escoragem",
		"date":"Thu Dec 25 2025 18:15:37 GMT+0000 (Coordinated Universal Time)",
		"url":"/digital-garden/meu-modelo-conforme/text/6-escoragem/",
		"content": "Escoragem\nAnteriormente, geramos a cobertura para os conjuntos de previs√£o. Na verdade, o m√©todo que utilizamos √© o mais tradicional, conhecido como cobertura marginal. Ele √© excelente para situa√ß√µes em que se deseja atender √† distribui√ß√£o como um todo. Por√©m, dependendo do seu problema, sua adaptabilidade ‚Äî ou seja, a capacidade de atender √†s classes espec√≠ficas ‚Äî pode n√£o ser ideal. N√£o h√° certo ou errado; √© preciso entender o que melhor atende ao seu problema. Existem diversos outros m√©todos, cada um com suas vantagens e desvantagens, como o RAPS, cobertura ass√≠metrica e classe condicional, conhecida tamb√©m como Mondrian.\n\nA ideia da previs√£o √© ter uma cobertura que tenha a mesma distribui√ß√£o de dados passados, como dados futuros. Esse conceito √© a permutabilidade. Isso significa que, n√£o importa de que √©poca o dado existe, ele ir√° ter a mesma distribui√ß√£o de probabilidade. √â importante entender isso, por duas raz√µes:\n\nCaso haja mudan√ßa brusca e mudan√ßa na distribui√ß√£o dos seus dados, a cobertura dever√° ser gerada novamente, pois ela deixa de atender para o que foi proposto. N√£o h√° necessidade de retreino de modelo, mas sim para a cobertura.\nPor conta dessa premissa, tamb√©m n√£o √© aconselhado, tampouco incentivado a fazer reamostragem de dados para n√£o afetar a distribui√ß√£o amostral dos dados. Para condi√ß√µes de dados desbalanceados, irei descrever como resolver no t√≥pico Classificador Conforme, preservando a calibra√ß√£o do modelo.\n\nUm ponto que preciso dar √™nfase, √© que o uso de cobertura n√£o gera apenas um √∫nico score como resultado, mas um conjunto de predi√ß√µes de todas as classes, podendo at√© todas as classes estarem na predi√ß√£o. Isso n√£o √© um bug! Modelos conformes que utilizam cobertura geram conjunto de respostas, sendo cada classe a ser testada dentro da cobertura.\n\nPonto Estimado vs Intervalo\nNa previs√£o conforme, ainda √© poss√≠vel modelar um ponto estimado de duas maneiras:\n1. Venn-Abers (VA)\nO VA √© um modelo de calibra√ß√£o de previs√£o conforme, ao qual oferece:\n2. P-valor dos NCScores\nPodemos estimar o p-valor dos scores de n√£o-conformidade para cada classe predita.\nConsidera√ß√µes Importantes\nEm ambos os cen√°rios:\nInterpreta√ß√£o\n\nConfian√ßa: Indica a probabilidade da classifica√ß√£o predita versus outras classes\nCredibilidade: Mostra o qu√£o adequada √© a previs√£o conforme para classificar a inst√¢ncia\n\nN√£o abordarei com profundidade estes dois m√©todos, mas tenha em mente a flexibilidade do framework.\n\n[!tip]\n√â importante n√£o confundir intervalos de predi√ß√£o com intervalos de confian√ßa, pois s√£o conceitualmente diferentes:\nO intervalo de confian√ßa nos permite estimar, com determinado grau de certeza, onde um par√¢metro populacional se encontra.\nJ√° o intervalo de predi√ß√£o nos permite estimar, tamb√©m com um grau de certeza espec√≠fico, onde o valor real de uma nova observa√ß√£o deve estar.\n\nCobertura\nUtilizar uma cobertura garantida de score de n√£o conformidade pode nos ajudar a interpretar sobre diversos pontos:\n\nEm um modelo de detec√ß√£o de imagens, conseguimos saber quais labels est√£o sendo apresentadas para respectivas imagens, e quais t√™m quantifica√ß√µes aproximadas de incerteza.\nEm modelos de automa√ß√£o ou detec√ß√£o, podemos solicitar analise humana aonde mais de uma label √© detectada.\nEm um modelo de recomenda√ß√£o, √© poss√≠vel identificar similaridades entre produtos, sendo poss√≠vel juntar ambos ou at√© ofertarem juntos.\n\ny_prob = rf.predict_proba(X_test)\nncscore = 1 - y_prob\n(ncscore &lt;= qhat).astype(int)\n\nAs poss√≠veis respostas, poder√£o ser, pensando em um classificador bin√°rio:\n\n[0, 0]: H√° garantia na probabilidade de que o dado escorado n√£o comp√µe nenhuma classe.\n[1, 0]: H√° garantia de que o dado comp√µe a classe ‚Äò0‚Äô.\n[0, 1]: H√° garantia de que o dado comp√µe a classe ‚Äò1‚Äô.\n[1, 1]: H√° garantia de que o dado comp√µem ambas as classes.\n\nO c√≥digo para fazermos futuras escoragens √© bem simples, a complexidade se d√° aos fundamentos de chegarmos em um bom entendimento.\nSe ainda n√£o ficou muito claro sobre o tema, antes de falarmos sobre valida√ß√£o e efici√™ncia, sugiro seguir os exemplos de Christoph Molnar:\nWeek #1: Getting Started With Conformal Prediction For Classification",
		"tags": ["1", "note"]
},

{
		"title": "7. Validade e Efici√™ncia",
		"date":"Thu Dec 25 2025 18:15:37 GMT+0000 (Coordinated Universal Time)",
		"url":"/digital-garden/meu-modelo-conforme/text/7-validade-e-eficiencia/",
		"content": "Validade e Efici√™ncia\nAo tentar criar seu primeiro modelo de previs√£o conforme, voc√™ pode ter encontrado um desafio: muitos conjuntos de predi√ß√£o do seu modelo retorna todas as classes. Mas por que isso acontece?\n√Ä medida que aumentamos o n√≠vel de cobertura (por exemplo, para 99%), os conjuntos de previs√£o conforme tendem a crescer. Isso ocorre porque o modelo precisa incluir mais classes para garantir que a verdadeira classe esteja no conjunto de previs√£o com a probabilidade desejada.\nEsse fen√¥meno est√° relacionado ao conceito de validade na previs√£o conforme. Ela assegura que a probabilidade de o conjunto de previs√£o conter a verdadeira classe seja, no m√≠nimo, igual ao n√≠vel de confian√ßa especificado. Por exemplo, com um n√≠vel de confian√ßa de 99%, esperamos que o conjunto de previs√£o inclua a classe correta em pelo menos 99% dos casos.\nContudo, essa garantia pode resultar em conjuntos de previs√£o maiores, especialmente quando o n√≠vel de confian√ßa √© muito alto. Isso acontece porque o modelo precisa ser mais conservador em suas previs√µes para manter a garantia de cobertura.\nPor outro lado, pode tamb√©m ocorrer o inverso, aonde ambos os valores n√£o atendem √† cobertura, tornando vazio o conjunto de predi√ß√µes. Isso pode ocorrer pois estamos mexendo em um intervalo gerado a partir de diversos valores, n√£o apenas um ponto fixo. Imagine que chegue um dado bem diferente do que j√° foi visto em todo hist√≥rico dos dados.\nNo artigo Model-Agnostic Nonconformity Functions for Conformal Classification, foram criadas duas m√©tricas de n√£o-conformidade, AvgC e OneC, retratando as propriedades de **validade **e efici√™ncia da cobertura, que nos auxiliam bastante a entender como nosso modelo est√° performando. Validade refere-se √† quantidade m√©dia de r√≥tulos sinalizados pelo modelo por conjunto de predi√ß√µes, enquanto efici√™ncia √© a propor√ß√£o de conjuntos de predi√ß√µes com apenas um valor. Quanto menor o valor de validade, mais informa√ß√£o podemos extrair do modelo, pois o conjunto de predi√ß√µes fica menor. Por outro lado, quanto maior o score OneC, melhor √© a capacidade do modelo de extrair informa√ß√£o do score de n√£o conformidade, conseguindo ser mais espec√≠fico em seu resultado.\nPodemos tamb√©m ver as duas propriedades visualmente no link abaixo:\nUncertainty Quantification (1): Enter Conformal Predictors\nEm meu projeto pessoal, fiz um gr√°fico que plota ambos os scores baseados em diferentes n√≠veis de Œ±. Caso tenha curiosidade, o c√≥digo est√° dispon√≠vel em meu GitHub.\n\nOutras m√©tricas que podem ser utilizadas para valida√ß√£o de modelo s√£o:\nTotal de conjunto Vazios\n\nQuantas vezes o modelo emitiu um conjunto de predi√ß√µes vazias, n√£o sendo informativo em seu resultado.\n\nTaxa de Erro\n\nM√©dia de conjunto de predi√ß√µes aonde o modelo errou em rela√ß√£o ao label original.\n\nCobertura Emp√≠rica\n√â uma m√©trica que geramos para saber o qu√£o temos a cobertura garantida no intervalo de predi√ß√£o em rela√ß√£o ao n√≠vel que foi modelado, em outras palavras, verificamos se, vamos supor, com um intervalo de 95% imposto √† cobertura, temos aproximadamente 95% de garantia real sob ela. Caso ocorra de que esse valor seja relativamente inferior ao imposto, √© possivel que o conceito de permutabilidade n√£o esteja sendo atendida e toda modelagem precisa ser revisada!\nDentro dos meus modelos conformes no github h√° um c√≥digo para gera√ß√£o dessa m√©trica, mas a l√≥gica √© o seguinte:\n\nA partir de uma massa de dados, gero o score de n√£o-conformidade e seto um n√∫mero arbitr√°rio na qual vou iterar sob eles.\nA cada itera√ß√£o, um percentual desses dados √© selecionado de forma aleat√≥ria e posteriormente separados entre dado de calibra√ß√£o e teste, gerando o qhat baseado no alpha que modelei. Nesse caso, nosso alpha era 0.05.\nCalcula a m√©dia da cobertura dos dados selecionados para valida√ß√£o desta itera√ß√£o.\nRepetimos o processo at√© o n√∫mero de itera√ß√µes seja atingido.\nPor fim tiramos a m√©dia de todas as coberturas geradas e comparamos com o valor modelado.\n\nH√° uma √≥tima explica√ß√£o sobre isso no link abaixo:\nA Tutorial on Conformal Prediction Part 2: Conditional Coverage and Diagnostics",
		"tags": [ "note"]
},

{
		"title": "8. Score de n√£o-conformidade",
		"date":"Thu Dec 25 2025 18:15:37 GMT+0000 (Coordinated Universal Time)",
		"url":"/digital-garden/meu-modelo-conforme/text/8-score-de-nao-conformidade/",
		"content": "Score de n√£o-conformidade\nVoc√™ pode utilizar qualquer tipo de score de n√£o-conformidade ou at√© mesmo criar um, mas deixarei documentado dois scores amplamente utilizados na √°rea acad√™mica.\nHinge Loss\nHinge, ou probabilidade inversa, refere-se ao quanto o modelo errou em rela√ß√£o ao r√≥tulo verdadeiro. Seu c√°lculo se baseia em 1 ‚àí P(y), sendo P(y) a predi√ß√£o do seu modelo. O range vai de 0 a 1, onde 0 significa que o modelo est√° correto, e 1 indica que o modelo est√° completamente errado.\nMargin\nMargin refere-se √† diferen√ßa entre a probabilidade da predi√ß√£o mais incorreta e a probabilidade correta. Valores menores ou iguais a zero indicam que o modelo tem certa confian√ßa em rela√ß√£o √† classe verdadeira, enquanto valores positivos representam uma incerteza em sua predi√ß√£o.",
		"tags": [ "note"]
},

{
		"title": "9. Aprendizado Sens√≠vel ao Custo",
		"date":"Thu Dec 25 2025 18:15:37 GMT+0000 (Coordinated Universal Time)",
		"url":"/digital-garden/meu-modelo-conforme/text/9-aprendizado-sensivel-ao-custo/",
		"content": "Aprendizado Sens√≠vel ao Custo\nO Aprendizado Sens√≠vel ao Custo √© uma abordagem que busca otimizar decis√µes considerando os custos associados a diferentes tipos de erros. Diferentemente das abordagens tradicionais, onde os custos de erro s√£o sim√©tricos, esta abordagem lida com custos assim√©tricos ‚Äî alguns erros podem ser mais custosos ou prejudiciais que outros. Esses erros podem ser de predi√ß√£o (Falsos Positivos ou Negativos) ou relacionados a regras de neg√≥cio, como fraudes ou aprova√ß√£o de um servi√ßo caro. A ideia central √© minimizar o custo total das previs√µes, em vez de simplesmente maximizar a precis√£o.\nExemplo de Treinamento com Aprendizado Sens√≠vel ao Custo:\nConsidere um banco desenvolvendo um modelo para detectar transa√ß√µes fraudulentas. A matriz de custos poderia ser estruturada da seguinte forma:\n\nPrevis√£o \\ Real\nFraude\nN√£o Fraude\n\nFraude\n$0\n$50\n\nN√£o Fraude\n$1000\n$0\n\nNeste cen√°rio:\n\nFalso Positivo (classificar uma transa√ß√£o leg√≠tima como fraude): Custa $50 √† empresa devido √† insatisfa√ß√£o do cliente.\nFalso Negativo (n√£o detectar uma fraude real): Custa $1000 √† empresa, representando o valor m√©dio de uma transa√ß√£o fraudulenta.\nVerdadeiro Positivo e Verdadeiro Negativo: N√£o t√™m custos associados.\n\nLogo, o modelo treinado ajustaria seus par√¢metros para minimizar o custo total. Isso pode resultar em aceitar mais falsos positivos para reduzir significativamente os falsos negativos mais custosos. Embora possa ter uma precis√£o geral ligeiramente menor, esse modelo seria mais eficaz em termos de redu√ß√£o de perdas financeiras para a empresa.\nDados Desbalanceados\nAl√©m disso, podemos aplicar essa metodologia para lidar com conjuntos de dados desbalanceados, onde uma classe √© significativamente mais representada que outra. Atribu√≠mos custos mais altos aos erros da classe menos representada, controlando assim a confiabilidade do modelo em rela√ß√£o √†s classes.\nPara implementar isso, primeiro criamos um peso para cada classe, proporcional ao volume de dados para treino. Simulando para duas classes:\n√≠peso-da-classe=total-de-dadostotal-de-classes√ótotal-de-registros-da-classe-espec√≠ficatotal_de_dados = 100\ntotal_da_classe_0 = len(y_train[y_train == 0]) # 90\nw1 = 100 / (2 * total_da_classe_0) #0.55\n\ntotal_da_classe_1 = len(y_train[y_train == 1]) # 10\nw2 = 100 / (2 * total_da_classe_1) #5\n\nrf = RandomForestClassifier()\nrf.fit(X_train, y_train, class_weight={0: 0.55, 1: 5})\n\nDesta forma, contabilizar√° os pesos das duas classes dentro da fun√ß√£o de perda. Neste caso, dentro de gini, contabilizar√° os dois pesos.\nGini=1‚àíW1‚àóProportionc12‚àíW2‚àóProportionc22scikit-learn por padr√£o, possibilita j√° calcular esse peso, apenas incrementado o parametro como ‚Äúbalanced‚Äù.\nrf.fit(X_train, y_train, class_weight=&quot;balanced&quot;)\n\nH√° outros m√©todos utilizando metadados mais espec√≠ficos. Para mais informa√ß√µes, recomendo a palestra no EuroSciPy 2023.\nEuroSciPy 2023 - Get the best from your scikit-learn classifier\nAvalia√ß√£o de Performance\nPrecisamos observar corretamente como nosso modelo atua no cen√°rio do nosso problema. Para isso, √© importante selecionar a melhor m√©trica para avalia√ß√£o. Existe uma lista expressiva de op√ß√µes. No contexto de classifica√ß√£o bin√°ria, irei abordar apenas as m√©tricas que s√£o de meu interesse.\n√â importante destacar que todas essas m√©tricas derivam da matriz de confus√£o, utilizando conceitos como Verdadeiro Positivo (VP), Falso Positivo (FP), Verdadeiro Negativo (VN) e Falso Negativo (FN).\n\n[!tip] üí°\nSempre que precisar discutir ou revisar alguma m√©trica para adequ√°-la ao seu problema, sugiro fortemente consultar o guia disponibilizado pela Nannyml ‚Äî vale a pena!\n\nF1-Score\nF1-Score √© uma das m√©tricas mais utilizadas para avaliar modelos. Seu c√°lculo √© feito pela a m√©dia harm√¥nica entre precis√£o e sensibilidade, fornecendo um √∫nico valor que equilibra ambas as m√©tricas. Sua f√≥rmula √©:\n√£√£F1=2√óPrecis√£o√óSensibilidadePrecis√£o+SensibilidadeOnde:\n\nPrecis√£o = VP / (VP + FP)\nSensibilidade = VP / (VP + FN)\n\n√â particularmente √∫til quando buscamos um equil√≠brio entre precis√£o e sensibilidade. Um valor alto indica que o modelo possui tanto boa precis√£o quanto boa sensibilidade.\nEntretanto, o F1-Score n√£o contabiliza os verdadeiros negativos e d√° √™nfase √† classe positiva, o que o torna a ser enviesado. Para entendermos isso, precisamos voltar e falar de como ele surgiu e qual era o seu prop√≥sito inicial. O F1-Score foi desenvolvido por van Rijsbergen, em 1979, para avaliar sistemas de recupera√ß√£o de informa√ß√£o, onde a precis√£o e sensibilidade tem maior grau de import√¢ncia do que a predi√ß√£o correta de VN. Segundo o artigo Assessing Software Defection Prediction Performance: Why Using the Matthews Correlation Coefficient Matters, √© exemplificado isso:\n\nEste dom√≠nio do problema √© caracterizado por contagens muito grandes, e frequentemente desconhecidas, de VN. Considere, por exemplo, a recupera√ß√£o de p√°ginas web. Saber o n√∫mero de p√°ginas irrelevantes corretamente n√£o recuperadas, ou seja, verdadeiros negativos, ser√° tanto desafiador quanto pouco interessante. Isso chegaria a centenas de milh√µes, possivelmente mais. Infelizmente, aplicar F1 no contexto completamente diferente de predi√ß√£o de defeitos n√£o √© equivalente.\n\nIsso √© bastante percept√≠vel quando h√° um grau de import√¢ncia nos Verdadeiros Negativos (VN) ou quando existe um desbalanceamento para a classe negativa. Nessas condi√ß√µes, a m√©trica pode mascarar a real performance do modelo. Tal fato √© evidenciado tamb√©m no artigo The advantages of the Matthews correlation coefficient (MCC) over F1 scoreand accuracy in binary classification evaluation, que demonstra cen√°rios onde a m√©trica pode gerar uma confian√ßa equivocada no modelo, sugerindo o uso de m√©tricas alternativas que sejam mais representativas do contexto geral.\nPor exemplo, supondo que temos um modelo de detec√ß√£o de indicativos de um paciente para uma doen√ßa muito comum:\n\nDados de Teste: 1000 pacientes\n980 pacientes (98%) t√™m a doen√ßa (positivos)\n20 pacientes (2%) n√£o t√™m a doen√ßa (negativos)\n\nSe um modelo simplesmente classificar todos como positivos:\n\nF1-Score: 0.99\n\nCom essa m√©trica, n√£o conseguimos avaliar se o modelo est√° superestimando os resultados ou simplesmente classificando todos os pacientes como doentes, mascarando assim problemas mais s√©rios. Por isso, recomenda-se utilizar m√©tricas que ofere√ßam um contexto mais amplo e uma vis√£o mais completa, considerando o peso de toda a matriz de confus√£o. Assim, abordarei a acur√°cia balanceada, uma normaliza√ß√£o da m√©trica Bookmaker informedness (BM).\n\n[!tip]\nN√£o h√° problema em usar o F1-Score, por√©m √© recomend√°vel combin√°-lo com outra m√©trica para obter um contexto maior do modelo.\n\nAcur√°cia Balanceada\nA partir delas podemos derivar uma m√©trica mais robusta para dados desbalanceados: a acur√°cia balanceada (BA). Seu diferencial √© avaliar o desempenho do modelo considerando igualmente todas as classes, independentemente de sua frequ√™ncia nos dados.\nA acur√°cia balanceada √© calculada como a m√©dia aritm√©tica entre sensibilidade e especificidade. Para um problema de classifica√ß√£o bin√°ria, a f√≥rmula √©:\n√°Acur√°cia Balanceada=12(VPVP+FN+VNVN+FP)Onde:\nA acur√°cia balanceada √© √∫til em cen√°rios onde as classes t√™m igual relev√¢ncia, independentemente de sua distribui√ß√£o nos dados.\nPor exemplo, imagine um sistema de controle de qualidade em uma f√°brica de componentes cr√≠ticos de aeronaves:\n\nVolumetria: 1.000 pe√ßas\n950 (95%) das pe√ßas s√£o aprovadas no controle de qualidade\n5 (5%) das pe√ßas apresentam defeitos\n\nSe um modelo de detec√ß√£o autom√°tica sempre aprovar as pe√ßas, ter√≠amos:\n\nAcur√°cia normal: 95%\nAcur√°cia balanceada: 50%\n\nNeste caso, tanto aprovar uma pe√ßa defeituosa quanto rejeitar uma pe√ßa boa s√£o igualmente cr√≠ticos: o primeiro pode comprometer a seguran√ßa da aeronave, e o segundo representa um preju√≠zo financeiro significativo, pois s√£o pe√ßas caras! Neste contexto em que os tipos de erros s√£o igualmente importantes, √© interessante considerarmos a acur√°cia balanceada.\nRetornando ao contexto original do problema ‚Äî adaptar o modelo para dados possivelmente desbalanceados ‚Äî e considerando que ambos os erros de classifica√ß√£o t√™m igual import√¢ncia, a acur√°cia balanceada √© mais adequada.\nAtualiza√ß√£o de Projeto!\nAp√≥s revis√£o do meu projeto, resolvi fazer uma altera√ß√£o na vers√£o da biblioteca. Nela, utilizo a possibilidade de escolher entre duas m√©tricas, Bookmaker Informedness (BM) ou Coeficiente de Correla√ß√£o de Matthews (MCC).\nBookmaker Informedness\nO Bookmaker Informedness √© outra m√©trica importante para avalia√ß√£o de modelos, especialmente em cen√°rios com classes desbalanceadas. Assim como a acur√°cia balanceada, ela busca fornecer uma avalia√ß√£o mais robusta do desempenho do modelo. Na realidade, BA √© uma normaliza√ß√£o de BM.\nO BM √© calculado como:\nBM=Sensibilidade+Especificidade‚àí1Esta m√©trica:\n\nVaria de -1 a +1, onde +1 indica predi√ß√£o perfeita\n0 indica que o modelo n√£o √© melhor que escolhas aleat√≥rias\nValores negativos indicam desempenho pior que aleat√≥rio\n\nO Bookmaker Informedness √© particularmente √∫til quando as classes t√™m igual import√¢ncia, independente de sua distribui√ß√£o nos dados, como tamb√©m √© a √∫nica m√©trica para avaliar aleatoriedade da predi√ß√£o, demonstrado no artigo The Matthews correlation coefficient (MCC) is more reliable than balanced accuracy, bookmaker informedness, and markedness in two-class confusion matrix evaluation - BioData Mining\nCoeficiente de Correla√ß√£o de Matthews\nO MCC √© considerado uma das m√©tricas mais completas para avalia√ß√£o de classificadores bin√°rios, pois:\n\nConsidera todos os elementos da matriz de confus√£o (VP, VN, FP, FN)\n√â especialmente √∫til para classes desbalanceadas\nFornece uma medida mais confi√°vel mesmo quando as classes t√™m tamanhos muito diferentes\nEm caso de seu score alto, m√©tricas como Brier Score, F1-Score, BM, ROC-AUC costumam apresentar bons resultados.\n\nA f√≥rmula do MCC √©:\nMCC=VP√óVN‚àíFP√óFN(VP+FP)(VP+FN)(VN+FP)(VN+FN)O MCC tem as seguintes caracter√≠sticas:\n\nVaria de -1 a +1, similar ao Bookmaker Informedness\n+1 representa uma classifica√ß√£o perfeita\n0 indica desempenho equivalente a predi√ß√µes aleat√≥rias\n-1 indica o pior desempenho poss√≠vel\n\nO MCC √© particularmente √∫til quando as classes t√™m igual import√¢ncia, independentemente de sua distribui√ß√£o nos dados. Diferentemente de outras m√©tricas, existe uma extensa literatura que recomenda seu uso como padr√£o no campo da estat√≠stica para garantir maior rigor na avalia√ß√£o dos modelos.\nPortanto, optou-se por utilizar tanto o MCC quanto o BM para avaliar os resultados.\n\n[!tip]\nComo o MCC considera tanto a preval√™ncia dos dados positivos quanto o vi√©s de qu√£o prov√°vel o modelo prev√™ corretamente a base de dados, n√£o √© aconselh√°vel utiliz√°-lo quando queremos comparar resultados entre diferentes bases de dados.\nPara esse cen√°rio, √© melhor utilizar BA ou BM.\n\nAprendizado Sens√≠vel a Custo versus Reamostragem\nUma diferen√ßa crucial √© que, ao contr√°rio dos m√©todos de undersampling ou oversampling, n√£o modificamos a distribui√ß√£o dos dados durante o treinamento. O modelo √© treinado com a distribui√ß√£o real dos dados dispon√≠veis, alterando apenas a forma como aprende a partir deles. Isso traz uma vantagem especial quando precisamos estimar a precis√£o e probabilidade do modelo em um cen√°rio real, pois a distribui√ß√£o dos dados reflete fielmente a realidade.",
		"tags": ["0", "5", "note"]
},

{
		"title": "Meu Modelo Conforme",
		"date":"Thu Dec 25 2025 18:15:37 GMT+0000 (Coordinated Universal Time)",
		"url":"/digital-garden/meu-modelo-conforme/text/meu-modelo-conforme/",
		"content": "<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/digital-garden/meu-modelo-conforme/text/1-introducao/\">1. Introdu√ß√£o</a>\n<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/digital-garden/meu-modelo-conforme/text/2-antes-de-comecarmos/\">2. Antes de Come√ßarmos‚Ä¶</a>\n<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/digital-garden/meu-modelo-conforme/text/3-probabilidade-e-calibracao-de-modelo/\">3. Probabilidade e Calibra√ß√£o de Modelo</a>\n<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/digital-garden/meu-modelo-conforme/text/4-previsao-conforme/\">4. Previs√£o Conforme</a>\n<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/digital-garden/meu-modelo-conforme/text/5-treinamento/\">5. Treinamento</a>\n<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/digital-garden/meu-modelo-conforme/text/6-escoragem/\">6. Escoragem</a>\n<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/digital-garden/meu-modelo-conforme/text/7-validade-e-eficiencia/\">7. Validade e Efici√™ncia</a>\n<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/digital-garden/meu-modelo-conforme/text/8-score-de-nao-conformidade/\">8. Score de n√£o-conformidade</a>\n<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/digital-garden/meu-modelo-conforme/text/9-aprendizado-sensivel-ao-custo/\">9. Aprendizado Sens√≠vel ao Custo</a>\n<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/digital-garden/meu-modelo-conforme/text/10-classificador-conforme/\">10. Classificador Conforme</a>\n<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/digital-garden/meu-modelo-conforme/text/11-referencias/\">11. Refer√™ncias</a>\n<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/digital-garden/meu-modelo-conforme/text/12-regressao/\">12. Regress√£o</a>",
		"tags": [ "note"]
},

{
		"title": "0. Roadmap",
		"date":"Thu Dec 25 2025 18:15:37 GMT+0000 (Coordinated Universal Time)",
		"url":"/digital-garden/path-for-the-true-and-brave/text/0-roadmap/",
		"content": "M√™s 1\n\nFree Tutorial - Causal AI in a Nutshell\nCausality, Decision Making &amp; Data Science (1 ~ 7)\nEstat√≠stica Psicobio II 2024 #23 - DAG I - Directed Acyclic Graphs - Princ√≠pios de Causalidade\nEstat√≠stica Psicobio II 2024 #24 - DAG II Directed Acyclic Graphs - d' separation; algoritmo PC e IC\nEstat√≠stica Psicobio II 2024 #25 - DAG III - Aplica√ß√µes do DAG, Propensity Scores e diff-n-diff\n\nM√™s 2\n\nUniversidade de Dados - Robson Tigre\nCausal Inference in Python - (Cap I, II, III)\nCausal Inference in Python - Noncompliance &amp; Instruments\nTools for Causality\n\nM√™s 3\n\nMentoria - Robson Tigre\nProjetos - ex.: estimativa de demanda, elasticidade de pre√ßo, infer√™ncia de rejeitados etc.\n\nCausal Bandits Podcast\n\nCausal Inference's Role In Fintech Explained By Matheus Facure Ep 9 | CausalBanditsPodcast.com\nCausal Inference &amp; Financial Modeling with Alexander Denev Ep 14\nCausal AI &amp; Individual Treatment Effects | Scott Mueller Ep. 20\n49% Less Loss with Causal ML | Stefan Feuerriegel S2E1\nThe Causal Gap: Truly Responsible AI Needs to Understand the Consequences | Zhijing Jin S2E7\nCausal Inference &amp; Clinical Trials: Myths of Randomization | Stephen Senn | CausalBanditsPodcast.com\n\nNext Steps\n\nPanel Data (Cap. IV)\nMastering Mostly Harmless Econometrics (Alberto Abadie, Joshua Angrist, and Christopher Walters)\nCausal Discovery Inference\nOnline Controlled Experiments\nThe Book of Why: The New Science of Cause and Effect | Amazon.com.br",
		"tags": ["23", "24", "25", "note"]
},

{
		"title": "1. Epifanias",
		"date":"Thu Dec 25 2025 18:15:37 GMT+0000 (Coordinated Universal Time)",
		"url":"/digital-garden/path-for-the-true-and-brave/text/1-epifanias/",
		"content": "Epifanias\nE c√° estamos Dezembro de 2025, semana de natal. Faz um tempo que n√£o escrevo nada publicamente ‚Äî na verdade at√© estava, concentrado em refinar o Tinyshift. O projeto cresceu bastante e estou bem feliz com o rumo que tomou, embora sei que ainda h√° muito o que fazer nele.\nNeste meio caminho, em epifanias, percebi algo. Quanto mais tempo trabalho em ci√™ncia de dados, mais certeza s√≥ tenho de uma coisa: eu sei absolutamente nada. Depois de tanto tempo estudando sob diversos temas, novamente senti que estava batendo em outro teto.\nNeste contexto, ficamos extremamente habituados em um escopo: associa√ß√£o. Quando digo isto, sempre pensamos em modelar sob forma de resultarmos na probabilidade de um acontecimento, de um n√∫mero, ou de uma classe em rela√ß√£o a outros fatores. Isto come√ßou a me pregar dois problemas:\n\nA primeira √© que estamos sempre falando de padr√µes. Comportamentos de fraude, spam, itens comprados juntos. Isso √© natural: nosso c√©rebro √© feito para reconhecer padr√µes, desde a Era da Pedra. Para nossa sobreviv√™ncia, sempre ficamos habituados a isso. Mas padr√µes n√£o s√£o causa e efeito. Imagine o cl√°ssico dataset sobre vendas de sorvete com uma feature de ataques de tubar√£o. Ao observar os dados voc√™ encontra tem padr√µes, associa√ß√µes fortes de um com outro! Seria sensato recomendar que seu cliente corte rela√ß√µes com empresas de sorvete? Claro que n√£o, ao menos pra mim! Ambas as vari√°veis podem ser influenciadas por um terceiro fator: a temperatura. No ver√£o as pessoas v√£o mais √† praia e compram mais sorvete ‚Äî como tamb√©m h√° mais chance de ataques. Isso √© o que chamamos de correla√ß√£o esp√∫ria. O mantra vale: associa√ß√£o n√£o implica causalidade.\nA segunda quest√£o √© pr√°tica: um modelo de Machine Learning tradicional frequentemente entrega apenas uma probabilidade. N√≥s, humanos, tomamos decis√µes com base nesse n√∫mero. Mas se nosso objetivo √© orientar a√ß√µes, por exemplo, reduzir churn, n√£o basta saber quem tem maior probabilidade de churn; precisamos saber qual √© o impacto de uma a√ß√£o (uma promo√ß√£o, atendimento diferenciado, cross-sell) sobre o churn. Quais a√ß√µes causam mais impacto para diferentes perfis de cliente? Facure fala exatamente disso no podcast do Aleksander Molak. Em vez de modelar apenas a probabilidade, quero saber qual interven√ß√£o impacta mais e por quanto ‚Äî ou seja, modelar sobre as regras de neg√≥cio, n√£o s√≥ previs√£o.\n\nModelos preditivos podem induzir a decis√µes equivocadas quando o objetivo √© agir no mundo. O prop√≥sito final de um modelo de ML √© resolver um problema de neg√≥cio; mover o ponteiro √© o que importa! Por isso, comecei a estudar formas de modelagem que foquem tomada de decis√£o: entender rela√ß√µes de causa e efeito para orientar interven√ß√µes eficazes. Assim, em vez de prever, posso estimar o impacto de prevenir clientes descontentes, quais fatores reduzem churn ou se um cross-sell aumenta a fidelidade.\nEstas anota√ß√µes, ou melhor, zettelkasten, s√£o minhas, em meio a minha jornada nessa selva que conhe√ßo t√£o pouco. N√£o √© e nunca vai ser um guia pr√°tico, mas achei que seria bom disponibilizar como portif√≥lio, e ajudar quem gostaria tamb√©m de come√ßar a ler ou discutir sobre. Nela, escreverei apenas t√≥picos que me interessam, focando em dados observacionais, estudos transversais. Infer√™ncia Causal √© gigante, ent√£o espere que tenha assuntos faltando. Mais importante, vamos ter um pouco de humildade epist√™mica aqui, okay?\n\n[!tip]\nN√£o h√° problema de utilizar este documento para aprender, mas sugiro que use somente como apoio! Importante ter sua pr√≥pria hist√≥ria, anota√ß√µes e tamb√©m suas epifanias!\nEm d√∫vida de como iniciar, deixarei o <a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/digital-garden/path-for-the-true-and-brave/text/0-roadmap/\">0. Roadmap</a> de como eu fiz. Agora, para boas refer√™ncias, siga Robson Tigre e Matheus Facure. Sou apenas um mero gafanhoto.\n\n[!Agradecimentos]\nAgrade√ßo de cora√ß√£o ao Altay de Souza por me lembrar que aprender pode ser algo divertido e mais leve, ao Robson Tigre por sua humildade e me responder sempre que poss√≠vel, e por fim ao Thiago Russo e ao meu primeiro time de Dados, por me ensinar a ser quem eu sou como cientista de dados.\nE antes que eu esque√ßa, ao Naruhodo e em especial ao - ‚ÄúNaruhodo, ilustr√≠ssimo ouvinte!‚Äù - Ken Fujioka junto com Altay, que me ensinam a cada dia a ser uma pessoa melhor.",
		"tags": [ "note"]
},

{
		"title": "10. Efeitos Heterog√™neos",
		"date":"Thu Dec 25 2025 18:15:37 GMT+0000 (Coordinated Universal Time)",
		"url":"/digital-garden/path-for-the-true-and-brave/text/10-efeitos-heterogeneos/",
		"content": "Efeitos Heterog√™neos\nNas an√°lises de infer√™ncia causal demonstradas anteriormente, exploramos o ATE sob uma perspectiva populacional. No entanto, em muitos cen√°rios, o interesse reside em entender como diferentes subgrupos reagem ao tratamento, identificando quem apresenta impactos maiores ou menores. Para capturar essa variabilidade, utilizamos o Efeito M√©dio de Tratamento Condicional (CATE), que nos permite observar os chamados efeitos heterog√™neos.\nO objetivo do CATE √© permitir que a tomada de decis√£o seja fundamentada nas caracter√≠sticas espec√≠ficas (X) de cada unidade. Em vez de perguntar apenas se &quot;o tratamento funciona&quot;, passamos a questionar: &quot;para quem o tratamento funciona melhor?&quot;**.\nMatematicamente, definimos o CATE como:\nœÑ(x)=E[Y1‚àíY0|X=x]Onde buscamos a diferen√ßa esperada entre os outcomes potenciais (Y1 e Y0), condicionada a um conjunto de covari√°veis X.\nRegress√£o Linear\nUma regress√£o linear simples estima apenas o coeficiente m√©dio do tratamento. Para identificar efeitos heterog√™neos, introduzimos termos de intera√ß√£o entre a vari√°vel de tratamento (T) e as caracter√≠sticas das unidades (X). Essa abordagem torna o modelo flex√≠vel, permitindo que a &quot;inclina√ß√£o&quot; (o efeito do tratamento) varie conforme o perfil da unidade.\nA equa√ß√£o assume a forma:\nyi=Œ≤0+Œ≤1Ti+Œ≤2Xi+Œ≤3(Ti√óXi)+œµiDeriva√ß√£o do Efeito\nPara isolar o efeito do tratamento em um modelo com intera√ß√µes, utilizamos a derivada parcial da vari√°vel de resultado (y) em rela√ß√£o ao tratamento (t).\nConsidere o modelo:\nyi=Œ≤0+Œ≤1ti+Œ≤2Xi+Œ≤3(ti√óXi)+œµiA varia√ß√£o de y para uma mudan√ßa infinitesimal em t √© dada por:\n‚àÇyi‚àÇti=Œ≤1+Œ≤3XiIsso nos mostra que o efeito do tratamento n√£o √© constante: ele depende diretamente dos valores das covari√°veis Xi de cada indiv√≠duo.\nAproxima√ß√£o por Diferen√ßa Finitas\nNa pr√°tica, como o modelo √© linear, essa derivada pode ser calculada exatamente atrav√©s da diferen√ßa entre duas predi√ß√µes. Usamos a defini√ß√£o de derivada onde o incremento (œµ) √© igual a 1 unidade:\nŒ¥yŒ¥t‚âày^(t+1)‚àíy^(t)Onde:\n\ny^(t+1) √© a predi√ß√£o do modelo incrementando o tratamento original em uma unidade.\ny^(t) √© a predi√ß√£o do modelo com os dados originais.\n\nExemplo (Causal Inference in Python: Applying Causal Inference in the Tech Industry\n\nimport statsmodels.formula.api as smf\n\n# 1. Defini√ß√£o das covari√°veis (caracter√≠sticas que podem causar heterogeneidade)\nX = [&quot;C(month)&quot;, &quot;C(weekday)&quot;, &quot;is_holiday&quot;, &quot;competitors_price&quot;]\n\n# 2. Especifica√ß√£o do modelo com Intera√ß√£o # A sintaxe 'discounts * (X)'\n# Isso permite que o efeito do desconto mude conforme o m√™s, feriado ou pre√ßo do concorrente.\nregr_cate = smf.ols(f&quot;sales ~ discounts*({'+'.join(X)})&quot;,\ndata=data).fit()\n\n# 3. Estimativa do CATE (Efeito M√©dio de Tratamento Condicional)\n# Calculamos a diferen√ßa entre duas realidades hipot√©ticas para cada unidade:\n# Realidade A: O desconto atual + 1 unidade\n# Realidade B: O desconto atual\n# A diferen√ßa entre as predi√ß√µes isola o efeito marginal do desconto naquele contexto espec√≠fico.\nols_cate_pred = (\nregr_cate.predict(data.assign(discounts=data[&quot;discounts&quot;]+1))\n-regr_cate.predict(data)\n)\n\nAvalia√ß√£o\nA ideia central de criar modelos CATE surge da necessidade de ordenar as unidades das mais sens√≠veis √†s menos sens√≠veis ao tratamento, visando a personaliza√ß√£o. Como n√£o podemos observar o efeito individual real para validar essa ordena√ß√£o, avaliamos grupos definidos pela predi√ß√£o do modelo. Diferentemente de um modelo tradicional de machine learning, focamos em verificar o qu√£o bem o modelo est√° em rela√ß√£o a essa segmenta√ß√£o para efeito causal m√©dio condicional. N√£o irei abordar a fundo, novamente aconselho a ler o livro do Matheus Facure pois h√° uma explica√ß√£o muito boa sobre. Pontuarei apenas as tr√™s formar em que ele comenta como m√©todos.\nOutro ponto a ressaltar, √© que se encontra exemplos bons da aplica√ß√£o aberta via o jupyter notebook exemplar do livro. Causal Inference in Python: Applying Causal Inference in the Tech Industry\nEfeito por Quantil\nA abordagem consiste em segmentar os dados em quantis baseados na predi√ß√£o do modelo e estimar o efeito dentro de cada parti√ß√£o. Se o efeito estimado em cada quantil estiver ordenado (por exemplo, do maior para o menor), isso indica que o modelo √© eficaz em ordenar o CATE verdadeiro. [Visualmente](causal-inference-in-python-code/causal-inference-in-python/06-Effect-Heterogeneity.ipynb at main ¬∑ matheusfacure/causal-inference-in-python-code ¬∑ GitHub), quanto maior for o efeito &quot;escada&quot; no gr√°fico de efeito por quantil, melhor o modelo distingue os efeitos altos dos baixos.\nCurva de Efeito Cumulativo\nSeguindo a l√≥gica anterior, a Curva de Efeito Cumulativo n√£o estima o efeito por grupos isolados, mas sim acumulando um grupo sobre o outro. O processo envolve ordenar os dados pelo score do modelo (predi√ß√£o CATE) e estimar o efeito ordenado de um valor N, depois do valor N + 1, e assim sucessivamente.\nEmbora essa curva permita resumir a qualidade do modelo calculando a √°rea entre a curva e o ATE, ela apresenta uma desvantagem: o in√≠cio da curva possui uma amostra pequeno, o que nos tr√°s maior incerteza devido ao tamanho reduzido da amostra acumulada naquele ponto.\nCurva de Ganho Cumulativo (Cumulative Gain)\nPara corrigir a quest√£o da vari√¢ncia no in√≠cio da curva de efeito cumulativo, utiliza-se a Curva de Ganho Cumulativo. A l√≥gica √© a mesma, por√©m multiplicamos cada ponto da curva de efeito pela propor√ß√£o da amostra acumulada (Ncum/N).\nO modelo que apresentar a maior √°rea entre a curva e a linha tracejada (representando o ATE) ‚Äî ou a maior soma dos valores da curva normalizada ‚Äî √© considerado o melhor em termos de ordena√ß√£o do CATE. Por conta disso, podemos tirar o AUC e utilizarmos para avaliar o modelo desse resultado.",
		"tags": [ "note"]
},

{
		"title": "11. Vari√°vel Instrumental",
		"date":"Thu Dec 25 2025 18:15:37 GMT+0000 (Coordinated Universal Time)",
		"url":"/digital-garden/path-for-the-true-and-brave/text/11-variavel-instrumental/",
		"content": "Vari√°vel Instrumental\nExistem cen√°rios em que √© invi√°vel controlar totalmente o vi√©s de vari√°vel omitida U. Nestes casos, problemas comuns incluem:\n\nA impossibilidade de coletar ou mensurar todas as vari√°veis de confus√£o.\n\nA impossibilidade de garantir que todos os indiv√≠duos designados ao grupo de tratamento efetivamente recebam ou utilizem o tratamento. Isso caracteriza uma viola√ß√£o do perfect compliance (ades√£o perfeita).\n\n[!tip]\nCompliance refere-se √† taxa de ades√£o, ou seja, o percentual de indiv√≠duos que efetivamente utilizaram o tratamento conforme designado.\n\nNestes cen√°rios, a vari√°vel n√£o observada U exerce influ√™ncia tanto sobre o tratamento D quanto sobre o resultado Y, enviesando as estimativas causais:\nD‚ÜêU‚ÜíYUma solu√ß√£o para contornar a falta de controle sobre U √© utilizar uma Vari√°vel Instrumental Z, que antecede D:\nZ‚ÜíD‚ÜêU‚ÜíYEssa abordagem isola a varia√ß√£o em D que √© induzida por Z, &quot;limpando&quot; a influ√™ncia de U. Para que isso funcione, as seguintes premissas devem ser atendidas:\n\nRelev√¢ncia: A rela√ß√£o entre o instrumento Z e o tratamento D deve ser forte.\n\nPr√°tica: Regredir Z em D e verificar se o R¬≤ e a Estat√≠stica F (p-valor) s√£o significativos.\n\nRestri√ß√£o de Exclus√£o: O instrumento Z deve afetar o resultado Y apenas atrav√©s de D, sem caminhos diretos.\n\nExogeneidade (Independ√™ncia): O instrumento deve ser n√£o correlacionado com o termo de erro ou vari√°veis omitidas (Cov(Z,U)=0).\n\nMonotonicidade: O instrumento deve afetar o tratamento numa √∫nica dire√ß√£o.\n\nA Vari√°vel Instrumental (IV) pode ser aplicada em dois contextos principais:\n\nCorre√ß√£o de Experimentos (RCTs): Para lidar com falhas de ades√£o (imperfect compliance). Por exemplo, quando Z √© a oferta do tratamento e D √© o uso efetivo. Nem todos os ofertados usam, mas a oferta (Z) √© aleat√≥ria.\n\nEstudos Observacionais: Quando n√£o houve randomiza√ß√£o e suspeita-se que vari√°veis de confus√£o desconhecidas (U) afetem a escolha do tratamento. Aqui, o instrumento funciona como um &quot;experimento natural&quot;, introduzindo uma aleatoriedade na atribui√ß√£o de D que o pesquisador n√£o p√¥de controlar manualmente.\n\nO instrumento provoca um choque ex√≥geno na vari√°vel D, gerando uma varia√ß√£o no tratamento que √© independente das caracter√≠sticas n√£o observadas U.\nEst√°gios\nPara calcular o efeito causal via IV, podemos decompor a an√°lise em duas regress√µes simples e uma divis√£o.\n\nPrimeiro Est√°gio (Impacto no Tratamento):\nRegredimos o tratamento D em rela√ß√£o ao instrumento Z.\n\nVerificamos a premissa de Relev√¢ncia. O coeficiente (œÄ) nos diz o quanto o instrumento aumenta a probabilidade ou intensidade do tratamento.$$D = \\alpha_1 + \\pi Z + e_1$$\n\nForma Reduzida (Inten√ß√£o de Tratar - ITTE):\nRegredimos o resultado Y diretamente em rela√ß√£o ao instrumento Z, ignorando o tratamento D por enquanto.\n\nComo Z √© aleat√≥rio/ex√≥geno, esse coeficiente (Œ≥) mostra o efeito causal da atribui√ß√£o do instrumento sobre o resultado.\n\nY=Œ±2+Œ≥Z+e2\n\nC√°lculo do LATE:\nO efeito causal final (Œ≤IV) √© a raz√£o entre esses dois coeficientes. Ou seja, ajustamos o efeito total (Œ≥) pela propor√ß√£o de pessoas que realmente aderiram ao tratamento (œÄ).\n√°Œ≤IV=Efeito de Z em Y (Forma Reduzida)Efeito de Z em D (Primeiro Est√°gio)=Œ≥œÄ\n\nimport statsmodels.formula.api as smf\n\n# 1. Primeiro Est√°gio: Efeito de Z em D\n# O coeficiente de Z aqui √© a taxa de ades√£o\nfirst_stage = smf.ols('D ~ Z', data=df).fit()\nden = first_stage.params['Z']\n\n# 2. Forma Reduzida: Efeito de Z em Y\n# O coeficiente de Z aqui √© o ITTE\nreduced_form = smf.ols('Y ~ Z', data=df).fit()\nnum = reduced_form.params['Z']\n\n# C√°lculo do Wald, ou LATE\nwald_estimator_sm = num / den\n\nprint(f&quot;Numerador (ITTE): {num}&quot;)\nprint(f&quot;Denominador (Compliance): {den}&quot;)\nprint(f&quot;Efeito Causal (Wald): {wald_estimator_sm}&quot;)\n\nM√≠nimos Quadrados em Dois Est√°gios (2SLS)\nEnquanto o c√°lculo do LATE via raz√£o √© intuitivo para um √∫nico instrumento, o m√©todo 2SLS permite a inclus√£o de m√∫ltiplas vari√°veis de controle e m√∫ltiplos instrumentos.\n\nPrimeiro Est√°gio (Purifica√ß√£o de D):\nRegride-se o tratamento D contra o instrumento Z (e demais controles). O objetivo n√£o √© analisar o coeficiente, mas sim obter os valores preditos (D^).\nD^=Œ±^+œÄ^Z\n\nSegundo Est√°gio (Estima√ß√£o Causal):\nSubstitui-se a vari√°vel de tratamento original (D) pelos valores preditos calculados no passo anterior (D^) e realiza-se a regress√£o do resultado Y sobre essa nova vari√°vel.\nY=Œ≤0+Œ≤2SLSD^+Œµ\n\nA intui√ß√£o aqui √© a decomposi√ß√£o da vari√¢ncia. A vari√°vel de tratamento original D possui dois componentes de varia√ß√£o:\n\nUma parte end√≥gena, correlacionada com U\nUma parte ex√≥gena, induzida pelo instrumento Z\n\nAo rodarmos o primeiro est√°gio e calcularmos D^, estamos isolando apenas a varia√ß√£o em D que √© explicada por Z. Como Z √© n√£o correlacionado com U, D^ tamb√©m ser√° independente de U.\nPortanto, o segundo est√°gio utiliza uma vers√£o &quot;limpa&quot; do tratamento. Ao regredir Y em D^, eliminamos a contamina√ß√£o do vi√©s de sele√ß√£o, permitindo que o OLS estime o efeito causal verdadeiro.\nfrom linearmodels.iv import IV2SLS\n\n# F√≥rmula: Y ~ Controles + [Endogeno ~ Instrumento]\n# O &quot;1&quot; representa a constante (intercepto)\nformula = 'Y ~ 1 + X + [D ~ Z]'\n\nmodel = IV2SLS.from_formula(formula, df)\nresult = model.fit()\n\nprint(result)\n\n[!tip] 2SLS vs. DoubleML (DML)\nO m√©todo 2SLS tradicional assume que as rela√ß√µes entre as vari√°veis de controle (covari√°veis) e o resultado s√£o lineares. Caso sejam n√£o lineares, o 2SLS pode falhar em remover todo o vi√©s. √â aqui que podemos utilizar o m√©todo de Double Machine Learning (DML) com uso de IV.",
		"tags": [ "note"]
},

{
		"title": "12. Double Machine Learning",
		"date":"Thu Dec 25 2025 18:15:37 GMT+0000 (Coordinated Universal Time)",
		"url":"/digital-garden/path-for-the-true-and-brave/text/12-double-machine-learning/",
		"content": "Double Machine Learning\n\nDouble ML: Causal Inference based on ML\nAgora, iremos adentrar um pouco na infer√™ncia causal moderna. Relembramos o uso do Teorema FWL para &quot;desviesamento&quot;. Ele demonstra que, em uma regress√£o linear, podemos &quot;remover&quot; o efeito das covari√°veis X atrav√©s de res√≠duos e ent√£o estimar o efeito de D (tratamento) sobre Y.\nO Double Machine Learning (DML) generaliza essa ideia usando Machine Learning para estimar os componentes que dependem de X e, em seguida, &quot;partializa&quot; (remove a influ√™ncia de) X em Y e D.\nO m√©todo se destaca por quatro pilares fundamentais:\n\nFramework n√£o param√©trico\nPermite usar quaisquer modelo, como Random Forests e Gradient Boosting para modelar as vari√°veis de confus√£o (X). Isso captura rela√ß√µes complexas e n√£o-lineares automaticamente.\n\nRedu√ß√£o de vi√©s\nModelos de Machine Learning usam regulariza√ß√£o (ex.: Lasso ou profundidade de √°rvores) para evitar overfitting, o que &quot;encolhe&quot; as previs√µes, distorcendo as estimativas de efeito causal. O DML resolve isso separando a estima√ß√£o do ru√≠do da estima√ß√£o do efeito.\n\nIntervalos de confian√ßa v√°lidos\n√â matematicamente invi√°vel calcular p-valores precisos diretamente de uma &quot;caixa preta&quot; como uma Rede Neural. O DML transforma o problema final numa regress√£o linear simples sobre res√≠duos, permitindo recuperar a teoria estat√≠stica cl√°ssica para calcular signific√¢ncia estat√≠stica.\n\nEfici√™ncia\nSignifica que o erro da estimativa diminui rapidamente √† medida que a amostra (n) cresce, comportando-se t√£o bem quanto uma regress√£o linear simples, mesmo utilizando modelos de ML complexos (que normalmente convergem mais devagar) para limpar os dados.\n\nSua ideia √© utilizar dois modelos preditivos separados: um para o potencial outcome e outro para o tratamento. O processo ocorre nos seguintes passos:\n\nEstimar o outcome Y: Usamos um modelo de ML flex√≠vel (q(X)) para prever Y com base nas caracter√≠sticas X.\n\nEstimar o tratamento T: Usamos outro modelo de ML flex√≠vel (g(X)) para prever o tratamento T com base nas caracter√≠sticas X (similar a um Propensity Score).\n\nObtemos os res√≠duos:\n\nRes√≠duo do outcome: Y~=Y‚àíq^(X)\n\nRes√≠duo do tratamento: T~=T‚àíg^(X)\n\n[!tip] Lembrete\nUtilizamos o res√≠duo justamente para isolarmos os efeitos ex√≥genos! Queremos apenas saber o Impacto do outcome sob os tratamentos, eliminando as vari√°veis de confus√£o.\n\nFazemos a regress√£o dos res√≠duos:\nY~=œÑT~+œµOnde œÑ √© o par√¢metro causal (ATE). Esse processo √© feito dinamicamente utilizando Cross-Fitting, que comentarei posteriormente.\n\nRegress√£o Parcialmente Linear e Ortogonaliza√ß√£o\nVamos olhar para a Regress√£o Parcialmente Linear (PLR).\nAssumimos que o mundo gerador dos dados segue:\nY=DŒ∏+g(X)+UD=m(X)+VOnde Œ∏ √© o nosso alvo (efeito causal) e g(X) √© uma fun√ß√£o complexa e desconhecida dos confoundings.\nSe tentarmos estimar Œ∏ diretamente com ML, o erro na estimativa de g(X) contamina Œ∏. A solu√ß√£o √© a Ortogonaliza√ß√£o:\n\nCalculamos a esperan√ßa condicional de Y dado X:\nE[Y|X]=E[D|X]Œ∏+g(X)Chamamos E[Y|X] de Y^ e E[D|X] de D^.\n\nSubtra√≠mos essa esperan√ßa da equa√ß√£o original:\nY‚àíE[Y|X]=(D‚àíE[D|X])Œ∏+(g(X)‚àíg(X))+U\n\nNote a m√°gica: o termo complexo g(X) se cancela! Ficamos apenas com os res√≠duos:\n(Y‚àíY^)=(D‚àíD^)Œ∏+UOu seja:\nY~=Œ∏D~+U\n\nAgora, o erro na estimativa de g(X) √© ortogonal (n√£o correlacionado) ao tratamento residual, permitindo que o OLS isole o Œ∏ &quot;limpo&quot;.\n\n[!tip] Premissas Importantes\n√â fundamental refrisar que esse m√©todo n√£o √© &quot;bala de prata&quot;. A validade causal ainda depende das premissas anteriores:\n\nIgnorabilidade: Y(d)‚ä•D|X. Ou seja, todas as vari√°veis de confus√£o relevantes foram inclu√≠das em X. √â importante refrisarmos isso que √© assumido que foi capturando todos os confounders relevantes. Na pr√°tica, n√£o temos como saber por exato, mas uma boa constru√ß√£o √© importante.\nDom√≠nio sob regra de neg√≥cio: Para toda a infer√™ncia causal, aqui n√£o muda. Por mais complexo que nosso modelo possa ser, ele sempre ser√° limitado relativo a tomada de decis√£o √†s escolhas de vari√°veis. Um bom DAG constru√≠do ainda √© necess√°rio, para evitar qualquer vi√©s sob o resultado.\nQualidade de dados: por mais que o DoubleML √© focado para estudos observacionais, aonde n√£o controlamos vari√°veis de confus√£o e n√£o temos uma randomiza√ß√£o controlada, ele ainda pode sofrer com dados ruins. Se a extra√ß√£o tiver algum vi√©s forte, problemas com campos, o resultado dele vai ser ineficiente para estimar causalidade.\nPositividade: Para valores de X relevantes, deve haver varia√ß√£o no tratamento (a probabilidade de tratamento P(T|X) n√£o deve ser nem 0 nem 1 estritos).\nRegularidade: Os estimadores de ML devem convergir suficientemente r√°pido. O uso de Cross-Fitting √© crucial para evitar vi√©s de overfitting e garantir a validade assint√≥tica.\n\nO Perigo no Overfitting\nVale ressaltar que a flexibilidade dos modelos de Machine Learning traz o risco de overfitting. Se o modelo entende demais os dados de treino, ele absorve ru√≠dos como se fossem padr√µes reais, tornando os res√≠duos enviesados em dire√ß√£o a zero, eliminando a varia√ß√£o necess√°ria para encontrarmos o efeito causal.\nPor conta disso, a pr√°tica padr√£o √© utilizar o Cross-Fitting:\n\nSelecionamos K poss√≠veis folds.\nNo K1, separamos os dados por exemplo em &quot;Treino&quot; e &quot;Hold-out&quot;.\nO modelo √© treinado apenas na base de Treino, e utilizamos os dados para calcular o res√≠duo do Hold-Out.\nAgora, retreinamos o modelo com outro K fold, at√© que todos os dados tenham seus res√≠duos calculados.\n\nAssim, mesmo que o modelo aprenda nos dados de treino, ele n√£o ter√° &quot;visto&quot; os dados de hold-out. Isso garante que os res√≠duos mantenham um ru√≠do real e a variabilidade honesta necess√°ria.\n\nDouble Machine Learning for Causal Inference: A Practical Guide | by Mohamed Hmamouch | Medium\nImplementa√ß√£o Pr√°tica: Calculando ATE e CATE com Python\nVamos utilizar a biblioteca DoubleML para aplicar os conceitos acima.\n1. Calculando o ATE\nPara o ATE, assumimos um efeito constante e usamos o modelo Partial Linear Regression (PLR).\nimport numpy as np\nimport pandas as pd\nfrom doubleml import DoubleMLData, DoubleMLPLR\nfrom sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n\n# --- Configura√ß√£o dos Dados ---\n# Suponha que temos um DataFrame 'df' com:\n# 'y': Outcome, 'd': Tratamento bin√°rio, 'X1'...'X5': Covari√°veis\ndata_dml = DoubleMLData(df,\ny_col='y',\nd_cols='d',\nx_cols=[f'X{i}' for i in range(5)])\n\n# --- Definindo os Modelos (Learners) ---\n# Modelo para prever Y (Outcome)\nml_l = RandomForestRegressor(n_estimators=100, max_depth=5)\n# Modelo para prever D (Propensity Score)\nml_m = RandomForestClassifier(n_estimators=100, max_depth=5)\n\n# --- Estimando ATE com Cross-Fitting ---\ndml_plr = DoubleMLPLR(data_dml,\nml_l=ml_l,\nml_m=ml_m,\nn_folds=3) # 3-fold Cross-Fitting\n\ndml_plr.fit()\nprint(dml_plr.summary)\n\nO resultado coef no sum√°rio ser√° o nosso œÑ (ATE), livre do vi√©s das covari√°veis.\n2. Calculando o CATE\nSe quisermos saber como o efeito varia de acordo com as caracter√≠sticas da pessoa (X), usamos o Interactive Regression Model (IRM). Em vez de calcular um n√∫mero √∫nico, projetamos o efeito causal nas covari√°veis usando um Preditor Linear (BLP).\nfrom doubleml import DoubleMLIRM\n\n# --- Usando IRM para permitir intera√ß√µes ---\n# ml_g prev√™ E[Y|X, D] e ml_m prev√™ E[D|X]\nml_g = RandomForestRegressor(n_estimators=100, max_depth=5)\nml_m = RandomForestClassifier(n_estimators=100, max_depth=5)\n\ndml_irm = DoubleMLIRM(data_dml,\nml_g=ml_g,\nml_m=ml_m,\nn_folds=3)\n\ndml_irm.fit()\n\n# --- Projetando a Heterogeneidade (CATE) ---\n# &quot;Como o efeito causal varia linearmente com as features X?&quot;\ncate_res = dml_irm.cate(basis=df[[f'X{i}' for i in range(5)]])\n\nprint(cate_res)\n\nInterpretando o CATE: Se no resultado do cate_res o coeficiente de uma vari√°vel (ex: X1: Idade) for positivo e significante, indica que o tratamento √© mais eficaz quanto maior for a idade do indiv√≠duo.\n\n[!tip]\nPLR: Assume que o efeito do tratamento (Œ∏) entra de forma aditiva e linear (n√£o interage complexamente com X na equa√ß√£o estrutural). √â ideal para tratamentos cont√≠nuos (ex: pre√ßo, dosagem).\nIRM: √â desenhado especificamente para tratamentos bin√°rios. Ele permite intera√ß√µes completas entre o tratamento e as covari√°veis, sendo mais robusto para heterogeneidade. Ele utiliza o estimador AIPW (Augmented Inverse Probability Weighting) por tr√°s dos panos, que possui a propriedade de Dupla Robustez (Doubly Robust).\n\nIntroduction to Causal Machine Learning with¬†DoubleML¬†for Python\n3. Calculando o GATE (Group Average Treatment Effect)\nEnquanto o CATE busca o efeito individual (que pode possuir alto ru√≠do estat√≠stico), o GATE busca o efeito m√©dio em um subgrupo espec√≠fico.\nA biblioteca DoubleML oferece um m√©todo dedicado .gate() para cada grupo. Para utiliz√°-lo, precisamos passar um DataFrame onde as colunas representam os grupos (indicadores bin√°rios/dummies).\n\n[!tip]\nPodemos calcular o GATE agregando as estimativas do CATE. Filtramos as unidades que pertencem ao grupo de interesse e tiramos a m√©dia dos seus efeitos causais estimados (œÑ^(x)).\n\nMatematicamente:\nœÑGATE=E[œÑ^(x)‚à£x‚ààGrupo]# --- Passo 1: Definir os Grupos de Interesse ---\n# Vamos criar, por exemplo, dois grupos baseados na vari√°vel X1 (ex: Idade normalizada)\n# Grupo 0: X1 &lt;= 0.5\n# Grupo 1: X1 &gt; 0.5\ngroups = pd.DataFrame({\n'Grupo_Baixo_X1': df['X1'] &lt;= 0.5,\n'Grupo_Alto_X1': df['X1'] &gt; 0.5\n})\n\n# --- Passo 2: Calcular o GATE via DoubleML ---\n# O m√©todo gate() ajusta uma regress√£o linear dos res√≠duos contra essas vari√°veis de grupo\ngate_res = dml_irm.gate(groups=groups)\n\nprint(gate_res)\n\n# --- Passo 3: Analisar os Intervalos de Confian√ßa ---\n# Verificamos se o intervalo de 95% cruza o zero ou se os grupos se sobrep√µem\nprint(gate_res.confint())\n\nEssa abordagem √© poderosa para decis√µes de neg√≥cio estrat√©gicas, onde n√£o podemos personalizar para cada indiv√≠duo, mas podemos criar pol√≠ticas para segmentos (ex: Regi√£o Norte vs. Sul).\n\nCaracter√≠stica\nCATE (Conditional Average Treatment Effect)\nGATE (Group Average Treatment Effect)\n\nDefini√ß√£o\nEfeito do tratamento para um indiv√≠duo (ou unidade) com caracter√≠sticas exatas X.\nM√©dia dos efeitos de tratamento para um subgrupo espec√≠fico da popula√ß√£o.\n\nN√≠vel de Granularidade\nMicro (Individual / Personalizado).\nMacro (Segmento / Cluster).\n\nNota√ß√£o Matem√°tica\nœÑ(x)=E[Y(1)‚àíY(0)‚à£X=x]\nœÑGATE=E[œÑ(x)‚à£x‚ààGrupo]\n\nPergunta de Neg√≥cio\n&quot;Qual desconto devo dar para este cliente espec√≠fico agora?&quot;\n&quot;A campanha funciona melhor na Regi√£o Sul ou na Regi√£o Norte?&quot;\n\nEstabilidade Estat√≠stica\nBaixa. Sofre com alta vari√¢ncia e ru√≠do, pois n=1 (ou muito pequeno) para aquele X.\nAlta. O ru√≠do individual tende a se cancelar na m√©dia do grupo, gerando estimativas mais robustas.\n\nNo DoubleML\nResultado da proje√ß√£o do efeito nas features (via dml_irm.cate() ou BLP).\nCalculado tirando a m√©dia das predi√ß√µes do CATE filtradas por um subconjunto do DataFrame.\n\nAplica√ß√£o Principal\nPersonaliza√ß√£o de produto, Medicina de precis√£o, Recomenda√ß√£o din√¢mica.\nDefini√ß√£o de estrat√©gia, Pol√≠tica p√∫blica, Decis√£o de portf√≥lio.\n\nDoubleML com Vari√°veis Instrumentais (IV)\nDiferente do DoubleML padr√£o (que limpa X apenas de Y e D), no cen√°rio com Vari√°vel Instrumental n√≥s precisamos limpar a influ√™ncia das covari√°veis (X) de tr√™s lugares: do Resultado (Y), do Tratamento (D) e do Instrumento (Z).\nSimulando o DoubleMLPIV para ter uma ideia, o processo envolve 3 modelos de Machine Learning e uma regress√£o IV 2SLS final.\nPremissas\n\nY depende de X,D,U.\nD depende de X,Z,U.\nZ depende de X\n\n1. Previs√£o\nPrimeiro, usamos ML para prever Y, D e Z usando apenas as covari√°veis X. O objetivo √© capturar toda a varia√ß√£o explicada por vari√°veis de confus√£o.\n\nModelo 1 (q(X)): Prever Y usando X.\nModelo 2 (m(X)): Prever D usando X.\nModelo 3 (r(X)): Prever Z usando X.\n\n2. Ortogonaliza√ß√£o Tripla\nSubtra√≠mos as previs√µes dos valores reais.\n\nY~=Y‚àíY^ML (Varia√ß√£o no outcome n√£o explicada por X)\nD~=D‚àíD^ML (Varia√ß√£o no tratamento n√£o explicada por X)\nZ~=Z‚àíZ^ML (Varia√ß√£o no instrumento n√£o explicada por X)\n\n3. Est√°gio Final (2SLS nos Res√≠duos)\nUsamos os res√≠duos do instrumento (Z~) para instrumentar os res√≠duos do tratamento (D~) e explicar os res√≠duos do resultado (Y~).\nimport numpy as np\nimport pandas as pd\nimport statsmodels.api as sm\nfrom sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n\n# --- 1. Gerando Dados Fict√≠cios (End√≥genos) ---\nnp.random.seed(42)\nn = 1000\n# X afeta tudo (confus√£o)\nX = np.random.normal(0, 1, (n, 3))\n# Z (instrumento) afeta D, mas tamb√©m depende de X\nZ = 0.5*X[:,0] + np.random.normal(0, 1, n)\n# U (n√£o observado) afeta D e Y\nU = np.random.normal(0, 1, n)\n# D (tratamento) depende de X, Z e U (vi√©s)\nD = 0.5*Z + 0.5*X[:,0] + U + np.random.normal(0, 0.5, n)\n# Y (outcome) depende de D, X e U. Efeito real de D √© 2.0\nY = 2.0*D + X[:,0] + U + np.random.normal(0, 0.5, n)\n\ndf = pd.DataFrame({'Y': Y, 'D': D, 'Z': Z})\nX_cols = pd.DataFrame(X, columns=['X1', 'X2', 'X3'])\n\n# --- 2. Fase de Machine Learning ---\n# Treinamos modelos para capturar a influ√™ncia de X em Y, D e Z\n\n# a) Prever Y dado X\nmodel_y = RandomForestRegressor(max_depth=5).fit(X_cols, df['Y'])\ny_hat = model_y.predict(X_cols)\ny_res = df['Y'] - y_hat # Res√≠duo Y (Ortogonalizado)\n\n# b) Prever D dado X\nmodel_d = RandomForestRegressor(max_depth=5).fit(X_cols, df['D'])\nd_hat = model_d.predict(X_cols)\nd_res = df['D'] - d_hat # Res√≠duo D (Ortogonalizado)\n\n# c) Prever Z dado X (Essencial para DoubleMLPIV!)\nmodel_z = RandomForestRegressor(max_depth=5).fit(X_cols, df['Z'])\nz_hat = model_z.predict(X_cols)\nz_res = df['Z'] - z_hat # Res√≠duo Z (Ortogonalizado)\n\n# --- 3. 2SLS cl√°ssico ---\n# y_res ~ beta * d_res (instrumentado por z_res)\n\n# 1¬∫ Est√°gio Manual: Regredir d_res contra z_res\nstage1 = sm.OLS(d_res, sm.add_constant(z_res)).fit()\nd_res_hat = stage1.predict() # Varia√ß√£o de D limpa de X e induzida por Z limpo\n\n# 2¬∫ Est√°gio Manual: Regredir y_res contra o predito do 1¬∫ est√°gio\nstage2 = sm.OLS(y_res, sm.add_constant(d_res_hat)).fit()",
		"tags": [ "note"]
},

{
		"title": "13. Guia de Equ√≠vocos",
		"date":"Thu Dec 25 2025 18:15:37 GMT+0000 (Coordinated Universal Time)",
		"url":"/digital-garden/path-for-the-true-and-brave/text/13-guia-de-equivocos/",
		"content": "Guia de Equ√≠vocos\nEmbora possamos utilizar os mesmos algoritmos de previs√£o para uma an√°lise causal, as abordagens divergem em termos de objetivos e interpreta√ß√£o. Enquanto modelos preditivos buscam correla√ß√µes est√°veis para prever o futuro, modelos causais exigem maior maturidade te√≥rica para identificar o efeito de uma interven√ß√£o.\nIrei deixar aqui alguns pontos de equ√≠vocos que podem surgir durante um percurso de constru√ß√£o de modelo. Alguns, podem parecer √≥bvio, mas sempre bom deixar descrito para n√£o esquecermos.\n1. Assumir causalidade em dados observacionais sem crit√©rio\nObserva√ß√µes emp√≠ricas que mostram associa√ß√£o entre duas vari√°veis n√£o permitem, por si s√≥, concluir causalidade. A associa√ß√£o pode ser fruto de confus√£o, causalidade reversa ou mera coincid√™ncia.\n\nExemplo: As vendas de sorvete e o n√∫mero de afogamentos aumentam simultaneamente; a temperatura (vari√°vel omitida) √© a causa comum de ambos.\nComo evitar: Sempre observe a constru√ß√£o do DAG, procure fontes de varia√ß√£o plausivelmente ex√≥genas, use desenho experimental quando poss√≠vel, e declare explicitamente as premissas necess√°rias para qualquer interpreta√ß√£o causal.\n\n2. Acreditar que a Randomiza√ß√£o resolve todos os problemas\nEnsaios aleatorizados reduzem vieses de sele√ß√£o na atribui√ß√£o do tratamento, mas n√£o* garantem validade externa autom√°tica, aus√™ncia de vieses de medi√ß√£o, ou aus√™ncia de n√£o‚Äëcompliance, perdas de seguimento e efeitos indiretos.\n\nExemplo: Um experimento onde muitos participantes do grupo de tratamento desistem (attrition) gera estimativas enviesadas.\nComo evitar: Monitore a ades√£o e perdas de seguimento; considere estimadores como Vari√°veis Instrumentais para lidar com a n√£o-conformidade.\n\n3. Controlar o m√°ximo de vari√°veis poss√≠vel\nDiferente do mundo preditivo, onde &quot;mais dados costumam ser melhor&quot;, na causalidade, incluir certas vari√°veis pode introduzir vi√©s. Controlar mediadores ou colisores pode distorcer o efeito real.\n\nPonto Chave: Um alto R2 ou poder preditivo n√£o implica poder causal. Incluir um colisor pode gerar uma correla√ß√£o esp√∫ria onde n√£o existe causalidade.\nComo evitar: Utilize o crit√©rio de Backdoor no seu DAG para decidir quais vari√°veis devem (e quais n√£o podem) ser controladas.\n\n4. Substituir o pensamento causal por modelos complexos\nModelos de Machine Learning altamente flex√≠veis podem prever o outcome com precis√£o, mas n√£o explicam o que aconteceria sob uma interven√ß√£o. A complexidade do algoritmo n√£o valida a suposi√ß√£o causal.\n\nComo evitar: Combine ML com frameworks causais (como Double Machine Learning), documente as premissas e realize an√°lises de sensibilidade.\n\n5. Ignorar a Heterogeneidade do Efeito\nAssumir que o efeito causal √© o mesmo para todos os indiv√≠duos (homogeneidade) pode mascarar resultados importantes.\n\nExemplo: Um desconto que aumenta as vendas para jovens, mas reduz o valor da marca para clientes premium.\nComo evitar: Estime efeitos heterog√™neos (CATE - Conditional Average Treatment Effect) e discuta os limites da generaliza√ß√£o dos resultados.\n\n6. Tratar o P-valor como prova de causalidade\nA signific√¢ncia estat√≠stica quantifica apenas a incerteza amostral sob um modelo espec√≠fico; ela n√£o valida suas suposi√ß√µes causais. Um efeito estatisticamente significativo (p&lt;0,05) n√£o elimina explica√ß√µes alternativas, como vari√°veis de confus√£o ou vi√©s de sele√ß√£o.\n\nO Trade-off: Isso est√° ligado ao equil√≠brio entre Vi√©s e Vari√¢ncia, que comentei anteriormente. Um modelo pode ter vari√¢ncia baixa (estimativas precisas/p-valor baixo), mas estar altamente enviesado por n√£o considerar a estrutura causal correta.\nMagnitude vs. Signific√¢ncia: Um tamanho de efeito grande ou um alto n√≠vel de signific√¢ncia n√£o garantem benef√≠cios pr√°ticos ou validade causal. Em grandes bases de dados (Big Data), quase qualquer correla√ß√£o irrelevante pode se tornar &quot;estatisticamente significativa&quot;, mesmo sem qualquer sentido causal. Uma vari√°vel com alto poder causal pode apresentar um p-valor alto (n√£o significante) se a amostra for pequena ou a vari√¢ncia for elevada. N√£o confunda precis√£o estat√≠stica com relev√¢ncia causal.\n\nComo evitar:\n\nFoque na magnitude do efeito e nos Intervalos de Confian√ßa, que mostram a incerteza de forma mais transparente.\nPriorize a robustez do desenho do estudo em vez da busca por p-valores baixos.\nCombine a evid√™ncia estat√≠stica com argumentos te√≥ricos e testes de sensibilidade.",
		"tags": [ "note"]
},

{
		"title": "14. GenAI",
		"date":"Thu Dec 25 2025 18:15:37 GMT+0000 (Coordinated Universal Time)",
		"url":"/digital-garden/path-for-the-true-and-brave/text/14-gen-ai/",
		"content": "GenAI\n√â importante salientar alguns pontos. Modelos de Large Language Models (LLMs) n√£o capturam, por si s√≥, rela√ß√µes de causalidade. H√° desafios conhecidos de reasoning em modelos n√£o determin√≠sticos e, para infer√™ncia causal, esses modelos n√£o substituem os conceitos e frameworks consolidados da econometria.\nAinda assim, LLMs podem ser usados como ferramenta de suporte, como por exemplo, para gerar hip√≥teses, explorar poss√≠veis vari√°veis instrumentais ou identificar potenciais confundidores ‚Äî por√©m sempre com muita cautela. O artigo Mining Causality: AI-Assisted Search for Instrumental Variables prop√µe um agente que auxilia na busca por vari√°veis instrumentais por meio de etapas de prompt e valida√ß√µes. Outra alternativa que complementa essa abordagem √© a biblioteca PyWhyLLM, que ajuda a encontrar rela√ß√µes (IVs, confundidores) que conectam tratamento ao desfecho.\nEssas ferramentas n√£o devem ser usadas para terceirizar decis√µes nem para substituir conhecimento de dom√≠nio ou regras de neg√≥cio. Seu uso exige criticidade, documenta√ß√£o cuidadosa e submiss√£o √† revis√£o por pares humanos. A interpreta√ß√£o dos resultados e a atribui√ß√£o de efeitos causais devem ser feitas por pesquisadores qualificados. Lembre-se interpreta√ß√µes equivocadas s√£o responsabilidade dos autores ‚Äî como comentado por Fisher. Quanto maior for o impacto ou a criticidade do trabalho, mais rigorosas devem ser as an√°lises.",
		"tags": [ "note"]
},

{
		"title": "2. Como Predi√ß√£o e Infer√™ncia Causal se Conversam",
		"date":"Thu Dec 25 2025 18:15:37 GMT+0000 (Coordinated Universal Time)",
		"url":"/digital-garden/path-for-the-true-and-brave/text/2-como-predicao-e-inferencia-causal-se-conversam/",
		"content": "Como Predi√ß√£o e Infer√™ncia Causal se Conversam\nPredi√ß√£o e infer√™ncia causal respondem a perguntas diferentes, mas complementares. Modelos de Machine Learning (ML) buscam estimar bem um resultado futuro, como por exemplo, quem tem maior probabilidade de churn. Infer√™ncia causal busca estimar o efeito - ou impacto - de uma interven√ß√£o, como por exemplo, quanto uma promo√ß√£o reduz o churn. Saber a probabilidade de um evento nem sempre informa qual a√ß√£o mudar√° esse evento; por isso precisamos das duas abordagens trabalhando em conjunto.\nA predi√ß√£o, por si s√≥, como falei anteriormente, foca na rela√ß√£o entre padr√µes, entre associa√ß√µes. Se o seu objetivo for encontrar apenas padr√µes e classificar - pense como em um problema de classifica√ß√£o de fraude, rotula√ß√£o de spam - a predi√ß√£o, simples, j√° resolve. Ela encontra padr√µes e te retorna comportamentos at√≠picos. Nisso, a formula j√° funciona, mas e quando precisamos a prescri√ß√£o? E se, sob dados de crime, voc√™ n√£o quer a probabilidade de uma reincid√™ncia de uma pessoa - √© um modelo claramente perigoso, mas apenas para fins comparativos! - mas gostaria de saber o impacto de programas de ressocializa√ß√£o e se houve uma causa e efeito, isto √©, se programas sociais auxiliam de fato para que esta pessoa n√£o cometa mais crimes? Um modelo de previs√£o n√£o resolveria. √â para isso que a infer√™ncia causal entra.\n\n[!tip]\nPredi√ß√£o: otimiza acur√°cia. Boa para segmenta√ß√£o, detec√ß√£o de anomalias e prioriza√ß√£o (ex.: identificar clientes em risco).\nInfer√™ncia causal: estima efeitos de interven√ß√µes e responde ‚Äúo que acontece se eu fizer X?‚Äù. Essencial para tomar decis√µes que mudam o mundo.\n\nMixtape Sessions: Foundation of Causality\n\n[!tip]\nBusiness impact is always a causal question",
		"tags": [ "note"]
},

{
		"title": "3. Teorias da Causalidade",
		"date":"Thu Dec 25 2025 18:15:37 GMT+0000 (Coordinated Universal Time)",
		"url":"/digital-garden/path-for-the-true-and-brave/text/3-teorias-da-causalidade/",
		"content": "Teorias da Causalidade\nA causalidade √© um conceito complexo, abordado por pensadores como Arist√≥teles, David Hume, e Kant, com contribui√ß√µes mais recentes de economistas como Angus Deaton e estat√≠sticos. Em diversas √°reas, h√° uma variabilidade de defini√ß√µes dela.\nPara o contexto da estat√≠stica e da modelagem de dados, a abordagem mais relevante √© a Causalidade Regular (diferente da Causalidade Estrita de Descartes, que se baseia em leis naturais). A Causalidade Regular foca em eventos probabil√≠sticos em vez de determin√≠sticos, dando um foco grande em probabilidade condicional. Essa linha de pensamento foi inicialmente influenciada por ideias de Hans Reichenbach e John Stuart Mill, evoluindo para o que √© hoje reconhecido como a moderna teoria da infer√™ncia causal, impulsionada por Judea Pearl e seu trabalho com Modelos Gr√°ficos Ac√≠clicos Direcionados (DAGs). Outros nomes, como Susan Haack e Deborah Mayo, tamb√©m trouxeram contribui√ß√µes importantes para a filosofia da causalidade e da estat√≠stica.\nNeste modelo, a causalidade √© definida por tr√™s aspectos principais:\n\nDirecionalidade: A rela√ß√£o de causa e efeito √© estruturada graficamente, indicando que o evento A causa o evento B (A‚ÜíB).\nTemporalidade: A causalidade √© expressa em termos de probabilidades condicionais ‚Äì a probabilidade de um evento, dado que o outro j√° ocorreu. No entanto, o conceito estat√≠stico fundamental aqui √© a probabilidade de a causa A ocorrer, dado o efeito B, se e somente se A for a causa. Em termos de probabilidades condicionais, o que √© crucial √© a compara√ß√£o entre P(B|A) e P(B|¬¨A) (a probabilidade do efeito B ocorrer na presen√ßa da causa A versus na sua aus√™ncia).\nReprodutibilidade (ou Invari√¢ncia): Para ser considerada causal, a rela√ß√£o observada entre os eventos deve ser invariante, ou seja, consistentemente reproduzida sob as mesmas condi√ß√µes e em diferentes contextos relevantes.\n\n[!tip]\nA Independ√™ncia Condicional √© a chave da infer√™ncia causal. Ela permite distinguir rela√ß√µes causais genu√≠nas de simples associa√ß√µes estat√≠sticas, identificando se a rela√ß√£o entre dois eventos desaparece ao condicionar uma terceira vari√°vel (a vari√°vel de confus√£o).\n\n[!tip]\nAs vari√°veis de confus√£o (ou vari√°veis confundidoras, ou confounders) s√£o vari√°veis que exercem influ√™ncia tanto na causa quanto no efeito em estudo.\n√â crucial identificar e controlar essas vari√°veis, pois a sua presen√ßa afeta diretamente a validade da infer√™ncia causal, levando a estimativas enviesadas do verdadeiro efeito, causando o que chamamos de associa√ß√£o esp√∫ria.\n\nDefini√ß√£o de Causalidade, Causa√ß√£o e Associa√ß√£o\nComo falei, existe uma defini√ß√£o ampla sobre causalidade, a qual varia conforme a √°rea de atua√ß√£o. Essa pluralidade de conceitos √© bem representada no artigo The Representation of Causality and Causation with Ontologies: A Systematic Literature Review, que demonstra como as defini√ß√µes mudam ao longo da literatura. Para o escopo probabil√≠stico em que atuaremos, adotaremos uma perspectiva mais pr√≥xima √† de Judea Pearl.\nCausalidade √© a rela√ß√£o direcional de causa e efeito entre entidades, vari√°veis ou eventos. J√° a causa√ß√£o refere-se ao mecanismo ou a√ß√£o pela qual a causa produz o efeito. Ambos os conceitos envolvem direcionalidade, temporalidade e influ√™ncia ‚Äî a ideia de que um elemento efetivamente gera uma altera√ß√£o no outro.\nEm contraste, a associa√ß√£o √© a mera rela√ß√£o estat√≠stica entre duas vari√°veis. √â fundamental n√£o confundirmos com causalidade. Por defini√ß√£o, a associa√ß√£o pode incluir vieses, enquanto a causa√ß√£o busca isolar rela√ß√µes diretas. Assim, duas vari√°veis podem n√£o ter influ√™ncia direta entre si, mas parecerem relacionadas por serem influenciadas por uma vari√°vel externa n√£o mapeada (lembremos da rela√ß√£o esp√∫ria). Nesses casos, h√° associa√ß√£o, mas n√£o h√° nexo causal direto.\n\n[!tip]\nCausal inference is the science of inferring causation from association and understanding when and why they differ. - Matheus Facure\n\nDefini√ß√£o Formal\nE[Y|T=1]‚àíE[Y|T=0]=E[Y1‚àíY0|T=1]‚èüATT+{E[Y0|T=1]‚àíE[Y0|T=0]}‚èüBIASAssocia√ß√£o √© igual ao efeito de tratamentos no grupo tratado mais o vi√©s, que por sua vez √© dado por como o grupo tratado e controlado diferem antes do tratamento, no caso de ambos de nenhum deles receberem o tratamento. Nela haver√° causalidade se n√£o houver vi√©s, isto √©, que em outras palavras, ocorrer√° causa√ß√£o somente se o grupo tratado e o controlado s√£o iguais ou compar√°veis, exceto pelo seu tratamento quando o resultado do n√£o tratado √© igual ao contrafactual do tratado.\nE[Y0|T=0]=E[Y0|T=1]Problema Fundamental da Infer√™ncia Causal\nO Problema Fundamental da Infer√™ncia Causal reside na impossibilidade de observar simultaneamente, na mesma unidade, o resultado factual e o resultado contrafactual .\nPara quantificar o efeito causal de um tratamento, seria necess√°rio calcular a diferen√ßa entre esses dois resultados. No entanto, uma √∫nica unidade (seja um indiv√≠duo, evento ou vari√°vel) s√≥ pode existir em um √∫nico estado (tratado ou n√£o tratado) em um dado momento.\nEm ess√™ncia, a quantifica√ß√£o exata exigiria um universo paralelo onde a unidade pudesse ser observada em condi√ß√µes id√™nticas, mas sob estados de tratamento opostos. Dado que isso √© logisticamente imposs√≠vel, o problema √© considerado o obst√°culo central da infer√™ncia causal.",
		"tags": [ "note"]
},

{
		"title": "4. Escada da Causa√ß√£o",
		"date":"Thu Dec 25 2025 18:15:37 GMT+0000 (Coordinated Universal Time)",
		"url":"/digital-garden/path-for-the-true-and-brave/text/4-escada-da-causacao/",
		"content": "Escada da Causa√ß√£o\nA escada da causa√ß√£o √© uma defini√ß√£o de Judea Pearl que organiza tr√™s n√≠veis de racioc√≠nio sobre dados e efeitos. Cada degrau responde a tipos distintos de perguntas e demanda m√©todos/assun√ß√µes diferentes.\n1. Primeiro Degrau: Associa√ß√£o\nAssocia√ß√£o √© o degrau mais b√°sico da escada da causalidade. Trata-se de detectar padr√µes e regularidades a partir de observa√ß√µes: ‚ÄúA e B tendem a ocorrer juntos‚Äù ou ‚Äúquando X aumenta, Y costuma aumentar/diminuir‚Äù. Ela √© a forma mais primitiva que temos disso. Como falei, √© algo que por padr√£o, fazemos no nosso dia a dia. √â a √°rea do observacional. Pense como uma coruja observando o movimento de um rato: ela n√£o precisa entender a anatomia do rato, apenas associar o ru√≠do na mata ao alimento. Da mesma forma, nossos ancestrais aprenderam que certos cogumelos s√£o venenosos; se quem comeu anteriormente veio a falecer, associamos o consumo √† morte.\n2. Segundo Degrau: Interven√ß√£o\nA interven√ß√£o vai al√©m da observa√ß√£o passiva; ela envolve a manipula√ß√£o ativa de vari√°veis para observar resultados. √â o n√≠vel dos experimentos controlados (Testes A/B). Por exemplo:\n\nUm gerente perguntando &quot;O que acontecer√° com nossas vendas de fio dental se dobrarmos o pre√ßo da pasta de dente?&quot;\nTomar aspirina para curar dor de cabe√ßa - intervindo na quantidade de aspirina para afetar o status da dor\nDefinir pre√ßos para vender excesso de estoque\n\nA interven√ß√£o √© superior √† associa√ß√£o porque envolve n√£o apenas observar, mas mudar o que existe. Ver fuma√ßa nos conta uma hist√≥ria completamente diferente sobre a probabilidade de fogo do que fazer fuma√ßa. N√£o podemos responder quest√µes sobre interven√ß√µes apenas com dados coletados passivamente, n√£o importa o tamanho do conjunto de dados ou a profundidade da rede neural.\n3. Terceiro Degrau: Contrafactuais\nSe a Associa√ß√£o √© sobre ver e a Interven√ß√£o √© sobre fazer, o Contrafactual √© sobre imaginar. Este √© o topo da escada e a caracter√≠stica que nos define como seres humanos. Ele lida com o &quot;e se?&quot;: a capacidade de olhar para o passado, comparar o que aconteceu com o que poderia ter ocorrido sob condi√ß√µes diferentes, e extrair uma li√ß√£o de causalidade profunda disso.\nDiferente dos degraus anteriores, o contrafactual (o que teria ocorrido se o tratamento n√£o tivesse sido aplicado) n√£o pode ser respondido apenas com dados atuais ou experimentos presentes, pois o evento (o que ocorreu com o tratamento) j√° passou. Exemplos:\n\nMedicina e Sa√∫de: &quot;O paciente faleceu. Ser√° que ele teria sobrevivido se tiv√©ssemos administrado o antibi√≥tico duas horas antes?&quot;\n\nMarketing e E-commerce: &quot;Tivemos 1.000 vendas nesta campanha. Quantas vendas ter√≠amos feito se n√£o tiv√©ssemos oferecido o cupom de desconto?&quot;\n\nSeguran√ßa P√∫blica: &quot;A criminalidade caiu ap√≥s a instala√ß√£o de novas c√¢meras. Ela teria ca√≠do da mesma forma se a taxa de desemprego n√£o tivesse diminu√≠do no mesmo per√≠odo?&quot;\n\nJusti√ßa e √âtica: &quot;O r√©u foi condenado por neglig√™ncia. Ele teria evitado o acidente se tivesse feito a manuten√ß√£o dos freios?&quot;",
		"tags": [ "note"]
},

{
		"title": "5. Design de Experimentos",
		"date":"Thu Dec 25 2025 18:15:37 GMT+0000 (Coordinated Universal Time)",
		"url":"/digital-garden/path-for-the-true-and-brave/text/5-design-de-experimentos/",
		"content": "Design de Experimentos\nNa introdu√ß√£o ao seu trabalho The Design of Experiments, Ronald Fisher demonstrou preocupa√ß√£o com a falta de clareza e rigor metodol√≥gico em experimentos. Ele notou que a aus√™ncia de um design experimental robusto poderia levar a:\n\nDificuldade de Interpreta√ß√£o: O leitor e, por vezes, o pr√≥prio cientista, poderiam ter percep√ß√µes diferentes sob os resultados, levando a conclus√µes que n√£o eram suportadas pelos dados, ou que poderiam ter ocorrido por acaso (chance), mesmo que a hip√≥tese fosse falsa.\nCar√™ncia Estrutural (Design): Falhas l√≥gicas e estruturais, com o experimento sendo fundamentalmente incorreto, muitas vezes devido a controles inadequados ou √† aus√™ncia de compara√ß√£o v√°lida.\n\nFisher prop√¥s um m√©todo rigoroso que visa trazer facilidade e confian√ßa ao cientista no t√≥pico de experimenta√ß√£o, desde o planejamento (design) at√© o desenvolvimento e an√°lise.\n\nConceitos Chave de Fisher:\n\nRandomiza√ß√£o: Para garantir que as caracter√≠sticas n√£o observ√°veis se distribuam igualmente.\nControle: Para isolar o efeito do tratamento.\nReplica√ß√£o: Para reduzir o erro experimental e aumentar a precis√£o.\n\nExperimentos Aleatorizados\nPara contornar o Problema Fundamental da Infer√™ncia Causal, car√™ncia de design de experimentos e controlar vi√©s de vari√°vel omitida, recorre-se a m√©todos de pesquisa como o Experimento Aleatorizado.\nO experimento aleatorizado, ou ensaio cl√≠nico randomizado (RCT), √© um procedimento no qual as unidades de uma amostra populacional s√£o alocadas de forma aleat√≥ria*(randomizada) ao grupo de tratamento ou ao grupo de controle.\nA randomiza√ß√£o √© crucial, pois:\n\nElimina vieses de sele√ß√£o e confus√£o.\nCria grupos estatisticamente compar√°veis.\n\nAo garantir que a √∫nica diferen√ßa sistem√°tica esperada entre os grupos √© a aplica√ß√£o do tratamento, a randomiza√ß√£o permite que a diferen√ßa observacional nos resultados seja interpretada como uma estimativa v√°lida do efeito causal m√©dio do tratamento na popula√ß√£o.\n\n[!tip]\nMesmo assim, RCT n√£o √© uma bala de prata. Existem premissas importantes em estudos observacionais que precisam ser respeitas tamb√©m em RCT. Muitas das vezes, ela de fato √©, mas √© importante termos conhecimento delas:\n\nSUTVA (Stable Unit Treatment Value Assumption)\n\nConsist√™ncia: o tratamento √© bem definido; o outcome observado para uma unidade sob o tratamento t √© igual ao potencial outcome Y(t).\nSem interfer√™ncia: o tratamento de uma unidade n√£o afeta o outcome de outra (sem spillovers/efeitos indiretos).\n\nIgnorabilidade / Unconfoundedness / Exchangeability\n\nOs potenciais outcomes s√£o independentes do tratamento, condicional √†s covari√°veis observadas: ‚üÇY(0),Y(1)‚üÇT|X. Em RCTs a randomiza√ß√£o garante ignorabilidade em expectativa.\n\nPositividade / Overlap\n\nPara todo valor de X considerado, h√° probabilidade estritamente positiva de receber cada condi√ß√£o: 0 &lt; P(T=1 | X) &lt; 1. Sem positividade n√£o √© poss√≠vel comparar contrafactuais em certas subpopula√ß√µes.\n\nControle de confundidores\n\nEm estudos observacionais: medir e ajustar os confundidores (regress√£o, propensity scores, IPW, matching, estratifica√ß√£o, etc.).\nEm RCTs: projetar blocos/estratifica√ß√£o quando necess√°rio e checar balanceamento pr√©-tratamento; ajustar para covari√°veis quando melhora precis√£o.\n\nAmea√ßa p√≥s-randomiza√ß√£o\n\nN√£o-ades√£o (noncompliance), perda amostral diferencial (attrition), contamina√ß√£o e mediadores induzidos por tratamento podem reintroduzir vi√©s.\n\n[!tip]\nChecagens pr√°ticas recomendadas\n\nVerificar balanceamento de covari√°veis pr√©-tratamento (tabelas/estad√≠sticas e testes; love plot).\nConferir overlap/propensity score distributions e excluir regi√µes sem suporte comum.\nMonitorar taxas de ades√£o e perda.\n\nLecture 3 ‚Äì The Magic of Randomized Control Trials\n\nLecture 3 ‚Äì The Magic of Randomized Control Trials\n\n[!tip]\nUm bom artigo que podemos observar o carinho de um bom design de experimento e aleatorizada, √© o artigo The impact of computer usage on academic performance: Evidence from a randomized trial at the United States Military Academy.\n\nPontos de Aten√ß√£o\n\nValida√ß√£o Interna: Refere-se √† confian√ßa de que o efeito observado no resultado √© causado unicamente pela manipula√ß√£o do tratamento (a vari√°vel independente) e n√£o por fatores externos, vieses ou erros de medi√ß√£o dentro do grupo de estudo. Um experimento tem alta validade interna se pudermos afirmar com certeza que o tratamento causou a mudan√ßa no resultado.\n\nPonto de Aten√ß√£o: Amea√ßas √† validade interna incluem a sele√ß√£o dos participantes, a matura√ß√£o (mudan√ßas nos participantes ao longo do tempo), a hist√≥ria (eventos externos que ocorrem durante o experimento) e a mortalidade/abandono (perda de participantes).\n\nValida√ß√£o Externa: Trata-se da capacidade de generalizar os resultados do experimento para a popula√ß√£o mais ampla ou para outros ambientes e contextos. Se os resultados s√≥ se aplicarem √† √°rea de amostragem espec√≠fica (demografia), a validade externa √© baixa.\n\nPonto de Aten√ß√£o: Amea√ßas √† validade externa incluem a intera√ß√£o entre sele√ß√£o e tratamento (o efeito s√≥ se aplica ao grupo selecionado) e os efeitos de laborat√≥rio (condi√ß√µes artificiais que n√£o refletem o mundo real).\n\nValidade de Construto\n\nDefini√ß√£o: Refere-se √† adequa√ß√£o das medidas. Garante que as vari√°veis operacionais (as formas concretas de medir ou manipular as vari√°veis no seu experimento) realmente representam os construtos te√≥ricos (os conceitos abstratos que voc√™ est√° estudando).\nEm outras palavras: √â a certeza de que o experimento est√° medindo aquilo que se prop√¥s a medir.\nPonto de Aten√ß√£o:\n\nDeve-se garantir que as m√©tricas realmente capturem a ess√™ncia dos conceitos (ex: satisfa√ß√£o do cliente, motiva√ß√£o).\nAmea√ßas Comuns:\n\nSub-representa√ß√£o do Construto: O teste n√£o mede todos os aspectos do conceito (a medida √© incompleta).\nVari√¢ncia de M√©todos Irrelevantes: A medi√ß√£o √© afetada por fatores n√£o relacionados ao conceito que se deseja medir.\n\nEfeito Spillover\n\nOcorre quando o tratamento aplicado ao Grupo de Tratamento afeta, indiretamente, o Grupo de Controle (ou vice-versa). Isso √© uma viola√ß√£o da suposi√ß√£o de que o resultado de uma unidade n√£o √© afetado pelo tratamento de outra (SUTVA violation). O tratamento &quot;vaza&quot; ou a informa√ß√£o/benef√≠cio se espalha.\n\nExemplos:\n\nEm experimentos geogr√°ficos, o tratamento aplicado em uma √°rea de teste afeta as pessoas em uma √°rea de controle vizinha\nUm participante do grupo de controle aprende sobre a nova funcionalidade com um amigo do grupo de tratamento (contamina√ß√£o).\nA mudan√ßa de pre√ßo em uma loja (grupo de tratamento) afeta a demanda ou percep√ß√£o dos clientes de uma loja vizinha (grupo de controle).\nEm experimentos geogr√°ficos, o tratamento aplicado em uma √°rea de teste afeta as pessoas em uma √°rea de controle vizinha.\n\nImplica√ß√£o: Se o spillover ocorrer, o Grupo de Controle n√£o √© mais uma verdadeira linha de base, o que compromete a validade intern. A estimativa do efeito causal do tratamento ser√° enviesada (subestimada ou superestimada).\nEstrat√©gias de Mitiga√ß√£o: Usar grupos de controle distantes (geogr√°fica ou socialmente) ou implementar cegamento (impedir que os participantes saibam quem recebeu o tratamento).\n\nProblemas com Experimentos Aleatorizados\nEm um RCT, os participantes s√£o distribu√≠dos aleatoriamente para o grupo de tratamento ou controle. Essa randomiza√ß√£o visa equilibrar todas as vari√°veis de confus√£o (tanto as conhecidas quanto as desconhecidas) entre os grupos, permitindo que qualquer diferen√ßa observada no resultado seja atribu√≠da, com alta confian√ßa, √† interven√ß√£o (causa).\nEmbora seja o padr√£o de ouro na metodologia experimental, ele n√£o oferece uma garantia absoluta de causalidade, pois a randomiza√ß√£o inicial √© apenas o primeiro passo. A causalidade pode ser comprometida por vieses p√≥s-randomiza√ß√£o que surgem durante a execu√ß√£o do estudo. Problemas como a desigualdade de caracter√≠sticas entre os participantes, perda ou at√© abandono podem prejudicar o resultado para uma generaliza√ß√£o dos resultados.\nAl√©m das limita√ß√µes metodol√≥gicas na condu√ß√£o do estudo, o RCT √© invi√°vel ou anti√©tico em in√∫meros cen√°rios de pesquisa causal. Existem fen√¥menos de interesse (como o efeito de eventos raros, exposi√ß√µes de longu√≠ssimo prazo, ou vari√°veis n√£o manipul√°veis, como o status socioecon√¥mico) onde a aleatoriedade √© inating√≠ve. Mais gravemente, a randomiza√ß√£o √© anti-√©tic em exposi√ß√µes que s√£o sabidamente prejudiciais. Por exemplo, seria moralmente inaceit√°vel randomizar uma popula√ß√£o para for√ßar um grupo a fumar a fim de analisar as chances de c√¢ncer de pulm√£o.\nPortanto, em contextos onde a interven√ß√£o n√£o pode ser controlada por um RCT devido a impedimentos √©ticos ou pr√°ticos, os pesquisadores devem recorrer a outras ferramentas, como tamb√©m √© poss√≠vel aplicar outros tipos de amostragens.\nExperimentos Condicionalmente Aleat√≥rios\nEm amostras de tamanho limitado ou dependendo de cen√°rios espec√≠ficos, a aleatoriza√ß√£o simples pode, por acaso, resultar em um desequil√≠brio em covari√°veis entre os grupos. Esse desequil√≠brio pode levar a um vi√©s de sele√ß√£o e comprometer a validade interna do experimento. Para mitigar esse risco e equilibrar as caracter√≠sticas importantes na amostra, podemos utilizar m√©todos de Aleatoriza√ß√£o Condicional. Um m√©todo mais simples e comumente utilizado, √© a estratifica√ß√£o por covari√°veis, isto √©, dividir a popula√ß√£o em subgrupos com base em que cada propor√ß√£o e caracter√≠sticas sejam divididas entre o grupo de controle e tratamento. Ainda sim, h√° diversos outros meios.\nElementos do Poder Estat√≠stico\n\nNo contexto de estudos experimentai, ainda estaremos trabalhando com testes de hip√≥teses, pois de fato estamos atuando com cen√°rios nas quais queremos estudar. Isto implica que estamos ainda sujeitos a cometer erros estat√≠sticos ao tomar uma decis√£o sobre a hip√≥tese nula H0.\nErros do Tipo I e Tipo II\n\nErro do Tipo I (Falso Positivo):\nOcorre quando rejeitamos a H0 quando ela √©, na verdade, verdadeira. A probabilidade de cometer um Erro Tipo I √© controlada pelo n√≠vel de signific√¢ncia Œ±. Comumente o valor de Œ± √© utilizado em 0,05, o que significa que aceitamos 5% de chance de concluir erroneamente que h√° um efeito.\n\n[!tip]\nNeste contexto, seria concluir que o tratamento teve um efeito quando, na realidade, a diferen√ßa observada foi devida puramente ao acaso.\n\nErro do Tipo II (Falso Negativo):\nOcorre quando falhamos em rejeitar a H0 quando ela √©, na verdade, falsa. A probabilidade de cometer um Erro Tipo II √© controlado pelo poder de teste, 1‚àíŒ≤.\n\n[!tip]\nNeste contexto, seria concluir que o tratamento n√£o teve um efeito (ou que n√£o houve diferen√ßa significativa) quando, na realidade, ele teve um efeito real na popula√ß√£o.\n\nAn√°lise de Poder Estat√≠stico\n√â fundamental que fa√ßamos uma an√°lise do poder, pois permite determinar o tamanho de amostra necess√°rio para detectar um efeito de determinado tamanho com uma probabilidade aceit√°vel. Os quatro termos inter-relacionados nesta an√°lise s√£o:\n\nTamanho da Amostra: O n√∫mero de observa√ß√µes inclu√≠das no estudo. Um aumento na amostra geralmente aumenta o Poder do Teste.\nN√≠vel de Signific√¢ncia Œ±: Se for diminu√≠do (ex: de 0,05 para 0,01), a chance de um Falso Positivo diminui, mas a exig√™ncia para rejeitar H0 √© maior, o que, por sua vez, diminuindo a sensibilidade do Poder do Teste (aumentando Œ≤).\nPoder do Teste (1‚àíŒ≤): O poder de teste √© a sensibilidade do estudo. Geralmente, o poder do teste √© fixado em 0,80 (ou 80%), o que significa que se um efeito real existir, o estudo tem 80% de chance de detect√°-lo.\nTamanho do Efeito (Effect Size - Cohen‚Äôs D) ou Efeito M√≠nimo Detect√°vel (Minimum Detectable Effect - MDE): O Tamanho do Efeito √© a magnitude da diferen√ßa ou relacionamento de interesse na popula√ß√£o. O MDE √© o menor tamanho de efeito que o estudo est√° equipado para detectar com as configura√ß√µes de amostra, n√≠vel de signific√¢ncia e Poder do teste.\n\nRela√ß√£o com o MDE:\n\nSe o MDE for muito alto (ex: 15%), o estudo √© muito &quot;grosseiro&quot; e pode falhar em detectar efeitos menores, mas clinicamente ou economicamente relevantes (ex: 2%), resultando em um aumento da probabilidade do Erro Tipo II.\nPara reduzir o MDE e, assim, aumentar a sensibilidade do estudo a efeitos menores, √© necess√°rio **aumentar o Tamanho da Amostra N.\n\nO MDE n√£o deve ser um n√∫mero arbitr√°rio; ele deve ser o menor efeito que √© economicamente ou clinicamente relevante para a sua √°rea. A An√°lise de Poder a Priori deve usar este MDE junto com o Poder e o Alpha para calcular o tamanho de amostra m√≠nimo necess√°rio. Se o tamanho da amostra for invi√°vel para o MDE de interesse, o estudo deve ser repensado.\n\n[!tip]\nSegundo Ron Kovahi, se o MDE for menor que 5%, dificilmente voc√™ ir√° detect√°-lo com confian√ßa, junto ao fato da quantidade de amostras necess√°rias para verificar. O ideal ser√° entre 5% a 10%.",
		"tags": [ "note"]
},

{
		"title": "6. DAG",
		"date":"Thu Dec 25 2025 18:15:37 GMT+0000 (Coordinated Universal Time)",
		"url":"/digital-garden/path-for-the-true-and-brave/text/6-dag/",
		"content": "DAG\nO Modelo Gr√°fico Ac√≠clico Direcionado (DAG) √© uma ferramenta visual e matem√°tica essencial na moderna teoria da infer√™ncia causal, especialmente em contextos observacionais onde experimentos s√£o invi√°veis ou anti√©ticos. Seu prop√≥sito principal √© tornar expl√≠citas as suposi√ß√µes causais: identificar caminhos que geram confus√£o, indicar quais vari√°veis devem ser ajustadas e orientar estrat√©gias de identifica√ß√£o, como caminhos backdoor.\nFundamentos Estruturais\n\nN√≥s (Vari√°veis): Cada n√≥ no gr√°fico representa uma vari√°vel aleat√≥ria. A estrutura do DAG √© definida com base na Independ√™ncia Condicional entre as vari√°veis, que √© o conceito-chave da moderna infer√™ncia causal. Ele permite traduzir as rela√ß√µes causais em restri√ß√µes estat√≠sticas test√°veis. Na teoria dos conjuntos, o conceito de Probabilidade Condicional P(B|A) ‚Äì que define a rela√ß√£o entre conjuntos de eventos ‚Äì √© an√°logo algebricamente a correla√ß√£o parcial r(X,Y)Z que √© usada em algoritmos de aprendizado de estrutura causal, como o Inductive Causality.\nArestas (Rela√ß√µes ‚Üí): As setas indicam a direcionalidade da causalidade. A‚ÜíB significa que A √© uma causa direta de B. O DAG representa a Causalidade Regular, focada em graus mensur√°veis (grada√ß√£o) de causalidade, diferentemente da Causalidade Estrita (classifica√ß√£o 0 ou 1).\nAciclicidade (N√£o C√≠clico): √â a regra fundamental. N√£o pode haver um ciclo fechado (por exemplo, A‚ÜíB e B‚ÜíA). Isso imp√µe uma ordem temporal e causal clara, garantindo que o modelo seja comput√°vel para infer√™ncia.\n\nObjetivos\n\nVisualizar caminhos entre tratamento D e desfecho Y: o DAG exp√µe todos os caminhos (causais e n√£o causais) que conectam D e Y, permitindo identificar fontes potenciais de vi√©s.\n\nIdentifica√ß√£o de vari√°veis de confus√£o: Conseguir localizar vari√°veis que s√£o causas tanto de D quanto de Y e, portanto, que precisam ser consideradas ao estimar o efeito causal.\n\nAplicar o crit√©rio do backdoor: ele fornece uma regra gr√°fica para encontrar conjuntos de vari√°veis que, se condicionados, bloqueiam todos os caminhos n√£o causais entre D e Y, permitindo identificar o efeito causal de D em Y.\n\nUm caminho backdoor √© um caminho entre D e Y que come√ßa com uma seta apontando para D (exemplo: D‚ÜêV‚ÜíY). Se esse caminho n√£o for bloqueado, ele causa vi√©s de confounding.\nAo controlar (condicionar) a vari√°vel V neste exemplo, o caminho traseiro √© bloqueado, e a associa√ß√£o restante entre D e Y pode ser interpretada como o efeito causal de D em Y.\n\n[!tip]\nIdentifica√ß√£o Causal via Backdoor: O objetivo do ajuste de backdoor √© simular uma interven√ß√£o f√≠sica (o operador do(x)) usando apenas dados observacionais. Ao bloquear os caminhos backdoor, eliminamos a &quot;contamina√ß√£o&quot; das associa√ß√µes esp√∫rias, permitindo que a correla√ß√£o restante seja interpretada como o efeito causal puro, aproximando o estudo observacional dos resultados de um Experimento Controlado Aleatorizado (RCT).\n\nEm ess√™ncia, enquanto o RCT tenta eliminar os vieses por meio da randomiza√ß√£o no design do estudo, o DAG ajuda a identificar e bloquear os confoundings por meio de ajustes na an√°lise dos dados observacionais.\nD-Separa√ß√£o\nA d‚Äësepara√ß√£o √© o crit√©rio gr√°fico que determina se um conjunto Z bloqueia todos os caminhos entre X e Y, implicando X‚ä•‚ä•Y|Z. Regras essenciais sobre bloqueio de um caminho:\n\nCadeia, garfo ou causa comum (X‚ÜíV‚ÜíY ou X‚ÜêV‚ÜíY): o caminho √© bloqueado se o n√≥ intermedi√°rio (B) estiver condicionado.\nUm colisor ou efeito comum (X‚ÜíV‚ÜêY): o caminho √© bloqueado se o colisor B N√ÉO for condicionado; condicionar o colisor (ou um de seus descendentes) abre o caminho (isto √©, cria depend√™ncia).\n\nSe todo caminho entre X e Y for bloqueado por Z, ent√£o X e Y s√£o d‚Äëseparados por Z no gr√°fico.\n\n[!tip]\nExemplo: A afirma√ß√£o de que X e Y s√£o d-separados por Z - X‚ä•‚ä•Y|Z - √© testada em dados usando correla√ß√£o parcial ou independ√™ncia condicional. A correla√ß√£o parcial entre X e Y dado Z, œÅXY‚ãÖZ, representa a correla√ß√£o entre os res√≠duos de uma regress√£o de X em Z e os res√≠duos de uma regress√£o de Y em Z. Um valor pr√≥ximo de zero para œÅXY‚ãÖZ corrobora a independ√™ncia e, portanto, a d-separa√ß√£o.\n\nEstat√≠stica Psicobio II 2024 #24 - DAG II Directed Acyclic Graphs - d' separation; algoritmo PC e IC\n\nTermos de Classifica√ß√£o\n\nEstat√≠stica Psicobio II 2024 #25 - DAG III - Aplica√ß√µes do DAG, Propensity Scores e diff-n-diff\nEm um DAG, as vari√°veis podem ser caracterizadas pela sua posi√ß√£o relativa √† Exposi√ß√£oe ao Desfecho. Abaixo os tipos mais relevantes e as a√ß√µes pr√°ticas recomendadas.\nTipos de Vari√°veis\n\nConfundidor (confus√£o)\nUm ancestral tanto da exposi√ß√£o quanto do desfecho.\n\nCria um caminho n√£o causal entre X e Y, distorcendo o verdadeiro efeito de X sobre Y.\nA√ß√£o: √â uma vari√°vel que devemos condicionar para fechar o caminho de confus√£o e obter uma estimativa n√£o enviesada do efeito causal.\nEstrutura: X‚ÜêV‚ÜíY\n\nMediador\nUm descendente da Exposi√ß√£o e um antecedente do Desfecho.\n\nFun√ß√£o: Explica o mecanismo pelo qual X afeta Y, estando no caminho causal de interesse.\nA√ß√£o: N√£o devemos condicionar a vari√°vel mediadora se nosso objetivo √© estimar o efeito total de X sobre Y. Condicionar V nos daria apenas o efeito direto de X sobre Y.\nEstrutura: X‚ÜíV‚ÜíY\n\nColisor\n\nUm descendente tanto da Exposi√ß√£o quanto do Desfecho\nFun√ß√£o: Por si s√≥, n√£o cria vi√©s. O vi√©s √© induzid apenas quando condicionamos (inclu√≠mos na an√°lise) o Colisor.\nA√ß√£o: N√£o devemos condicionar o colisor. Condicionar um Colisor abre um caminho de vi√©s, levando ao fen√¥meno chamado vi√©s de sele√ß√£o ou vi√©s do colisor.\nEstrutura: X‚ÜíV‚ÜêY",
		"tags": ["24", "25", "note"]
},

{
		"title": "7. Regress√£o Linear",
		"date":"Thu Dec 25 2025 18:15:37 GMT+0000 (Coordinated Universal Time)",
		"url":"/digital-garden/path-for-the-true-and-brave/text/7-regressao-linear/",
		"content": "Regress√£o Linear\nModelos de regress√£o linear t√™m ampla aplicabilidade na infer√™ncia causal. Pelo m√©todo dos m√≠nimos quadrados ordin√°rios (MQO), conseguimos estimar par√¢metros que, sob suposi√ß√µes apropriadas, t√™m interpreta√ß√£o causal.\nDada uma rela√ß√£o simples Y ~ X + Œµ, podemos estimar o efeito de X sobre Y pelas estimativas MQO, Œ≤^0 e Œ≤^1.\n\n[!tip]\nO coeficiente Œ≤^0 pode ser interpretado como o valor esperado de Y quando X=0 (e quando todas as outras vari√°veis no modelo s√£o zero).\n\nAten√ß√£o: essa interpreta√ß√£o s√≥ √© √∫til quando X = 0 √© um valor plaus√≠vel/observado.\n\n[!tip]\nEm um estudo com grupo de controle e tratamento (X indica tratamento), Œ≤^0 √© a m√©dia do grupo controle e Œ≤^1 √© a diferen√ßa m√©dia (efeito m√©dio) entre tratamento e controle ‚Äî desde que as suposi√ß√µes de identifica√ß√£o sejam satisfeitas.\n\nO coeficiente Œ≤^1 representa a varia√ß√£o m√©dia esperada em Y resultante de um aumento unit√°rio em X, mantendo constantes as demais covari√°veis do modelo.\n\nSe X for a vari√°vel de tratamento e for cont√≠nua, Œ≤^1 √© a varia√ß√£o m√©dia de Y associada a um aumento unit√°rio em X (sob suposi√ß√µes causais).\nSe X for uma dummy de tratamento e as suposi√ß√µes de identifica√ß√£o forem plaus√≠veis, Œ≤^1 pode ser interpretado como o Efeito M√©dio do Tratamento (ATE ou ATT dependendo da popula√ß√£o condicionada). Se Y for bin√°rio e voc√™ usar um modelo linear de probabilidade, Œ≤^1 aproxima o efeito m√©dio (ATE) sob ignorabilidade, mas tem limita√ß√µes (valores previstos fora de [0,1], heterocedasticidade). Para resultados bin√°rios, usar regress√£o log√≠stica.\n\n[!tip] üí°\n√â crucial controlar vari√°veis de confus√£o. Se omitirmos vari√°veis que influenciam tanto X quanto Y, seu efeito ser√° absorvido no termo de erro e incorretamente atribu√≠do a X, gerando vi√©s de vari√°vel omitida. Em caso de d√∫vida sobre quais tipos de vari√°veis vale a pena controlar, veja este paper, se baseando no DAG: A Crash Course in Good and Bad Controls\n\nO Trade-off entre Vi√©s e Vari√¢ncia\nEntretanto, condicionar (ou incluir) covari√°veis irrelevantes ou em excesso no modelo pode introduzir um risco: o aumento da vari√¢ncia do estimador de Œ≤^1.\nO aumento na vari√¢ncia ocorre frequentemente devido √† multicolinearidade e significa que as estimativas de Œ≤^1 ser√£o menos precisas. Isso resulta em intervalos de confian√ßa mais amplo, tornando mais dif√≠cil rejeitar a hip√≥tese nula e obter um resultado estatisticamente significativo.\nTeorema Frisch‚ÄëWaugh‚ÄëLovell\nOutra forma de observamos isso, √© entendermos melhor o funcionamento do teorema Teorema Frisch-Waugh-Lovell (FWL).\nEle demonstra que o coeficiente de X em uma regress√£o m√∫ltipla Y ~ X + Z √© igual ao coeficiente obtido ao regressar os res√≠duos de Y sobre Z nos res√≠duos de X sobre Z. Em termos pr√°ticos, isso significa que a contribui√ß√£o de cada regressora pode ser entendida como a associa√ß√£o entre as partes de Y e X que n√£o s√£o explicadas por Z. Isto pode ser dividido em tr√™s etapas\n\nDesviesamento (Debiasing Step)\n\nRemover o vi√©s das vari√°veis de controle Z da sua vari√°vel de interesse X.\nRegredimos a vari√°vel de tratamento X nas covari√°veis de controle Z, (ex: X‚àºZ)\nColetamos os res√≠duos dessa regress√£o X~. Estes res√≠duos representam a parte de X que √© ortogonal (n√£o correlacionada) aos controles Z.\n\nRemo√ß√£o de Ru√≠do (Denoising Step)\n\nRemover o ru√≠do das vari√°veis de controle Z da sua vari√°vel dependente Y.\nRegredimos a vari√°vel dependente Y nas mesmas covari√°veis de controle Z, (ex: Y‚àºZ)\nColetamos os res√≠duos dessa regress√£o Y~. Estes res√≠duos representam a parte de Y que √© independente dos controles Z.\n\nRegress√£o Final\n\nA estimativa final do efeito causal Œ≤^1 √© obtida regredindo o res√≠duo da vari√°vel dependente no res√≠duo da vari√°vel de tratamento: Y~‚àºX~.\nO Œ≤^ obtido nesta regress√£o de res√≠duos √© id√™ntico ao Œ≤^1 da regress√£o original Y‚àºX+Z.\n\nUma melhor explica√ß√£o sobre este tema pode ser encontrada no livro Causal Inference in Python: Applying Causal Inference in the Tech Industry, de Matheus Facure.\nPara ver os exemplos via c√≥digo, √© s√≥ acessar aqui.\n\n[!tip]\nVale relembrarmos, que para atua√ß√£o de dados categoricos - ou discretiza√ß√µes de valores n√∫mericos que queremos atuar como - necessitamos transform√°-los como vari√°vel Dummy. Para cada coluna, √© necess√°rio transform√°-lo em uma covari√°vel de 0 ou 1. Assim, o modelo de Regress√£o ir√° comportar cada categoria como uma linha adversa, se comportando como uma categoria a parte ao outcome que queremos observar. Utilizando Pandas, podemos utilizar o pd.get_dummies. Via modelagem statsmodels, basta dentro da formula ao ols, inserirmos como outcome ~ C(Variable).\n\n[!tip]\nLembrete: a regress√£o linear assume que a rela√ß√£o entre as regressoras e o resultado (condicional) √© linear. Se a rela√ß√£o verdadeira for n√£o linear, a especifica√ß√£o linear pode provocar vi√©s de especifica√ß√£o. √â importante verificar se isso ocorre, especialmente entre a vari√°vel de tratamento e o desfecho; caso ocorra, podemos aplicar transforma√ß√µes adequadas, por exemplo: logaritmos, termos polinomiais, intera√ß√µes ou transforma√ß√µes multiplicativas.\n\nSpline\nNo contexto de vari√°veis de controle com rela√ß√£o n√£o linear, podemos modelar via Spline. Desta forma, o modelo consegue se convergir, conseguindo observar melhor a interven√ß√£o.\nimport numpy as np\nimport pandas as pd\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\nfrom scipy.special import expit # Equivalente ao plogis (inverse logit)\nimport matplotlib.pyplot as plt\n\n# 1. Fun√ß√µes de Simula√ß√£o ----\ndef sim_data(n=250, beta_trt=1.5, z1_mean=5, z1_sd=2,\nz2_size=1, z2_prob=0.5, z1_on_x=0.05,\nz2_on_x=0.2, z1_on_y=0.5, z2_on_y=0.3):\n\n# Criando o DataFrame\nz1 = np.random.normal(z1_mean, z1_sd, n)\nz2 = np.random.binomial(z2_size, z2_prob, n)\n\nprob = expit(z1_on_x * z1 + z2_on_x * z2)\nx = np.random.binomial(1, prob, n)\n\n# Gerando Y (Linear por padr√£o, vamos alterar depois)\ny = beta_trt * x + z1_on_y * z1 + z2_on_y * z2 + np.random.normal(0, 1, n)\n\nreturn pd.DataFrame({'x': x, 'y': y, 'z1': z1, 'z2': z2})\n\n# 2. Gerando Dados N√£o-Lineares ----\nnp.random.seed(456)\ndf = sim_data()\n# Alterando y para ter rela√ß√£o n√£o-linear com z1 (z1^3 + z1)\ndf['y'] = 1.5 * df['x'] + (df['z1']**3) + df['z1'] + df['z2'] + np.random.normal(0, 1, 250)\n\n# 3. Ajustando Modelos ----\n\n# Modelo 1: Apenas termos lineares\nmod1 = smf.ols(&quot;y ~ x + z1 + z2&quot;, data=df).fit()\nprint(&quot;--- Modelo 1: Linear ---&quot;)\nprint(mod1.summary().tables[1])\n\n# Modelo 2: Usando Natural Splines (cr() ou bs())\n# O patsy usa cr() para cubics splines ou voc√™ pode importar splines.\n# Para Natural Splines igual ao R, usamos 'cr' ou instalamos dmetar/patsy extens√µes.\n# O termo cr(z1, df=4) √© o mais pr√≥ximo do ns(z1, 4)\nmod2 = smf.ols(&quot;y ~ x + cr(z1, df=4) + z2&quot;, data=df).fit()\nprint(&quot;\\n--- Modelo 2: Splines ---&quot;)\nprint(mod2.summary().tables[1])\n\n# 4. Verifica√ß√£o de Performance (Bonus) ----\n# Python n√£o tem uma biblioteca id√™ntica ao 'performance' do R em um √∫nico comando,\n# mas podemos checar os res√≠duos manualmente.\n\ndef check_predictions(model, title):\nplt.figure(figsize=(8, 5))\nplt.hist(model.model.endog, alpha=0.5, label='Realidade', bins=30)\nplt.hist(model.fittedvalues, alpha=0.5, label='Predi√ß√£o', bins=30)\nplt.title(f&quot;Check Predictions: {title}&quot;)\nplt.legend()\nplt.show()\n\ncheck_predictions(mod1, &quot;Modelo Linear&quot;)\ncheck_predictions(mod2, &quot;Modelo com Splines&quot;)\n\nRegress√£o Linear como Modelo para Potenciais Outcome\nOutra possibilidade de utilizar a regress√£o linear, √© atuar como um modelo de imputa√ß√£o de potenciais resultados. Isto quer dizer que conseguimos estimar os efeitos causais, seja ATE ou ATT, preechendo valores contrafactuais.\nA l√≥gica reside na capacidade da regress√£o de modelar as fun√ß√µes de resultado potencial:E[Y0|X] e E[Y1|X].\nEfeito de Tratamento M√©dio (ATE)\n\n[!tip]\nRelembrando! O ATE √© calculado como a diferen√ßa m√©dia entre o que toda a popula√ß√£o teria se fosse tratada E^[Y1|Xi] e o que toda a popula√ß√£o teria se n√£o fosse tratada E^[Y0|Xi]\n\nATE=1N‚àëi(E^[Y1|Xi]‚àíE^[Y0|Xi])\n\nOnde E^[Y0|Xi] e E^[Y1|Xi] s√£o modelos de regress√£o ajustados, respectivamente, nas unidades de controle T=0 e nas unidades tratadas T=1.\n\nC√°lculo Simplificado com statsmodels\nEm um modelo de regress√£o linear que inclui covari√°veis X, o estimador do ATE √© equivalente ao coeficiente da vari√°vel de tratamento T.\nSe o seu modelo √© Y=Œ≤0+Œ≤1T+Œ≤2X+œµ, a estimativa de Œ≤^1 √© o ATE.\nPython\nformula_ate = 'Y ~ T + X1 + X2'\nmodel_ate = smf.ols(formula_ate, data=data).fit()\nate_estimate = model_ate.params['T']\n\nEfeito M√©dio de Tratamento nos Tratados (ATT)\n\n[!tip] üí°\nRelembrando! O ATT √© a diferen√ßa m√©dia entre o resultado observado para o grupo tratado Yi e o seu resultado contrafactual imputado E^[Y0|Xi]\nATT=1N1‚àëi:Ti=1(Yi‚àíE^[Y0|Xi])\nIsto significa que usamos o grupo de controle T=0 para construir o modelo que prev√™ o resultado potencial Y0.\n\nC√°lculo Simplificado com statsmodels\nmodel_mu0 = smf.ols('Y ~ X1 + X2', data=data[data['T'] == 0]).fit()\nimputed_y0 = model_mu0.predict(data[data['T'] == 1]) # Imputar o contrafactual, isto √©, usar model_mu0 para prever o Y_0 para as unidades do grupo tratado T=1.\natt_estimate = (data[data['T'] == 1]['Y'] - imputed_y0).mean()",
		"tags": [ "note"]
},

{
		"title": "8. Vi√©s",
		"date":"Thu Dec 25 2025 18:15:37 GMT+0000 (Coordinated Universal Time)",
		"url":"/digital-garden/path-for-the-true-and-brave/text/8-vies/",
		"content": "Vi√©s\nO vi√©s ocorre porque a vari√°vel de confus√£o cria uma associa√ß√£o esp√∫ria (falsa) entre o Tratamento (a Causa, A) e o Resultado (o Efeito, B). Isso acontece quando o Tratamento e o Resultado compartilham uma causa comum (a vari√°vel de confus√£o, C).\nEm outras palavras, a vari√°vel de confus√£o (C) influencia:\n\nA probabilidade de receber o Tratamento (C‚ÜíA).\nO Resultado de interesse (C‚ÜíB).\n\nGraficamente, a rela√ß√£o esp√∫ria √© representada no DAG (Modelo Gr√°fico Ac√≠clico Direcionado) como um caminho backdoor: A‚ÜêC‚ÜíB\nSem controlar adequadamente (ajustar ou condicionar) essa vari√°vel, a nossa estimativa do efeito de A em B incluir√° o efeito indireto de C em B, fazendo parecer que A tem um efeito maior (ou menor) do que realmente tem.\nVi√©s de sele√ß√£o\nOcorre quando os participantes de um estudo s√£o sistematicamente diferentes dos n√£o participantes por quest√µes que n√£o podemos controlar completamente.\nEndogeneidade &amp; Vi√©s de vari√°vel omitida\nA Endogeneidade √© um problema estat√≠stico que ocorre quando a vari√°vel de tratamento (ou preditor inclu√≠do) X1 √© correlacionada com o termo de erro do modelo.\nO Vi√©s de Vari√°vel Omitida √© uma forma comum de endogeneidade. Ele acontece quando uma vari√°vel relevante X2 √© omitida do modelo de regress√£o, resultando em estimativas enviesadas do efeito do tratamento X1. O vi√©s ocorre se e somente se a vari√°vel omitida X2 satisfizer duas condi√ß√µes:\n\nAfeta o resultado Y\nTem correla√ß√£o com a vari√°vel de tratamento X1\n\nIsto ocorre pois os efeitos das vari√°veis de confus√£o estar√£o correlacionadas com o termo de erro do modelo, pois o estimador de M√≠nimos Quadrados Ordin√°rios (MQO) se torna viesado e inconsistente, o que significa que as estimativas dos coeficientes n√£o representam o verdadeiro efeito causal entre as vari√°veis.\n\n[!tip]\nUma an√°lise r√°pida de verificar uma vari√°vel de confus√£o sob isso √© durante a an√°lise explorat√≥ria utilizando pairplot da biblioteca Seaborn.\nNela, conseguiremos ver se h√° uma correla√ß√£o forte das covari√°veis com o tratamento.\nsns.pairplot(data[[&quot;T&quot;, &quot;C1&quot;, &quot;C2&quot;, &quot;C3&quot;]], diag_kind=&quot;hist&quot;)\n\nDeriva√ß√£o do Estimador de M√≠nimos Quadrados Ordin√°rios (MQO)\nModelo verdadeiro Y=Œ≤0+Œ≤1X1+Œ≤2X2+u, onde E[u]=0 e Cov(u,X1)=Cov(u,X2)=0\nSuponha que estimemos por MQO apenas Y sobre X1 (isto √©, omitimos X2). O estimador de MQO para o coeficiente de X1 na regress√£o simples √© Œ±1=Cov(Y,X1)Var(X1).\nSubstituindo o modelo verdadeiro em Cov(Y,X1): Cov(Y,X1)=Cov(Œ≤0+Œ≤1X1+Œ≤2X2+u,;X1)=Œ≤1Var(X1)+Œ≤2Cov(X2,X1)+Cov(u,X1)\nAssumindo (Cov(u,X1)=0), temos: Œ±1=Œ≤1+Œ≤2Cov(X2,X1)Var(X1)\nPortanto, o valor esperado do estimador √© E[Œ±1]=Œ≤1+Œ≤2Cov(X2,X1)Var(X1).\nO termo adicional Œ≤2Cov(X2,X1)Var(X1) √© o vi√©s por omiss√£o. Ele ser√° diferente de zero sempre que:\n\nŒ≤2‚â†0 (ou seja, X2 afeta Y) e\nCov(X2,X1)‚â†0 (ou seja, X2 est√° correlacionada com X1).\n\nEm outras palavras: se X2 √© relevante para Y e est√° correlacionada com X1, ent√£o ao omiti-la o efeito de X2 √© parcialmente atribu√≠do a X1, enviesando Œ±1.",
		"tags": [ "note"]
},

{
		"title": "9. Escore de Propens√£o",
		"date":"Thu Dec 25 2025 18:15:37 GMT+0000 (Coordinated Universal Time)",
		"url":"/digital-garden/path-for-the-true-and-brave/text/9-escore-de-propensao/",
		"content": "Escore de Propens√£o\nNo contexto de infer√™ncia causal, podemos ter dois cen√°rios: estudos experimentais, onde h√° controle da randomiza√ß√£o por meio de RCTs e, por consequ√™ncia, melhor controle dos confundidores; e estudos observacionais, onde n√£o controlamos como os dados foram obtidos, podendo haver vi√©s(es). Para esse √∫ltimo contexto, devemos, de alguma forma, simular a randomiza√ß√£o. Em outras palavras, controlar vieses que possam prejudicar o estudo. Um dos m√©todos que podemos utilizar, o escore de propens√£o (Propensity Score), que serve para aproximar condi√ß√µes de randomiza√ß√£o em estudos observacionais, nos quais a aloca√ß√£o do tratamento n√£o √© aleat√≥ria e os dados j√° foram coletados. Nesse cen√°rio n√£o h√° controle das diferen√ßas entre os grupos de tratamento e controle, o que pode gerar vi√©s por vari√°veis de confus√£o.\n\n[!tip]\nExemplos comuns para utilizarmos o escore de propens√£o:\n\nVi√©s de Sele√ß√£o: Pessoas que escolhem receber um tratamento s√£o fundamentalmente diferentes daquelas que n√£o o recebem.\n\nExemplo: Indiv√≠duos mais saud√°veis ou mais ricos podem ter maior acesso ou propens√£o a um novo medicamento.\n\nNoncompliance: Mesmo em ensaios cl√≠nicos, se houver falta de ades√£o total ao tratamento, o efeito causal (como o ATE ou ATT) calculado diretamente pode estar enviesado, comprometendo os resultados e sua interpretabilidade.\n\nA defini√ß√£o formal √©:\ne(X)=P(T=1|X)Onde T √© a vari√°vel de tratamento e X covari√°veis.\nAo condicionarmos nas covari√°veis, o escore de propens√£o controla as vari√°veis de confus√£o, ajudando a alcan√ßarmos a independ√™ncia condicional ‚Äî o tratamento T torna-se independente do resultado potencial, desde que se condicione no escore de propens√£o, T‚ä•Yt|e(X).\n\n[!tip]\nO Escore de Propens√£o √© uma ferramenta tamb√©m conhecida para redu√ß√£o de dimensionalidade. Em vez de ter que controlar dezenas de covari√°veis X diretamente na an√°lise de resultado, podemos simplesmente controlar o escore e(X).\n\n[!tip]\nO conceito do Escore de Propens√£o √© estritamente aplicado a tratamentos bin√°rios (discretizados ou dicot√¥micos: Sim/N√£o). Para tratamentos cont√≠nuos, um m√©todo utilizado √© o Generalized Propensity Score (GPS), aonde modela envolta a densidade condicional, ao inv√©s da probabilidade condicional.\n\nImportante destacar, que ainda sim, precisamos que as premissas de ignorabilidade, positividade e SUTVA devem ser respeitadas antes de aplicar. Relembrando que comentei sobre esse tema em <a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/digital-garden/path-for-the-true-and-brave/text/5-design-de-experimentos/\">5. Design de Experimentos</a>.\nPara utilizarmos o score de propens√£o, basta regredirmos a interven√ß√£o com suas covari√°veis em uma regress√£o log√≠stica. Seu resultado, final, seria a probabilidade de uma unidade receber o tratamento condicional √†s covari√°veis pr√©‚Äëtratamento X.\nExemplo (Causal Inference in Python: Applying Causal Inference in the Tech Industry\nimport statsmodels.formula.api as smf\n\n# 1. Estimar o Escore de Propens√£o\nps_model = smf.logit(&quot;&quot;&quot;intervention ~\ntenure + last_engagement_score + department_score\n+ C(n_of_reports) + C(gender) + C(role)&quot;&quot;&quot;, data=df).fit(disp=0)\n\n# 2. Adicionar o Escore de Propens√£o como nova coluna\ndata_ps = df.assign(\npropensity_score = ps_model.predict(df),\n)\n\ndata_ps[[&quot;intervention&quot;, &quot;engagement_score&quot;, &quot;propensity_score&quot;]].head()\n\n# 3. Estimar o Efeito Causal usando o Escore de Propens√£o como covari√°vel\nmodel = smf.ols(&quot;engagement_score ~ intervention + propensity_score&quot;,\ndata=data_ps).fit()\n\n# O coeficiente 'intervention' neste modelo representa o ATE ajustado pelo escore de propens√£o\nprint(&quot;ATE Ajustado por Escore de Propens√£o:&quot;, model.params[&quot;intervention&quot;])\n\nPondera√ß√£o por Escore de Propens√£o Inverso\nUma vez tendo esse score, podemos estimar o efeito m√©dio de tratamento. Uma das formas que podemos √© por Pondera√ß√£o por Score de Propens√£o Inverso (IPW).\nA ideia de IPW √© reponderar a sua amostra para criar uma pseudo-popula√ß√£o onde a distribui√ß√£o das vari√°veis de confus√£o X √© a mesma nos grupos de tratamento T=1 e controle T=0. Isto imita as condi√ß√µes de um ensaio aleat√≥rio. O peso W atribu√≠do a cada indiv√≠duo √© o inverso da probabilidade de o indiv√≠duo ter recebido o tratamento que realmente recebeu. Essa probabilidade √© o Escore de Propens√£o e^(x). Utilizando desta forma, estimamos um ATE em uma popula√ß√£o observacional e voc√™ quiser criar uma pseudo‚Äëpopula√ß√£o em que o tratamento √© independente das covari√°veis observadas.\n\n[!tip]\nUnidades Incomuns (Alto Peso):\n\nUnidades que receberam um tratamento improv√°vel (e.g., alto risco de rotatividade, mas n√£o receberam o treino) recebem um peso alto.\n\nIsso os torna mais representativos da popula√ß√£o em geral, essencialmente for√ßando um balanceamento da amostra.\n\nUnidades Comuns (Baixo Peso):\n\nUnidades que receberam um tratamento prov√°vel recebem um peso baixo.\n\nO peso para cada unidade Wi √© calculado da seguinte forma, onde Ti √© o tratamento real recebido:\nWi=1P(Ti|Xi)={1e^(xi)se¬†Ti=111‚àíe^(xi)se¬†Ti=0\n[!tip]\nAo dar um peso alto a unidades tratadas que parecem unidades de controle, e unidades de controle que parecem unidades tratadas, o m√©todo garante que o grupo de tratamento e o grupo de controle na pseudo-popula√ß√£o sejam compar√°veis.\n\nExemplo (Causal Inference in Python: Applying Causal Inference in the Tech Industry\n√©√©√©Efeito Causal=(M√©dia ponderada do resultadose todos fossem tratados)‚àí(M√©dia ponderada do resultadose ningu√©m fosse tratado)# 1. Calcular os pesos IPW para cada grupo\nweight_t = 1 / data_ps.query(&quot;intervention == 1&quot;)[&quot;propensity_score&quot;]\nweight_nt = 1 / (1 - data_ps.query(&quot;intervention == 0&quot;)[&quot;propensity_score&quot;])\n\n# 2. Obter os resultados (engagement_score) por grupo\nt1 = data_ps.query(&quot;intervention == 1&quot;)[&quot;engagement_score&quot;]\nt0 = data_ps.query(&quot;intervention == 0&quot;)[&quot;engagement_score&quot;]\n\n# 3. Estimar o Resultado Potencial M√©dio (E[Y^t])\ny1_num = sum(t1 * weight_t) # Numerador: Somat√≥rio (Y * W) para T=1\ny1_den = sum(weight_t) # Denominador: Somat√≥rio (W) para T=1\ny1 = y1_num / y1_den\n\ny0_num = sum(t0 * weight_nt) # Numerador: Somat√≥rio (Y * W) para T=0\ny0_den = sum(weight_nt) # Denominador: Somat√≥rio (W) para T=0\ny0 = y0_num / y0_den\n\nprint(&quot;E[Y1] (Tratado):&quot;, y1)\nprint(&quot;E[Y0] (Controle):&quot;, y0)\nprint(&quot;ATE:&quot;, y1 - y0)\n\nEstimativa Duplamente Robusta\nO Escore de Propens√£o e(X) e a Pondera√ß√£o por Escore de Propens√£o Inverso (IPW) s√£o ferramentas para controlar vari√°veis de confus√£o e simular a randomiza√ß√£o em dados observacionais. O IPW, em particular, √© um estimador baseado em design que se foca em balancear os grupos.\nEntretanto, uma preocupa√ß√£o comum em infer√™ncia causal √© a especifica√ß√£o incorreta dos modelos. E se o modelo que usamos para calcular o Escore de Propens√£o estiver errado? Isso nos leva √† busca por estimadores mais resilientes.\nO Conceito &quot;Duplamente Robusto&quot;\nUm estimador √© considerado Duplamente Robusto (Double Robust - DR) se a estimativa do efeito causal for consistente (ou seja, convergir√° para o verdadeiro efeito causal) se:\n\nO modelo para o Escore de Propens√£o estiver corretamente especificado.\nOU\nO modelo para o outcome potencial que estima estiver corretamente especificado.\n\nEm outras palavras, o estimador DR converge para o modelo que estiver correto. Isso confere uma vantagem e aumenta a confian√ßa na estimativa final, pois voc√™ s√≥ precisa acertar em um dos dois modelos. A ideia central √© que o estimador utiliza ambos os modelos - por exemplo, IPW + Regress√£o Log√≠stica - para construir um estimador para o resultado potencial.\nUm estimador DR popular para o resultado potencial m√©dio sob tratamento pode ser escrito como:\nŒºtDR(Œº^,e^)=1N‚àëi=1N[Œº^t(Xi)+Ti‚àíe^(Xi)e^(Xi)(Yi‚àíŒº^t(Xi))]Onde:\n\nYi √© o resultado observado.\nTi √© a vari√°vel de tratamento.\nŒº^t(Xi) √© a previs√£o do resultado Y pelo modelo, assumindo o tratamento t\ne^(Xi) √© o Escore de Propens√£o.\n\nSe o Escore de Propens√£o estiver correto:\nO termo Ti‚àíe^(Xi)e^(Xi) tender√° a zero na m√©dia, e o segundo termo todo se anular√°.\nIsto deixa apenas o primeiro termo, 1N‚àëi=1NŒº^t(Xi), que converge para a estimativa do resultado do modelo. Neste caso, a estimativa DR se comporta como um estimador design-based.\nSe o modelo estiver correto:\nO segundo termo, (Yi‚àíŒº^t(Xi)), tender√° a zero na m√©dia, pois Œº^t(Xi) √© uma previs√£o precisa de Yi.\nA estimativa DR converge para um estimador outcome-based que se baseia primariamente no modelo.",
		"tags": [ "note"]
},

{
		"title": "Infer√™ncia Causal",
		"date":"Thu Dec 25 2025 18:15:37 GMT+0000 (Coordinated Universal Time)",
		"url":"/digital-garden/path-for-the-true-and-brave/text/inferencia-causal/",
		"content": "<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/digital-garden/path-for-the-true-and-brave/text/0-roadmap/\">0. Roadmap</a>\n<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/digital-garden/path-for-the-true-and-brave/text/1-epifanias/\">1. Epifanias</a>\n<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/digital-garden/path-for-the-true-and-brave/text/2-como-predicao-e-inferencia-causal-se-conversam/\">2. Como Predi√ß√£o e Infer√™ncia Causal se Conversam</a>\n<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/digital-garden/path-for-the-true-and-brave/text/3-teorias-da-causalidade/\">3. Teorias da Causalidade</a>\n<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/digital-garden/path-for-the-true-and-brave/text/4-escada-da-causacao/\">4. Escada da Causa√ß√£o</a>\n<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/digital-garden/path-for-the-true-and-brave/text/5-design-de-experimentos/\">5. Design de Experimentos</a>\n<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/digital-garden/path-for-the-true-and-brave/text/6-dag/\">6. DAG</a>\n<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/digital-garden/path-for-the-true-and-brave/text/7-regressao-linear/\">7. Regress√£o Linear</a>\n<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/digital-garden/path-for-the-true-and-brave/text/8-vies/\">8. Vi√©s</a>\n<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/digital-garden/path-for-the-true-and-brave/text/9-escore-de-propensao/\">9. Escore de Propens√£o</a>\n<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/digital-garden/path-for-the-true-and-brave/text/10-efeitos-heterogeneos/\">10. Efeitos Heterog√™neos</a>\n<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/digital-garden/path-for-the-true-and-brave/text/12-double-machine-learning/\">12. Double Machine Learning</a>\n<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/digital-garden/path-for-the-true-and-brave/text/13-guia-de-equivocos/\">13. Guia de Equ√≠vocos</a>\n<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/digital-garden/path-for-the-true-and-brave/text/14-gen-ai/\">14. GenAI</a>",
		"tags": [ "note"]
}
]