[
{
		"title": "Digital Garden Home",
		"date":"Sun Jan 04 2026 14:40:44 GMT+0000 (Coordinated Universal Time)",
		"url":"/",
		"content": "<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/digital-garden/meu-modelo-conforme/text/meu-modelo-conforme/\">Meu Modelo Conforme</a>\n<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/digital-garden/path-for-the-true-and-brave/text/inferencia-causal/\">Inferência Causal</a>\nTinyshift",
		"tags": [ "note","gardenEntry"]
},

{
		"title": "1. Introdução",
		"date":"Sun Jan 04 2026 14:40:44 GMT+0000 (Coordinated Universal Time)",
		"url":"/digital-garden/meu-modelo-conforme/text/1-introducao/",
		"content": "Introdução\n\n[!note]\n&quot;The true measure of a man is not his intelligence or how high he rises in this freak establishment. No, the true measure of a man is this: how quickly can he respond to the needs of others and how much of himself he can give&quot; — Philip K. Dick\n\nOlá, meu nome é Lucas Leão, sou Cientista de Dados — ou pelo menos tento ser. Se você, assim como eu, já se sentiu estagnado e desejava se aperfeiçoar em alguma tecnologia ou teoria que só ouvia falar, saiba que estamos no mesmo barco. Para fins temporais, escrevo este texto em Dezembro 2023.\nDurante minha jornada criando modelos de Machine Learning, uma dúvida persistia: como posso ter mais confiança nos meus modelos? Não me entenda mal! Confio nas minhas habilidades, mas busco uma garantia extra na modelagem para evitar futuras dores de cabeça, tendo melhor noção sobre as incertezas das predições.\nSegundo o artigo Is there a role for statistics in artificial intelligence?, a quantificação de incerteza é frequentemente negligenciada em aplicações de inteligência artificial por dois motivos principais:\n\nFalsa crença de que &quot;Big Data&quot; automaticamente garante resultados exatos\nComplexidade dos métodos dificulta a criação de regiões de incerteza estatisticamente válidas\n\nNos últimos anos, surgiram diversas propostas para quantificar incerteza em modelos de Machine Learning e Deep Learning. No entanto, apenas o método de Previsão Conforme teve sua validade teórica comprovada, demonstrando intervalos de previsão que fornecem cobertura empírica efetiva para dados futuros — ou seja, um intervalo de previsão que de fato cobre valores futuros em (1 - α) das vezes.\nEste documento é um diário dessa jornada para explorar tanto a quantificação de incerteza quanto novos métodos de balanceamento de modelo. Nele, desenvolvi duas camadas adicionais ao modelo de RandomForestClassifier, atrelado ao meu objetivo de estudo. Se encontrar qualquer erro ou tiver sugestões de melhoria, por favor, mande-me um e-mail sem receio. Ficarei grato em revisar. Se estiver pensando em aplicar essa metodologia a outro problema, não hesite em me contatar. Valeu!\nGithub\n\nhttps://github.com/heylucasleao/tinycp",
		"tags": [ "note"]
},

{
		"title": "10. Classificador Conforme",
		"date":"Sun Jan 04 2026 14:40:44 GMT+0000 (Coordinated Universal Time)",
		"url":"/digital-garden/meu-modelo-conforme/text/10-classificador-conforme/",
		"content": "Classificador Conforme\nParabéns por chegar a este tópico. Agora, vamos explorar a síntese de todos os conceitos discutidos anteriormente e apresentar uma visão detalhada do modelo que criei. Certamente, pode haver conflitos conceituais. Caso ocorra, não tenha medo de me comunicar. Objetivo desse diário é demonstrar minha linha de pensamento, e como cheguei até aqui.\nO objetivo era desenvolver um modelo com alta adaptabilidade, flexibilidade e características específicas oferecidas pelo RandomForest, incluindo:\n\nCapacidade de processar dados de alta dimensionalidade e extrair correlações complexas.\nHabilidade de treinar modelos com dados de baixa frequência.\nRobustez no tratamento de conjuntos de dados desbalanceados.\nEficiência computacional, permitindo treinamento e inferência rápidas.\n\nAo incorporar a calibração conformal (Venn-Abers), o modelo alcança:\n\nRegulação precisa do score, transformando-o em uma medida verdadeiramente probabilística e mitigando riscos de overfitting.\nMaior confiabilidade nas previsões, essencial para aplicações críticas.\n\nA implementação da Previsão Conforme proporciona:\n\nAprimoramento significativo na interpretabilidade dos resultados do modelo.\nEstabelecimento de uma garantia de cobertura, permitindo controle preciso sobre a confiança do modelo.\nFlexibilidade na modelagem do intervalo de predição, adaptável a diferentes cenários.\nCapacidade de quantificar a incerteza das previsões.\n\nA integração de propriedades de Aprendizado Sensível ao Custo oferece:\n\nVersatilidade para lidar com diversos tipos de distribuições de dados.\nCalibração baseada no custo de erro e não somente performance.\nCapacidade de ajustar o modelo para minimizar custos em cenários assimétricos de erro.\n\nClassificador Conforme Binário\nUm diferencial que não mencionei é a utilização de uma ideia baseada nos artigos Venn Prediction for Survival Analysis e Efficient Venn predictors using random forests. Nessa abordagem, os dados não utilizados no treinamento de cada árvore, conhecidos como amostras OOB (Out-of-Bag), são empregados para gerar nossa cobertura. A ideia é que teremos uma representatividade populacional de cada arvore de decisão. Em teoria, isso elimina a necessidade de uma base de calibração separada. No entanto, neste caso, utilizo esses dados para outro propósito.\nÉ importante ressaltar também que transformo o conjunto de predições em uma única resposta: se o modelo tem certeza de que há apenas o rótulo verdadeiro ou não. Isso compromete a interpretabilidade do conjunto de predições do modelo. Conceitualmente, reconheço que isso pode ser questionável, mas o faço para obter flexibilidade na utilização do Aprendizado Sensível a Custo. Vale notar que internamente ainda é possível recuperar essa informação.\nCalibração do Valor α\nApós a criação do modelo conforme, ainda não há uma definição clara do valor α. Para determiná-lo, calibro para o melhor resultado da acurácia balanceada em um intervalo de 0.01 a 0.10. O objetivo é encontrar a melhor cobertura que permita ao modelo obter o menor custo de erro com uma garantia mínima de 90%. Haverá situações em que não há razão para reduzir α, possibilitando seu estreitamento, enquanto em outras, o modelo poderá ter uma eficiência melhor com um aumento desse valor.\n\n[!tip]\nAo unir os três tópicos e calibrar o α, estabelecemos um nível de significância que equilibra o custo entre falsos positivos e falsos negativos, evita overfitting e mantém uma distribuição representativa para a cobertura.\n\nAvaliação de Performance\nPara certificar que tudo ocorreu bem com o modelo, verifico seu performance com dados de validação utilizando uma função chamada evaluate. As métricas que ele retorna são:\n- &quot;total&quot;: A quantidade total de dados utilizados para avaliação.\n- &quot;alpha&quot;: O nível de significância estabelecido da cobertura.\n- &quot;empirical_coverage&quot;: A cobertura empírica dos conjuntos da Previsão Conforme.\n- &quot;one_c&quot;: A proporção de conjuntos de predição contendo exatamente um elemento.\n- &quot;avg_c&quot;: O tamanho médio dos conjuntos de predição.\n- &quot;empty&quot;: A proporção de conjuntos de predição vazios.\n- &quot;error&quot;: A taxa de erro de classificação.\n- &quot;log_loss&quot;: A perda logarítmica das predições.\n- &quot;ece&quot;: O erro de calibração esperado.\n- &quot;bm&quot;: O índice de informação do bookmaker.\n- &quot;mcc&quot;: O coeficiente de correlação de Matthews.\n- &quot;f1&quot;: O F1-Score\n- &quot;fpr&quot;: A taxa de falsos positivos.\n\nDistribuição Beta\n\nA distribuição Beta é uma distribuição de probabilidade contínua no intervalo [0, 1], ideal para observar e quantificar a incerteza na probabilidade do modelo. Sua função de densidade de probabilidade é definida por dois parâmetros α e β, que controlam a forma da distribuição e permitem modelar diferentes tipos de incerteza probabilística. É importante destacar que, devido ao rigor da Previsão Conforme, a cobertura segue naturalmente essa distribuição, assegurando a confiabilidade do modelo. Embora não seja estritamente necessário analisar a Beta especificamente para este fim, não discrimino o uso para análises posteriores, como nos testes A/B.\nReferência de meu Projeto\nhttps://github.com/HeyLucasLeao/cp-study/blob/master/cp.ipynb",
		"tags": [ "note"]
},

{
		"title": "11. Referências",
		"date":"Sun Jan 04 2026 14:40:44 GMT+0000 (Coordinated Universal Time)",
		"url":"/digital-garden/meu-modelo-conforme/text/11-referencias/",
		"content": "Referências\n\nInterpretable Uncertainty\nUnlocking Reliable Machine Learning: Conformal Prediction by Valery Manokhin\nDistribution-Free Uncertainty Quantification\nUncertainty Quantification: Enter Conformal Predictors\nUnderstanding, Generating, and Evaluating Prediction Intervals\nIntroduction To Conformal Prediction With Python: A Short Guide For Quantifying Uncertainty Of Machine Learning Models\nA Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification\nPractical Guide to Applied Conformal Prediction in Python: Learn and apply the best uncertainty frameworks to your industry applications\nUma Introdução Prática à Previsão Conforme\nCalibrando Modelos de Classificação Binária com Previsão Conforme\nAplicando Previsão Conforme em Modelos de Classificação\nHow to calibrate your classifier in an intelligent way using Venn-Abers Conformal Prediction\nWeek #4: Overview Of Conformal Predictors\nWeek #2: Intuition Behind Conformal Prediction\nWeek #1: Getting Started With Conformal Prediction For Classification\nConformal Prediction: Prediction with guaranteed performance\nIsotonic Regression : Another Level of Regression Method\nExpected Calibration Error (ECE): A Step-by-Step Visual Explanation\nConformal prediction for classification",
		"tags": ["4", "2", "1", "note"]
},

{
		"title": "12. Regressão",
		"date":"Sun Jan 04 2026 14:40:44 GMT+0000 (Coordinated Universal Time)",
		"url":"/digital-garden/meu-modelo-conforme/text/12-regressao/",
		"content": "Regressão\n\nUnd,erstanding, Generating, and Evaluating Prediction Intervals\nNa predição, estimamos resultados com base em dados históricos, assumindo que padrões passados podem nos ajudar a prever o futuro — sempre considerando um grau de incerteza. Na regressão, buscamos estimar um ponto específico. Por exemplo, na regressão linear, projetamos uma linha baseada em valores médios para obter o resultado desejado. Porém, estatisticamente, isso nos diz pouco: qual é o nível de incerteza do modelo? Que garantia temos de que minha casa realmente vale R$535.295?\nEm 1937, Jerzy Neyman introduziu o conceito de intervalos de confiança, argumentando que determinar um valor exato para um parâmetro populacional baseado em amostras tem utilidade limitada. É mais valioso estabelecer um intervalo de valores possíveis, com um nível de confiança definido de que o valor real esteja contido nele. Assim, podemos avaliar o grau de incerteza ao estimar um parâmetro. No contexto de previsão, este conceito é bastante relevante. A variabilidade e incerteza, sejam aleatórias ou epistêmicas, frequentemente dificultam a representação de todos os cenários possíveis. Por isso, quantificar a incerteza do modelo pode ser mais útil do que simplesmente fornecer um ponto médio. É aqui que entra a regressão quantílica: em vez de estimar um ponto médio, ela estima via quantil — o que é mais representativo para distribuições adversas de dados no dia a dia — permitindo-nos estimar duas previsões e utilizá-las como intervalo.\n\nLinear vs. Quantile Regression\n\nLinear vs. Quantile Regression\nEntretanto, a regressão quantílica não oferece garantia estatística de cobertura da previsão. Embora seja mais informativa, falta essa garantia formal. É nesse contexto que a previsão conforme se torna valiosa. Por exemplo, em vez de afirmar que minha casa vale R$535.295, posso apresentar um intervalo com 95% de confiança: entre R$515.629 e R$545.800. Mesmo sem um valor exato, tenho uma margem confiável do possível valor da casa e sei em qual faixa o modelo está seguro. Considere outro cenário: e se o intervalo fosse de R$480.000 a R$800.000? Tal amplitude indicaria claramente um problema no resultado. Seriam as características da minha casa que dificultam a previsão? A região onde moro influencia os preços? Ou o modelo está simplesmente incorreto? Todas essas análises se tornam possíveis ao examinar a amplitude do intervalo — algo que um valor pontual estimado jamais nos permitiria.\nApós a criação do método de Previsão Conforme para classificação na minha biblioteca, aprendi muito sobre o método e o tema em geral. Com isso, decidi expandir o projeto, oferecendo suporte contínuo à biblioteca. Para aprofundar meu entendimento, implementei dois métodos de regressão usando ICP simples via divisão de dados de treino e calibração: o ConformalizedRegression e o ConformalizedQuantileRegression.\n\nA diferença maior é que ConformalizedRegression aceita um modelo de regressão normal baseado no scikit-learn , e o ConformalizedQuantileRegression(CQR), que aceita modelos que preditam intervalos quantílicos, baseado no quantile-forest . A razão disso é que originalmente, a regressão conforme foi introduzida criando intervalos com a previsão estimada do modelo. O único problema que devido a forma desse treino, é que o modelo original não é capaz de ser tão adaptivo com a distribuição dos dados, tornando o intervalo da previsão menos abrangente. Para sanar isso, o ConformalizedQuantileRegressor se torna melhor para essas previsões, devido ao modelo utiliza ser um modelo quantil que predita um intervalo de previsão, identificando intervalos mais adaptativos entre os dados. E sim, ambos aceitam geração da cobertura baseado em Out-Of-Bag (OOB).\n\nTheoretical Foundations of Conformal Prediction",
		"tags": [ "note"]
},

{
		"title": "2. Antes de Começarmos…",
		"date":"Sun Jan 04 2026 14:40:44 GMT+0000 (Coordinated Universal Time)",
		"url":"/digital-garden/meu-modelo-conforme/text/2-antes-de-comecarmos/",
		"content": "Antes de começarmos...\nA Importância da Incerteza\nAntes de mais nada, queria compartilhar uma reflexão importante. Minha jornada com ciência de dados me fez perceber algo interessante: quanto mais me aprofundava nesse campo, mais distante ficava do pensamento estatístico tradicional. A razão? A estatística trabalha fundamentalmente com a ótica da incerteza e nossa compreensão das limitações dos resultados.\nSegundo o artigo Importance of being uncertain:\n\nA estatística nos ajuda a responder esta questão. Ela nos fornece uma maneira de modelar quantitativamente o papel do acaso em nossos experimentos e representar dados não como medições precisas, mas como estimativas com erro. Também nos mostra como o erro em valores de entrada se propaga através dos cálculos. A aplicação prática deste framework teórico é associar incerteza ao resultado dos experimentos e atribuir níveis de confiança a afirmações que generalizam além das observações.\n\nPercebi que estava sempre focando no acerto, e não no erro! Pode parecer uma reflexão simples, mas isso muda totalmente nosso paradigma diário: devemos buscar estar menos errados, não mais certos. É preciso aceitar viver sob a incerteza, reconhecendo o papel do erro. Altay Souza enfatiza esse conceito frequentemente em suas aulas de Estatística Aplicada à Psicobiologia, pela UNIFESP. Para entender mais esse entendimento, recomendo suas oito primeiras aulas — serão úteis para a vida inteira, prometo.\nDe volta aos Princípios\nAndrey Kolmogorov, matemático nascido no século XX, foi crucial para o desenvolvimento da ciência moderna. Suas contribuições inestimáveis abrangem desde a biologia, topologia e geologia até a teoria da probabilidade. Ele revolucionou nossa compreensão científica de tal forma que, sem suas descobertas, este artigo possivelmente nem existiria. Kolmogorov estabeleceu não apenas a definição matemática da probabilidade por meio de seus axiomas, mas também descreveu o Teorema Central do Limite. Seus axiomas não são meras construções matemáticas — são padrões fundamentais observados na natureza, comparáveis às leis da física como a gravidade. Assim como podemos observar e comprovar a gravidade empiricamente, os axiomas probabilísticos se manifestam em fenômenos naturais, da genética à mecânica quântica, demonstrando sua validade universal.\nA teoria da probabilidade de Kolmogorov marcou a matemática moderna ao estabelecer uma base axiomática rigorosa para seu estudo. Até seu trabalho em 1933, a teoria carecia de fundamento matemático formal. Com sua obra &quot;Fundamentos da Teoria da Probabilidade&quot;, ele unificou diferentes interpretações da probabilidade em uma única estrutura matemática coerente.\nSua abordagem revolucionária combinou a teoria dos conjuntos com a teoria da medida para definir probabilidade de forma matematicamente precisa. Essa formalização estabeleceu a teoria da probabilidade como um campo independente da matemática, permitindo representar eventos probabilísticos através de funções.\nSua contribuição vai além da formalização matemática — oferece um framework que permite modelar fenômenos aleatórios em diversos campos científicos, da física quântica à biologia molecular, economia e ciência da computação.\nPara fundamentar isso, ele estabeleceu três axiomas da teoria da probabilidade:\n\nNão-negatividade: A probabilidade de qualquer evento deve ser maior ou igual a zero.\n\nP(A)∈ℝ+\nNormalização: A probabilidade do espaço amostral total (Ω) é igual a 1.\n\nP(Ω)=1\nAditividade: Para eventos mutuamente exclusivos, a probabilidade da união é igual à soma das probabilidades individuais.\n\nP(A∪B)=P(A)+P(B)\n[!note]\nEstes axiomas são importantes porque:\n\nFornecem uma base matemática rigorosa para o cálculo de probabilidades\nPermitem derivar todas as outras regras e teoremas de probabilidade\nSão fundamentais para entender o Teorema Central do Limite\n\nCom base nesses axiomas, ele enunciou o Teorema do Limite Central, que demonstra:\n\nAo coletar múltiplas amostras de uma população e calcular suas médias, a distribuição dessas médias amostrais tende a uma distribuição normal, independentemente da distribuição original dos dados (sendo necessárias no mínimo 30 amostras para esta convergência, conforme seu experimento).\nA média dessas médias amostrais converge consistentemente para a verdadeira média populacional.\n\nIsso nos permite utilizar amostras para estimar parâmetros populacionais, eliminando a necessidade de dados censitários.\nPara ver a prova visual do TLC, basta clicar no link abaixo. Você perceberá que quanto mais amostras forem coletadas, mais a distribuição da amostra tenderá a uma normal, com sua média convergindo para a média da população.\nProbability Distributions\nEste conceito é um dos pilares para a inferências sobre populações a partir de amostras. Com isso, conseguimos criar intervalos de confiança.\nCaso queira saber mais sobre Kolmogorov, sugiro esse link.\nIntervalo de Confiança\nDesenvolvido por Jerzy Neyman em 1937, como parte de sua teoria de estimação por intervalos. Esta contribuição ofereceu uma alternativa mais robusta às estimativas pontuais.\nNeyman propôs que, ao invés de tentar adivinhar o valor exato de um parâmetro populacional, seria mais útil estabelecer um intervalo de valores prováveis, junto com um nível de confiança associado. Esta abordagem reconhece explicitamente a incerteza inerente à inferência estatística.\n\n[!tip]\nA interpretação correta de um intervalo de confiança de 95% é:\nSe repetíssemos o processo de amostragem muitas vezes e calculássemos o intervalo de confiança para cada amostra, aproximadamente 95% desses intervalos conteriam o verdadeiro parâmetro populacional.\n\nEsta interpretação frequentista é crucial para entender que o intervalo de confiança não nos diz a probabilidade de que o parâmetro populacional esteja dentro do intervalo calculado, mas sim a confiabilidade do método de construção do intervalo ao longo de múltiplas amostras. Uma boa representação visual do intervalo de confiança pode ser vista por aqui.\n\nIntervalo de Confiança da Média de Idade de Pacientes com Câncer Cervical\nÉ importante termos uma noção sobre os temas demonstrados pois são cruciais para a entendermos a Previsão Conforme. Nele, iremos quantificar a incerteza, melhorarmos nossa confiabilidade e interpretabilidade do modelo.",
		"tags": [ "note"]
},

{
		"title": "3. Probabilidade e Calibração de Modelo",
		"date":"Sun Jan 04 2026 14:40:44 GMT+0000 (Coordinated Universal Time)",
		"url":"/digital-garden/meu-modelo-conforme/text/3-probabilidade-e-calibracao-de-modelo/",
		"content": "Probabilidade e Calibração de Modelo\nA probabilidade do modelo é um conceito crucial na aprendizagem de máquina. Ela representa a confiança do modelo em suas previsões, oferecendo insights sobre seu desempenho e confiabilidade.\nA ideia em geral é que essa probabilidade, seja empírica, ou seja, refletindo que dados similares caem nesse percentual.\nImagine um modelo de visão computacional que verifica se as cerejas do café estão maduras o suficiente para colheita. Se separarmos todas as cerejas às quais o modelo atribuiu um score probabilístico de 0.80 e, manualmente, verificarmos que 40% delas estão realmente maduras, logo que o modelo está descalibrado. Isso poderá trazer risco a colheita, dando falsas expectativas e sendo imprevisivel seus resultados, demonstrando uma alta confiança. Em contra partida, a calibração quando bem feita oferece maior segurança de que o modelo se comportará adequadamente em um ambiente de produção, além de fornecer informações importantes sobre as incertezas do modelo, proporcionando previsibilidade para os stakeholders.\nIsto é bem exemplificado no artigo Calibration: the Achilles heel of predictiveanalytics:\n\nSe o algoritmo é usado para informar pacientes, estimativas de risco mal calibradas levam a falsas expectativas tanto para pacientes quanto para profissionais de saúde. Os pacientes podem tomar decisões pessoais antecipando um evento, ou sua ausência, que na verdade eram equivocadas. Por exemplo, considere um modelo de predição que prevê a chance de um tratamento de fertilização in vitro (FIV) resultar em um nascimento [14]. Independentemente do quão bem os modelos possam discriminar entre tratamentos que resultam em nascimento versus aqueles que não resultam, é claro que uma super ou subestimação da chance de nascimento torna os algoritmos clinicamente inaceitáveis. Por exemplo, uma forte superestimação da chance de nascimento após FIV daria falsas esperanças a casais que já estão passando por uma experiência estressante e emocional. Tratar um casal que, na realidade, tem um prognóstico favorável expõe a mulher desnecessariamente a possíveis efeitos colaterais prejudiciais, como a síndrome de hiperestimulação ovariana.\n\nProbability Calibration : Data Science Concepts\nNão é um problema novo\nGlenn W. Brier, meteorologista, enfrentou um problema similar em meados do século 20 com previsões do tempo. Como poderia avaliar a precisão de suas estimativas em relação ao que realmente acontecia? Foi assim que desenvolveu o &quot;Brier Score&quot;, uma métrica que avalia a precisão das previsões probabilísticas, comparando as probabilidades previstas com os resultados observados. Um score menor indica previsões mais precisas. Até os dias de hoje, é uma métrica essencial para entendermos o comportamento de nossas previsões.\nThe Brier Score Explained | Model Calibration\nOutra métrica utilizada nesse contexto é o Log Loss, que quantifica a incerteza na probabilidade das predições do modelo, comparando-as com os resultados reais. Utilizar essas duas métricas pode fornecer perspectivas diferentes sobre o desempenho do modelo.\nEm geral, modelos de ML não garantem boa calibração, ou seja, seu score probabilístico pode não representar realmente uma probabilidade. Isso é evidenciado na palestra de Guillaume Lemaitre, que também demonstra como técnicas populares de balanceamento podem prejudicar bastante essa calibração.\nUma forma de observar isso é através da curva de confiabilidade, que compara as probabilidades previstas pelo modelo com as frequências reais observadas dos eventos. Ela demonstra se o modelo está bem calibrado, confiante demais ou não. Para comparação, é criada uma linha diagonal perfeita que representa um modelo perfeitamente calibrado, onde as probabilidades previstas correspondem exatamente às frequências observadas. Se a curva de predição ficar abaixo da linha diagonal, significa que o modelo está confiante demais, prevendo probabilidades mais altas do que deveria em relação ao percentual real de ocorrências. Caso a curva fique acima da linha diagonal, sugere que o modelo está subestimando suas previsões, sendo menos confiante do que deveria.\n\nBMC Medical Informatics and Decision Making\nTendo isso em mente, vamos considerar um cenário: você está desenvolvendo um modelo de predição para identificar quando seu pedido no iFood pode resultar em uma experiência ruim. Para isso, você coletou 10 características de 100.000 pedidos (sim, você adora pedir comida!) ao longo de 5 anos. Ao analisar os dados, você percebeu que a distribuição é desbalanceada — apenas 20% dos registros indicam uma experiência negativa. Isso é um bom sinal, mas como seu modelo se comportaria com esse desbalanceamento? Você decide, então, experimentar quatro tipos de modelos:\n\nRandomForestClassifier (RF) sem nenhum tratamento nos dados\nBalancedRandomForestClassifier\nRF utilizando a técnica de Random Under-Sampling (RUS)\nRF utilizando a técnica de Synthetic Minority Over-sampling Technique (SMOTE)\nhttps://github.com/HeyLucasLeao/cp-study/blob/master/calibration_demo.ipynb\n\nFeito esses quatro modelos, se depara com isso:\nCurva de Confiabilidade\n\nRandomForestClassifier\n\nBalancedRandomForestClassifier\n\nRUS RandomForestClassifier\n\nSMOTE RandomForestClassifier\nO modelo sem tratamento do desbalanceamento de dados é, na verdade, melhor calibrado do que aqueles que utilizaram técnicas de reamostragem, como SMOTE, ROS ou RUS. Isto também é evidenciado em diversos, artigo, como por exemplo:\n\nThe harm of class imbalance corrections for risk prediction models: illustration and simulation using logistic regression\nThe harms of class imbalance corrections for machine learning based prediction models: a simulation study\nStop Oversampling for Class Imbalance Learning: A Critical Review\n\nAlém disso, observa-se que alguns modelos são naturalmente descalibrados após seu treinamento, independentemente do tratamento de dados. Conforme demonstrado no artigo Probabilistic Prediction in scikit-learn, é necessário adicionar um método de calibração para melhorar as estimativas.\nVenn-Abers\nNesse contexto, utilizo o Venn-Abers, um modelo de calibração que fornece um intervalo de probabilidade, auxiliando na interpretação e quantificação da incerteza na previsão de um modelo. Para obter as probabilidades, o método usa regressão isotônica para calibrar as previsões, aplicando-a duas vezes: primeiro assumindo que o rótulo verdadeiro é 0, depois assumindo que é 1. Esse processo gera duas funções de calibração, f0 e f1, que calculam os intervalos de probabilidade e representam os limites inferior e superior da probabilidade do rótulo ser 1. É possível também trabalhar com uma única probabilidade como resultado, que é o que faremos neste projeto. O artigo original sugere a fórmula:\np=p11−p0+p1Reamostragem\nConsiderando que a reamostragem prejudica a calibração do modelo, decidi abordar o problema das classes de outra maneira, preservando a distribuição original dos dados. É importante ressaltar também que o desbalanceamento por si só nem sempre prejudica o modelo — há arquiteturas pensadas nestes cenários, regularizando o viés. Durante anos, existiu uma concepção de que árvores de decisão, quando aplicadas em dados desbalanceados, inevitavelmente produziriam modelos enviesados para a classe majoritária. Entretanto, existem evidências de que árvores de decisão são capazes de lidar com esse cenário e, em algumas situações, podem até desenvolver uma tendência favorável à classe minoritária, com ajustes específicos. No caso do RandomForestClassifier, por exemplo, ajustamos o critério do modelo com base na proporção das classes, o que auxilia na generalização. Para um entendimento mais profundo, sugiro a leitura do artigo Towards understanding the bias in decision trees.",
		"tags": [ "note"]
},

{
		"title": "4. Previsão Conforme",
		"date":"Sun Jan 04 2026 14:40:44 GMT+0000 (Coordinated Universal Time)",
		"url":"/digital-garden/meu-modelo-conforme/text/4-previsao-conforme/",
		"content": "Previsão Conforme\nA melhor descrição que encontrei sobre o tema encontra-se no artigo Theoretical Foundations of Conformal Prediction, que descreve como:\n\nA previsão conforme é uma abordagem estatística para quantificação de incerteza onde as previsões do modelo são acompanhadas por um intervalo ou conjunto, comunicando o grau de confiabilidade em qualquer previsão, sem depender de pressupostos sobre a certeza do modelo.\n\nPortanto, é um framework de aprendizagem de máquina que permite quantificar incertezas e criar intervalos de predição. Isso possibilita melhores interpretações do modelo, maior segurança e garantias de probabilidade empírica nos resultados.\nSuas vantagens são:\n\nCobertura Garantida: As regiões de previsão oferecem garantias de cobertura para o resultado final.\nAgnosticismo de Modelo: É compatível com qualquer modelo ou área de Machine Learning.\nIndependência de Distribuição: As previsões conformes não pressupõem uma distribuição de probabilidade específica (Gaussiana, Gama, Poisson etc.), ampliando sua aplicabilidade.\nAusência de Retreino: Não é necessário reestimar o modelo após a previsão inicial.\nPredição Probabilística: Oferece previsões com medidas de confiança, permitindo controlar o nível de garantia do próprio modelo.\nFlexibilidade de Tamanho de Dados: A validade das previsões é mantida independentemente do tamanho do conjunto de dados. Contudo, um conjunto de dados pequeno para calibração gera menos valor se comparado a uma volumetria maior.\nEficiência Computacional: As previsões mantêm a eficiência computacional, sendo ideais para aplicações em tempo real e grandes conjuntos de dados.\n\nExistem dois tipos de categorias: Transductive Conformal Prediction (TCP) e Inductive Conformal Prediction (ICP).\nTransductive Conformal Prediction (TCP):\nO TCP foi o método original de Previsão Conforme. Sua característica principal é que, para cada novo ponto de dados, o modelo é treinado inteiramente para cada resultado possível. Por exemplo, em um modelo binário de classificação, o modelo será treinado uma vez para o valor 0 e outra para o valor 1, calculando um score de não conformidade para cada caso.\n\n[!tip]\nOu seja, o modelo irá ser treinado para cada rótulo e para cada ponto novo a ser testado!\n\nEsse processo garante alta precisão, pois considera toda a informação disponível para cada previsão. Este processo se assimila na técnica Jacknife, que faz uma é um processo de leave-one-out para estimação de variância e viés , aonde:\n\nRemove de forma **não **aleatória uma observação por vez do conjunto de dados\nCalcula a estatística de interesse com as observações restantes\nUtiliza essas estimativas para avaliar o variância e viés do estimador\n\nNo contexto da Previsão Conforme, esta abordagem tem como objetivo as estimativas de incerteza, embora⁠, em contra partida pode ser computacionalmente ineficiente dependendo da quantidade de dados tanto de treinamento, como para teste.\nInductive Conformal Prediction (ICP):\nO ICP foi desenvolvido como uma alternativa mais eficiente ao TCP. Nele treinamos uma única vez utilizando dados separados ao do treinamento do nosso modelo base. Com esse conjunto de dados de calibração, geramos um intervalo que são aplicados a novos dados para previsão.\nEmbora o TCP ofereça potencialmente maior precisão, o ICP é geralmente preferido em aplicações práticas devido à sua eficiência computacional, especialmente em cenários com a necessidade de previsões em tempo real.\nUma explicação visual sobre a diferença de ambos pode ser vista por aqui:\nUncertainty Quantification (3): From Full to Split Conformal Methods\nLogo, para este projeto, farei apenas o método ICP.\nCobertura Garantida\nPara compreender a garantia de cobertura, vamos analisar duas expressões matemáticas fundamentais:\nP(Yn+1∈C(Xn+1))≥1−αEla que a probabilidade do próximo valor Y estar contido no conjunto de predição C(Xn+1) é de pelo menos 1-α, onde α representa nossa taxa de erro desejada.\nC(Xn+1)={y∈Y:s(Xn+1,y)≤q^}Esta segunda expressão define o conjunto de predição utilizando um score de não-conformidade. Este score, calculado a partir de novos dados, é comparado com o quantil conforme (q̂), que estabelece nosso limiar para dados conformes. Em termos práticos, isso cria um conjunto de predição onde temos uma garantia probabilística de 1-α de que o próximo valor Y estará contido.\nPara que isso seja respeitado, devemos assumir que os dados respeitem a permutabilidase e que sejam dados independentes e identicamente distribuídos (i.i.d.), assegurando a validade estatística da cobertura.\nPermutabilidade\nO termo se refere à propriedade de uma sequência de variáveis aleatórias em que a ordem de aparecimento não afeta sua distribuição de probabilidade conjunta.\nEm termos mais simples, significa que os elementos de uma sequência podem ser reorganizados sem afetar suas propriedades probabilísticas fundamentais. Por exemplo:\nImagine uma urna com 3 bolas coloridas (vermelha, azul e verde) das quais você vai retirar uma a uma. Considere as seguintes sequências possíveis:\n\nSequência 1: (Vermelha, Azul, Verde)\nSequência 2: (Verde, Vermelha, Azul)\nSequência 3: (Azul, Verde, Vermelha)\n\nSe as bolas são retiradas aleatoriamente e recolocadas, a probabilidade de obter qualquer uma dessas sequências é idêntica. Isso demonstra que a sequência é permutável — você pode reorganizar os elementos e a distribuição de probabilidade permanece inalterada.\nEm resumo, para que a previsão conforme funcione adequadamente, os dados de calibração devem seguir a mesma distribuição dos dados que serão preditos no dia a dia. Podemos validar isso através de diferentes métodos: análise de cobertura empírica, que abordarei posteriormente, teste t de Student ou teste de Kolmogorov-Smirnov.",
		"tags": [ "note"]
},

{
		"title": "5. Treinamento",
		"date":"Sun Jan 04 2026 14:40:44 GMT+0000 (Coordinated Universal Time)",
		"url":"/digital-garden/meu-modelo-conforme/text/5-treinamento/",
		"content": "Treinamento\nNos meus projetos iniciais de carreira, como o de ansiedade e pandemia em época de Covid-19 ou o balanço sobre os dados e previsibilidade sobre a pandemia na região do Amazonas, eu acreditava que apenas gerar o F1 Score ou analisar o ROC-AUC resolveria todos os meus problemas. Porém, quando me deparava com novos dados, eu não sabia o que estava acontecendo. Percebi, tarde demais, que o modelo não estava calibrado!\n\nIntroduction To Conformal Prediction\nPara resolver esse problema, uma opção é transformar nosso modelo em um modelo conforme, que descrevi anteriormente. Eu até poderia ter parado apenas na camada de calibração Venn-Abers, que por si só já transforma nosso modelo em um conforme, mas a geração de cobertura nos dá outras interpretabilidades e possibilidades, que irei comentar no próximos tópicos.\n\n[!tip]\nNão há necessidade de termos uma modelo de calibração se quiser calibrar fazendo uma cobertura de previsão conforme. Apenas faço para melhorar integridade das probabilidades.\n\nDivisão de Dados\nVamos seguir este processo:\n\nDurante o treinamento, dividiremos os dados em três partes: dados de treinamento, calibração e validação.\n\nPor motivos de viés, não utilizamos a mesma massa de dados de treinamento do modelo para gerar o nosso ponto de corte para cobertura de dados conformes.\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\nX_train, X_calib, y_train, y_calib = train_test_split(X_train, y_train, test_size=0.25, random_state=42)\n\nPor conta de meu projeto, vou permanecer com RandomForestClassifier, mas pode ser qualquer um. A fim de simplicidade, deixarei também para termos apenas 2 classes de previsão.\n\nrf = RandomForestClassifier(random_state=42, n_jobs=-1)\nrf.fit(X_train, y_train)\n\nGrau de Incerteza\nPrecisamos tornar esse modelo conforme. Para isso, vamos estabelecer um limite máximo de incerteza do modelo para determinar se a classe predita é provavelmente a verdadeira.\nEsse grau de incerteza é chamado de score de não-conformidade. Existem várias maneiras de calculá-lo, mas para simplificar, usaremos o Hinge Loss, também conhecido como probabilidade inversa. Este score é calculado como 1 − P(y), onde P(y) é a predição do seu modelo. Podemos interpretá-lo como a distância entre a previsão do nosso modelo e a label verdadeira. Quanto mais próximo de 1, mais incerto é o resultado; quanto mais próximo de 0, mais certo.\nCobertura\nDurante o treinamento utilizamos esse score apenas para as probabilidades das classes verdadeiras, a fim de gerar um ponto de corte. Esse ponto separa novos dados que podem conter cada uma das classes em potencial. Chamamos isso de cobertura, pois garante com um grau de confiabilidade que a label verdadeira estará dentro do conjunto de predição. Abordaremos esse conceito com mais detalhes posteriormente.\n# Total de Dados\nn = len(X_calib)\n\n# Score do Modelo\ny_prob = model.predict_proba(X_calib)\n\n# Filtramos apenas para as probabilidades das labels verdadeiras\ny_prob = y_prob[np.arange(n),y_calib]\n\n# Hinge Loss\nnon_conformity_score = 1 - y_prob\n\nUma vez gerado, criaremos o q̂ , que é um ponto de corte baseado em medida de posição. Para todos os scores de não-conformidade, ordenamos seus valores do maior para o menor. Isso nos permite traçar um quantil baseado no nível de confiança, garantindo um percentual de cobertura.\nRecapitulando, o processo envolve:\n\nDefinir nosso nível de confiança α.\nGerar o q̂, que será o quantil (1 - α) desse score ordenado, do maior para o menor. Esse é o percentual de garantia. Por exemplo: com um α de 0.10, teremos um ponto de corte com 90% de garantia.\n\nn = len(nonconformity_score)\nalpha = 0.1\nq_level = np.ceil((n + 1) * (1 - alpha)) / n\nqhat = np.quantile(nonconformity_score, q_level, method=&quot;higher&quot;)\n\n[!tip]\nO q_level é necessário para ajustar a posição do quantil dentro do conjunto de dados finito, distribuindo adequadamente as posições dos quantis.\n\nCom todos os elementos gerados, podemos plotar o resultado. É importante lembrar que tudo abaixo desse q̂ tem cobertura garantida. Dessa forma, os 90% de cobertura significam que há a garantia de 90% para a classe verdadeira estar contida no conjunto de predição. É por essa razão que se utiliza o termo &quot;incerteza rigorosa&quot; para Previsão Conforme — existe uma probabilidade empírica por trás disso!\nfig = px.histogram(\nnonconformity_score,\ntitle=&quot;Score de Não Conformidade&quot;,\ncolor_discrete_sequence=[&quot;grey&quot;, &quot;orange&quot;],\nwidth=800,\nheight=400)\nfig.update_yaxes(title_text=&quot;Total&quot;)\nfig.update_xaxes(title_text=&quot;Score&quot;)\nfig.update_layout(legend=dict(title=&quot;Label&quot;))\nfig.add_vline(x=qhat, line_dash=&quot;dash&quot;, line_color=&quot;black&quot;, annotation_text=&quot;qhat&quot;, annotation_position=&quot;top&quot;)",
		"tags": [ "note"]
},

{
		"title": "6. Escoragem",
		"date":"Sun Jan 04 2026 14:40:44 GMT+0000 (Coordinated Universal Time)",
		"url":"/digital-garden/meu-modelo-conforme/text/6-escoragem/",
		"content": "Escoragem\nAnteriormente, geramos a cobertura para os conjuntos de previsão. Na verdade, o método que utilizamos é o mais tradicional, conhecido como cobertura marginal. Ele é excelente para situações em que se deseja atender à distribuição como um todo. Porém, dependendo do seu problema, sua adaptabilidade — ou seja, a capacidade de atender às classes específicas — pode não ser ideal. Não há certo ou errado; é preciso entender o que melhor atende ao seu problema. Existem diversos outros métodos, cada um com suas vantagens e desvantagens, como o RAPS, cobertura assímetrica e classe condicional, conhecida também como Mondrian.\n\nA Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification\n\nClasse Condicional\nA ideia da previsão é ter uma cobertura que tenha a mesma distribuição de dados passados, como dados futuros. Esse conceito é a permutabilidade. Isso significa que, não importa de que época o dado existe, ele irá ter a mesma distribuição de probabilidade. É importante entender isso, por duas razões:\n\nCaso haja mudança brusca e mudança na distribuição dos seus dados, a cobertura deverá ser gerada novamente, pois ela deixa de atender para o que foi proposto. Não há necessidade de retreino de modelo, mas sim para a cobertura.\nPor conta dessa premissa, também não é aconselhado, tampouco incentivado a fazer reamostragem de dados para não afetar a distribuição amostral dos dados. Para condições de dados desbalanceados, irei descrever como resolver no tópico Classificador Conforme, preservando a calibração do modelo.\n\nUm ponto que preciso dar ênfase, é que o uso de cobertura não gera apenas um único score como resultado, mas um conjunto de predições de todas as classes, podendo até todas as classes estarem na predição. Isso não é um bug! Modelos conformes que utilizam cobertura geram conjunto de respostas, sendo cada classe a ser testada dentro da cobertura.\n\nUnderstanding, Generating, and Evaluating Prediction Intervals\nPonto Estimado vs Intervalo\nNa previsão conforme, ainda é possível modelar um ponto estimado de duas maneiras:\n1. Venn-Abers (VA)\nO VA é um modelo de calibração de previsão conforme, ao qual oferece:\n2. P-valor dos NCScores\nPodemos estimar o p-valor dos scores de não-conformidade para cada classe predita.\nConsiderações Importantes\nEm ambos os cenários:\nInterpretação\n\nConfiança: Indica a probabilidade da classificação predita versus outras classes\nCredibilidade: Mostra o quão adequada é a previsão conforme para classificar a instância\n\nNão abordarei com profundidade estes dois métodos, mas tenha em mente a flexibilidade do framework.\n\n[!tip]\nÉ importante não confundir intervalos de predição com intervalos de confiança, pois são conceitualmente diferentes:\nO intervalo de confiança nos permite estimar, com determinado grau de certeza, onde um parâmetro populacional se encontra.\nJá o intervalo de predição nos permite estimar, também com um grau de certeza específico, onde o valor real de uma nova observação deve estar.\n\nCobertura\nUtilizar uma cobertura garantida de score de não conformidade pode nos ajudar a interpretar sobre diversos pontos:\n\nUncertainty Sets for Image Classifiers using Conformal Prediction\n\nEm um modelo de detecção de imagens, conseguimos saber quais labels estão sendo apresentadas para respectivas imagens, e quais têm quantificações aproximadas de incerteza.\nEm modelos de automação ou detecção, podemos solicitar analise humana aonde mais de uma label é detectada.\nEm um modelo de recomendação, é possível identificar similaridades entre produtos, sendo possível juntar ambos ou até ofertarem juntos.\n\ny_prob = rf.predict_proba(X_test)\nncscore = 1 - y_prob\n(ncscore &lt;= qhat).astype(int)\n\nAs possíveis respostas, poderão ser, pensando em um classificador binário:\n\n[0, 0]: Há garantia na probabilidade de que o dado escorado não compõe nenhuma classe.\n[1, 0]: Há garantia de que o dado compõe a classe ‘0’.\n[0, 1]: Há garantia de que o dado compõe a classe ‘1’.\n[1, 1]: Há garantia de que o dado compõem ambas as classes.\n\nO código para fazermos futuras escoragens é bem simples, a complexidade se dá aos fundamentos de chegarmos em um bom entendimento.\nSe ainda não ficou muito claro sobre o tema, antes de falarmos sobre validação e eficiência, sugiro seguir os exemplos de Christoph Molnar:\nWeek #1: Getting Started With Conformal Prediction For Classification",
		"tags": ["1", "note"]
},

{
		"title": "7. Validade e Eficiência",
		"date":"Sun Jan 04 2026 14:40:44 GMT+0000 (Coordinated Universal Time)",
		"url":"/digital-garden/meu-modelo-conforme/text/7-validade-e-eficiencia/",
		"content": "Validade e Eficiência\nAo tentar criar seu primeiro modelo de previsão conforme, você pode ter encontrado um desafio: muitos conjuntos de predição do seu modelo retorna todas as classes. Mas por que isso acontece?\nÀ medida que aumentamos o nível de cobertura (por exemplo, para 99%), os conjuntos de previsão conforme tendem a crescer. Isso ocorre porque o modelo precisa incluir mais classes para garantir que a verdadeira classe esteja no conjunto de previsão com a probabilidade desejada.\nEsse fenômeno está relacionado ao conceito de validade na previsão conforme. Ela assegura que a probabilidade de o conjunto de previsão conter a verdadeira classe seja, no mínimo, igual ao nível de confiança especificado. Por exemplo, com um nível de confiança de 99%, esperamos que o conjunto de previsão inclua a classe correta em pelo menos 99% dos casos.\nContudo, essa garantia pode resultar em conjuntos de previsão maiores, especialmente quando o nível de confiança é muito alto. Isso acontece porque o modelo precisa ser mais conservador em suas previsões para manter a garantia de cobertura.\nPor outro lado, pode também ocorrer o inverso, aonde ambos os valores não atendem à cobertura, tornando vazio o conjunto de predições. Isso pode ocorrer pois estamos mexendo em um intervalo gerado a partir de diversos valores, não apenas um ponto fixo. Imagine que chegue um dado bem diferente do que já foi visto em todo histórico dos dados.\nNo artigo Model-Agnostic Nonconformity Functions for Conformal Classification, foram criadas duas métricas de não-conformidade, AvgC e OneC, retratando as propriedades de **validade **e eficiência da cobertura, que nos auxiliam bastante a entender como nosso modelo está performando. Validade refere-se à quantidade média de rótulos sinalizados pelo modelo por conjunto de predições, enquanto eficiência é a proporção de conjuntos de predições com apenas um valor. Quanto menor o valor de validade, mais informação podemos extrair do modelo, pois o conjunto de predições fica menor. Por outro lado, quanto maior o score OneC, melhor é a capacidade do modelo de extrair informação do score de não conformidade, conseguindo ser mais específico em seu resultado.\nPodemos também ver as duas propriedades visualmente no link abaixo:\nUncertainty Quantification (1): Enter Conformal Predictors\nEm meu projeto pessoal, fiz um gráfico que plota ambos os scores baseados em diferentes níveis de α. Caso tenha curiosidade, o código está disponível em meu GitHub.\n\nOutras métricas que podem ser utilizadas para validação de modelo são:\nTotal de conjunto Vazios\n\nQuantas vezes o modelo emitiu um conjunto de predições vazias, não sendo informativo em seu resultado.\n\nTaxa de Erro\n\nMédia de conjunto de predições aonde o modelo errou em relação ao label original.\n\nCobertura Empírica\nÉ uma métrica que geramos para saber o quão temos a cobertura garantida no intervalo de predição em relação ao nível que foi modelado, em outras palavras, verificamos se, vamos supor, com um intervalo de 95% imposto à cobertura, temos aproximadamente 95% de garantia real sob ela. Caso ocorra de que esse valor seja relativamente inferior ao imposto, é possivel que o conceito de permutabilidade não esteja sendo atendida e toda modelagem precisa ser revisada!\nDentro dos meus modelos conformes no github há um código para geração dessa métrica, mas a lógica é o seguinte:\n\nA partir de uma massa de dados, gero o score de não-conformidade e seto um número arbitrário na qual vou iterar sob eles.\nA cada iteração, um percentual desses dados é selecionado de forma aleatória e posteriormente separados entre dado de calibração e teste, gerando o qhat baseado no alpha que modelei. Nesse caso, nosso alpha era 0.05.\nCalcula a média da cobertura dos dados selecionados para validação desta iteração.\nRepetimos o processo até o número de iterações seja atingido.\nPor fim tiramos a média de todas as coberturas geradas e comparamos com o valor modelado.\n\nHá uma ótima explicação sobre isso no link abaixo:\nA Tutorial on Conformal Prediction Part 2: Conditional Coverage and Diagnostics",
		"tags": [ "note"]
},

{
		"title": "8. Score de não-conformidade",
		"date":"Sun Jan 04 2026 14:40:44 GMT+0000 (Coordinated Universal Time)",
		"url":"/digital-garden/meu-modelo-conforme/text/8-score-de-nao-conformidade/",
		"content": "Score de não-conformidade\nVocê pode utilizar qualquer tipo de score de não-conformidade ou até mesmo criar um, mas deixarei documentado dois scores amplamente utilizados na área acadêmica.\nHinge Loss\nHinge, ou probabilidade inversa, refere-se ao quanto o modelo errou em relação ao rótulo verdadeiro. Seu cálculo se baseia em 1 − P(y), sendo P(y) a predição do seu modelo. O range vai de 0 a 1, onde 0 significa que o modelo está correto, e 1 indica que o modelo está completamente errado.\nMargin\nMargin refere-se à diferença entre a probabilidade da predição mais incorreta e a probabilidade correta. Valores menores ou iguais a zero indicam que o modelo tem certa confiança em relação à classe verdadeira, enquanto valores positivos representam uma incerteza em sua predição.",
		"tags": [ "note"]
},

{
		"title": "9. Aprendizado Sensível ao Custo",
		"date":"Sun Jan 04 2026 14:40:44 GMT+0000 (Coordinated Universal Time)",
		"url":"/digital-garden/meu-modelo-conforme/text/9-aprendizado-sensivel-ao-custo/",
		"content": "Aprendizado Sensível ao Custo\nO Aprendizado Sensível ao Custo é uma abordagem que busca otimizar decisões considerando os custos associados a diferentes tipos de erros. Diferentemente das abordagens tradicionais, onde os custos de erro são simétricos, esta abordagem lida com custos assimétricos — alguns erros podem ser mais custosos ou prejudiciais que outros. Esses erros podem ser de predição (Falsos Positivos ou Negativos) ou relacionados a regras de negócio, como fraudes ou aprovação de um serviço caro. A ideia central é minimizar o custo total das previsões, em vez de simplesmente maximizar a precisão.\nExemplo de Treinamento com Aprendizado Sensível ao Custo:\nConsidere um banco desenvolvendo um modelo para detectar transações fraudulentas. A matriz de custos poderia ser estruturada da seguinte forma:\n\nPrevisão \\ Real\nFraude\nNão Fraude\n\nFraude\n$0\n$50\n\nNão Fraude\n$1000\n$0\n\nNeste cenário:\n\nFalso Positivo (classificar uma transação legítima como fraude): Custa $50 à empresa devido à insatisfação do cliente.\nFalso Negativo (não detectar uma fraude real): Custa $1000 à empresa, representando o valor médio de uma transação fraudulenta.\nVerdadeiro Positivo e Verdadeiro Negativo: Não têm custos associados.\n\nLogo, o modelo treinado ajustaria seus parâmetros para minimizar o custo total. Isso pode resultar em aceitar mais falsos positivos para reduzir significativamente os falsos negativos mais custosos. Embora possa ter uma precisão geral ligeiramente menor, esse modelo seria mais eficaz em termos de redução de perdas financeiras para a empresa.\nDados Desbalanceados\nAlém disso, podemos aplicar essa metodologia para lidar com conjuntos de dados desbalanceados, onde uma classe é significativamente mais representada que outra. Atribuímos custos mais altos aos erros da classe menos representada, controlando assim a confiabilidade do modelo em relação às classes.\nPara implementar isso, primeiro criamos um peso para cada classe, proporcional ao volume de dados para treino. Simulando para duas classes:\nípeso-da-classe=total-de-dadostotal-de-classes×total-de-registros-da-classe-específicatotal_de_dados = 100\ntotal_da_classe_0 = len(y_train[y_train == 0]) # 90\nw1 = 100 / (2 * total_da_classe_0) #0.55\n\ntotal_da_classe_1 = len(y_train[y_train == 1]) # 10\nw2 = 100 / (2 * total_da_classe_1) #5\n\nrf = RandomForestClassifier()\nrf.fit(X_train, y_train, class_weight={0: 0.55, 1: 5})\n\nDesta forma, contabilizará os pesos das duas classes dentro da função de perda. Neste caso, dentro de gini, contabilizará os dois pesos.\nGini=1−W1∗Proportionc12−W2∗Proportionc22scikit-learn por padrão, possibilita já calcular esse peso, apenas incrementado o parametro como “balanced”.\nrf.fit(X_train, y_train, class_weight=&quot;balanced&quot;)\n\nHá outros métodos utilizando metadados mais específicos. Para mais informações, recomendo a palestra no EuroSciPy 2023.\nEuroSciPy 2023 - Get the best from your scikit-learn classifier\nAvaliação de Performance\nPrecisamos observar corretamente como nosso modelo atua no cenário do nosso problema. Para isso, é importante selecionar a melhor métrica para avaliação. Existe uma lista expressiva de opções. No contexto de classificação binária, irei abordar apenas as métricas que são de meu interesse.\nÉ importante destacar que todas essas métricas derivam da matriz de confusão, utilizando conceitos como Verdadeiro Positivo (VP), Falso Positivo (FP), Verdadeiro Negativo (VN) e Falso Negativo (FN).\n\n[!tip]\nSempre que precisar discutir ou revisar alguma métrica para adequá-la ao seu problema, sugiro fortemente consultar o guia disponibilizado pela Nannyml — vale a pena!\n\nF1-Score\nF1-Score é uma das métricas mais utilizadas para avaliar modelos. Seu cálculo é feito pela a média harmônica entre precisão e sensibilidade, fornecendo um único valor que equilibra ambas as métricas. Sua fórmula é:\nããF1=2×Precisão×SensibilidadePrecisão+SensibilidadeOnde:\n\nPrecisão = VP / (VP + FP)\nSensibilidade = VP / (VP + FN)\n\nÉ particularmente útil quando buscamos um equilíbrio entre precisão e sensibilidade. Um valor alto indica que o modelo possui tanto boa precisão quanto boa sensibilidade.\nEntretanto, o F1-Score não contabiliza os verdadeiros negativos e dá ênfase à classe positiva, o que o torna a ser enviesado. Para entendermos isso, precisamos voltar e falar de como ele surgiu e qual era o seu propósito inicial. O F1-Score foi desenvolvido por van Rijsbergen, em 1979, para avaliar sistemas de recuperação de informação, onde a precisão e sensibilidade tem maior grau de importância do que a predição correta de VN. Segundo o artigo Assessing Software Defection Prediction Performance: Why Using the Matthews Correlation Coefficient Matters, é exemplificado isso:\n\nEste domínio do problema é caracterizado por contagens muito grandes, e frequentemente desconhecidas, de VN. Considere, por exemplo, a recuperação de páginas web. Saber o número de páginas irrelevantes corretamente não recuperadas, ou seja, verdadeiros negativos, será tanto desafiador quanto pouco interessante. Isso chegaria a centenas de milhões, possivelmente mais. Infelizmente, aplicar F1 no contexto completamente diferente de predição de defeitos não é equivalente.\n\nIsso é bastante perceptível quando há um grau de importância nos Verdadeiros Negativos (VN) ou quando existe um desbalanceamento para a classe negativa. Nessas condições, a métrica pode mascarar a real performance do modelo. Tal fato é evidenciado também no artigo The advantages of the Matthews correlation coefficient (MCC) over F1 scoreand accuracy in binary classification evaluation, que demonstra cenários onde a métrica pode gerar uma confiança equivocada no modelo, sugerindo o uso de métricas alternativas que sejam mais representativas do contexto geral.\nPor exemplo, supondo que temos um modelo de detecção de indicativos de um paciente para uma doença muito comum:\n\nDados de Teste: 1000 pacientes\n980 pacientes (98%) têm a doença (positivos)\n20 pacientes (2%) não têm a doença (negativos)\n\nSe um modelo simplesmente classificar todos como positivos:\n\nF1-Score: 0.99\n\nCom essa métrica, não conseguimos avaliar se o modelo está superestimando os resultados ou simplesmente classificando todos os pacientes como doentes, mascarando assim problemas mais sérios. Por isso, recomenda-se utilizar métricas que ofereçam um contexto mais amplo e uma visão mais completa, considerando o peso de toda a matriz de confusão. Assim, abordarei a acurácia balanceada, uma normalização da métrica Bookmaker informedness (BM).\n\n[!tip]\nNão há problema em usar o F1-Score, porém é recomendável combiná-lo com outra métrica para obter um contexto maior do modelo.\n\nAcurácia Balanceada\nA partir delas podemos derivar uma métrica mais robusta para dados desbalanceados: a acurácia balanceada (BA). Seu diferencial é avaliar o desempenho do modelo considerando igualmente todas as classes, independentemente de sua frequência nos dados.\nA acurácia balanceada é calculada como a média aritmética entre sensibilidade e especificidade. Para um problema de classificação binária, a fórmula é:\náAcurácia Balanceada=12(VPVP+FN+VNVN+FP)Onde:\nA acurácia balanceada é útil em cenários onde as classes têm igual relevância, independentemente de sua distribuição nos dados.\nPor exemplo, imagine um sistema de controle de qualidade em uma fábrica de componentes críticos de aeronaves:\n\nVolumetria: 1.000 peças\n950 (95%) das peças são aprovadas no controle de qualidade\n5 (5%) das peças apresentam defeitos\n\nSe um modelo de detecção automática sempre aprovar as peças, teríamos:\n\nAcurácia normal: 95%\nAcurácia balanceada: 50%\n\nNeste caso, tanto aprovar uma peça defeituosa quanto rejeitar uma peça boa são igualmente críticos: o primeiro pode comprometer a segurança da aeronave, e o segundo representa um prejuízo financeiro significativo, pois são peças caras! Neste contexto em que os tipos de erros são igualmente importantes, é interessante considerarmos a acurácia balanceada.\nRetornando ao contexto original do problema — adaptar o modelo para dados possivelmente desbalanceados — e considerando que ambos os erros de classificação têm igual importância, a acurácia balanceada é mais adequada.\nAtualização de Projeto!\nApós revisão do meu projeto, resolvi fazer uma alteração na versão da biblioteca. Nela, utilizo a possibilidade de escolher entre duas métricas, Bookmaker Informedness (BM) ou Coeficiente de Correlação de Matthews (MCC).\nBookmaker Informedness\nO Bookmaker Informedness é outra métrica importante para avaliação de modelos, especialmente em cenários com classes desbalanceadas. Assim como a acurácia balanceada, ela busca fornecer uma avaliação mais robusta do desempenho do modelo. Na realidade, BA é uma normalização de BM.\nO BM é calculado como:\nBM=Sensibilidade+Especificidade−1Esta métrica:\n\nVaria de -1 a +1, onde +1 indica predição perfeita\n0 indica que o modelo não é melhor que escolhas aleatórias\nValores negativos indicam desempenho pior que aleatório\n\nO Bookmaker Informedness é particularmente útil quando as classes têm igual importância, independente de sua distribuição nos dados, como também é a única métrica para avaliar aleatoriedade da predição, demonstrado no artigo The Matthews correlation coefficient (MCC) is more reliable than balanced accuracy, bookmaker informedness, and markedness in two-class confusion matrix evaluation - BioData Mining\nCoeficiente de Correlação de Matthews\nO MCC é considerado uma das métricas mais completas para avaliação de classificadores binários, pois:\n\nConsidera todos os elementos da matriz de confusão (VP, VN, FP, FN)\nÉ especialmente útil para classes desbalanceadas\nFornece uma medida mais confiável mesmo quando as classes têm tamanhos muito diferentes\nEm caso de seu score alto, métricas como Brier Score, F1-Score, BM, ROC-AUC costumam apresentar bons resultados.\n\nA fórmula do MCC é:\nMCC=VP×VN−FP×FN(VP+FP)(VP+FN)(VN+FP)(VN+FN)O MCC tem as seguintes características:\n\nVaria de -1 a +1, similar ao Bookmaker Informedness\n+1 representa uma classificação perfeita\n0 indica desempenho equivalente a predições aleatórias\n-1 indica o pior desempenho possível\n\nO MCC é particularmente útil quando as classes têm igual importância, independentemente de sua distribuição nos dados. Diferentemente de outras métricas, existe uma extensa literatura que recomenda seu uso como padrão no campo da estatística para garantir maior rigor na avaliação dos modelos.\nPortanto, optou-se por utilizar tanto o MCC quanto o BM para avaliar os resultados.\n\n[!tip]\nComo o MCC considera tanto a prevalência dos dados positivos quanto o viés de quão provável o modelo prevê corretamente a base de dados, não é aconselhável utilizá-lo quando queremos comparar resultados entre diferentes bases de dados.\nPara esse cenário, é melhor utilizar BA ou BM.\n\nAprendizado Sensível a Custo versus Reamostragem\nUma diferença crucial é que, ao contrário dos métodos de undersampling ou oversampling, não modificamos a distribuição dos dados durante o treinamento. O modelo é treinado com a distribuição real dos dados disponíveis, alterando apenas a forma como aprende a partir deles. Isso traz uma vantagem especial quando precisamos estimar a precisão e probabilidade do modelo em um cenário real, pois a distribuição dos dados reflete fielmente a realidade.",
		"tags": ["0", "5", "note"]
},

{
		"title": "Meu Modelo Conforme",
		"date":"Sun Jan 04 2026 14:40:44 GMT+0000 (Coordinated Universal Time)",
		"url":"/digital-garden/meu-modelo-conforme/text/meu-modelo-conforme/",
		"content": "<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/digital-garden/meu-modelo-conforme/text/1-introducao/\">digital-garden/meu-modelo-conforme/text/1. Introdução</a>\n<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/digital-garden/meu-modelo-conforme/text/2-antes-de-comecarmos/\">2. Antes de Começarmos…</a>\n<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/digital-garden/meu-modelo-conforme/text/3-probabilidade-e-calibracao-de-modelo/\">3. Probabilidade e Calibração de Modelo</a>\n<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/digital-garden/meu-modelo-conforme/text/4-previsao-conforme/\">4. Previsão Conforme</a>\n<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/digital-garden/meu-modelo-conforme/text/5-treinamento/\">5. Treinamento</a>\n<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/digital-garden/meu-modelo-conforme/text/6-escoragem/\">6. Escoragem</a>\n<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/digital-garden/meu-modelo-conforme/text/7-validade-e-eficiencia/\">7. Validade e Eficiência</a>\n<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/digital-garden/meu-modelo-conforme/text/8-score-de-nao-conformidade/\">8. Score de não-conformidade</a>\n<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/digital-garden/meu-modelo-conforme/text/9-aprendizado-sensivel-ao-custo/\">9. Aprendizado Sensível ao Custo</a>\n<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/digital-garden/meu-modelo-conforme/text/10-classificador-conforme/\">10. Classificador Conforme</a>\n<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/digital-garden/meu-modelo-conforme/text/11-referencias/\">11. Referências</a>\n<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/digital-garden/meu-modelo-conforme/text/12-regressao/\">12. Regressão</a>",
		"tags": [ "note"]
},

{
		"title": "0. Roadmap",
		"date":"Sun Jan 04 2026 14:40:44 GMT+0000 (Coordinated Universal Time)",
		"url":"/digital-garden/path-for-the-true-and-brave/text/0-roadmap/",
		"content": "Mês 1\n\nFree Tutorial - Causal AI in a Nutshell\nCausality, Decision Making &amp; Data Science (1 ~ 7)\nEstatística Psicobio II 2024 #23 - DAG I - Directed Acyclic Graphs - Princípios de Causalidade\nEstatística Psicobio II 2024 #24 - DAG II Directed Acyclic Graphs - d' separation; algoritmo PC e IC\nEstatística Psicobio II 2024 #25 - DAG III - Aplicações do DAG, Propensity Scores e diff-n-diff\n\nMês 2\n\nUniversidade de Dados - Robson Tigre\nCausal Inference in Python - (Cap I, II, III)\nCausal Inference in Python - Noncompliance &amp; Instruments\nTools for Causality\n\nMês 3\n\nEveryday causal inference\nMentoria - Robson Tigre\n\nMês 4\n\nProjetos Quasi-Experimentais\n\nNext Steps\n\nPanel Data (Cap. IV)\nCausal Discovery Inference\nOnline Controlled Experiments\nThe Book of Why: The New Science of Cause and Effect | Amazon.com.br",
		"tags": ["23", "24", "25", "note"]
},

{
		"title": "1. Introdução",
		"date":"Sun Jan 04 2026 14:40:44 GMT+0000 (Coordinated Universal Time)",
		"url":"/digital-garden/path-for-the-true-and-brave/text/1-introducao/",
		"content": "Introdução\nE cá estamos Dezembro de 2025, semana de natal. Faz um tempo que não escrevo nada publicamente — na verdade até estava, concentrado em refinar o Tinyshift. O projeto cresceu bastante e estou bem feliz com o rumo que tomou, embora sei que ainda há muito o que fazer nele.\nNeste meio caminho, em epifanias, percebi algo. Quanto mais tempo trabalho em ciência de dados, mais certeza só tenho de uma coisa: eu sei absolutamente nada. Depois de tanto tempo estudando sob diversos temas, novamente senti que estava batendo em outro teto.\nNeste contexto, ficamos extremamente habituados em um escopo: associação. Quando digo isto, sempre pensamos em modelar sob forma de resultarmos na probabilidade de um acontecimento, de um número, ou de uma classe em relação a outros fatores. Isto começou a me pregar dois problemas:\n\nA primeira é que estamos sempre falando de padrões. Comportamentos de fraude, spam, itens comprados juntos. Isso é natural: nosso cérebro é feito para reconhecer padrões, desde a Era da Pedra. Para nossa sobrevivência, sempre ficamos habituados a isso. Mas padrões não são causa e efeito. Imagine o clássico dataset sobre vendas de sorvete com uma feature de ataques de tubarão. Ao observar os dados você encontra tem padrões, associações fortes de um com outro! Seria sensato recomendar que seu cliente corte relações com empresas de sorvete? Claro que não, ao menos pra mim! Ambas as variáveis podem ser influenciadas por um terceiro fator: a temperatura. No verão as pessoas vão mais à praia e compram mais sorvete — como também há mais chance de ataques. Isso é o que chamamos de correlação espúria. O mantra vale: associação não implica causalidade.\nA segunda questão é prática: um modelo de Machine Learning tradicional frequentemente entrega apenas uma probabilidade. Nós, humanos, tomamos decisões com base nesse número. Mas se nosso objetivo é orientar ações, por exemplo, reduzir churn, não basta saber quem tem maior probabilidade de churn; precisamos saber qual é o impacto de uma ação (uma promoção, atendimento diferenciado, cross-sell) sobre o churn. Quais ações causam mais impacto para diferentes perfis de cliente? Facure fala exatamente disso no podcast do Aleksander Molak. Em vez de modelar apenas a probabilidade, quero saber qual intervenção impacta mais e por quanto — ou seja, modelar sobre as regras de negócio, não só previsão.\n\nModelos preditivos podem induzir a decisões equivocadas quando o objetivo é agir no mundo. O propósito final de um modelo de ML é resolver um problema de negócio; mover o ponteiro é o que importa! Por isso, comecei a estudar formas de modelagem que foquem tomada de decisão: entender relações de causa e efeito para orientar intervenções eficazes. Assim, em vez de prever, posso estimar o impacto de prevenir clientes descontentes, quais fatores reduzem churn ou se um cross-sell aumenta a fidelidade.\nEstas anotações em Zettelkasten são o registro da minha jornada nessa selva que conheço tão pouco. Elas não são e nunca vão ser um guia prático, mas achei que seria bom disponibilizá-las como portfólio e para ajudar quem também gostaria de começar a ler ou discutir sobre o tema.\nAqui, escreverei apenas tópicos que me interessam, focando em dados observacionais e estudos transversais. Inferência Causal é gigante, então espere por lacunas nesse conteúdo. Mais importante: vamos ter um pouco de humildade epistêmica aqui, combinado?\n\n[!tip]\nEste documento não tem a pretensão de ser um ponto focal de ensinar, mas sim um registro pessoal de aprendizado. Escrever me ajuda a fixar o conteúdo e, ao torná-lo público, espero facilitar o caminho de quem também quer desbravar este tema, mas se sente perdido no início.\nComo ponto de partida, criei o <a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/digital-garden/path-for-the-true-and-brave/text/0-roadmap/\">0. Roadmap</a> detalhando o caminho que eu percorri. Como referências essenciais, recomendo acompanhar Robson Tigre e Matheus Facure — seus respectivos livros são excelentes e complementares.\nNote que alguns assuntos no roadmap se repetem ou são revisitados. Isso é intencional. Acredito que a fixação do conhecimento acontece através da:\n\nSíntese: Criar anotações próprias e explicar o assunto;\n\nPrática: Aplicar o que foi estudado;\n\nDiversidade: Consumir o mesmo tema por diferentes fontes e perspectivas.",
		"tags": [ "note"]
},

{
		"title": "10. Efeitos Heterogêneos",
		"date":"Sun Jan 04 2026 14:40:44 GMT+0000 (Coordinated Universal Time)",
		"url":"/digital-garden/path-for-the-true-and-brave/text/10-efeitos-heterogeneos/",
		"content": "Efeitos Heterogêneos\nNas análises de inferência causal demonstradas anteriormente, exploramos o ATE sob uma perspectiva populacional. No entanto, em muitos cenários, o interesse reside em entender como diferentes subgrupos reagem ao tratamento, identificando quem apresenta impactos maiores ou menores. Para capturar essa variabilidade, utilizamos o Efeito Médio de Tratamento Condicional (CATE), que nos permite observar os chamados efeitos heterogêneos.\nO objetivo do CATE é permitir que a tomada de decisão seja fundamentada nas características específicas (X) de cada unidade. Em vez de perguntar apenas se &quot;o tratamento funciona&quot;, passamos a questionar: &quot;para quem o tratamento funciona melhor?&quot;**.\nMatematicamente, definimos o CATE como:\nτ(x)=E[Yi(1)−Yi(0)∣Xi=x]Onde buscamos a diferença esperada entre os outcomes potenciais (Y1 e Y0), condicionada a um conjunto de covariáveis X.\nRegressão Linear\nUma regressão linear simples estima apenas o coeficiente médio do tratamento. Para identificar efeitos heterogêneos, introduzimos termos de interação entre a variável de tratamento (T) e as características das unidades (X). Essa abordagem torna o modelo flexível, permitindo que a &quot;inclinação&quot; (o efeito do tratamento) varie conforme o perfil da unidade.\nA equação assume a forma:\nyi=β0+β1Di+β2Xi+β3(Di×Xi)+ϵi.Derivação do Efeito\nPara isolar o efeito do tratamento em um modelo com interações, utilizamos a derivada parcial da variável de resultado (y) em relação ao tratamento (D).\nConsidere o modelo:\nyi=β0+β1Di+β2Xi+β3(Di×Xi)+ϵiA variação de y para uma mudança infinitesimal em t é dada por:\n∂yi∂Di=β1+β3XiIsso nos mostra que o efeito do tratamento não é constante: ele depende diretamente dos valores das covariáveis Xi de cada indivíduo.\nAproximação por Diferença Finitas\nNa prática, como o modelo é linear, essa derivada pode ser calculada exatamente através da diferença entre duas predições. Usamos a definição de derivada onde o incremento (ϵ) é igual a 1 unidade:\nδyδD≈y^(D+1)−y^(t)Onde:\n\ny^(D+1) é a predição do modelo incrementando o tratamento original em uma unidade.\ny^(D) é a predição do modelo com os dados originais.\n\nExemplo (Causal Inference in Python: Applying Causal Inference in the Tech Industry\n\nimport statsmodels.formula.api as smf\n\n# 1. Definição das covariáveis (características que podem causar heterogeneidade)\nX = [&quot;C(month)&quot;, &quot;C(weekday)&quot;, &quot;is_holiday&quot;, &quot;competitors_price&quot;]\n\n# 2. Especificação do modelo com Interação # A sintaxe 'discounts * (X)'\n# Isso permite que o efeito do desconto mude conforme o mês, feriado ou preço do concorrente.\nregr_cate = smf.ols(f&quot;sales ~ discounts*({'+'.join(X)})&quot;,\ndata=data).fit()\n\n# 3. Estimativa do CATE (Efeito Médio de Tratamento Condicional)\n# Calculamos a diferença entre duas realidades hipotéticas para cada unidade:\n# Realidade A: O desconto atual + 1 unidade\n# Realidade B: O desconto atual\n# A diferença entre as predições isola o efeito marginal do desconto naquele contexto específico.\nols_cate_pred = (\nregr_cate.predict(data.assign(discounts=data[&quot;discounts&quot;]+1))\n-regr_cate.predict(data)\n)\n\nAvaliação\nA ideia central de criar modelos CATE surge da necessidade de ordenar as unidades das mais sensíveis às menos sensíveis ao tratamento, visando a personalização. Como não podemos observar o efeito individual real para validar essa ordenação, avaliamos grupos definidos pela predição do modelo. Diferentemente de um modelo tradicional de machine learning, focamos em verificar o quão bem o modelo está em relação a essa segmentação para efeito causal médio condicional. Não irei abordar a fundo, novamente aconselho a ler o livro do Matheus Facure pois há uma explicação boa sobre. Pontuarei apenas as três formar em que ele comenta como métodos.\nOutro ponto a ressaltar, é que se encontra exemplos bons da aplicação aberta via o jupyter notebook exemplar do livro. Causal Inference in Python: Applying Causal Inference in the Tech Industry.\nEfeito por Quantil\nA abordagem consiste em segmentar os dados em quantis baseados na predição do modelo e estimar o efeito dentro de cada partição. Se o efeito estimado em cada quantil estiver ordenado (por exemplo, do maior para o menor), isso indica que o modelo é eficaz em ordenar o CATE verdadeiro. Visualmente, quanto maior for o efeito &quot;escada&quot; no gráfico de efeito por quantil, melhor o modelo distingue os efeitos altos dos baixos.\nCurva de Efeito Cumulativo\nSeguindo a lógica anterior, a Curva de Efeito Cumulativo não estima o efeito por grupos isolados, mas sim acumulando um grupo sobre o outro. O processo envolve ordenar os dados pelo score do modelo (predição CATE) e estimar o efeito ordenado de um valor N, depois do valor N + 1, e assim sucessivamente.\nEmbora essa curva permita resumir a qualidade do modelo calculando a área entre a curva e o ATE, ela apresenta uma desvantagem: o início da curva possui uma amostra pequeno, o que nos trás maior incerteza devido ao tamanho reduzido da amostra acumulada naquele ponto.\nCurva de Ganho Cumulativo (Cumulative Gain)\nPara corrigir a questão da variância no início da curva de efeito cumulativo, utiliza-se a Curva de Ganho Cumulativo. A lógica é a mesma, porém multiplicamos cada ponto da curva de efeito pela proporção da amostra acumulada (Ncum/N).\nO modelo que apresentar a maior área entre a curva e a linha tracejada (representando o ATE) — ou a maior soma dos valores da curva normalizada — é considerado o melhor em termos de ordenação do CATE. Por conta disso, podemos tirar o AUC e utilizarmos para avaliar o modelo desse resultado.",
		"tags": [ "note"]
},

{
		"title": "11. Variável Instrumental",
		"date":"Sun Jan 04 2026 14:40:44 GMT+0000 (Coordinated Universal Time)",
		"url":"/digital-garden/path-for-the-true-and-brave/text/11-variavel-instrumental/",
		"content": "Variável Instrumental\nExistem cenários em que é inviável controlar totalmente o viés de variável omitida U. Nestes casos, problemas comuns incluem:\n\nA impossibilidade de coletar ou mensurar todas as variáveis de confusão.\n\nA impossibilidade de garantir que todos os indivíduos designados ao grupo de tratamento efetivamente recebam ou utilizem o tratamento. Isso caracteriza uma violação do perfect compliance (adesão perfeita).\n\n[!tip] Nota\nCompliance refere-se à taxa de adesão, ou seja, o percentual de indivíduos que efetivamente utilizaram o tratamento conforme designado.\n\nNestes cenários, a variável não observada U exerce influência tanto sobre o tratamento D quanto sobre o resultado Y, enviesando as estimativas causais:\nD←U→YUma solução para contornar a falta de controle sobre U é utilizar uma Variável Instrumental Z, que antecede D:\nZ→D←U→YEssa abordagem isola a variação em D que é induzida por Z, &quot;limpando&quot; a influência de U. Para que isso funcione, as seguintes premissas devem ser atendidas:\n\nRelevância: A relação entre o instrumento Z e o tratamento D deve ser forte.\n\nPrática: Regredir Z em D e verificar se o R² e a Estatística F (p-valor) são significativos.\n\nRestrição de Exclusão: O instrumento Z deve afetar o resultado Y apenas através de D, sem caminhos diretos.\n\nExogeneidade (Independência): O instrumento deve ser não correlacionado com o termo de erro ou variáveis omitidas (Cov(Z,U)=0).\n\nMonotonicidade: O instrumento deve afetar o tratamento numa única direção.\n\nA Variável Instrumental (IV) pode ser aplicada em dois contextos principais:\n\nCorreção de Experimentos (RCTs): Para lidar com falhas de adesão (imperfect compliance). Por exemplo, quando Z é a oferta do tratamento e D é o uso efetivo. Nem todos os ofertados usam, mas a oferta (Z) é aleatória.\n\nEstudos Observacionais: Quando não houve randomização e suspeita-se que variáveis de confusão desconhecidas (U) afetem a escolha do tratamento. Aqui, o instrumento funciona como um &quot;experimento natural&quot;, introduzindo uma aleatoriedade na atribuição de D que o pesquisador não pôde controlar manualmente.\n\nO instrumento provoca um choque exógeno na variável D, gerando uma variação no tratamento que é independente das características não observadas U.\nEstágios\nPara calcular o efeito causal via IV, podemos decompor a análise em duas regressões simples e uma divisão.\n\nPrimeiro Estágio (Impacto no Tratamento):\nRegredimos o tratamento D em relação ao instrumento Z.\n\nVerificamos a premissa de Relevância. O coeficiente (π) nos diz o quanto o instrumento aumenta a probabilidade ou intensidade do tratamento.$$D = \\alpha_1 + \\pi Z + e_1$$\n\nForma Reduzida (Intenção de Tratar - ITTE):\nRegredimos o resultado Y diretamente em relação ao instrumento Z, ignorando o tratamento D por enquanto.\n\nComo Z é aleatório/exógeno, esse coeficiente (γ) mostra o efeito causal da atribuição do instrumento sobre o resultado.\n\nY=α2+γZ+e2\n\nCálculo do LATE:\nO efeito causal final (βIV) é a razão entre esses dois coeficientes. Ou seja, ajustamos o efeito total (γ) pela proporção de pessoas que realmente aderiram ao tratamento (π).\náβIV=Efeito de Z em Y (Forma Reduzida)Efeito de Z em D (Primeiro Estágio)=γπ\n\nimport statsmodels.formula.api as smf\n\n# 1. Primeiro Estágio: Efeito de Z em D\n# O coeficiente de Z aqui é a taxa de adesão\nfirst_stage = smf.ols('D ~ Z', data=df).fit()\nden = first_stage.params['Z']\n\n# 2. Forma Reduzida: Efeito de Z em Y\n# O coeficiente de Z aqui é o ITTE\nreduced_form = smf.ols('Y ~ Z', data=df).fit()\nnum = reduced_form.params['Z']\n\n# Cálculo do Wald, ou LATE\nwald_estimator_sm = num / den\n\nprint(f&quot;Numerador (ITTE): {num}&quot;)\nprint(f&quot;Denominador (Compliance): {den}&quot;)\nprint(f&quot;Efeito Causal (Wald): {wald_estimator_sm}&quot;)\n\nMínimos Quadrados em Dois Estágios (2SLS)\nEnquanto o cálculo do LATE via razão é intuitivo para um único instrumento, o método 2SLS permite a inclusão de múltiplas variáveis de controle e múltiplos instrumentos.\n\nPrimeiro Estágio (Purificação de D):\nRegride-se o tratamento D contra o instrumento Z (e demais controles). O objetivo não é analisar o coeficiente, mas sim obter os valores preditos (D^).\nD^=α^+π^Z\n\nSegundo Estágio (Estimação Causal):\nSubstitui-se a variável de tratamento original (D) pelos valores preditos calculados no passo anterior (D^) e realiza-se a regressão do resultado Y sobre essa nova variável.\nY=β0+β2SLSD^+ε\n\nA intuição aqui é a decomposição da variância. A variável de tratamento original D possui dois componentes de variação:\n\nUma parte endógena, correlacionada com U\nUma parte exógena, induzida pelo instrumento Z\n\nAo rodarmos o primeiro estágio e calcularmos D^, estamos isolando apenas a variação em D que é explicada por Z. Como Z é não correlacionado com U, D^ também será independente de U.\nPortanto, o segundo estágio utiliza uma versão &quot;limpa&quot; do tratamento. Ao regredir Y em D^, eliminamos a contaminação do viés de seleção, permitindo que o OLS estime o efeito causal verdadeiro.\nfrom linearmodels.iv import IV2SLS\n\n# Fórmula: Y ~ Controles + [Endogeno ~ Instrumento]\n# O &quot;1&quot; representa a constante (intercepto)\nformula = 'Y ~ 1 + X + [D ~ Z]'\n\nmodel = IV2SLS.from_formula(formula, df)\nresult = model.fit()\n\nprint(result)\n\n[!tip] 2SLS vs. DoubleML (DML)\nO método 2SLS tradicional assume que as relações entre as variáveis de controle (covariáveis) e o resultado são lineares. Caso sejam não lineares, o 2SLS pode falhar em remover todo o viés. É aqui que podemos utilizar o método de Double Machine Learning (DML) com uso de IV.",
		"tags": [ "note"]
},

{
		"title": "12. Double Machine Learning",
		"date":"Sun Jan 04 2026 14:40:44 GMT+0000 (Coordinated Universal Time)",
		"url":"/digital-garden/path-for-the-true-and-brave/text/12-double-machine-learning/",
		"content": "Double Machine Learning\n\nDouble ML: Causal Inference based on ML\nAgora, iremos adentrar um pouco na inferência causal moderna. Relembramos o uso do Teorema FWL para &quot;desviesamento&quot;. Ele demonstra que, em uma regressão linear, podemos &quot;remover&quot; o efeito das covariáveis X através de resíduos e então estimar o efeito de D (tratamento) sobre Y.\nO Double Machine Learning (DML) generaliza essa ideia usando Machine Learning para estimar os componentes que dependem de X e, em seguida, &quot;partializa&quot; (remove a influência de) X em Y e D.\nO método se destaca por quatro pilares fundamentais:\n\nFramework não paramétrico\nPermite usar quaisquer modelo, como Random Forests e Gradient Boosting para modelar as variáveis de confusão (X). Isso captura relações complexas e não-lineares automaticamente.\n\nRedução de viés\nModelos de Machine Learning usam regularização (ex.: Lasso ou profundidade de árvores) para evitar overfitting, o que &quot;encolhe&quot; as previsões, distorcendo as estimativas de efeito causal. O DML resolve isso separando a estimação do ruído da estimação do efeito.\n\nIntervalos de confiança válidos\nÉ matematicamente inviável calcular p-valores precisos diretamente de uma &quot;caixa preta&quot; como uma Rede Neural. O DML transforma o problema final numa regressão linear simples sobre resíduos, permitindo recuperar a teoria estatística clássica para calcular significância estatística.\n\nEficiência\nSignifica que o erro da estimativa diminui rapidamente à medida que a amostra (n) cresce, comportando-se tão bem quanto uma regressão linear simples, mesmo utilizando modelos de ML complexos (que normalmente convergem mais devagar) para limpar os dados.\n\nSua ideia é utilizar dois modelos preditivos separados: um para o potencial outcome e outro para o tratamento. O processo ocorre nos seguintes passos:\n\nEstimar o outcome Y: Usamos um modelo de ML flexível (q(X)) para prever Y com base nas características X.\n\nEstimar o tratamento D: Usamos outro modelo de ML flexível (g(X)) para prever o tratamento D com base nas características X (similar a um Propensity Score).\n\nObtemos os resíduos:\n\nResíduo do outcome: Y~=Y−q^(X)\n\nResíduo do tratamento: D~=D−g^(X)\n\n[!tip] Lembrete\nUtilizamos o resíduo justamente para isolarmos os efeitos exógenos! Queremos apenas saber o Impacto do outcome sob os tratamentos, eliminando as variáveis de confusão.\n\nFazemos a regressão dos resíduos:\nY~=τD~+ϵOnde τ é o parâmetro causal (ATE). Esse processo é feito dinamicamente utilizando Cross-Fitting, que comentarei posteriormente.\n\nRegressão Parcialmente Linear e Ortogonalização\nVamos olhar para a Regressão Parcialmente Linear (PLR).\nAssumimos que o mundo gerador dos dados segue:\nY=Dθ+g(X)+UD=m(X)+VOnde θ é o nosso alvo (efeito causal) e g(X) é uma função complexa e desconhecida dos confoundings.\nSe tentarmos estimar θ diretamente com ML, o erro na estimativa de g(X) contamina θ. A solução é a Ortogonalização:\n\nCalculamos a esperança condicional de Y dado X:\nE[Y|X]=E[D|X]θ+g(X)Chamamos E[Y|X] de Y^ e E[D|X] de D^.\n\nSubtraímos essa esperança da equação original:\nY−E[Y|X]=(D−E[D|X])θ+(g(X)−g(X))+U\n\nNote a mágica: o termo complexo g(X) se cancela! Ficamos apenas com os resíduos:\n(Y−Y^)=(D−D^)θ+UOu seja:\nY~=θD~+U\n\nAgora, o erro na estimativa de g(X) é ortogonal (não correlacionado) ao tratamento residual, permitindo que o OLS isole o θ &quot;limpo&quot;.\n\n[!tip] Premissas Importantes\nÉ fundamental refrisar que esse método não é &quot;bala de prata&quot;. A validade causal ainda depende das premissas anteriores:\n\nIgnorabilidade: Y(d)⊥D|X. Ou seja, todas as variáveis de confusão relevantes foram incluídas em X. É importante refrisarmos isso que é assumido que foi capturando todos os confounders relevantes. Na prática, não temos como saber por exato, mas uma boa construção é importante.\nDomínio sob regra de negócio: Para toda a inferência causal, aqui não muda. Por mais complexo que nosso modelo possa ser, ele sempre será limitado relativo a tomada de decisão às escolhas de variáveis. Um bom DAG construído ainda é necessário, para evitar qualquer viés sob o resultado.\nQualidade de dados: por mais que o DoubleML é focado para estudos observacionais, aonde não controlamos variáveis de confusão e não temos uma randomização controlada, ele ainda pode sofrer com dados ruins. Se a extração tiver algum viés forte, problemas com campos, o resultado dele vai ser ineficiente para estimar causalidade.\nPositividade: Para valores de X relevantes, deve haver variação no tratamento (a probabilidade de tratamento P(D|X) não deve ser nem 0 nem 1 estritos, como também valores extremos).\nRegularidade: Os estimadores de ML devem convergir suficientemente rápido. O uso de Cross-Fitting é crucial para evitar viés de overfitting e garantir a validade assintótica.\n\nO Perigo no Overfitting\nVale ressaltar que a flexibilidade dos modelos de Machine Learning traz o risco de overfitting. Se o modelo entende demais os dados de treino, ele absorve ruídos como se fossem padrões reais, tornando os resíduos enviesados em direção a zero, eliminando a variação necessária para encontrarmos o efeito causal.\nPor conta disso, a prática padrão é utilizar o Cross-Fitting:\n\nSelecionamos K possíveis folds.\nNo K1, separamos os dados por exemplo em &quot;Treino&quot; e &quot;Hold-out&quot;.\nO modelo é treinado apenas na base de Treino, e utilizamos os dados para calcular o resíduo do Hold-Out.\nAgora, retreinamos o modelo com outro K fold, até que todos os dados tenham seus resíduos calculados.\n\nAssim, mesmo que o modelo aprenda nos dados de treino, ele não terá &quot;visto&quot; os dados de hold-out. Isso garante que os resíduos mantenham um ruído real e a variabilidade honesta necessária.\n\nDouble Machine Learning for Causal Inference: A Practical Guide | by Mohamed Hmamouch | Medium\nImplementação Prática: Calculando ATE e CATE com Python\nVamos utilizar a biblioteca DoubleML para aplicar os conceitos acima.\n1. Calculando o ATE\nPara o ATE, assumimos um efeito constante e usamos o modelo Partial Linear Regression (PLR).\nimport numpy as np\nimport pandas as pd\nfrom doubleml import DoubleMLData, DoubleMLPLR\nfrom sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n\n# --- Configuração dos Dados ---\n# Suponha que temos um DataFrame 'df' com:\n# 'y': Outcome, 'd': Tratamento binário, 'X1'...'X5': Covariáveis\ndata_dml = DoubleMLData(df,\ny_col='y',\nd_cols='d',\nx_cols=[f'X{i}' for i in range(5)])\n\n# --- Definindo os Modelos (Learners) ---\n# Modelo para prever Y (Outcome)\nml_l = RandomForestRegressor(n_estimators=100, max_depth=5)\n# Modelo para prever D (Propensity Score)\nml_m = RandomForestClassifier(n_estimators=100, max_depth=5)\n\n# --- Estimando ATE com Cross-Fitting ---\ndml_plr = DoubleMLPLR(data_dml,\nml_l=ml_l,\nml_m=ml_m,\nn_folds=3) # 3-fold Cross-Fitting\n\ndml_plr.fit()\nprint(dml_plr.summary)\n\nO resultado coef no sumário será o nosso τ (ATE), livre do viés das covariáveis.\n2. Calculando o CATE\nSe quisermos saber como o efeito varia de acordo com as características da pessoa (X), usamos o Interactive Regression Model (IRM). Em vez de calcular um número único, projetamos o efeito causal nas covariáveis usando um Preditor Linear (BLP).\nfrom doubleml import DoubleMLIRM\n\n# --- Usando IRM para permitir interações ---\n# ml_g prevê E[Y|X, D] e ml_m prevê E[D|X]\nml_g = RandomForestRegressor(n_estimators=100, max_depth=5)\nml_m = RandomForestClassifier(n_estimators=100, max_depth=5)\n\ndml_irm = DoubleMLIRM(data_dml,\nml_g=ml_g,\nml_m=ml_m,\nn_folds=3)\n\ndml_irm.fit()\n\n# --- Projetando a Heterogeneidade (CATE) ---\n# &quot;Como o efeito causal varia linearmente com as features X?&quot;\ncate_res = dml_irm.cate(basis=df[[f'X{i}' for i in range(5)]])\n\nprint(cate_res)\n\nInterpretando o CATE: Se no resultado do cate_res o coeficiente de uma variável (ex: X1: Idade) for positivo e significante, indica que o tratamento é mais eficaz quanto maior for a idade do indivíduo.\n\n[!tip] Nota\nPLR: Assume que o efeito do tratamento (θ) entra de forma aditiva e linear (não interage complexamente com X na equação estrutural). É ideal para tratamentos contínuos (ex: preço, dosagem).\nIRM: É desenhado especificamente para tratamentos binários. Ele permite interações completas entre o tratamento e as covariáveis, sendo mais robusto para heterogeneidade. Ele utiliza o estimador AIPW (Augmented Inverse Probability Weighting) por trás dos panos, que possui a propriedade de Dupla Robustez (Doubly Robust).\n\nIntroduction to Causal Machine Learning with DoubleML for Python\n3. Calculando o GATE (Group Average Treatment Effect)\nEnquanto o CATE busca o efeito individual (que pode possuir alto ruído estatístico), o GATE busca o efeito médio em um subgrupo específico.\nA biblioteca DoubleML oferece um método dedicado .gate() para cada grupo. Para utilizá-lo, precisamos passar um DataFrame onde as colunas representam os grupos (indicadores binários/dummies).\n\n[!tip] Nota\nPodemos calcular o GATE agregando as estimativas do CATE. Filtramos as unidades que pertencem ao grupo de interesse e tiramos a média dos seus efeitos causais estimados (τ^(x)).\n\nMatematicamente:\nτGATE=E[τ^(x)∣x∈Grupo]# --- Passo 1: Definir os Grupos de Interesse ---\n# Vamos criar, por exemplo, dois grupos baseados na variável X1 (ex: Idade normalizada)\n# Grupo 0: X1 &lt;= 0.5\n# Grupo 1: X1 &gt; 0.5\ngroups = pd.DataFrame({\n'Grupo_Baixo_X1': df['X1'] &lt;= 0.5,\n'Grupo_Alto_X1': df['X1'] &gt; 0.5\n})\n\n# --- Passo 2: Calcular o GATE via DoubleML ---\n# O método gate() ajusta uma regressão linear dos resíduos contra essas variáveis de grupo\ngate_res = dml_irm.gate(groups=groups)\n\nprint(gate_res)\n\n# --- Passo 3: Analisar os Intervalos de Confiança ---\n# Verificamos se o intervalo de 95% cruza o zero ou se os grupos se sobrepõem\nprint(gate_res.confint())\n\nEssa abordagem é poderosa para decisões de negócio estratégicas, onde não podemos personalizar para cada indivíduo, mas podemos criar políticas para segmentos (ex: Região Norte vs. Sul).\n\nCaracterística\nCATE (Conditional Average Treatment Effect)\nGATE (Group Average Treatment Effect)\n\nDefinição\nEfeito do tratamento para um indivíduo (ou unidade) com características exatas X.\nMédia dos efeitos de tratamento para um subgrupo específico da população.\n\nNível de Granularidade\nMicro (Individual / Personalizado).\nMacro (Segmento / Cluster).\n\nNotação Matemática\nτ(x)=E[Y(1)−Y(0)∣X=x]\nτGATE=E[τ(x)∣x∈Grupo]\n\nPergunta de Negócio\n&quot;Qual desconto devo dar para este cliente específico agora?&quot;\n&quot;A campanha funciona melhor na Região Sul ou na Região Norte?&quot;\n\nEstabilidade Estatística\nBaixa. Sofre com alta variância e ruído, pois n=1 (ou muito pequeno) para aquele X.\nAlta. O ruído individual tende a se cancelar na média do grupo, gerando estimativas mais robustas.\n\nNo DoubleML\nResultado da projeção do efeito nas features (via dml_irm.cate() ou BLP).\nCalculado tirando a média das predições do CATE filtradas por um subconjunto do DataFrame.\n\nAplicação Principal\nPersonalização de produto, Medicina de precisão, Recomendação dinâmica.\nDefinição de estratégia, Política pública, Decisão de portfólio.\n\nDoubleML com Variáveis Instrumentais (IV)\nDiferente do DoubleML padrão (que limpa X apenas de Y e D), no cenário com Variável Instrumental nós precisamos limpar a influência das covariáveis (X) de três lugares: do Resultado (Y), do Tratamento (D) e do Instrumento (Z).\nSimulando o DoubleMLPIV para ter uma ideia, o processo envolve 3 modelos de Machine Learning e uma regressão IV 2SLS final.\nPremissas\n\nY depende de X,D,U.\nD depende de X,Z,U.\nZ depende de X\n\n1. Previsão\nPrimeiro, usamos ML para prever Y, D e Z usando apenas as covariáveis X. O objetivo é capturar toda a variação explicada por variáveis de confusão.\n\nModelo 1 (q(X)): Prever Y usando X.\nModelo 2 (m(X)): Prever D usando X.\nModelo 3 (r(X)): Prever Z usando X.\n\n2. Ortogonalização Tripla\nSubtraímos as previsões dos valores reais.\n\nY~=Y−Y^ML (Variação no outcome não explicada por X)\nD~=D−D^ML (Variação no tratamento não explicada por X)\nZ~=Z−Z^ML (Variação no instrumento não explicada por X)\n\n3. Estágio Final (2SLS nos Resíduos)\nUsamos os resíduos do instrumento (Z~) para instrumentar os resíduos do tratamento (D~) e explicar os resíduos do resultado (Y~).\nimport numpy as np\nimport pandas as pd\nimport statsmodels.api as sm\nfrom sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n\n# --- 1. Gerando Dados Fictícios (Endógenos) ---\nnp.random.seed(42)\nn = 1000\n# X afeta tudo (confusão)\nX = np.random.normal(0, 1, (n, 3))\n# Z (instrumento) afeta D, mas também depende de X\nZ = 0.5*X[:,0] + np.random.normal(0, 1, n)\n# U (não observado) afeta D e Y\nU = np.random.normal(0, 1, n)\n# D (tratamento) depende de X, Z e U (viés)\nD = 0.5*Z + 0.5*X[:,0] + U + np.random.normal(0, 0.5, n)\n# Y (outcome) depende de D, X e U. Efeito real de D é 2.0\nY = 2.0*D + X[:,0] + U + np.random.normal(0, 0.5, n)\n\ndf = pd.DataFrame({'Y': Y, 'D': D, 'Z': Z})\nX_cols = pd.DataFrame(X, columns=['X1', 'X2', 'X3'])\n\n# --- 2. Fase de Machine Learning ---\n# Treinamos modelos para capturar a influência de X em Y, D e Z\n\n# a) Prever Y dado X\nmodel_y = RandomForestRegressor(max_depth=5).fit(X_cols, df['Y'])\ny_hat = model_y.predict(X_cols)\ny_res = df['Y'] - y_hat # Resíduo Y (Ortogonalizado)\n\n# b) Prever D dado X\nmodel_d = RandomForestRegressor(max_depth=5).fit(X_cols, df['D'])\nd_hat = model_d.predict(X_cols)\nd_res = df['D'] - d_hat # Resíduo D (Ortogonalizado)\n\n# c) Prever Z dado X (Essencial para DoubleMLPIV!)\nmodel_z = RandomForestRegressor(max_depth=5).fit(X_cols, df['Z'])\nz_hat = model_z.predict(X_cols)\nz_res = df['Z'] - z_hat # Resíduo Z (Ortogonalizado)\n\n# --- 3. 2SLS clássico ---\n# y_res ~ beta * d_res (instrumentado por z_res)\n\n# 1º Estágio Manual: Regredir d_res contra z_res\nstage1 = sm.OLS(d_res, sm.add_constant(z_res)).fit()\nd_res_hat = stage1.predict() # Variação de D limpa de X e induzida por Z limpo\n\n# 2º Estágio Manual: Regredir y_res contra o predito do 1º estágio\nstage2 = sm.OLS(y_res, sm.add_constant(d_res_hat)).fit()",
		"tags": [ "note"]
},

{
		"title": "13. GenAI",
		"date":"Sun Jan 04 2026 14:40:44 GMT+0000 (Coordinated Universal Time)",
		"url":"/digital-garden/path-for-the-true-and-brave/text/13-gen-ai/",
		"content": "GenAI\nÉ importante salientar alguns pontos. Modelos de Large Language Models (LLMs) não capturam, por si só, relações de causalidade. Há desafios conhecidos de reasoning em modelos não determinísticos e, para inferência causal, esses modelos não substituem os conceitos e frameworks consolidados da econometria.\nAinda assim, LLMs podem ser usados como ferramenta de suporte, como por exemplo, para gerar hipóteses, explorar possíveis variáveis instrumentais ou identificar potenciais confundidores — porém sempre com muita cautela. O artigo Mining Causality: AI-Assisted Search for Instrumental Variables propõe um agente que auxilia na busca por variáveis instrumentais por meio de etapas de prompt e validações. Outra alternativa que complementa essa abordagem é a biblioteca PyWhyLLM, que ajuda a encontrar relações (IVs, confundidores) que conectam tratamento ao desfecho, como também o Causal LLM Agent.\nEssas ferramentas não devem ser usadas para terceirizar decisões nem para substituir conhecimento de domínio ou regras de negócio. Seu uso exige criticidade, documentação cuidadosa e submissão à revisão por pares humanos. A interpretação dos resultados e a atribuição de efeitos causais devem ser feitas por pesquisadores qualificados. Lembre-se interpretações equivocadas são responsabilidade dos autores — como comentado por Fisher. Quanto maior for o impacto ou a criticidade do trabalho, mais rigorosas devem ser as análises.\n\n[!tip] Causal Reasoning\nCaso tenha interesse para linhas de pesquisa voltado a Large Language Models (LLM), sugiro observar o trabalho de Zhijing Jing, sua linha de pesquisa é voltada a este tema.",
		"tags": [ "note"]
},

{
		"title": "14. Boas Práticas",
		"date":"Sun Jan 04 2026 14:40:44 GMT+0000 (Coordinated Universal Time)",
		"url":"/digital-garden/path-for-the-true-and-brave/text/14-boas-praticas/",
		"content": "Boas Práticas\nUm artigo útil para orientar um projeto end‑to‑end é Causal machine learning for predicting treatment outcomes. A fim de facilitar para identificar qual abordagem utilizar também, criei um infográfico dinâmico.\n\n[!tip] Exploração Experimental\nCaso seja adepto ao uso de ferramentas de GenAI, pode-se utilizar o PyWhyLLM como um assistente para exploração, como também o Causal LLM Agent.\n\nEquívocos\nEmbora possamos utilizar os mesmos algoritmos de previsão para uma análise causal, as abordagens divergem em termos de objetivos e interpretação. Modelos causais exigem maior maturidade teórica para identificar o efeito de uma intervenção.\nIrei deixar aqui alguns pontos de equívocos que podem surgir durante um percurso de construção de modelo. Alguns, podem parecer óbvio, mas sempre bom deixar descrito para não esquecermos.\n1. Assumir causalidade em dados observacionais sem critério\nObservações empíricas que mostram associação entre duas variáveis não permitem, por si só, concluir causalidade. A associação pode ser fruto de confusão, causalidade reversa ou mera coincidência.\n\nExemplo: As vendas de sorvete e o número de afogamentos aumentam simultaneamente; a temperatura (variável omitida) é a causa comum de ambos.\nComo evitar: Sempre observe a construção do DAG, procure fontes de variação plausivelmente exógenas, use desenho experimental quando possível, e declare explicitamente as premissas necessárias para qualquer interpretação causal.\n\n2. Acreditar que a Randomização resolve todos os problemas\nEnsaios aleatorizados reduzem vieses de seleção na atribuição do tratamento, mas não* garantem validade externa automática, ausência de vieses de medição, ou ausência de não‑compliance, perdas de seguimento e efeitos indiretos.\n\nExemplo: Um experimento onde muitos participantes do grupo de tratamento desistem (attrition) gera estimativas enviesadas.\nComo evitar: Monitore a adesão e perdas de seguimento; considere estimadores como Variáveis Instrumentais para lidar com a não-conformidade.\n\n3. Controlar o máximo de variáveis possível\nDiferente do mundo preditivo, onde &quot;mais dados costumam ser melhor&quot;, na causalidade, incluir certas variáveis pode introduzir viés. Controlar mediadores ou colisores pode distorcer o efeito real.\n\nPonto Chave: Um alto R2 ou poder preditivo não implica poder causal. Incluir um colisor pode gerar uma correlação espúria onde não existe causalidade.\nComo evitar: Utilize o critério de Backdoor no seu DAG para decidir quais variáveis devem (e quais não podem) ser controladas.\n\n4. Substituir o pensamento causal por modelos complexos\nModelos de Machine Learning altamente flexíveis podem prever o outcome com precisão, mas não explicam o que aconteceria sob uma intervenção. A complexidade do algoritmo não valida a suposição causal.\n\nComo evitar: Combine ML com frameworks causais (como Double Machine Learning), documente as premissas e realize análises de sensibilidade.\n\n5. Ignorar a Heterogeneidade do Efeito\nAssumir que o efeito causal é o mesmo para todos os indivíduos (homogeneidade) pode mascarar resultados importantes.\n\nExemplo: Um desconto que aumenta as vendas para jovens, mas reduz o valor da marca para clientes premium.\nComo evitar: Estime efeitos heterogêneos (CATE - Conditional Average Treatment Effect) e discuta os limites da generalização dos resultados.\n\n6. Tratar o P-valor como prova de causalidade\nA significância estatística quantifica apenas a incerteza amostral sob um modelo específico; ela não valida suas suposições causais. Um efeito estatisticamente significativo (p&lt;0,05) não elimina explicações alternativas, como variáveis de confusão ou viés de seleção.\n\nO Trade-off: Isso está ligado ao equilíbrio entre Viés e Variância, que comentei anteriormente. Um modelo pode ter variância baixa (estimativas precisas/p-valor baixo), mas estar altamente enviesado por não considerar a estrutura causal correta.\nMagnitude vs. Significância: Um tamanho de efeito grande ou um alto nível de significância não garantem benefícios práticos ou validade causal. Em grandes bases de dados (Big Data), quase qualquer correlação irrelevante pode se tornar &quot;estatisticamente significativa&quot;, mesmo sem qualquer sentido causal. Uma variável com alto poder causal pode apresentar um p-valor alto (não significante) se a amostra for pequena ou a variância for elevada. Não confunda precisão estatística com relevância causal.\n\nComo evitar:\n\nFoque na magnitude do efeito e nos Intervalos de Confiança, que mostram a incerteza de forma mais transparente.\nPriorize a robustez do desenho do estudo em vez da busca por p-valores baixos.\nCombine a evidência estatística com argumentos teóricos e testes de sensibilidade.",
		"tags": [ "note"]
},

{
		"title": "2. Predição & Inferência Causal",
		"date":"Sun Jan 04 2026 14:40:44 GMT+0000 (Coordinated Universal Time)",
		"url":"/digital-garden/path-for-the-true-and-brave/text/2-predicao-and-inferencia-causal/",
		"content": "Predição &amp; Inferência Causal\nModelagem preditiva e inferência causal possuem propósitos distintos. Enquanto modelos de Machine Learning focam em estimar um outcome futuro (como a probabilidade de churn), a inferência causal busca entender os resultados potenciais de uma intervenção (como o quanto uma promoção evitaria esse churn).\nÉ crucial distinguir essas abordagens: prever a probabilidade de um evento não é o mesmo que saber como alterá-lo. A predição prioriza a precisão da estimativa baseada em associações. Já a causalidade foca no mecanismo e na relação entre variáveis, sendo essencial para quantificar o impacto de tratamentos e guiar decisões estratégicas. Em outras palavras e exemplificando por regressão linear, um focamos no R2 e outro na estimativa do β que não esteja enviesada.\n\n[!Note] Leitura Recomendada\nA note about R-squared - Robson Tigre\n\nAlém disso, a inferência causal permite observar efeitos heterogêneos, ou seja, como o impacto de um tratamento varia entre diferentes subgrupos. Isso possibilita uma personalização mais eficiente, direcionando intervenções para onde elas trazem maiores benefícios, conforme escrevi em <a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/digital-garden/path-for-the-true-and-brave/text/10-efeitos-heterogeneos/\">10. Efeitos Heterogêneos</a>.\n\n[!tip] Comparação\nPredição: otimiza acurácia. Boa para segmentação, detecção de anomalias e priorização (ex.: identificar clientes em risco).\nInferência causal: estima efeitos de intervenções e responde “o que acontece se eu fizer X?”. Essencial para tomar decisões que mudam o mundo.\n\nMixtape Sessions: Foundation of Causality\n\n[!tip] Citação\nI always try to explain managers that they need Causal Machine Learning by saying, &quot;well you have correlation and here you want more causation and these are your technical problems and maybe it never really worked.&quot;\nI've been testing that for a couple of years. My current way is to simply explain it with like a crystal ball: Does a manager really want to have one crystal ball telling what the future will be like?\nA manager wants to change the future, so they don't want a crystal ball, rather they want to have crystal balls. One for decision A, the second for decision B and then they can look into the future how certain decisions will improve outcomes and they can pick the decision that works best for their company. - Stefan Feuerriegel",
		"tags": [ "note"]
},

{
		"title": "3. Teorias da Causalidade",
		"date":"Sun Jan 04 2026 14:40:44 GMT+0000 (Coordinated Universal Time)",
		"url":"/digital-garden/path-for-the-true-and-brave/text/3-teorias-da-causalidade/",
		"content": "Teorias da Causalidade\nA causalidade é um conceito complexo, abordado por pensadores como Aristóteles, David Hume, e Kant, com contribuições mais recentes de economistas como Angus Deaton e estatísticos. Em diversas áreas, há uma variabilidade de definições dela.\nPara o contexto da estatística e da modelagem de dados, a abordagem mais relevante é a Causalidade Regular (diferente da Causalidade Estrita de Descartes, que se baseia em leis naturais). A Causalidade Regular foca em eventos probabilísticos em vez de determinísticos, dando um foco grande em probabilidade condicional. Essa linha de pensamento foi inicialmente influenciada por ideias de Hans Reichenbach e John Stuart Mill, evoluindo para o que é hoje reconhecido como a moderna teoria da inferência causal, impulsionada por Judea Pearl e seu trabalho com Modelos Gráficos Acíclicos Direcionados (DAGs). Outros nomes, como Susan Haack e Deborah Mayo, também trouxeram contribuições importantes para a filosofia da causalidade e da estatística.\nNeste modelo, a causalidade é definida por três aspectos principais:\n\nDirecionalidade: A relação de causa e efeito é estruturada graficamente, indicando que o evento A causa o evento B (A→B).\nTemporalidade: A causalidade é expressa em termos de probabilidades condicionais – a probabilidade de um evento, dado que o outro já ocorreu. No entanto, o conceito estatístico fundamental aqui é a probabilidade de a causa A ocorrer, dado o efeito B, se e somente se A for a causa. Em termos de probabilidades condicionais, o que é crucial é a comparação entre P(B|A) e P(B|¬A) (a probabilidade do efeito B ocorrer na presença da causa A versus na sua ausência).\nReprodutibilidade (ou Invariância): Para ser considerada causal, a relação observada entre os eventos deve ser invariante, ou seja, consistentemente reproduzida sob as mesmas condições e em diferentes contextos relevantes.\n\n[!tip] Nota\nA Independência Condicional é a chave da inferência causal. Ela permite distinguir relações causais genuínas de simples associações estatísticas, identificando se a relação entre dois eventos desaparece ao condicionar uma terceira variável (a variável de confusão).\n\n[!tip] Nota\nAs variáveis de confusão (ou variáveis confundidoras, ou confounders) são variáveis que exercem influência tanto na causa quanto no efeito em estudo.\nÉ crucial identificar e controlar essas variáveis, pois a sua presença afeta diretamente a validade da inferência causal, levando a estimativas enviesadas do verdadeiro efeito, causando o que chamamos de associação espúria.\n\nDefinição de Causalidade, Causação e Associação\nComo falei, existe uma definição ampla sobre causalidade, a qual varia conforme a área de atuação. Essa pluralidade de conceitos é bem representada no artigo The Representation of Causality and Causation with Ontologies: A Systematic Literature Review, que demonstra como as definições mudam ao longo da literatura. Para o escopo probabilístico em que atuaremos, adotaremos uma perspectiva mais próxima à de Judea Pearl.\nCausalidade é a relação direcional de causa e efeito entre entidades, variáveis ou eventos. Já a causação refere-se ao mecanismo ou ação pela qual a causa produz o efeito. Ambos os conceitos envolvem direcionalidade, temporalidade e influência — a ideia de que um elemento efetivamente gera uma alteração no outro.\nEm contraste, a associação é a mera relação estatística entre duas variáveis. É fundamental não confundirmos com causalidade. Por definição, a associação pode incluir vieses, enquanto a causação busca isolar relações diretas. Assim, duas variáveis podem não ter influência direta entre si, mas parecerem relacionadas por serem influenciadas por uma variável externa não mapeada (lembremos da relação espúria). Nesses casos, há associação, mas não há nexo causal direto.\n\n[!tip] Citação\nCausal inference is the science of inferring causation from association and understanding when and why they differ. - Matheus Facure\n\nProblema Fundamental da Inferência Causal\nO Problema Fundamental da Inferência Causal reside na impossibilidade de observar simultaneamente, na mesma unidade, o resultado factual e o resultado contrafactual .\nPara quantificar o efeito causal de um tratamento, seria necessário calcular a diferença entre esses dois resultados. No entanto, uma única unidade (seja um indivíduo, evento ou variável) só pode existir em um único estado (tratado ou não tratado) em um dado momento.\nEm essência, a quantificação exata exigiria um universo paralelo onde a unidade pudesse ser observada em condições idênticas, mas sob estados de tratamento opostos. Dado que isso é logisticamente impossível, o problema é considerado o obstáculo central da inferência causal.\nDefinição Formal\nPara formalizar a causalidade, utilizamos a notação de Resultados Potenciais, fundamental para o entendimento do que constitui um efeito causal versus uma associação.\n1. Notação Básica\nAntes de equacionar o problema, definimos as variáveis para uma unidade i:\n\nDi: A variável de tratamento (Binária: 1 se tratado, 0 se controle).\nYi: O outcome observado (o que realmente aconteceu).\nY1i: O potencial outcome se a unidade tivesse sido tratada.\nY0i: O potencial outcome se a unidade não tivesse sido tratada.\n\n[!tip] A Realidade Observada\nDevido ao Problema Fundamental da Inferência Causal, nós observamos apenas um dos estados. O resultado observado é definido como:\nYi=DiY1i+(1−Di)Y0i\n2. Decomposição\nA equação fundamental é:\nçãçéE[Y|D=1]−E[Y|D=0]⏟Associação (Diferença Observada)=E[Y1−Y0|D=1]⏟ATT (Efeito Causal)+{E[Y0|D=1]−E[Y0|D=0]}⏟ViésATT (Average Treatment Effect on the Treated)\nRepresenta o efeito causal para o grupo que foi tratado. É a diferença entre o que aconteceu com eles (Y1) e o que teria acontecido se eles não tivessem sido tratados (Y0, o contrafactual).\n\nViés:\nEste é o termo crítico. Ele compara o estado basal (Y0) dos dois grupos.E[Y0|D=1]−E[Y0|D=0]Em outras palavras: &quot;Mesmo sem o tratamento, o grupo tratado já seria diferente do grupo de controle?&quot;. Se esse termo for diferente de zero, temos um viés.\n\n3. Identificação Causal (Exchangeability)\nPara que a Associação seja igual à Causalidade, o termo de Viés deve ser nulo. Isso ocorre quando:\nE[Y0|D=1]=E[Y0|D=0]Significa que o resultado do grupo de controle (Y0|D=0) é um substituto perfeito para o contrafactual do grupo tratado (Y0|D=1). Em termos práticos, os grupos devem ser comparáveis antes do tratamento.\n\n[!tip] Exemplo Intuitivo\nImagine testar um remédio em um hospital (D=1) versus pessoas na rua (D=0).\n\nAssociação: As pessoas no hospital têm saúde pior (Y) que as da rua.\nViés: O grupo tratado (T=1) já teria uma saúde basal (Y0) pior, mesmo sem remédio.\nConclusão: E[Y0|D=1]≠E[Y0|D=0]. O viés de seleção é negativo, mascarando o possível efeito positivo do remédio.\n\nMastering Mostly Harmless Econometrics - Part 1",
		"tags": [ "note"]
},

{
		"title": "4. Escada da Causação",
		"date":"Sun Jan 04 2026 14:40:44 GMT+0000 (Coordinated Universal Time)",
		"url":"/digital-garden/path-for-the-true-and-brave/text/4-escada-da-causacao/",
		"content": "Escada da Causação\nA escada da causação é uma definição de Judea Pearl que organiza três níveis de raciocínio sobre dados e efeitos. Cada degrau responde a tipos distintos de perguntas e demanda métodos/assunções diferentes.\n1. Primeiro Degrau: Associação\nAssociação é o degrau mais básico da escada da causalidade. Trata-se de detectar padrões e regularidades a partir de observações: “A e B tendem a ocorrer juntos” ou “quando X aumenta, Y costuma aumentar/diminuir”. Ela é a forma mais primitiva que temos disso. Como falei, é algo que por padrão, fazemos no nosso dia a dia. É a área do observacional. Pense como uma coruja observando o movimento de um rato: ela não precisa entender a anatomia do rato, apenas associar o ruído na mata ao alimento. Da mesma forma, nossos ancestrais aprenderam que certos cogumelos são venenosos; se quem comeu anteriormente veio a falecer, associamos o consumo à morte.\n2. Segundo Degrau: Intervenção\nA intervenção vai além da observação passiva; ela envolve a manipulação ativa de variáveis para observar resultados. É o nível dos experimentos controlados (Testes A/B). Por exemplo:\n\nUm gerente perguntando &quot;O que acontecerá com nossas vendas de fio dental se dobrarmos o preço da pasta de dente?&quot;\nTomar aspirina para curar dor de cabeça - intervindo na quantidade de aspirina para afetar o status da dor\nDefinir preços para vender excesso de estoque\n\nA intervenção é superior à associação porque envolve não apenas observar, mas mudar o que existe. Ver fumaça nos conta uma história completamente diferente sobre a probabilidade de fogo do que fazer fumaça. Não podemos responder questões sobre intervenções apenas com dados coletados passivamente, não importa o tamanho do conjunto de dados ou a profundidade da rede neural.\n3. Terceiro Degrau: Contrafactuais\nSe a Associação é sobre ver e a Intervenção é sobre fazer, o Contrafactual é sobre imaginar. Este é o topo da escada e a característica que nos define como seres humanos. Ele lida com o &quot;e se?&quot;: a capacidade de olhar para o passado, comparar o que aconteceu com o que poderia ter ocorrido sob condições diferentes, e extrair uma lição de causalidade profunda disso.\nDiferente dos degraus anteriores, o contrafactual (o que teria ocorrido se o tratamento não tivesse sido aplicado) não pode ser respondido apenas com dados atuais ou experimentos presentes, pois o evento (o que ocorreu com o tratamento) já passou. Exemplos:\n\nMedicina e Saúde: &quot;O paciente faleceu. Será que ele teria sobrevivido se tivéssemos administrado o antibiótico duas horas antes?&quot;\n\nMarketing e E-commerce: &quot;Tivemos 1.000 vendas nesta campanha. Quantas vendas teríamos feito se não tivéssemos oferecido o cupom de desconto?&quot;\n\nSegurança Pública: &quot;A criminalidade caiu após a instalação de novas câmeras. Ela teria caído da mesma forma se a taxa de desemprego não tivesse diminuído no mesmo período?&quot;\n\nJustiça e Ética: &quot;O réu foi condenado por negligência. Ele teria evitado o acidente se tivesse feito a manutenção dos freios?&quot;",
		"tags": [ "note"]
},

{
		"title": "5. Design de Experimentos",
		"date":"Sun Jan 04 2026 14:40:44 GMT+0000 (Coordinated Universal Time)",
		"url":"/digital-garden/path-for-the-true-and-brave/text/5-design-de-experimentos/",
		"content": "Design de Experimentos\nNa introdução ao seu trabalho The Design of Experiments, Ronald Fisher demonstrou preocupação com a falta de clareza e rigor metodológico em experimentos. Ele notou que a ausência de um design experimental robusto poderia levar a:\n\nDificuldade de Interpretação: O leitor e, por vezes, o próprio cientista, poderiam ter interpretações diferentes sobre os resultados, levando a conclusões não suportadas pelos dados ou que poderiam ter ocorrido por acaso (chance), mesmo que a hipótese fosse falsa.\nCarência Estrutural (Design): Falhas lógicas e estruturais tornam o experimento fundamentalmente incorreto, muitas vezes devido a controles inadequados ou à ausência de uma comparação válida.\n\nExperimentos mal projetados resultam em desperdício de recursos (tempo e dinheiro) e em decisões estratégicas equivocadas. Em um cenário de tomada de decisão, é imprescindível sermos cautelosos e rigorosos para manter o controle sobre a inferência.\nFisher propôs um método para trazer facilidade e confiança à experimentação, baseando-se em três pilares:\n\nRandomização: Garante que características não observáveis se distribuam igualmente entre os grupos, eliminando viés de seleção.\n\nControle: Isola o efeito do tratamento de fatores externos (ruído).\n\nReplicação: Reduz o erro experimental e aumenta a precisão da estimativa.\n\nExperimentos Aleatorizados\nPara contornar o Problema Fundamental da Inferência Causal, suprir a carência de design de experimentos e controlar o viés de variável omitida, recorre-se a métodos de pesquisa como o Experimento Aleatorizado.\nO experimento aleatorizado, ou ensaio clínico randomizado (RCT), é um procedimento no qual as unidades de uma amostra populacional são alocadas de forma aleatória (randomizada) ao grupo de tratamento ou ao grupo de controle.\nA randomização é crucial, pois:\n\nElimina vieses de seleção e confusão.\nCria grupos estatisticamente comparáveis (balanceados).\n\nAo garantir que a única diferença sistemática esperada entre os grupos seja a aplicação do tratamento, a randomização permite que a diferença observacional nos resultados seja interpretada como uma estimativa válida do efeito causal médio do tratamento na população.\n\n[!tip] Lembre-se: O Conceito do Contrafactual\nAo criarmos dois grupos estatisticamente idênticos na média, o grupo de controle representa uma foto do &quot;futuro que não aconteceu&quot; para o grupo tratado. Isso torna plausível responder a perguntas contrafactuais: &quot;O que teria acontecido se não tivéssemos aplicado a mudança?&quot;\n\nLecture 3 – The Magic of Randomized Control Trials\n\nLecture 3 – The Magic of Randomized Control Trials\n\n[!note] Leitura Recomendada\nThe impact of computer usage on academic performance: Evidence from a randomized trial at the United States Military Academy.\n\nPremissas\nMolak, em conversa com Thanos Vlontzos enfatiza que nunca nos livramos totalmente das premissas. Todo modelo, causal ou não, repousa sobre suposições; o objetivo não é eliminá‑las, mas escolher aquelas com as quais podemos conviver e torná‑las explícitas. Segundo ele, o problema não é ter premissas iniciais, e sim esquecê‑las: uma suposição negligenciada pode fazer um projeto parecer perfeito na superfície, mas esconder uma &quot;mancha enorme&quot; que, mais tarde, causará problemas. Isso vale tanto para estudos experimentais quanto especialmente para estudos observacionais. As premissas que devemos respeitar são:\n\nSUTVA (Stable Unit Treatment Value Assumption)\n- Consistência: O tratamento é bem definido; o outcome observado para uma unidade sob o tratamento D é igual ao resultado potencial Y(D).\n- Sem interferência: O tratamento de uma unidade não afeta o resultado de outra (sem spillovers/efeitos indiretos).\nIgnorabilidade / Unconfoundedness / Exchangeability\n- Os resultados potenciais são independentes da atribuição do tratamento, condicional às covariáveis observadas: {Y(0),Y(1)}⊥D|X. Em RCTs ideais, a randomização garante ignorabilidade por definição.\nPositividade / Overlap\n- Para todo valor de X considerado, há probabilidade estritamente positiva de receber cada condição: 0&lt;P(T=1|X)&lt;1. Sem positividade, não é possível comparar contrafactuais em certas subpopulações.\nControle de confundidores\n- Em estudos observacionais: Medir e ajustar os confundidores (regressão, propensity scores, IPW, etc.).\n- Em RCTs: Projetar estratificação quando necessário para garantir balanceamento e ajustar para covariáveis na análise para melhorar a precisão (redução de variância).\nAmeaças pós-randomização\n- Não-adesão (noncompliance), perda amostral diferencial (attrition), contaminação e mediadores induzidos pelo tratamento podem reintroduzir viés de seleção.\n\nPontos de Atenção\n\nValidade Interna:\n\nDefinição: Refere-se à confiança de que o efeito observado no resultado é causado unicamente pela manipulação do tratamento (variável independente) e não por fatores externos, vieses ou erros de condução. Um experimento tem alta validade interna se pudermos afirmar com certeza que o tratamento causou a mudança no resultado.\nAmeaças: Seleção dos participantes, mudanças naturais ao longo do tempo, eventos externos durante o experimento e mortalidade/perda amostral.\n\nValidação Externa: Trata-se da capacidade de generalizar os resultados do experimento para a população mais ampla ou para outros ambientes e contextos. Se os resultados só se aplicam à amostra específica estudada, a validade externa é baixa.\n\nAmeaças: Interação entre seleção e tratamento (o efeito só existe no grupo específico selecionado) e efeitos de laboratório (condições artificiais que não refletem o mundo real).\n\nValidade de Construto\n\nDefinição: Refere-se à adequação das medidas. Garante que as variáveis operacionais (como você mede ou manipula algo) realmente representam os construtos teóricos (os conceitos abstratos estudados).\nEm outras palavras: É a certeza de que o experimento está medindo aquilo que se propôs a medir.\nPonto de Atenção:\n\nDeve-se garantir que as métricas realmente capturem a essência dos conceitos (ex: satisfação do cliente, motivação).\nAmeaças Comuns:\n\nSub-representação do Construto: A métrica é incompleta e não captura a totalidade do conceito.\nVariância de Métodos Irrelevantes: A medição é contaminada por fatores alheios ao conceito de interesse.\n\nEfeito Spillover (Violação da SUTVA):\n\nOcorre quando o tratamento aplicado ao Grupo de Tratamento afeta, indiretamente, o Grupo de Controle (ou vice-versa). O tratamento &quot;vaza&quot; ou a informação/benefício se espalha.\n\nExemplos:\n\nUm participante do controle aprende sobre a nova funcionalidade com um amigo do tratamento.\nUm participante do grupo de controle aprende sobre a nova funcionalidade com um amigo do grupo de tratamento (contaminação).\nA mudança de preço em uma loja (tratamento) altera a demanda de uma loja vizinha (controle).\nEm experimentos geográficos, a intervenção em uma área afeta a área contígua.\n\nImplicação: Se houver spillover, o grupo de controle deixa de ser uma linha de base pura, comprometendo a validade interna. A estimativa do efeito será enviesada.\nMitigação: Usar clusters/agrupamentos distantes (geográfica ou socialmente) ou implementar cegamento rigoroso.\n\nElementos do Poder Estatístico\n\nNo contexto de estudos experimentai, ainda estaremos trabalhando com testes de hipóteses, pois de fato estamos atuando com cenários nas quais queremos estudar. Isto implica que estamos ainda sujeitos a cometer erros estatísticos ao tomar uma decisão sobre a hipótese nula H0.\nErros do Tipo I e Tipo II\n\nErro do Tipo I (Falso Positivo):\nOcorre quando rejeitamos a H0 quando ela é, na verdade, verdadeira. A probabilidade de cometer um Erro Tipo I é controlada pelo nível de significância α. Comumente o valor de α é utilizado em 0,05, o que significa que aceitamos 5% de chance de concluir erroneamente que há um efeito.\nNeste contexto, seria concluir que o tratamento teve um efeito quando, na realidade, a diferença observada foi devida puramente ao acaso.\nErro do Tipo II (Falso Negativo):\nOcorre quando falhamos em rejeitar a H0 quando ela é, na verdade, falsa. A probabilidade de cometer um Erro Tipo II é controlado pelo poder de teste, 1−β.\nNeste contexto, seria concluir que o tratamento não teve um efeito (ou que não houve diferença significativa) quando, na realidade, ele teve um efeito real na população.\nAnálise de Poder Estatístico\nÉ fundamental que façamos uma análise do poder, pois permite determinar o tamanho de amostra necessário para detectar um efeito de determinado tamanho com uma probabilidade aceitável. Os quatro termos inter-relacionados nesta análise são:\n\nTamanho da Amostra: O número de observações incluídas no estudo. Um aumento na amostra geralmente aumenta o Poder do Teste.\n\nNível de Significância α: Se for diminuído (ex: de 0,05 para 0,01), a chance de um Falso Positivo diminui, mas a exigência para rejeitar H0 é maior, o que, por sua vez, diminuindo a sensibilidade do Poder do Teste (aumentando β).\n\nPoder do Teste (1−β): O poder de teste é a sensibilidade do estudo. Geralmente, o poder do teste é fixado em 0,80 (ou 80%), o que significa que se um efeito real existir, o estudo tem 80% de chance de detectá-lo.\n\nTamanho do Efeito (Effect Size - Cohen’s D) ou Efeito Mínimo Detectável (Minimum Detectable Effect - MDE): O Tamanho do Efeito é a magnitude da diferença ou relacionamento de interesse na população. O MDE é o menor tamanho de efeito que o estudo está equipado para detectar com as configurações de amostra, nível de significância e Poder do teste.\n\nRelação com o MDE:\n\nSe o MDE for muito alto (ex: 15%), o estudo é muito &quot;grosseiro&quot; e pode falhar em detectar efeitos menores, mas clinicamente ou economicamente relevantes (ex: 2%), resultando em um aumento da probabilidade do Erro Tipo II.\nPara reduzir o MDE e, assim, aumentar a sensibilidade do estudo a efeitos menores, é necessário **aumentar o Tamanho da Amostra N.\n\nO MDE não deve ser um número arbitrário; ele deve ser o menor efeito que é economicamente ou clinicamente relevante para a sua área. A Análise de Poder a Priori deve usar este MDE junto com o Poder e o Alpha para calcular o tamanho de amostra mínimo necessário. Se o tamanho da amostra for inviável para o MDE de interesse, o estudo deve ser repensado.\n\n[!tip] Nota\nSegundo Ron Kovahi, se o MDE for menor que 5%, dificilmente você irá detectá-lo com confiança, junto ao fato da quantidade de amostras necessárias para verificar. O ideal será entre 5% a 10%.\n\nElementos fundamentais do desenho experimental\n\n[!note] Leitura Recomendada\nFormulating a well-defined causal question - Robson Tigre\n\nPara responder a uma pergunta de pesquisa com objetivo causal, é imperativo definir, de forma precisa e mensurável, os componentes estruturais do estudo. A ausência de definições rigorosas torna a inferência ambígua e sujeita a interpretações contraditórias.\n1. Tratamento (Di)\nRefere-se à intervenção ou exposição que está sendo investigada.\n\nDefinição Operacional: Descreva exatamente o que constitui &quot;receber o tratamento&quot;. Evite ambiguidades. Por exemplo, em vez de &quot;receber um cupom&quot;, especifique &quot;receber um cupom de 10% de desconto via e-mail às 09:00&quot;.\n\nEscopo e Intensidade: O tratamento é binário (D∈{0,1}), contínuo (ex: dose de um medicamento) ou multivalorado (ex: variações A/B/C)?\n\nConsistência e SUTVA: A definição deve ser clara o suficiente para garantir que não existam múltiplas versões ocultas do tratamento que afetem o resultado de formas diferentes, violando SUTVA. Se duas pessoas recebem Di=1, elas devem ter recebido essencialmente a mesma intervenção.\n\n2. Potenciais Outcomes (Yi(0),Yi(1))\nOs potenciais outcomes representam os resultados teóricos que a unidade i apresentaria sob cada condição de tratamento.\n\nMensurabilidade: Como o outcome observado Yi será coletado? Temos dados confiáveis para mensurar o estado contrafactual, seja via desenho experimental (RCT) ou métodos observacionais?\n\nDefinição da Métrica: Especifique a métrica exata e a janela temporal.\n\nExemplo: &quot;Conversão&quot; é vago. &quot;Compra confirmada (Y&gt;0) no período de 7 dias após a exposição&quot; é preciso.\n\nTransformações: Defina previamente se usará a métrica bruta, logaritmo, ou taxas.\n\nValidade de Construto: A métrica escolhida realmente representa o conceito que queremos estudar? Uma definição robusta minimiza o erro de medição e garante que estamos capturando o fenômeno de interesse.\n\n3. Unidade de Observação (Ui)\nDefine a entidade fundamental sobre a qual o tratamento é aplicado e o desfecho é medido.\n\nNível de Agregação: Quem é a unidade experimental? Um usuário individual, uma sessão de navegador, uma loja física ou um município?\n\nAlinhamento Tratamento-Unidade: É crucial verificar se a unidade de análise coincide com a unidade de randomização/tratamento.\n\nInterferência: A escolha da unidade afeta a probabilidade de interferência entre unidades? É preciso observar para não violar a SUTVA.\n\nValidade Externa: As características das unidades observadas na amostra permitem generalizar os resultados para a população-alvo?\n\n4. Estimand (O parâmetro de interesse)\nO Estimand é a quantidade teórica exata que queremos estimar. Ele guia todo o desenho do estudo e o cálculo do tamanho da amostra.\n\nDefinição do Parâmetro: O que queremos descobrir?\n\nATE (Average Treatment Effect): O efeito médio para toda a população. E[Y(1)−Y(0)].\n\nATT (Average Treatment Effect on the Treated): O efeito médio apenas para quem de fato recebeu o tratamento.\n\nCATE (Conditional Average Treatment Effect): O efeito médio para um subgrupo específico (heterogeneidade).\n\nMecanismo de Atribuição\n\n[!tip] Citação\nI think it's wrong to think any causality comes only in the modeling part. It comes in the entire system building process:\n\nFrom the data collection (thinking about which parameters come into play);\nObviously the data modeling;\nAnd then to actually making it robust and serving it to the End Customer.\n\nSo this is, for example, a very crucial point: Gathering correct data, especially in the medical field, is extremely hard and extremely crucial. - Thanos Vlontzos\n\nO mecanismo de atribuição é o processo (conhecido ou desconhecido) que determina quais unidades recebem o tratamento e quais recebem o controle. Formalmente, ele descreve a lei de probabilidade condicional P(W|X,Y(0),Y(1)) que governa a alocação do tratamento W.\nEm um RCT, este mecanismo é controlado e conhecido (ex: moeda, sorteio). Em estudos observacionais, ele é desconhecido e precisa ser estimado. Essa estimativa é justamente o cálculo da probabilidade de receber o tratamento P(W=1|X), valor que chamamos de Escore de Propensão, ao qual nos permite rebalancear os grupos e validar se as premissas de identificação foram respeitadas.\nProblemas com Experimentos Aleatorizados\nEm um RCT, os participantes são distribuídos aleatoriamente para o grupo de tratamento ou controle. Essa randomização visa equilibrar todas as variáveis de confusão (tanto as conhecidas quanto as desconhecidas) entre os grupos, permitindo que qualquer diferença observada no resultado seja atribuída, com alta confiança, à intervenção (causa).\nEmbora seja o padrão de ouro na metodologia experimental, ele não oferece uma garantia absoluta de causalidade, pois a randomização inicial é apenas o primeiro passo. A causalidade pode ser comprometida por vieses pós-randomização que surgem durante a execução do estudo. Problemas como a desigualdade de características entre os participantes, perda ou até abandono podem prejudicar o resultado para uma generalização dos resultados.\nAlém das limitações metodológicas na condução do estudo, o RCT é inviável ou antiético em inúmeros cenários de pesquisa causal. Existem fenômenos de interesse (como o efeito de eventos raros, exposições de longuíssimo prazo, ou variáveis não manipuláveis, como o status socioeconômico) onde a aleatoriedade é inatingível. Mais gravemente, a randomização é antiética em exposições que são sabidamente prejudiciais. Por exemplo, seria moralmente inaceitável randomizar uma população para forçar um grupo a fumar a fim de analisar as chances de câncer de pulmão.\nPortanto, em contextos onde a intervenção não pode ser controlada por um RCT devido a impedimentos éticos ou práticos, os pesquisadores devem recorrer a outras ferramentas, como também é possível aplicar outros tipos de amostragens.\n\n[!note] Leitura Recomendada\nHow to run experiments that actually answer your questions - Robson Tigre",
		"tags": [ "note"]
},

{
		"title": "6. DAG",
		"date":"Sun Jan 04 2026 14:40:44 GMT+0000 (Coordinated Universal Time)",
		"url":"/digital-garden/path-for-the-true-and-brave/text/6-dag/",
		"content": "DAG\nO Modelo Gráfico Acíclico Direcionado (DAG) é uma ferramenta visual e matemática essencial na moderna teoria da inferência causal, especialmente em contextos observacionais onde experimentos são inviáveis ou antiéticos. Seu propósito principal é tornar explícitas as suposições causais: identificar caminhos que geram confusão, indicar quais variáveis devem ser ajustadas e orientar estratégias de identificação, como caminhos backdoor.\nFundamentos Estruturais\n\nNós (Variáveis): Cada nó no gráfico representa uma variável aleatória. A estrutura do DAG é definida com base na Independência Condicional entre as variáveis, que é o conceito-chave da moderna inferência causal. Ele permite traduzir as relações causais em restrições estatísticas testáveis. Na teoria dos conjuntos, o conceito de Probabilidade Condicional P(B|A) – que define a relação entre conjuntos de eventos – é análogo algebricamente a correlação parcial r(X,Y)Z que é usada em algoritmos de aprendizado de estrutura causal, como o Inductive Causality.\nArestas (Relações →): As setas indicam a direcionalidade da causalidade. A→B significa que A é uma causa direta de B. O DAG representa a Causalidade Regular, focada em graus mensuráveis (gradação) de causalidade, diferentemente da Causalidade Estrita (classificação 0 ou 1).\nAciclicidade (Não Cíclico): É a regra fundamental. Não pode haver um ciclo fechado (por exemplo, A→B e B→A). Isso impõe uma ordem temporal e causal clara, garantindo que o modelo seja computável para inferência.\n\nObjetivos\n\nVisualizar caminhos entre tratamento D e desfecho Y: o DAG expõe todos os caminhos (causais e não causais) que conectam D e Y, permitindo identificar fontes potenciais de viés.\n\nIdentificação de variáveis de confusão: Conseguir localizar variáveis que são causas tanto de D quanto de Y e, portanto, que precisam ser consideradas ao estimar o efeito causal.\n\nAplicar o critério do backdoor: ele fornece uma regra gráfica para encontrar conjuntos de variáveis que, se condicionados, bloqueiam todos os caminhos não causais entre D e Y, permitindo identificar o efeito causal de D em Y.\n\nUm caminho backdoor é um caminho entre D e Y que começa com uma seta apontando para D (exemplo: D←V→Y). Se esse caminho não for bloqueado, ele causa viés de confounding.\nAo controlar (condicionar) a variável V neste exemplo, o caminho traseiro é bloqueado, e a associação restante entre D e Y pode ser interpretada como o efeito causal de D em Y.\n\n[!tip] Nota\nIdentificação Causal via Backdoor: O objetivo do ajuste de backdoor é simular uma intervenção física (o operador do(x)) usando apenas dados observacionais. Ao bloquear os caminhos backdoor, eliminamos a &quot;contaminação&quot; das associações espúrias, permitindo que a correlação restante seja interpretada como o efeito causal puro, aproximando o estudo observacional dos resultados de um Experimento Controlado Aleatorizado (RCT).\n\nEm essência, enquanto o RCT tenta eliminar os vieses por meio da randomização no design do estudo, o DAG ajuda a identificar e bloquear os confoundings por meio de ajustes na análise dos dados observacionais.\nD-Separação\nA d‑separação é o critério gráfico que determina se um conjunto Z bloqueia todos os caminhos entre X e Y, implicando X⊥⊥Y|Z. Regras essenciais sobre bloqueio de um caminho:\n\nCadeia, garfo ou causa comum (X→V→Y ou X←V→Y): o caminho é bloqueado se o nó intermediário (B) estiver condicionado.\nUm colisor ou efeito comum (X→V←Y): o caminho é bloqueado se o colisor B NÃO for condicionado; condicionar o colisor (ou um de seus descendentes) abre o caminho (isto é, cria dependência).\n\nSe todo caminho entre X e Y for bloqueado por Z, então X e Y são d‑separados por Z no gráfico.\n\n[!tip] Exemplo\nA afirmação de que X e Y são d-separados por Z - X⊥⊥Y|Z - é testada em dados usando correlação parcial ou independência condicional. A correlação parcial entre X e Y dado Z, ρXY⋅Z, representa a correlação entre os resíduos de uma regressão de X em Z e os resíduos de uma regressão de Y em Z. Um valor próximo de zero para ρXY⋅Z corrobora a independência e, portanto, a d-separação.\nUma explicação de correlação parcial pode ser vista via Mastering Mostly Harmless Econometrics - Part 2 a partir de 1:08:30.\n\nEstatística Psicobio II 2024 #24 - DAG II Directed Acyclic Graphs - d' separation; algoritmo PC e IC\n\nTermos de Classificação\n\nEstatística Psicobio II 2024 #25 - DAG III - Aplicações do DAG, Propensity Scores e diff-n-diff\nEm um DAG, as variáveis podem ser caracterizadas pela sua posição relativa à Exposição e ao Desfecho. Abaixo os tipos mais relevantes e as ações práticas recomendadas.\nTipos de Variáveis\n\nConfundidor (confusão)\nUm ancestral tanto da exposição quanto do desfecho.\n\nCria um caminho não causal entre X e Y, distorcendo o verdadeiro efeito de X sobre Y.\nAção: É uma variável que devemos condicionar para fechar o caminho de confusão e obter uma estimativa não enviesada do efeito causal.\nEstrutura: X←V→Y\n\nMediador\nUm descendente da Exposição e um antecedente do Desfecho.\n\nFunção: Explica o mecanismo pelo qual X afeta Y, estando no caminho causal de interesse.\nAção: Não devemos condicionar a variável mediadora se nosso objetivo é estimar o efeito total de X sobre Y. Condicionar V nos daria apenas o efeito direto de X sobre Y.\nEstrutura: X→V→Y\n\nColisor\n\nUm descendente tanto da Exposição quanto do Desfecho\nFunção: Por si só, não cria viés. O viés é induzid apenas quando condicionamos (incluímos na análise) o Colisor.\nAção: Não devemos condicionar o colisor. Condicionar um Colisor abre um caminho de viés, levando ao fenômeno chamado viés de seleção ou viés do colisor.\nEstrutura: X→V←Y",
		"tags": ["24", "25", "note"]
},

{
		"title": "7. Regressão Linear",
		"date":"Sun Jan 04 2026 14:40:44 GMT+0000 (Coordinated Universal Time)",
		"url":"/digital-garden/path-for-the-true-and-brave/text/7-regressao-linear/",
		"content": "Regressão Linear\n\n[!note] Leitura Recomendada\nLinear regression: our go-to tool - Robson Tigre.\n\nOs modelos de regressão linear são ferramentas fundamentais na inferência causal. Utilizando o método dos Mínimos Quadrados Ordinários (MQO), é possível estimar parâmetros que, sob as suposições corretas de identificação, possuem uma interpretação causal direta.\nConsiderando uma relação linear simples Y∼X+ε, estimamos o efeito de X sobre Y através dos coeficientes β^0 e β^1.\n1. O Intercepto (β^0)\nO coeficiente β^0 representa o valor esperado de Y quando X=0 (assumindo que todas as outras covariáveis do modelo também sejam zero).\n\nPonto de Atenção: Essa interpretação matemática só possui valor prático se X=0 for um cenário plausível ou observado nos dados (ex: idade = 0 pode não fazer sentido em certas análises laborais).\n\n[!tip] Interpretação em Experimentos\nEm estudos com grupos de Controle e Tratamento (onde X é uma dummy indicando o tratamento), β^0 representa a média do grupo de controle. Consequentemente, β^1 captura a diferença média entre os grupos (efeito do tratamento).\n\n2. O Coeficiente de Interesse (β^1)\nO coeficiente β^1 isola a variação média esperada em Y dada uma alteração em X, mantendo constantes as demais variáveis do modelo (ceteris paribus). A interpretação varia conforme a natureza de X:\n\nSe X for contínua: β^1 é a variação média em Y associada a um aumento de uma unidade em X.\n\nSe X for binária (Dummy de Tratamento): β^1 é interpretado como o Efeito Médio do Tratamento (ATE ou ATT, dependendo da população condicionada).\n\n[!tip] Variáveis Categóricas e Dummies\nPara utilizar dados categóricos (strings ou categorias numéricas) em uma regressão, é necessário transformá-los em variáveis binárias (Dummies).\n\nImplementação:\n\nPandas: Utilize pd.get_dummies(df, columns=['Var'], drop_first=True).\n\nStatsmodels: Na fórmula, basta envolver a variável com C(): outcome ~ C(Variavel).\n\nAtenção (Armadilha da Dummy): Para uma variável com N categorias, devemos criar apenas N−1 colunas de dummies. Se incluirmos todas as N colunas junto com o intercepto, criamos multicolinearidade perfeita (redundância).\n\nInterpretação: A categoria omitida torna-se a Categoria de Referência. Os coeficientes das outras dummies representam a diferença média em relação a essa categoria base (quando todas as dummies são 0).\n\n3. Termo de Interação\nMuitas vezes, a suposição de que o efeito de X sobre Y é constante para todos é muito forte. Para capturar como o efeito varia dependendo de uma terceira variável Z, incluímos um termo de interação (produto) no modelo:\nY=β0+β1X+β2Z+β3(X⋅Z)+εNeste modelo, o efeito de X sobre Y não é mais apenas β1. O efeito marginal de X passa a depender do valor de Z:\nΔYΔX=β1+β3ZA interpretação dos coeficientes muda:\n\nβ1 (Efeito Principal de X): Representa o efeito de X sobre Y apenas quando Z=0. Não é mais o efeito médio global.\n\nβ3 (Coeficiente de Interação): Representa o quanto o efeito de X muda para cada unidade adicional de Z.\n\nSe Z for uma variável binária (ex: Z=1 para Mulheres, Z=0 para Homens) e X for o tratamento, então β3 é a diferença de efeito do tratamento entre mulheres e homens, por exemplo.\n\n[!TIP] Lembrete\nAo incluir uma interação X⋅Z, sempre inclua as variáveis originais X e Z no modelo separadamente. Omitir β1 ou β2 força o intercepto ou a inclinação a passar pela origem de forma artificial, enviesando a estimativa da interação.\n\nO Trade-off entre Viés e Variância\n\n[!Note] Leitura Recomendada\nCausal Inference in Python: Applying Causal Inference — Part II, Cap. Frisch-Waugh-Lovell Theorem and Orthogonalization, pág. 106\n\nCondicionar covariáveis irrelevantes ou em excesso no modelo pode introduzir um risco: o aumento da variância do estimador de β^1.\nO aumento na variância ocorre frequentemente devido à multicolinearidade e significa que as estimativas de β^1 serão menos precisas. Isso resulta em intervalos de confiança mais amplo, tornando mais difícil rejeitar a hipótese nula e obter um resultado estatisticamente significativo.\nTeorema Frisch‑Waugh‑Lovell\nOutra forma de observamos isso, é entendermos melhor o funcionamento do teorema Teorema Frisch-Waugh-Lovell (FWL).\nEle demonstra que o coeficiente de X em uma regressão múltipla Y ~ X + Z é igual ao coeficiente obtido ao regressar os resíduos de Y sobre Z nos resíduos de X sobre Z. Em termos práticos, isso significa que a contribuição de cada regressora pode ser entendida como a associação entre as partes de Y e X que não são explicadas por Z. Isto pode ser dividido em três etapas\n\nDesviesamento (Debiasing Step)\n\nRemover o viés das variáveis de controle Z da sua variável de interesse X.\nRegredimos a variável de tratamento X nas covariáveis de controle Z, (ex: X∼Z)\nColetamos os resíduos dessa regressão X~. Estes resíduos representam a parte de X que é ortogonal (não correlacionada) aos controles Z.\n\nRemoção de Ruído (Denoising Step)\n\nRemover o ruído das variáveis de controle Z da sua variável dependente Y.\nRegredimos a variável dependente Y nas mesmas covariáveis de controle Z, (ex: Y∼Z)\nColetamos os resíduos dessa regressão Y~. Estes resíduos representam a parte de Y que é independente dos controles Z.\n\nRegressão Final\n\nA estimativa final do efeito causal β^1 é obtida regredindo o resíduo da variável dependente no resíduo da variável de tratamento: Y~∼X~.\nO β^ obtido nesta regressão de resíduos é idêntico ao β^1 da regressão original Y∼X+Z.\n\nPara ver exemplos via código, é só acessar aqui.\n\n[!tip] Lembrete\nA regressão linear assume que a relação entre as regressoras e o resultado (condicional) é linear. Se a relação verdadeira for não linear, a especificação linear pode provocar viés de especificação. É importante verificar se isso ocorre, especialmente entre a variável de tratamento e o desfecho; caso ocorra, podemos aplicar transformações adequadas, por exemplo: logaritmos, termos polinomiais, interações ou transformações multiplicativas.\n\nRegressão Linear como Modelo para Potenciais Outcome\nOutra possibilidade de utilizar a regressão linear, é atuar como um modelo de imputação de potenciais resultados. Isto quer dizer que conseguimos estimar os efeitos causais, seja ATE ou ATT, preechendo valores contrafactuais.\nA lógica reside na capacidade da regressão de modelar as funções de resultado potencial:E[Y0|X] e E[Y1|X].\nEfeito de Tratamento Médio (ATE)\n\n[!tip] Lembrete\nO ATE é calculado como a diferença média entre o que toda a população teria se fosse tratada E^[Y1|Xi] e o que toda a população teria se não fosse tratada E^[Y0|Xi]\n\nATE=1N∑i(E^[Y1|Xi]−E^[Y0|Xi])\n\nOnde E^[Y0|Xi] e E^[Y1|Xi] são modelos de regressão ajustados, respectivamente, nas unidades de controle T=0 e nas unidades tratadas T=1.\n\nCálculo Simplificado com statsmodels\nEm um modelo de regressão linear que inclui covariáveis X, o estimador do ATE é equivalente ao coeficiente da variável de tratamento D.\nSe o seu modelo é Y=β0+β1D+β2X+ϵ, a estimativa de β^1 é o ATE.\nPython\nformula_ate = 'Y ~ D + X1 + X2'\nmodel_ate = smf.ols(formula_ate, data=data).fit()\nate_estimate = model_ate.params['D']\n\nEfeito Médio de Tratamento nos Tratados (ATT)\n\n[!tip] Lembrete\nO ATT é a diferença média entre o resultado observado para o grupo tratado Yi e o seu resultado contrafactual imputado E^[Y0|Xi]\nATT=1N1∑i:Di=1(Yi−E^[Y0|Xi])\nIsto significa que usamos o grupo de controle D=0 para construir o modelo que prevê o resultado potencial Y0.\n\nCálculo Simplificado com statsmodels\nmodel_mu0 = smf.ols('Y ~ X1 + X2', data=data[data['D'] == 0]).fit()\nimputed_y0 = model_mu0.predict(data[data['D'] == 1]) # Imputar o contrafactual, isto é, usar model_mu0 para prever o Y_0 para as unidades do grupo tratado T=1.\natt_estimate = (data[data['D'] == 1]['Y'] - imputed_y0).mean()",
		"tags": [ "note"]
},

{
		"title": "8. Viés",
		"date":"Sun Jan 04 2026 14:40:44 GMT+0000 (Coordinated Universal Time)",
		"url":"/digital-garden/path-for-the-true-and-brave/text/8-vies/",
		"content": "Viés\nO viés ocorre porque a variável de confusão cria uma associação espúria (falsa) entre o Tratamento (a Causa, A) e o Resultado (o Efeito, B). Isso acontece quando o Tratamento e o Resultado compartilham uma causa comum (a variável de confusão, C).\nEm outras palavras, a variável de confusão (C) influencia:\n\nA probabilidade de receber o Tratamento (C→A).\nO Resultado de interesse (C→B).\n\nGraficamente, a relação espúria é representada no DAG (Modelo Gráfico Acíclico Direcionado) como um caminho backdoor: A←C→B\nSem controlar adequadamente (ajustar ou condicionar) essa variável, a nossa estimativa do efeito de A em B incluirá o efeito indireto de C em B, fazendo parecer que A tem um efeito maior (ou menor) do que realmente tem.\n\n[!note] Leitura Recomendada\nA Crash Course in Good and Bad Controls\n\nViés de seleção\nSurge quando a amostra analisada não representa fielmente a população de interesse, devido a um critério de seleção (implícito ou explícito) que correlaciona a probabilidade de receber o Tratamento com o próprio Resultado. Esse fenômeno pode ocorrer tanto na etapa de coleta de dados quanto na divisão dos grupos, comprometendo a validade interna e externa das estimativas. Por essa razão, é fundamental dedicar atenção ao <a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/digital-garden/path-for-the-true-and-brave/text/5-design-de-experimentos/\">5. Design de Experimentos</a> e ao mecanismo de atribuição, garantindo que o processo de entrada no estudo não introduza correlações artificiais que invalidem a inferência causal.\nExemplos\n\nAutoseleção: Quando o indivíduo decide se quer participar ou não do tratamento. Pessoas que se voluntariam para um programa de treinamento profissional podem ser mais motivadas do que as que não se voluntariam. Se a &quot;motivação&quot; afeta o salário final, comparar voluntários com não-voluntários enviesará o efeito do treinamento.\n\nViés de Atrito: Comum em estudos longitudinais. Se os participantes que abandonam o estudo são sistematicamente diferentes dos que ficam (ex: em um teste de medicamento, os que sentem muitos efeitos colaterais desistem), a análise final será feita apenas sobre os &quot;sobreviventes&quot;, distorcendo o efeito real.\n\nTruncamento Incidental: Ocorre quando observamos o resultado Y apenas para uma subamostra selecionada. O exemplo clássico é a &quot;Equação de Salários de Heckman&quot;: só observamos o salário de quem decide trabalhar. Se a decisão de trabalhar estiver correlacionada com habilidades não observadas, a média salarial da amostra não representa a média da população.\n\nFormalização\nPara que a estimativa do efeito causal seja válida, precisamos que a atribuição do tratamento seja independente dos resultados potenciais (Independência). O viés de seleção quebra essa premissa:\n(Y1,Y0)⊥̸D∣S=1Onde S=1 indica que o indivíduo faz parte da amostra observada. Isso implica que:\n\nE[Y0|D=1,S=1]≠E[Y0|D=0,S=1]\n\nOu seja, mesmo na ausência do tratamento, o grupo que foi &quot;selecionado&quot; para o tratamento teria um desempenho diferente do grupo de controle devido a características inerentes à seleção.\nViés de variável omitida (OVB) &amp; Endogeneidade\n\n[!note] Leitura Recomendada\nThe anatomy of omitted variable bias - Robson Tigre\n\nA Endogeneidade ocorre quando uma variável explicativa em um modelo de regressão é correlacionada com o termo de erro (ϵ).\nO OVB é uma das formas mais frequentes de endogeneidade. Ele surge quando omitimos do modelo uma variável Xomitida que deveria estar presente. Para que essa omissão gere viés no coeficiente da variável de tratamento D, duas condições devem ser atendidas simultaneamente:\n\nRelevância para o Outcome: A variável omitida deve ser um determinante de Y.\n\nCorrelação com o Tratamento: A variável omitida deve estar correlacionada com a variável de tratamento D.\n\nImpacto no Modelo\nQuando essas condições são atendidas, o efeito da variável omitida é &quot;capturado&quot; pelo termo de erro, tornando-o correlacionado com o tratamento. Matematicamente, o viés pode ser expressado como:\nBias=βomitida⋅δDXOnde βomitida é o efeito da variável omitida sobre Y, e δDX resulta da regressão da variável omitida contra o tratamento. Como consequência, o estimador de MQO torna-se viesado e inconsistente, falhando em capturar o verdadeiro efeito causal.\n\n[!tip] Nota\nUma análise rápida de verificar uma variável de confusão sob isso é durante a análise exploratória utilizando pairplot da biblioteca Seaborn.\nNela, conseguiremos ver se há uma correlação forte das covariáveis com o tratamento.\nsns.pairplot(data[[&quot;T&quot;, &quot;C1&quot;, &quot;C2&quot;, &quot;C3&quot;]], diag_kind=&quot;hist&quot;)\n\nDerivação do Estimador de Mínimos Quadrados Ordinários (MQO)\nModelo verdadeiro Y=β0+β1X1+β2X2+u, onde E[u]=0 e Cov(u,X1)=Cov(u,X2)=0\nSuponha que estimemos por MQO apenas Y sobre X1 (isto é, omitimos X2). O estimador de MQO para o coeficiente de X1 na regressão simples é α1=Cov(Y,X1)Var(X1).\nSubstituindo o modelo verdadeiro em Cov(Y,X1): Cov(Y,X1)=Cov(β0+β1X1+β2X2+u,X1)=β1Var(X1)+β2Cov(X2,X1)+Cov(u,X1)\nAssumindo (Cov(u,X1)=0), temos: α1=β1+β2Cov(X2,X1)Var(X1)\nPortanto, o valor esperado do estimador é E[α1]=β1+β2Cov(X2,X1)Var(X1).\nO termo adicional β2Cov(X2,X1)Var(X1) é o viés por omissão. Ele será diferente de zero sempre que:\n\nβ2≠0 (ou seja, X2 afeta Y) e\nCov(X2,X1)≠0 (ou seja, X2 está correlacionada com X1).\n\nEm outras palavras: se X2 é relevante para Y e está correlacionada com X1, então ao omiti-la o efeito de X2 é parcialmente atribuído a X1, enviesando α1.\n\n[!tip] Exemplo\nPodemos ver uma representação de OVB e como avaliar variáveis de controle em uma regressão a partir da aula ministrada em Mastering Mostly Harmless Econometrics - Part 2, a partir de 01:14:00.",
		"tags": [ "note"]
},

{
		"title": "9. Escore de Propensão",
		"date":"Sun Jan 04 2026 14:40:44 GMT+0000 (Coordinated Universal Time)",
		"url":"/digital-garden/path-for-the-true-and-brave/text/9-escore-de-propensao/",
		"content": "Escore de Propensão\nEm inferência causal distinguimos dois cenários: estudos experimentais, nos quais o pesquisador controla o mecanismo de atribuição - por exemplo, usando RCT - e conhece as probabilidades de receber o tratamento; e estudos observacionais, nos quais a alocação não é controlada e pode haver vieses por confusão. Em estudos observacionais precisamos, de certa forma, “simular” a randomização para reduzir vieses decorrentes de diferenças nas covariáveis pré‑tratamento entre tratados e controles.\nA definição formal é:\ne(X)=P(D=1|X)Onde D é a variável de tratamento e X covariáveis.\nAo condicionarmos nas covariáveis, o escore de propensão controla as variáveis de confusão, ajudando a alcançarmos a independência condicional — o tratamento D torna-se independente do resultado potencial, desde que se condicione no escore de propensão, ⟂Y(0),Y(1)⟂D|e(X).\n\n[!tip] Cenários comuns\n\nViés de Seleção: Pessoas que escolhem receber um tratamento são fundamentalmente diferentes daquelas que não o recebem.\n\nExemplo: Indivíduos mais saudáveis ou mais ricos podem ter maior acesso ou propensão a um novo medicamento.\n\nNoncompliance: Mesmo em ensaios clínicos, se houver falta de adesão total ao tratamento, o efeito causal (como o ATE ou ATT) calculado diretamente pode estar enviesado, comprometendo os resultados e sua interpretabilidade.\n\n[!tip] Nota\nO conceito do Escore de Propensão é estritamente aplicado a tratamentos binários (discretizados ou dicotômicos: Sim/Não). Para tratamentos contínuos, um método utilizado é o Generalized Propensity Score (GPS), aonde modela envolta a densidade condicional, ao invés da probabilidade condicional.\n\nImportante destacar, que ainda sim, precisamos que as premissas de ignorabilidade, positividade e SUTVA devem ser respeitadas antes de aplicar. Relembrando que comentei sobre esse tema em <a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/digital-garden/path-for-the-true-and-brave/text/5-design-de-experimentos/\">5. Design de Experimentos</a>.\nPara utilizarmos o score de propensão, basta regredirmos a intervenção com suas covariáveis em modelo probabilístico, como a regressão logística. Seu resultado, final, seria a probabilidade de uma unidade receber o tratamento condicional dado às covariáveis pré‑tratamento X.\nExemplo (Causal Inference in Python: Applying Causal Inference in the Tech Industry\nimport statsmodels.formula.api as smf\n\n# 1. Estimar o Escore de Propensão\nps_model = smf.logit(&quot;&quot;&quot;intervention ~\ntenure + last_engagement_score + department_score\n+ C(n_of_reports) + C(gender) + C(role)&quot;&quot;&quot;, data=df).fit(disp=0)\n\n# 2. Adicionar o Escore de Propensão como nova coluna\ndata_ps = df.assign(\npropensity_score = ps_model.predict(df),\n)\n\ndata_ps[[&quot;intervention&quot;, &quot;engagement_score&quot;, &quot;propensity_score&quot;]].head()\n\n# 3. Estimar o Efeito Causal usando o Escore de Propensão como covariável\nmodel = smf.ols(&quot;engagement_score ~ intervention + propensity_score&quot;,\ndata=data_ps).fit()\n\n# O coeficiente 'intervention' neste modelo representa o ATE ajustado pelo escore de propensão\nprint(&quot;ATE Ajustado por Escore de Propensão:&quot;, model.params[&quot;intervention&quot;])\n\nPonderação por Escore de Propensão Inverso\nUma vez tendo esse score, podemos estimar o efeito médio de tratamento. Uma das formas que podemos é por Ponderação por Score de Propensão Inverso (IPW).\nA ideia de IPW é reponderar a sua amostra para criar uma pseudo-população onde a distribuição das variáveis de confusão X é a mesma nos grupos de tratamento D=1 e controle D=0. Isto imita as condições de um ensaio aleatório. O peso W atribuído a cada indivíduo é o inverso da probabilidade de o indivíduo ter recebido o tratamento que realmente recebeu. Essa probabilidade é o Escore de Propensão e^(x). Utilizando desta forma, estimamos um ATE em uma população observacional e você quiser criar uma pseudo‑população em que o tratamento é independente das covariáveis observadas.\n\n[!tip] Exemplo\nUnidades Incomuns (Alto Peso):\n\nUnidades que receberam um tratamento improvável (e.g., alto risco de rotatividade, mas não receberam o treino) recebem um peso alto.\n\nIsso os torna mais representativos da população em geral, essencialmente forçando um balanceamento da amostra.\n\nUnidades Comuns (Baixo Peso):\n\nUnidades que receberam um tratamento provável recebem um peso baixo.\n\nO peso para cada unidade Wi é calculado da seguinte forma, onde Di é o tratamento real recebido:\nWi=1P(Di|Xi)={1e^(xi)se Di=111−e^(xi)se Di=0\n[!tip] Nota\nAo dar um peso alto a unidades tratadas que parecem unidades de controle, e unidades de controle que parecem unidades tratadas, o método garante que o grupo de tratamento e o grupo de controle na pseudo-população sejam comparáveis.\n\nExemplo (Causal Inference in Python: Applying Causal Inference in the Tech Industry\néééEfeito Causal=(Média ponderada do resultadose todos fossem tratados)−(Média ponderada do resultadose ninguém fosse tratado)# 1. Calcular os pesos IPW para cada grupo\nweight_t = 1 / data_ps.query(&quot;intervention == 1&quot;)[&quot;propensity_score&quot;]\nweight_nt = 1 / (1 - data_ps.query(&quot;intervention == 0&quot;)[&quot;propensity_score&quot;])\n\n# 2. Obter os resultados (engagement_score) por grupo\nt1 = data_ps.query(&quot;intervention == 1&quot;)[&quot;engagement_score&quot;]\nt0 = data_ps.query(&quot;intervention == 0&quot;)[&quot;engagement_score&quot;]\n\n# 3. Estimar o Resultado Potencial Médio (E[Y^t])\ny1_num = sum(t1 * weight_t) # Numerador: Somatório (Y * W) para T=1\ny1_den = sum(weight_t) # Denominador: Somatório (W) para T=1\ny1 = y1_num / y1_den\n\ny0_num = sum(t0 * weight_nt) # Numerador: Somatório (Y * W) para T=0\ny0_den = sum(weight_nt) # Denominador: Somatório (W) para T=0\ny0 = y0_num / y0_den\n\nprint(&quot;E[Y1] (Tratado):&quot;, y1)\nprint(&quot;E[Y0] (Controle):&quot;, y0)\nprint(&quot;ATE:&quot;, y1 - y0)\n\nEstimativa Duplamente Robusta\nO Escore de Propensão e(X) e a Ponderação por Escore de Propensão Inverso (IPW) são ferramentas para controlar variáveis de confusão e simular a randomização em dados observacionais. O IPW, em particular, é um estimador baseado em design que se foca em balancear os grupos.\nEntretanto, uma preocupação comum em inferência causal é a especificação incorreta dos modelos. E se o modelo que usamos para calcular o Escore de Propensão estiver errado? Isso nos leva à busca por estimadores mais resilientes.\nO Conceito &quot;Duplamente Robusto&quot;\nUm estimador é considerado Duplamente Robusto (Double Robust - DR) se a estimativa do efeito causal for consistente (ou seja, convergirá para o verdadeiro efeito causal) se:\n\nO modelo para o Escore de Propensão estiver corretamente especificado.\nOU\nO modelo para o outcome potencial que estima estiver corretamente especificado.\n\nEm outras palavras, o estimador DR converge para o modelo que estiver correto. Isso confere uma vantagem e aumenta a confiança na estimativa final, pois você só precisa acertar em um dos dois modelos. A ideia central é que o estimador utiliza ambos os modelos - por exemplo, IPW + Regressão Logística - para construir um estimador para o resultado potencial.\nUm estimador DR popular para o resultado potencial médio sob tratamento pode ser escrito como:\nμtDR(μ^,e^)=1N∑i=1N[μ^t(Xi)+Di−e^(Xi)e^(Xi)(Yi−μ^t(Xi))]Onde:\n\nYi é o resultado observado.\nDi é a variável de tratamento.\nμ^t(Xi) é a previsão do resultado Y pelo modelo, assumindo o tratamento t\ne^(Xi) é o Escore de Propensão.\n\nSe o Escore de Propensão estiver correto:\nO termo Di−e^(Xi)e^(Xi) tenderá a zero na média, e o segundo termo todo se anulará.\nIsto deixa apenas o primeiro termo, 1N∑i=1Nμ^t(Xi), que converge para a estimativa do resultado do modelo. Neste caso, a estimativa DR se comporta como um estimador design-based.\nSe o modelo estiver correto:\nO segundo termo, (Yi−μ^t(Xi)), tenderá a zero na média, pois μ^t(Xi) é uma previsão precisa de Yi.\nA estimativa DR converge para um estimador outcome-based que se baseia primariamente no modelo.",
		"tags": [ "note"]
},

{
		"title": "Inferência Causal",
		"date":"Sun Jan 04 2026 14:40:44 GMT+0000 (Coordinated Universal Time)",
		"url":"/digital-garden/path-for-the-true-and-brave/text/inferencia-causal/",
		"content": "<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/digital-garden/path-for-the-true-and-brave/text/0-roadmap/\">0. Roadmap</a>\n<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/digital-garden/path-for-the-true-and-brave/text/1-introducao/\">1. Introdução</a>\n<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/digital-garden/path-for-the-true-and-brave/text/2-predicao-and-inferencia-causal/\">2. Predição &amp; Inferência Causal</a>\n<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/digital-garden/path-for-the-true-and-brave/text/3-teorias-da-causalidade/\">3. Teorias da Causalidade</a>\n<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/digital-garden/path-for-the-true-and-brave/text/4-escada-da-causacao/\">4. Escada da Causação</a>\n<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/digital-garden/path-for-the-true-and-brave/text/5-design-de-experimentos/\">5. Design de Experimentos</a>\n<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/digital-garden/path-for-the-true-and-brave/text/6-dag/\">6. DAG</a>\n<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/digital-garden/path-for-the-true-and-brave/text/7-regressao-linear/\">7. Regressão Linear</a>\n<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/digital-garden/path-for-the-true-and-brave/text/8-vies/\">8. Viés</a>\n<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/digital-garden/path-for-the-true-and-brave/text/9-escore-de-propensao/\">9. Escore de Propensão</a>\n<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/digital-garden/path-for-the-true-and-brave/text/10-efeitos-heterogeneos/\">10. Efeitos Heterogêneos</a>\n<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/digital-garden/path-for-the-true-and-brave/text/12-double-machine-learning/\">12. Double Machine Learning</a>\n<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/digital-garden/path-for-the-true-and-brave/text/13-gen-ai/\">13. GenAI</a>\n<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/digital-garden/path-for-the-true-and-brave/text/14-boas-praticas/\">14. Boas Práticas</a>",
		"tags": [ "note"]
}
]