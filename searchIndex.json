[
{
		"title": "0. Roadmap",
		"date":"Thu Dec 25 2025 17:13:13 GMT+0000 (Coordinated Universal Time)",
		"url":"/path-for-the-true-and-brave/causalidade/0-roadmap/",
		"content": "Mês 1\n\nFree Tutorial - Causal AI in a Nutshell\nCausality, Decision Making &amp; Data Science (1 ~ 7)\nEstatística Psicobio II 2024 #23 - DAG I - Directed Acyclic Graphs - Princípios de Causalidade\nEstatística Psicobio II 2024 #24 - DAG II Directed Acyclic Graphs - d' separation; algoritmo PC e IC\nEstatística Psicobio II 2024 #25 - DAG III - Aplicações do DAG, Propensity Scores e diff-n-diff\n\nMês 2\n\nUniversidade de Dados - Robson Tigre\nCausal Inference in Python - (Cap I, II, III)\nCausal Inference in Python - Noncompliance &amp; Instruments\nTools for Causality\n\nMês 3\n\nMentoria - Robson Tigre\nProjetos - ex.: estimativa de demanda, elasticidade de preço, inferência de rejeitados etc.\n\nCausal Bandits Podcast\n\nCausal Inference's Role In Fintech Explained By Matheus Facure Ep 9 | CausalBanditsPodcast.com\nCausal Inference &amp; Financial Modeling with Alexander Denev Ep 14\nCausal AI &amp; Individual Treatment Effects | Scott Mueller Ep. 20\n49% Less Loss with Causal ML | Stefan Feuerriegel S2E1\nThe Causal Gap: Truly Responsible AI Needs to Understand the Consequences | Zhijing Jin S2E7\nCausal Inference &amp; Clinical Trials: Myths of Randomization | Stephen Senn | CausalBanditsPodcast.com\n\nNext Steps\n\nPanel Data (Cap. IV)\nMastering Mostly Harmless Econometrics (Alberto Abadie, Joshua Angrist, and Christopher Walters)\nCausal Discovery Inference\nOnline Controlled Experiments\nThe Book of Why: The New Science of Cause and Effect | Amazon.com.br",
		"tags": ["23", "24", "25", "note"]
},

{
		"title": "1. Epifanias",
		"date":"Thu Dec 25 2025 17:13:13 GMT+0000 (Coordinated Universal Time)",
		"url":"/path-for-the-true-and-brave/causalidade/1-epifanias/",
		"content": "Epifanias\nE cá estamos Dezembro de 2025, semana de natal. Faz um tempo que não escrevo nada publicamente — na verdade até estava, concentrado em refinar o Tinyshift. O projeto cresceu bastante e estou bem feliz com o rumo que tomou, embora sei que ainda há muito o que fazer nele.\nNeste meio caminho, em epifanias, percebi algo. Quanto mais tempo trabalho em ciência de dados, mais certeza só tenho de uma coisa: eu sei absolutamente nada. Depois de tanto tempo estudando sob diversos temas, novamente senti que estava batendo em outro teto.\nNeste contexto, ficamos extremamente habituados em um escopo: associação. Quando digo isto, sempre pensamos em modelar sob forma de resultarmos na probabilidade de um acontecimento, de um número, ou de uma classe em relação a outros fatores. Isto começou a me pregar dois problemas:\n\nA primeira é que estamos sempre falando de padrões. Comportamentos de fraude, spam, itens comprados juntos. Isso é natural: nosso cérebro é feito para reconhecer padrões, desde a Era da Pedra. Para nossa sobrevivência, sempre ficamos habituados a isso. Mas padrões não são causa e efeito. Imagine o clássico dataset sobre vendas de sorvete com uma feature de ataques de tubarão. Ao observar os dados você encontra tem padrões, associações fortes de um com outro! Seria sensato recomendar que seu cliente corte relações com empresas de sorvete? Claro que não, ao menos pra mim! Ambas as variáveis podem ser influenciadas por um terceiro fator: a temperatura. No verão as pessoas vão mais à praia e compram mais sorvete — como também há mais chance de ataques. Isso é o que chamamos de correlação espúria. O mantra vale: associação não implica causalidade.\nA segunda questão é prática: um modelo de Machine Learning tradicional frequentemente entrega apenas uma probabilidade. Nós, humanos, tomamos decisões com base nesse número. Mas se nosso objetivo é orientar ações, por exemplo, reduzir churn, não basta saber quem tem maior probabilidade de churn; precisamos saber qual é o impacto de uma ação (uma promoção, atendimento diferenciado, cross-sell) sobre o churn. Quais ações causam mais impacto para diferentes perfis de cliente? Facure fala exatamente disso no podcast do Aleksander Molak. Em vez de modelar apenas a probabilidade, quero saber qual intervenção impacta mais e por quanto — ou seja, modelar sobre as regras de negócio, não só previsão.\n\nModelos preditivos podem induzir a decisões equivocadas quando o objetivo é agir no mundo. O propósito final de um modelo de ML é resolver um problema de negócio; mover o ponteiro é o que importa! Por isso, comecei a estudar formas de modelagem que foquem tomada de decisão: entender relações de causa e efeito para orientar intervenções eficazes. Assim, em vez de prever, posso estimar o impacto de prevenir clientes descontentes, quais fatores reduzem churn ou se um cross-sell aumenta a fidelidade.\nEstas anotações, ou melhor, zettelkasten, são minhas, em meio a minha jornada nessa selva que conheço tão pouco. Não é e nunca vai ser um guia prático, mas achei que seria bom disponibilizar como portifólio, e ajudar quem gostaria também de começar a ler ou discutir sobre. Nela, escreverei apenas tópicos que me interessam, focando em dados observacionais, estudos transversais. Inferência Causal é gigante, então espere que tenha assuntos faltando. Mais importante, vamos ter um pouco de humildade epistêmica aqui, okay?\n\n[!tip]\nNão há problema de utilizar este documento para aprender, mas sugiro que use somente como apoio! Importante ter sua própria história, anotações e também suas epifanias!\nEm dúvida de como iniciar, deixarei o Roadmap que eu segui, do zero absoluto ao tema. Agora, para boas referências, siga Robson Tigre e Matheus Facure. Sou apenas um mero gafanhoto.\n\n[!Agradecimentos]\nAgradeço de coração ao Altay de Souza por me lembrar que aprender pode ser algo divertido e mais leve, ao Robson Tigre por sua humildade e me responder sempre que possível, e por fim ao Thiago Russo e ao meu primeiro time de Dados, por me ensinar a ser quem eu sou como cientista de dados.\nE antes que eu esqueça, ao Naruhodo e em especial ao - “Naruhodo, ilustríssimo ouvinte!” - Ken Fujioka junto com Altay, que me ensinam a cada dia a ser uma pessoa melhor.",
		"tags": [ "note"]
},

{
		"title": "10. Efeitos Heterogêneos",
		"date":"Thu Dec 25 2025 17:13:13 GMT+0000 (Coordinated Universal Time)",
		"url":"/path-for-the-true-and-brave/causalidade/10-efeitos-heterogeneos/",
		"content": "Efeitos Heterogêneos\nNas análises de inferência causal demonstradas anteriormente, exploramos o ATE sob uma perspectiva populacional. No entanto, em muitos cenários, o interesse reside em entender como diferentes subgrupos reagem ao tratamento, identificando quem apresenta impactos maiores ou menores. Para capturar essa variabilidade, utilizamos o Efeito Médio de Tratamento Condicional (CATE), que nos permite observar os chamados efeitos heterogêneos.\nO objetivo do CATE é permitir que a tomada de decisão seja fundamentada nas características específicas (X) de cada unidade. Em vez de perguntar apenas se &quot;o tratamento funciona&quot;, passamos a questionar: &quot;para quem o tratamento funciona melhor?&quot;**.\nMatematicamente, definimos o CATE como:\nτ(x)=E[Y1−Y0|X=x]Onde buscamos a diferença esperada entre os outcomes potenciais (Y1 e Y0), condicionada a um conjunto de covariáveis X.\nRegressão Linear\nUma regressão linear simples estima apenas o coeficiente médio do tratamento. Para identificar efeitos heterogêneos, introduzimos termos de interação entre a variável de tratamento (T) e as características das unidades (X). Essa abordagem torna o modelo flexível, permitindo que a &quot;inclinação&quot; (o efeito do tratamento) varie conforme o perfil da unidade.\nA equação assume a forma:\nyi=β0+β1Ti+β2Xi+β3(Ti×Xi)+ϵiDerivação do Efeito\nPara isolar o efeito do tratamento em um modelo com interações, utilizamos a derivada parcial da variável de resultado (y) em relação ao tratamento (t).\nConsidere o modelo:\nyi=β0+β1ti+β2Xi+β3(ti×Xi)+ϵiA variação de y para uma mudança infinitesimal em t é dada por:\n∂yi∂ti=β1+β3XiIsso nos mostra que o efeito do tratamento não é constante: ele depende diretamente dos valores das covariáveis Xi de cada indivíduo.\nAproximação por Diferença Finitas\nNa prática, como o modelo é linear, essa derivada pode ser calculada exatamente através da diferença entre duas predições. Usamos a definição de derivada onde o incremento (ϵ) é igual a 1 unidade:\nδyδt≈y^(t+1)−y^(t)Onde:\n\ny^(t+1) é a predição do modelo incrementando o tratamento original em uma unidade.\ny^(t) é a predição do modelo com os dados originais.\n\nExemplo (Causal Inference in Python: Applying Causal Inference in the Tech Industry\n\nimport statsmodels.formula.api as smf\n\n# 1. Definição das covariáveis (características que podem causar heterogeneidade)\nX = [&quot;C(month)&quot;, &quot;C(weekday)&quot;, &quot;is_holiday&quot;, &quot;competitors_price&quot;]\n\n# 2. Especificação do modelo com Interação # A sintaxe 'discounts * (X)'\n# Isso permite que o efeito do desconto mude conforme o mês, feriado ou preço do concorrente.\nregr_cate = smf.ols(f&quot;sales ~ discounts*({'+'.join(X)})&quot;,\ndata=data).fit()\n\n# 3. Estimativa do CATE (Efeito Médio de Tratamento Condicional)\n# Calculamos a diferença entre duas realidades hipotéticas para cada unidade:\n# Realidade A: O desconto atual + 1 unidade\n# Realidade B: O desconto atual\n# A diferença entre as predições isola o efeito marginal do desconto naquele contexto específico.\nols_cate_pred = (\nregr_cate.predict(data.assign(discounts=data[&quot;discounts&quot;]+1))\n-regr_cate.predict(data)\n)\n\nAvaliação\nA ideia central de criar modelos CATE surge da necessidade de ordenar as unidades das mais sensíveis às menos sensíveis ao tratamento, visando a personalização. Como não podemos observar o efeito individual real para validar essa ordenação, avaliamos grupos definidos pela predição do modelo. Diferentemente de um modelo tradicional de machine learning, focamos em verificar o quão bem o modelo está em relação a essa segmentação para efeito causal médio condicional. Não irei abordar a fundo, novamente aconselho a ler o livro do Matheus Facure pois há uma explicação muito boa sobre. Pontuarei apenas as três formar em que ele comenta como métodos.\nOutro ponto a ressaltar, é que se encontra exemplos bons da aplicação aberta via o jupyter notebook exemplar do livro. Causal Inference in Python: Applying Causal Inference in the Tech Industry\nEfeito por Quantil\nA abordagem consiste em segmentar os dados em quantis baseados na predição do modelo e estimar o efeito dentro de cada partição. Se o efeito estimado em cada quantil estiver ordenado (por exemplo, do maior para o menor), isso indica que o modelo é eficaz em ordenar o CATE verdadeiro. [Visualmente](causal-inference-in-python-code/causal-inference-in-python/06-Effect-Heterogeneity.ipynb at main · matheusfacure/causal-inference-in-python-code · GitHub), quanto maior for o efeito &quot;escada&quot; no gráfico de efeito por quantil, melhor o modelo distingue os efeitos altos dos baixos.\nCurva de Efeito Cumulativo\nSeguindo a lógica anterior, a Curva de Efeito Cumulativo não estima o efeito por grupos isolados, mas sim acumulando um grupo sobre o outro. O processo envolve ordenar os dados pelo score do modelo (predição CATE) e estimar o efeito ordenado de um valor N, depois do valor N + 1, e assim sucessivamente.\nEmbora essa curva permita resumir a qualidade do modelo calculando a área entre a curva e o ATE, ela apresenta uma desvantagem: o início da curva possui uma amostra pequeno, o que nos trás maior incerteza devido ao tamanho reduzido da amostra acumulada naquele ponto.\nCurva de Ganho Cumulativo (Cumulative Gain)\nPara corrigir a questão da variância no início da curva de efeito cumulativo, utiliza-se a Curva de Ganho Cumulativo. A lógica é a mesma, porém multiplicamos cada ponto da curva de efeito pela proporção da amostra acumulada (Ncum/N).\nO modelo que apresentar a maior área entre a curva e a linha tracejada (representando o ATE) — ou a maior soma dos valores da curva normalizada — é considerado o melhor em termos de ordenação do CATE. Por conta disso, podemos tirar o AUC e utilizarmos para avaliar o modelo desse resultado.",
		"tags": [ "note"]
},

{
		"title": "11. Variável Instrumental",
		"date":"Thu Dec 25 2025 17:13:13 GMT+0000 (Coordinated Universal Time)",
		"url":"/path-for-the-true-and-brave/causalidade/11-variavel-instrumental/",
		"content": "Variável Instrumental\nExistem cenários em que é inviável controlar totalmente o viés de variável omitida U. Nestes casos, problemas comuns incluem:\n\nA impossibilidade de coletar ou mensurar todas as variáveis de confusão.\n\nA impossibilidade de garantir que todos os indivíduos designados ao grupo de tratamento efetivamente recebam ou utilizem o tratamento. Isso caracteriza uma violação do perfect compliance (adesão perfeita).\n\n[!tip]\nCompliance refere-se à taxa de adesão, ou seja, o percentual de indivíduos que efetivamente utilizaram o tratamento conforme designado.\n\nNestes cenários, a variável não observada U exerce influência tanto sobre o tratamento D quanto sobre o resultado Y, enviesando as estimativas causais:\nD←U→YUma solução para contornar a falta de controle sobre U é utilizar uma Variável Instrumental Z, que antecede D:\nZ→D←U→YEssa abordagem isola a variação em D que é induzida por Z, &quot;limpando&quot; a influência de U. Para que isso funcione, as seguintes premissas devem ser atendidas:\n\nRelevância: A relação entre o instrumento Z e o tratamento D deve ser forte.\n\nPrática: Regredir Z em D e verificar se o R² e a Estatística F (p-valor) são significativos.\n\nRestrição de Exclusão: O instrumento Z deve afetar o resultado Y apenas através de D, sem caminhos diretos.\n\nExogeneidade (Independência): O instrumento deve ser não correlacionado com o termo de erro ou variáveis omitidas (Cov(Z,U)=0).\n\nMonotonicidade: O instrumento deve afetar o tratamento numa única direção.\n\nA Variável Instrumental (IV) pode ser aplicada em dois contextos principais:\n\nCorreção de Experimentos (RCTs): Para lidar com falhas de adesão (imperfect compliance). Por exemplo, quando Z é a oferta do tratamento e D é o uso efetivo. Nem todos os ofertados usam, mas a oferta (Z) é aleatória.\n\nEstudos Observacionais: Quando não houve randomização e suspeita-se que variáveis de confusão desconhecidas (U) afetem a escolha do tratamento. Aqui, o instrumento funciona como um &quot;experimento natural&quot;, introduzindo uma aleatoriedade na atribuição de D que o pesquisador não pôde controlar manualmente.\n\nO instrumento provoca um choque exógeno na variável D, gerando uma variação no tratamento que é independente das características não observadas U.\nEstágios\nPara calcular o efeito causal via IV, podemos decompor a análise em duas regressões simples e uma divisão.\n\nPrimeiro Estágio (Impacto no Tratamento):\nRegredimos o tratamento D em relação ao instrumento Z.\n\nVerificamos a premissa de Relevância. O coeficiente (π) nos diz o quanto o instrumento aumenta a probabilidade ou intensidade do tratamento.$$D = \\alpha_1 + \\pi Z + e_1$$\n\nForma Reduzida (Intenção de Tratar - ITTE):\nRegredimos o resultado Y diretamente em relação ao instrumento Z, ignorando o tratamento D por enquanto.\n\nComo Z é aleatório/exógeno, esse coeficiente (γ) mostra o efeito causal da atribuição do instrumento sobre o resultado.\n\nY=α2+γZ+e2\n\nCálculo do LATE:\nO efeito causal final (βIV) é a razão entre esses dois coeficientes. Ou seja, ajustamos o efeito total (γ) pela proporção de pessoas que realmente aderiram ao tratamento (π).\náβIV=Efeito de Z em Y (Forma Reduzida)Efeito de Z em D (Primeiro Estágio)=γπ\n\nimport statsmodels.formula.api as smf\n\n# 1. Primeiro Estágio: Efeito de Z em D\n# O coeficiente de Z aqui é a taxa de adesão\nfirst_stage = smf.ols('D ~ Z', data=df).fit()\nden = first_stage.params['Z']\n\n# 2. Forma Reduzida: Efeito de Z em Y\n# O coeficiente de Z aqui é o ITTE\nreduced_form = smf.ols('Y ~ Z', data=df).fit()\nnum = reduced_form.params['Z']\n\n# Cálculo do Wald, ou LATE\nwald_estimator_sm = num / den\n\nprint(f&quot;Numerador (ITTE): {num}&quot;)\nprint(f&quot;Denominador (Compliance): {den}&quot;)\nprint(f&quot;Efeito Causal (Wald): {wald_estimator_sm}&quot;)\n\nMínimos Quadrados em Dois Estágios (2SLS)\nEnquanto o cálculo do LATE via razão é intuitivo para um único instrumento, o método 2SLS permite a inclusão de múltiplas variáveis de controle e múltiplos instrumentos.\n\nPrimeiro Estágio (Purificação de D):\nRegride-se o tratamento D contra o instrumento Z (e demais controles). O objetivo não é analisar o coeficiente, mas sim obter os valores preditos (D^).\nD^=α^+π^Z\n\nSegundo Estágio (Estimação Causal):\nSubstitui-se a variável de tratamento original (D) pelos valores preditos calculados no passo anterior (D^) e realiza-se a regressão do resultado Y sobre essa nova variável.\nY=β0+β2SLSD^+ε\n\nA intuição aqui é a decomposição da variância. A variável de tratamento original D possui dois componentes de variação:\n\nUma parte endógena, correlacionada com U\nUma parte exógena, induzida pelo instrumento Z\n\nAo rodarmos o primeiro estágio e calcularmos D^, estamos isolando apenas a variação em D que é explicada por Z. Como Z é não correlacionado com U, D^ também será independente de U.\nPortanto, o segundo estágio utiliza uma versão &quot;limpa&quot; do tratamento. Ao regredir Y em D^, eliminamos a contaminação do viés de seleção, permitindo que o OLS estime o efeito causal verdadeiro.\nfrom linearmodels.iv import IV2SLS\n\n# Fórmula: Y ~ Controles + [Endogeno ~ Instrumento]\n# O &quot;1&quot; representa a constante (intercepto)\nformula = 'Y ~ 1 + X + [D ~ Z]'\n\nmodel = IV2SLS.from_formula(formula, df)\nresult = model.fit()\n\nprint(result)\n\n[!tip] 2SLS vs. DoubleML (DML)\nO método 2SLS tradicional assume que as relações entre as variáveis de controle (covariáveis) e o resultado são lineares. Caso sejam não lineares, o 2SLS pode falhar em remover todo o viés. É aqui que podemos utilizar o método de Double Machine Learning (DML) com uso de IV.",
		"tags": [ "note"]
},

{
		"title": "12. Double Machine Learning",
		"date":"Thu Dec 25 2025 17:13:13 GMT+0000 (Coordinated Universal Time)",
		"url":"/path-for-the-true-and-brave/causalidade/12-double-machine-learning/",
		"content": "Double Machine Learning\n\nDouble ML: Causal Inference based on ML\nAgora, iremos adentrar um pouco na inferência causal moderna. Relembramos o uso do Teorema FWL para &quot;desviesamento&quot;. Ele demonstra que, em uma regressão linear, podemos &quot;remover&quot; o efeito das covariáveis X através de resíduos e então estimar o efeito de D (tratamento) sobre Y.\nO Double Machine Learning (DML) generaliza essa ideia usando Machine Learning para estimar os componentes que dependem de X e, em seguida, &quot;partializa&quot; (remove a influência de) X em Y e D.\nO método se destaca por quatro pilares fundamentais:\n\nFramework não paramétrico\nPermite usar quaisquer modelo, como Random Forests e Gradient Boosting para modelar as variáveis de confusão (X). Isso captura relações complexas e não-lineares automaticamente.\n\nRedução de viés\nModelos de Machine Learning usam regularização (ex.: Lasso ou profundidade de árvores) para evitar overfitting, o que &quot;encolhe&quot; as previsões, distorcendo as estimativas de efeito causal. O DML resolve isso separando a estimação do ruído da estimação do efeito.\n\nIntervalos de confiança válidos\nÉ matematicamente inviável calcular p-valores precisos diretamente de uma &quot;caixa preta&quot; como uma Rede Neural. O DML transforma o problema final numa regressão linear simples sobre resíduos, permitindo recuperar a teoria estatística clássica para calcular significância estatística.\n\nEficiência\nSignifica que o erro da estimativa diminui rapidamente à medida que a amostra (n) cresce, comportando-se tão bem quanto uma regressão linear simples, mesmo utilizando modelos de ML complexos (que normalmente convergem mais devagar) para limpar os dados.\n\nSua ideia é utilizar dois modelos preditivos separados: um para o potencial outcome e outro para o tratamento. O processo ocorre nos seguintes passos:\n\nEstimar o outcome Y: Usamos um modelo de ML flexível (q(X)) para prever Y com base nas características X.\n\nEstimar o tratamento T: Usamos outro modelo de ML flexível (g(X)) para prever o tratamento T com base nas características X (similar a um Propensity Score).\n\nObtemos os resíduos:\n\nResíduo do outcome: Y~=Y−q^(X)\n\nResíduo do tratamento: T~=T−g^(X)\n\n[!tip] Lembrete\nUtilizamos o resíduo justamente para isolarmos os efeitos exógenos! Queremos apenas saber o Impacto do outcome sob os tratamentos, eliminando as variáveis de confusão.\n\nFazemos a regressão dos resíduos:\nY~=τT~+ϵOnde τ é o parâmetro causal (ATE). Esse processo é feito dinamicamente utilizando Cross-Fitting, que comentarei posteriormente.\n\nRegressão Parcialmente Linear e Ortogonalização\nVamos olhar para a Regressão Parcialmente Linear (PLR).\nAssumimos que o mundo gerador dos dados segue:\nY=Dθ+g(X)+UD=m(X)+VOnde θ é o nosso alvo (efeito causal) e g(X) é uma função complexa e desconhecida dos confoundings.\nSe tentarmos estimar θ diretamente com ML, o erro na estimativa de g(X) contamina θ. A solução é a Ortogonalização:\n\nCalculamos a esperança condicional de Y dado X:\nE[Y|X]=E[D|X]θ+g(X)Chamamos E[Y|X] de Y^ e E[D|X] de D^.\n\nSubtraímos essa esperança da equação original:\nY−E[Y|X]=(D−E[D|X])θ+(g(X)−g(X))+U\n\nNote a mágica: o termo complexo g(X) se cancela! Ficamos apenas com os resíduos:\n(Y−Y^)=(D−D^)θ+UOu seja:\nY~=θD~+U\n\nAgora, o erro na estimativa de g(X) é ortogonal (não correlacionado) ao tratamento residual, permitindo que o OLS isole o θ &quot;limpo&quot;.\n\n[!tip] Premissas Importantes\nÉ fundamental refrisar que esse método não é &quot;bala de prata&quot;. A validade causal ainda depende das premissas anteriores:\n\nIgnorabilidade: Y(d)⊥D|X. Ou seja, todas as variáveis de confusão relevantes foram incluídas em X. É importante refrisarmos isso que é assumido que foi capturando todos os confounders relevantes. Na prática, não temos como saber por exato, mas uma boa construção é importante.\nDomínio sob regra de negócio: Para toda a inferência causal, aqui não muda. Por mais complexo que nosso modelo possa ser, ele sempre será limitado relativo a tomada de decisão às escolhas de variáveis. Um bom DAG construído ainda é necessário, para evitar qualquer viés sob o resultado.\nQualidade de dados: por mais que o DoubleML é focado para estudos observacionais, aonde não controlamos variáveis de confusão e não temos uma randomização controlada, ele ainda pode sofrer com dados ruins. Se a extração tiver algum viés forte, problemas com campos, o resultado dele vai ser ineficiente para estimar causalidade.\nPositividade: Para valores de X relevantes, deve haver variação no tratamento (a probabilidade de tratamento P(T|X) não deve ser nem 0 nem 1 estritos).\nRegularidade: Os estimadores de ML devem convergir suficientemente rápido. O uso de Cross-Fitting é crucial para evitar viés de overfitting e garantir a validade assintótica.\n\nO Perigo no Overfitting\nVale ressaltar que a flexibilidade dos modelos de Machine Learning traz o risco de overfitting. Se o modelo entende demais os dados de treino, ele absorve ruídos como se fossem padrões reais, tornando os resíduos enviesados em direção a zero, eliminando a variação necessária para encontrarmos o efeito causal.\nPor conta disso, a prática padrão é utilizar o Cross-Fitting:\n\nSelecionamos K possíveis folds.\nNo K1, separamos os dados por exemplo em &quot;Treino&quot; e &quot;Hold-out&quot;.\nO modelo é treinado apenas na base de Treino, e utilizamos os dados para calcular o resíduo do Hold-Out.\nAgora, retreinamos o modelo com outro K fold, até que todos os dados tenham seus resíduos calculados.\n\nAssim, mesmo que o modelo aprenda nos dados de treino, ele não terá &quot;visto&quot; os dados de hold-out. Isso garante que os resíduos mantenham um ruído real e a variabilidade honesta necessária.\n\nDouble Machine Learning for Causal Inference: A Practical Guide | by Mohamed Hmamouch | Medium\nImplementação Prática: Calculando ATE e CATE com Python\nVamos utilizar a biblioteca DoubleML para aplicar os conceitos acima.\n1. Calculando o ATE\nPara o ATE, assumimos um efeito constante e usamos o modelo Partial Linear Regression (PLR).\nimport numpy as np\nimport pandas as pd\nfrom doubleml import DoubleMLData, DoubleMLPLR\nfrom sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n\n# --- Configuração dos Dados ---\n# Suponha que temos um DataFrame 'df' com:\n# 'y': Outcome, 'd': Tratamento binário, 'X1'...'X5': Covariáveis\ndata_dml = DoubleMLData(df,\ny_col='y',\nd_cols='d',\nx_cols=[f'X{i}' for i in range(5)])\n\n# --- Definindo os Modelos (Learners) ---\n# Modelo para prever Y (Outcome)\nml_l = RandomForestRegressor(n_estimators=100, max_depth=5)\n# Modelo para prever D (Propensity Score)\nml_m = RandomForestClassifier(n_estimators=100, max_depth=5)\n\n# --- Estimando ATE com Cross-Fitting ---\ndml_plr = DoubleMLPLR(data_dml,\nml_l=ml_l,\nml_m=ml_m,\nn_folds=3) # 3-fold Cross-Fitting\n\ndml_plr.fit()\nprint(dml_plr.summary)\n\nO resultado coef no sumário será o nosso τ (ATE), livre do viés das covariáveis.\n2. Calculando o CATE\nSe quisermos saber como o efeito varia de acordo com as características da pessoa (X), usamos o Interactive Regression Model (IRM). Em vez de calcular um número único, projetamos o efeito causal nas covariáveis usando um Preditor Linear (BLP).\nfrom doubleml import DoubleMLIRM\n\n# --- Usando IRM para permitir interações ---\n# ml_g prevê E[Y|X, D] e ml_m prevê E[D|X]\nml_g = RandomForestRegressor(n_estimators=100, max_depth=5)\nml_m = RandomForestClassifier(n_estimators=100, max_depth=5)\n\ndml_irm = DoubleMLIRM(data_dml,\nml_g=ml_g,\nml_m=ml_m,\nn_folds=3)\n\ndml_irm.fit()\n\n# --- Projetando a Heterogeneidade (CATE) ---\n# &quot;Como o efeito causal varia linearmente com as features X?&quot;\ncate_res = dml_irm.cate(basis=df[[f'X{i}' for i in range(5)]])\n\nprint(cate_res)\n\nInterpretando o CATE: Se no resultado do cate_res o coeficiente de uma variável (ex: X1: Idade) for positivo e significante, indica que o tratamento é mais eficaz quanto maior for a idade do indivíduo.\n\n[!tip]\nPLR: Assume que o efeito do tratamento (θ) entra de forma aditiva e linear (não interage complexamente com X na equação estrutural). É ideal para tratamentos contínuos (ex: preço, dosagem).\nIRM: É desenhado especificamente para tratamentos binários. Ele permite interações completas entre o tratamento e as covariáveis, sendo mais robusto para heterogeneidade. Ele utiliza o estimador AIPW (Augmented Inverse Probability Weighting) por trás dos panos, que possui a propriedade de Dupla Robustez (Doubly Robust).\n\nIntroduction to Causal Machine Learning with DoubleML for Python\n3. Calculando o GATE (Group Average Treatment Effect)\nEnquanto o CATE busca o efeito individual (que pode possuir alto ruído estatístico), o GATE busca o efeito médio em um subgrupo específico.\nA biblioteca DoubleML oferece um método dedicado .gate() para cada grupo. Para utilizá-lo, precisamos passar um DataFrame onde as colunas representam os grupos (indicadores binários/dummies).\n\n[!tip]\nPodemos calcular o GATE agregando as estimativas do CATE. Filtramos as unidades que pertencem ao grupo de interesse e tiramos a média dos seus efeitos causais estimados (τ^(x)).\n\nMatematicamente:\nτGATE=E[τ^(x)∣x∈Grupo]# --- Passo 1: Definir os Grupos de Interesse ---\n# Vamos criar, por exemplo, dois grupos baseados na variável X1 (ex: Idade normalizada)\n# Grupo 0: X1 &lt;= 0.5\n# Grupo 1: X1 &gt; 0.5\ngroups = pd.DataFrame({\n'Grupo_Baixo_X1': df['X1'] &lt;= 0.5,\n'Grupo_Alto_X1': df['X1'] &gt; 0.5\n})\n\n# --- Passo 2: Calcular o GATE via DoubleML ---\n# O método gate() ajusta uma regressão linear dos resíduos contra essas variáveis de grupo\ngate_res = dml_irm.gate(groups=groups)\n\nprint(gate_res)\n\n# --- Passo 3: Analisar os Intervalos de Confiança ---\n# Verificamos se o intervalo de 95% cruza o zero ou se os grupos se sobrepõem\nprint(gate_res.confint())\n\nEssa abordagem é poderosa para decisões de negócio estratégicas, onde não podemos personalizar para cada indivíduo, mas podemos criar políticas para segmentos (ex: Região Norte vs. Sul).\n\nCaracterística\nCATE (Conditional Average Treatment Effect)\nGATE (Group Average Treatment Effect)\n\nDefinição\nEfeito do tratamento para um indivíduo (ou unidade) com características exatas X.\nMédia dos efeitos de tratamento para um subgrupo específico da população.\n\nNível de Granularidade\nMicro (Individual / Personalizado).\nMacro (Segmento / Cluster).\n\nNotação Matemática\nτ(x)=E[Y(1)−Y(0)∣X=x]\nτGATE=E[τ(x)∣x∈Grupo]\n\nPergunta de Negócio\n&quot;Qual desconto devo dar para este cliente específico agora?&quot;\n&quot;A campanha funciona melhor na Região Sul ou na Região Norte?&quot;\n\nEstabilidade Estatística\nBaixa. Sofre com alta variância e ruído, pois n=1 (ou muito pequeno) para aquele X.\nAlta. O ruído individual tende a se cancelar na média do grupo, gerando estimativas mais robustas.\n\nNo DoubleML\nResultado da projeção do efeito nas features (via dml_irm.cate() ou BLP).\nCalculado tirando a média das predições do CATE filtradas por um subconjunto do DataFrame.\n\nAplicação Principal\nPersonalização de produto, Medicina de precisão, Recomendação dinâmica.\nDefinição de estratégia, Política pública, Decisão de portfólio.\n\nDoubleML com Variáveis Instrumentais (IV)\nDiferente do DoubleML padrão (que limpa X apenas de Y e D), no cenário com Variável Instrumental nós precisamos limpar a influência das covariáveis (X) de três lugares: do Resultado (Y), do Tratamento (D) e do Instrumento (Z).\nSimulando o DoubleMLPIV para ter uma ideia, o processo envolve 3 modelos de Machine Learning e uma regressão IV 2SLS final.\nPremissas\n\nY depende de X,D,U.\nD depende de X,Z,U.\nZ depende de X\n\n1. Previsão\nPrimeiro, usamos ML para prever Y, D e Z usando apenas as covariáveis X. O objetivo é capturar toda a variação explicada por variáveis de confusão.\n\nModelo 1 (q(X)): Prever Y usando X.\nModelo 2 (m(X)): Prever D usando X.\nModelo 3 (r(X)): Prever Z usando X.\n\n2. Ortogonalização Tripla\nSubtraímos as previsões dos valores reais.\n\nY~=Y−Y^ML (Variação no outcome não explicada por X)\nD~=D−D^ML (Variação no tratamento não explicada por X)\nZ~=Z−Z^ML (Variação no instrumento não explicada por X)\n\n3. Estágio Final (2SLS nos Resíduos)\nUsamos os resíduos do instrumento (Z~) para instrumentar os resíduos do tratamento (D~) e explicar os resíduos do resultado (Y~).\nimport numpy as np\nimport pandas as pd\nimport statsmodels.api as sm\nfrom sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n\n# --- 1. Gerando Dados Fictícios (Endógenos) ---\nnp.random.seed(42)\nn = 1000\n# X afeta tudo (confusão)\nX = np.random.normal(0, 1, (n, 3))\n# Z (instrumento) afeta D, mas também depende de X\nZ = 0.5*X[:,0] + np.random.normal(0, 1, n)\n# U (não observado) afeta D e Y\nU = np.random.normal(0, 1, n)\n# D (tratamento) depende de X, Z e U (viés)\nD = 0.5*Z + 0.5*X[:,0] + U + np.random.normal(0, 0.5, n)\n# Y (outcome) depende de D, X e U. Efeito real de D é 2.0\nY = 2.0*D + X[:,0] + U + np.random.normal(0, 0.5, n)\n\ndf = pd.DataFrame({'Y': Y, 'D': D, 'Z': Z})\nX_cols = pd.DataFrame(X, columns=['X1', 'X2', 'X3'])\n\n# --- 2. Fase de Machine Learning ---\n# Treinamos modelos para capturar a influência de X em Y, D e Z\n\n# a) Prever Y dado X\nmodel_y = RandomForestRegressor(max_depth=5).fit(X_cols, df['Y'])\ny_hat = model_y.predict(X_cols)\ny_res = df['Y'] - y_hat # Resíduo Y (Ortogonalizado)\n\n# b) Prever D dado X\nmodel_d = RandomForestRegressor(max_depth=5).fit(X_cols, df['D'])\nd_hat = model_d.predict(X_cols)\nd_res = df['D'] - d_hat # Resíduo D (Ortogonalizado)\n\n# c) Prever Z dado X (Essencial para DoubleMLPIV!)\nmodel_z = RandomForestRegressor(max_depth=5).fit(X_cols, df['Z'])\nz_hat = model_z.predict(X_cols)\nz_res = df['Z'] - z_hat # Resíduo Z (Ortogonalizado)\n\n# --- 3. 2SLS clássico ---\n# y_res ~ beta * d_res (instrumentado por z_res)\n\n# 1º Estágio Manual: Regredir d_res contra z_res\nstage1 = sm.OLS(d_res, sm.add_constant(z_res)).fit()\nd_res_hat = stage1.predict() # Variação de D limpa de X e induzida por Z limpo\n\n# 2º Estágio Manual: Regredir y_res contra o predito do 1º estágio\nstage2 = sm.OLS(y_res, sm.add_constant(d_res_hat)).fit()",
		"tags": [ "note"]
},

{
		"title": "13. Guia de Equívocos",
		"date":"Thu Dec 25 2025 17:13:13 GMT+0000 (Coordinated Universal Time)",
		"url":"/path-for-the-true-and-brave/causalidade/13-guia-de-equivocos/",
		"content": "Guia de Equívocos\nEmbora possamos utilizar os mesmos algoritmos de previsão para uma análise causal, as abordagens divergem em termos de objetivos e interpretação. Enquanto modelos preditivos buscam correlações estáveis para prever o futuro, modelos causais exigem maior maturidade teórica para identificar o efeito de uma intervenção.\nIrei deixar aqui alguns pontos de equívocos que podem surgir durante um percurso de construção de modelo. Alguns, podem parecer óbvio, mas sempre bom deixar descrito para não esquecermos.\n1. Assumir causalidade em dados observacionais sem critério\nObservações empíricas que mostram associação entre duas variáveis não permitem, por si só, concluir causalidade. A associação pode ser fruto de confusão, causalidade reversa ou mera coincidência.\n\nExemplo: As vendas de sorvete e o número de afogamentos aumentam simultaneamente; a temperatura (variável omitida) é a causa comum de ambos.\nComo evitar: Sempre observe a construção do DAG, procure fontes de variação plausivelmente exógenas, use desenho experimental quando possível, e declare explicitamente as premissas necessárias para qualquer interpretação causal.\n\n2. Acreditar que a Randomização resolve todos os problemas\nEnsaios aleatorizados reduzem vieses de seleção na atribuição do tratamento, mas não* garantem validade externa automática, ausência de vieses de medição, ou ausência de não‑compliance, perdas de seguimento e efeitos indiretos.\n\nExemplo: Um experimento onde muitos participantes do grupo de tratamento desistem (attrition) gera estimativas enviesadas.\nComo evitar: Monitore a adesão e perdas de seguimento; considere estimadores como Variáveis Instrumentais para lidar com a não-conformidade.\n\n3. Controlar o máximo de variáveis possível\nDiferente do mundo preditivo, onde &quot;mais dados costumam ser melhor&quot;, na causalidade, incluir certas variáveis pode introduzir viés. Controlar mediadores ou colisores pode distorcer o efeito real.\n\nPonto Chave: Um alto R2 ou poder preditivo não implica poder causal. Incluir um colisor pode gerar uma correlação espúria onde não existe causalidade.\nComo evitar: Utilize o critério de Backdoor no seu DAG para decidir quais variáveis devem (e quais não podem) ser controladas.\n\n4. Substituir o pensamento causal por modelos complexos\nModelos de Machine Learning altamente flexíveis podem prever o outcome com precisão, mas não explicam o que aconteceria sob uma intervenção. A complexidade do algoritmo não valida a suposição causal.\n\nComo evitar: Combine ML com frameworks causais (como Double Machine Learning), documente as premissas e realize análises de sensibilidade.\n\n5. Ignorar a Heterogeneidade do Efeito\nAssumir que o efeito causal é o mesmo para todos os indivíduos (homogeneidade) pode mascarar resultados importantes.\n\nExemplo: Um desconto que aumenta as vendas para jovens, mas reduz o valor da marca para clientes premium.\nComo evitar: Estime efeitos heterogêneos (CATE - Conditional Average Treatment Effect) e discuta os limites da generalização dos resultados.\n\n6. Tratar o P-valor como prova de causalidade\nA significância estatística quantifica apenas a incerteza amostral sob um modelo específico; ela não valida suas suposições causais. Um efeito estatisticamente significativo (p&lt;0,05) não elimina explicações alternativas, como variáveis de confusão ou viés de seleção.\n\nO Trade-off: Isso está ligado ao equilíbrio entre Viés e Variância, que comentei anteriormente. Um modelo pode ter variância baixa (estimativas precisas/p-valor baixo), mas estar altamente enviesado por não considerar a estrutura causal correta.\nMagnitude vs. Significância: Um tamanho de efeito grande ou um alto nível de significância não garantem benefícios práticos ou validade causal. Em grandes bases de dados (Big Data), quase qualquer correlação irrelevante pode se tornar &quot;estatisticamente significativa&quot;, mesmo sem qualquer sentido causal. Uma variável com alto poder causal pode apresentar um p-valor alto (não significante) se a amostra for pequena ou a variância for elevada. Não confunda precisão estatística com relevância causal.\n\nComo evitar:\n\nFoque na magnitude do efeito e nos Intervalos de Confiança, que mostram a incerteza de forma mais transparente.\nPriorize a robustez do desenho do estudo em vez da busca por p-valores baixos.\nCombine a evidência estatística com argumentos teóricos e testes de sensibilidade.",
		"tags": [ "note"]
},

{
		"title": "14. GenAI",
		"date":"Thu Dec 25 2025 17:13:13 GMT+0000 (Coordinated Universal Time)",
		"url":"/path-for-the-true-and-brave/causalidade/14-gen-ai/",
		"content": "GenAI\nÉ importante salientar alguns pontos. Modelos de Large Language Models (LLMs) não capturam, por si só, relações de causalidade. Há desafios conhecidos de reasoning em modelos não determinísticos e, para inferência causal, esses modelos não substituem os conceitos e frameworks consolidados da econometria.\nAinda assim, LLMs podem ser usados como ferramenta de suporte, como por exemplo, para gerar hipóteses, explorar possíveis variáveis instrumentais ou identificar potenciais confundidores — porém sempre com muita cautela. O artigo Mining Causality: AI-Assisted Search for Instrumental Variables propõe um agente que auxilia na busca por variáveis instrumentais por meio de etapas de prompt e validações. Outra alternativa que complementa essa abordagem é a biblioteca PyWhyLLM, que ajuda a encontrar relações (IVs, confundidores) que conectam tratamento ao desfecho.\nEssas ferramentas não devem ser usadas para terceirizar decisões nem para substituir conhecimento de domínio ou regras de negócio. Seu uso exige criticidade, documentação cuidadosa e submissão à revisão por pares humanos. A interpretação dos resultados e a atribuição de efeitos causais devem ser feitas por pesquisadores qualificados. Lembre-se interpretações equivocadas são responsabilidade dos autores — como comentado por Fisher. Quanto maior for o impacto ou a criticidade do trabalho, mais rigorosas devem ser as análises.",
		"tags": [ "note"]
},

{
		"title": "2. Como Predição e Inferência Causal se Conversam",
		"date":"Thu Dec 25 2025 17:13:13 GMT+0000 (Coordinated Universal Time)",
		"url":"/path-for-the-true-and-brave/causalidade/2-como-predicao-e-inferencia-causal-se-conversam/",
		"content": "Como Predição e Inferência Causal se Conversam\nPredição e inferência causal respondem a perguntas diferentes, mas complementares. Modelos de Machine Learning (ML) buscam estimar bem um resultado futuro, como por exemplo, quem tem maior probabilidade de churn. Inferência causal busca estimar o efeito - ou impacto - de uma intervenção, como por exemplo, quanto uma promoção reduz o churn. Saber a probabilidade de um evento nem sempre informa qual ação mudará esse evento; por isso precisamos das duas abordagens trabalhando em conjunto.\nA predição, por si só, como falei anteriormente, foca na relação entre padrões, entre associações. Se o seu objetivo for encontrar apenas padrões e classificar - pense como em um problema de classificação de fraude, rotulação de spam - a predição, simples, já resolve. Ela encontra padrões e te retorna comportamentos atípicos. Nisso, a formula já funciona, mas e quando precisamos a prescrição? E se, sob dados de crime, você não quer a probabilidade de uma reincidência de uma pessoa - é um modelo claramente perigoso, mas apenas para fins comparativos! - mas gostaria de saber o impacto de programas de ressocialização e se houve uma causa e efeito, isto é, se programas sociais auxiliam de fato para que esta pessoa não cometa mais crimes? Um modelo de previsão não resolveria. É para isso que a inferência causal entra.\n\n[!tip]\nPredição: otimiza acurácia. Boa para segmentação, detecção de anomalias e priorização (ex.: identificar clientes em risco).\nInferência causal: estima efeitos de intervenções e responde “o que acontece se eu fizer X?”. Essencial para tomar decisões que mudam o mundo.\n\nMixtape Sessions: Foundation of Causality\n\n[!tip]\nBusiness impact is always a causal question",
		"tags": [ "note"]
},

{
		"title": "3. Teorias da Causalidade",
		"date":"Thu Dec 25 2025 17:13:13 GMT+0000 (Coordinated Universal Time)",
		"url":"/path-for-the-true-and-brave/causalidade/3-teorias-da-causalidade/",
		"content": "Teorias da Causalidade\nA causalidade é um conceito complexo, abordado por pensadores como Aristóteles, David Hume, e Kant, com contribuições mais recentes de economistas como Angus Deaton e estatísticos. Em diversas áreas, há uma variabilidade de definições dela.\nPara o contexto da estatística e da modelagem de dados, a abordagem mais relevante é a Causalidade Regular (diferente da Causalidade Estrita de Descartes, que se baseia em leis naturais). A Causalidade Regular foca em eventos probabilísticos em vez de determinísticos, dando um foco grande em probabilidade condicional. Essa linha de pensamento foi inicialmente influenciada por ideias de Hans Reichenbach e John Stuart Mill, evoluindo para o que é hoje reconhecido como a moderna teoria da inferência causal, impulsionada por Judea Pearl e seu trabalho com Modelos Gráficos Acíclicos Direcionados (DAGs). Outros nomes, como Susan Haack e Deborah Mayo, também trouxeram contribuições importantes para a filosofia da causalidade e da estatística.\nNeste modelo, a causalidade é definida por três aspectos principais:\n\nDirecionalidade: A relação de causa e efeito é estruturada graficamente, indicando que o evento A causa o evento B (A→B).\nTemporalidade: A causalidade é expressa em termos de probabilidades condicionais – a probabilidade de um evento, dado que o outro já ocorreu. No entanto, o conceito estatístico fundamental aqui é a probabilidade de a causa A ocorrer, dado o efeito B, se e somente se A for a causa. Em termos de probabilidades condicionais, o que é crucial é a comparação entre P(B|A) e P(B|¬A) (a probabilidade do efeito B ocorrer na presença da causa A versus na sua ausência).\nReprodutibilidade (ou Invariância): Para ser considerada causal, a relação observada entre os eventos deve ser invariante, ou seja, consistentemente reproduzida sob as mesmas condições e em diferentes contextos relevantes.\n\n[!tip]\nA Independência Condicional é a chave da inferência causal. Ela permite distinguir relações causais genuínas de simples associações estatísticas, identificando se a relação entre dois eventos desaparece ao condicionar uma terceira variável (a variável de confusão).\n\n[!tip]\nAs variáveis de confusão (ou variáveis confundidoras, ou confounders) são variáveis que exercem influência tanto na causa quanto no efeito em estudo.\nÉ crucial identificar e controlar essas variáveis, pois a sua presença afeta diretamente a validade da inferência causal, levando a estimativas enviesadas do verdadeiro efeito, causando o que chamamos de associação espúria.\n\nDefinição de Causalidade, Causação e Associação\nComo falei, existe uma definição ampla sobre causalidade, a qual varia conforme a área de atuação. Essa pluralidade de conceitos é bem representada no artigo The Representation of Causality and Causation with Ontologies: A Systematic Literature Review, que demonstra como as definições mudam ao longo da literatura. Para o escopo probabilístico em que atuaremos, adotaremos uma perspectiva mais próxima à de Judea Pearl.\nCausalidade é a relação direcional de causa e efeito entre entidades, variáveis ou eventos. Já a causação refere-se ao mecanismo ou ação pela qual a causa produz o efeito. Ambos os conceitos envolvem direcionalidade, temporalidade e influência — a ideia de que um elemento efetivamente gera uma alteração no outro.\nEm contraste, a associação é a mera relação estatística entre duas variáveis. É fundamental não confundirmos com causalidade. Por definição, a associação pode incluir vieses, enquanto a causação busca isolar relações diretas. Assim, duas variáveis podem não ter influência direta entre si, mas parecerem relacionadas por serem influenciadas por uma variável externa não mapeada (lembremos da relação espúria). Nesses casos, há associação, mas não há nexo causal direto.\n\n[!tip]\nCausal inference is the science of inferring causation from association and understanding when and why they differ. - Matheus Facure\n\nDefinição Formal\nE[Y|T=1]−E[Y|T=0]=E[Y1−Y0|T=1]⏟ATT+{E[Y0|T=1]−E[Y0|T=0]}⏟BIASAssociação é igual ao efeito de tratamentos no grupo tratado mais o viés, que por sua vez é dado por como o grupo tratado e controlado diferem antes do tratamento, no caso de ambos de nenhum deles receberem o tratamento. Nela haverá causalidade se não houver viés, isto é, que em outras palavras, ocorrerá causação somente se o grupo tratado e o controlado são iguais ou comparáveis, exceto pelo seu tratamento quando o resultado do não tratado é igual ao contrafactual do tratado.\nE[Y0|T=0]=E[Y0|T=1]Problema Fundamental da Inferência Causal\nO Problema Fundamental da Inferência Causal reside na impossibilidade de observar simultaneamente, na mesma unidade, o resultado factual e o resultado contrafactual .\nPara quantificar o efeito causal de um tratamento, seria necessário calcular a diferença entre esses dois resultados. No entanto, uma única unidade (seja um indivíduo, evento ou variável) só pode existir em um único estado (tratado ou não tratado) em um dado momento.\nEm essência, a quantificação exata exigiria um universo paralelo onde a unidade pudesse ser observada em condições idênticas, mas sob estados de tratamento opostos. Dado que isso é logisticamente impossível, o problema é considerado o obstáculo central da inferência causal.",
		"tags": [ "note"]
},

{
		"title": "4. Escada da Causação",
		"date":"Thu Dec 25 2025 17:13:13 GMT+0000 (Coordinated Universal Time)",
		"url":"/path-for-the-true-and-brave/causalidade/4-escada-da-causacao/",
		"content": "Escada da Causação\nA escada da causação é uma definição de Judea Pearl que organiza três níveis de raciocínio sobre dados e efeitos. Cada degrau responde a tipos distintos de perguntas e demanda métodos/assunções diferentes.\n1. Primeiro Degrau: Associação\nAssociação é o degrau mais básico da escada da causalidade. Trata-se de detectar padrões e regularidades a partir de observações: “A e B tendem a ocorrer juntos” ou “quando X aumenta, Y costuma aumentar/diminuir”. Ela é a forma mais primitiva que temos disso. Como falei, é algo que por padrão, fazemos no nosso dia a dia. É a área do observacional. Pense como uma coruja observando o movimento de um rato: ela não precisa entender a anatomia do rato, apenas associar o ruído na mata ao alimento. Da mesma forma, nossos ancestrais aprenderam que certos cogumelos são venenosos; se quem comeu anteriormente veio a falecer, associamos o consumo à morte.\n2. Segundo Degrau: Intervenção\nA intervenção vai além da observação passiva; ela envolve a manipulação ativa de variáveis para observar resultados. É o nível dos experimentos controlados (Testes A/B). Por exemplo:\n\nUm gerente perguntando &quot;O que acontecerá com nossas vendas de fio dental se dobrarmos o preço da pasta de dente?&quot;\nTomar aspirina para curar dor de cabeça - intervindo na quantidade de aspirina para afetar o status da dor\nDefinir preços para vender excesso de estoque\n\nA intervenção é superior à associação porque envolve não apenas observar, mas mudar o que existe. Ver fumaça nos conta uma história completamente diferente sobre a probabilidade de fogo do que fazer fumaça. Não podemos responder questões sobre intervenções apenas com dados coletados passivamente, não importa o tamanho do conjunto de dados ou a profundidade da rede neural.\n3. Terceiro Degrau: Contrafactuais\nSe a Associação é sobre ver e a Intervenção é sobre fazer, o Contrafactual é sobre imaginar. Este é o topo da escada e a característica que nos define como seres humanos. Ele lida com o &quot;e se?&quot;: a capacidade de olhar para o passado, comparar o que aconteceu com o que poderia ter ocorrido sob condições diferentes, e extrair uma lição de causalidade profunda disso.\nDiferente dos degraus anteriores, o contrafactual (o que teria ocorrido se o tratamento não tivesse sido aplicado) não pode ser respondido apenas com dados atuais ou experimentos presentes, pois o evento (o que ocorreu com o tratamento) já passou. Exemplos:\n\nMedicina e Saúde: &quot;O paciente faleceu. Será que ele teria sobrevivido se tivéssemos administrado o antibiótico duas horas antes?&quot;\n\nMarketing e E-commerce: &quot;Tivemos 1.000 vendas nesta campanha. Quantas vendas teríamos feito se não tivéssemos oferecido o cupom de desconto?&quot;\n\nSegurança Pública: &quot;A criminalidade caiu após a instalação de novas câmeras. Ela teria caído da mesma forma se a taxa de desemprego não tivesse diminuído no mesmo período?&quot;\n\nJustiça e Ética: &quot;O réu foi condenado por negligência. Ele teria evitado o acidente se tivesse feito a manutenção dos freios?&quot;",
		"tags": [ "note"]
},

{
		"title": "5. Design de Experimentos",
		"date":"Thu Dec 25 2025 17:13:13 GMT+0000 (Coordinated Universal Time)",
		"url":"/path-for-the-true-and-brave/causalidade/5-design-de-experimentos/",
		"content": "Design de Experimentos\nNa introdução ao seu trabalho The Design of Experiments, Ronald Fisher demonstrou preocupação com a falta de clareza e rigor metodológico em experimentos. Ele notou que a ausência de um design experimental robusto poderia levar a:\n\nDificuldade de Interpretação: O leitor e, por vezes, o próprio cientista, poderiam ter percepções diferentes sob os resultados, levando a conclusões que não eram suportadas pelos dados, ou que poderiam ter ocorrido por acaso (chance), mesmo que a hipótese fosse falsa.\nCarência Estrutural (Design): Falhas lógicas e estruturais, com o experimento sendo fundamentalmente incorreto, muitas vezes devido a controles inadequados ou à ausência de comparação válida.\n\nFisher propôs um método rigoroso que visa trazer facilidade e confiança ao cientista no tópico de experimentação, desde o planejamento (design) até o desenvolvimento e análise.\n\nConceitos Chave de Fisher:\n\nRandomização: Para garantir que as características não observáveis se distribuam igualmente.\nControle: Para isolar o efeito do tratamento.\nReplicação: Para reduzir o erro experimental e aumentar a precisão.\n\nExperimentos Aleatorizados\nPara contornar o Problema Fundamental da Inferência Causal, carência de design de experimentos e controlar viés de variável omitida, recorre-se a métodos de pesquisa como o Experimento Aleatorizado.\nO experimento aleatorizado, ou ensaio clínico randomizado (RCT), é um procedimento no qual as unidades de uma amostra populacional são alocadas de forma aleatória*(randomizada) ao grupo de tratamento ou ao grupo de controle.\nA randomização é crucial, pois:\n\nElimina vieses de seleção e confusão.\nCria grupos estatisticamente comparáveis.\n\nAo garantir que a única diferença sistemática esperada entre os grupos é a aplicação do tratamento, a randomização permite que a diferença observacional nos resultados seja interpretada como uma estimativa válida do efeito causal médio do tratamento na população.\n\n[!tip]\nMesmo assim, RCT não é uma bala de prata. Existem premissas importantes em estudos observacionais que precisam ser respeitas também em RCT. Muitas das vezes, ela de fato é, mas é importante termos conhecimento delas:\n\nSUTVA (Stable Unit Treatment Value Assumption)\n\nConsistência: o tratamento é bem definido; o outcome observado para uma unidade sob o tratamento t é igual ao potencial outcome Y(t).\nSem interferência: o tratamento de uma unidade não afeta o outcome de outra (sem spillovers/efeitos indiretos).\n\nIgnorabilidade / Unconfoundedness / Exchangeability\n\nOs potenciais outcomes são independentes do tratamento, condicional às covariáveis observadas: ⟂Y(0),Y(1)⟂T|X. Em RCTs a randomização garante ignorabilidade em expectativa.\n\nPositividade / Overlap\n\nPara todo valor de X considerado, há probabilidade estritamente positiva de receber cada condição: 0 &lt; P(T=1 | X) &lt; 1. Sem positividade não é possível comparar contrafactuais em certas subpopulações.\n\nControle de confundidores\n\nEm estudos observacionais: medir e ajustar os confundidores (regressão, propensity scores, IPW, matching, estratificação, etc.).\nEm RCTs: projetar blocos/estratificação quando necessário e checar balanceamento pré-tratamento; ajustar para covariáveis quando melhora precisão.\n\nAmeaça pós-randomização\n\nNão-adesão (noncompliance), perda amostral diferencial (attrition), contaminação e mediadores induzidos por tratamento podem reintroduzir viés.\n\n[!tip]\nChecagens práticas recomendadas\n\nVerificar balanceamento de covariáveis pré-tratamento (tabelas/estadísticas e testes; love plot).\nConferir overlap/propensity score distributions e excluir regiões sem suporte comum.\nMonitorar taxas de adesão e perda.\n\nLecture 3 – The Magic of Randomized Control Trials\n\nLecture 3 – The Magic of Randomized Control Trials\n\n[!tip]\nUm bom artigo que podemos observar o carinho de um bom design de experimento e aleatorizada, é o artigo The impact of computer usage on academic performance: Evidence from a randomized trial at the United States Military Academy.\n\nPontos de Atenção\n\nValidação Interna: Refere-se à confiança de que o efeito observado no resultado é causado unicamente pela manipulação do tratamento (a variável independente) e não por fatores externos, vieses ou erros de medição dentro do grupo de estudo. Um experimento tem alta validade interna se pudermos afirmar com certeza que o tratamento causou a mudança no resultado.\n\nPonto de Atenção: Ameaças à validade interna incluem a seleção dos participantes, a maturação (mudanças nos participantes ao longo do tempo), a história (eventos externos que ocorrem durante o experimento) e a mortalidade/abandono (perda de participantes).\n\nValidação Externa: Trata-se da capacidade de generalizar os resultados do experimento para a população mais ampla ou para outros ambientes e contextos. Se os resultados só se aplicarem à área de amostragem específica (demografia), a validade externa é baixa.\n\nPonto de Atenção: Ameaças à validade externa incluem a interação entre seleção e tratamento (o efeito só se aplica ao grupo selecionado) e os efeitos de laboratório (condições artificiais que não refletem o mundo real).\n\nValidade de Construto\n\nDefinição: Refere-se à adequação das medidas. Garante que as variáveis operacionais (as formas concretas de medir ou manipular as variáveis no seu experimento) realmente representam os construtos teóricos (os conceitos abstratos que você está estudando).\nEm outras palavras: É a certeza de que o experimento está medindo aquilo que se propôs a medir.\nPonto de Atenção:\n\nDeve-se garantir que as métricas realmente capturem a essência dos conceitos (ex: satisfação do cliente, motivação).\nAmeaças Comuns:\n\nSub-representação do Construto: O teste não mede todos os aspectos do conceito (a medida é incompleta).\nVariância de Métodos Irrelevantes: A medição é afetada por fatores não relacionados ao conceito que se deseja medir.\n\nEfeito Spillover\n\nOcorre quando o tratamento aplicado ao Grupo de Tratamento afeta, indiretamente, o Grupo de Controle (ou vice-versa). Isso é uma violação da suposição de que o resultado de uma unidade não é afetado pelo tratamento de outra (SUTVA violation). O tratamento &quot;vaza&quot; ou a informação/benefício se espalha.\n\nExemplos:\n\nEm experimentos geográficos, o tratamento aplicado em uma área de teste afeta as pessoas em uma área de controle vizinha\nUm participante do grupo de controle aprende sobre a nova funcionalidade com um amigo do grupo de tratamento (contaminação).\nA mudança de preço em uma loja (grupo de tratamento) afeta a demanda ou percepção dos clientes de uma loja vizinha (grupo de controle).\nEm experimentos geográficos, o tratamento aplicado em uma área de teste afeta as pessoas em uma área de controle vizinha.\n\nImplicação: Se o spillover ocorrer, o Grupo de Controle não é mais uma verdadeira linha de base, o que compromete a validade intern. A estimativa do efeito causal do tratamento será enviesada (subestimada ou superestimada).\nEstratégias de Mitigação: Usar grupos de controle distantes (geográfica ou socialmente) ou implementar cegamento (impedir que os participantes saibam quem recebeu o tratamento).\n\nProblemas com Experimentos Aleatorizados\nEm um RCT, os participantes são distribuídos aleatoriamente para o grupo de tratamento ou controle. Essa randomização visa equilibrar todas as variáveis de confusão (tanto as conhecidas quanto as desconhecidas) entre os grupos, permitindo que qualquer diferença observada no resultado seja atribuída, com alta confiança, à intervenção (causa).\nEmbora seja o padrão de ouro na metodologia experimental, ele não oferece uma garantia absoluta de causalidade, pois a randomização inicial é apenas o primeiro passo. A causalidade pode ser comprometida por vieses pós-randomização que surgem durante a execução do estudo. Problemas como a desigualdade de características entre os participantes, perda ou até abandono podem prejudicar o resultado para uma generalização dos resultados.\nAlém das limitações metodológicas na condução do estudo, o RCT é inviável ou antiético em inúmeros cenários de pesquisa causal. Existem fenômenos de interesse (como o efeito de eventos raros, exposições de longuíssimo prazo, ou variáveis não manipuláveis, como o status socioeconômico) onde a aleatoriedade é inatingíve. Mais gravemente, a randomização é anti-étic em exposições que são sabidamente prejudiciais. Por exemplo, seria moralmente inaceitável randomizar uma população para forçar um grupo a fumar a fim de analisar as chances de câncer de pulmão.\nPortanto, em contextos onde a intervenção não pode ser controlada por um RCT devido a impedimentos éticos ou práticos, os pesquisadores devem recorrer a outras ferramentas, como também é possível aplicar outros tipos de amostragens.\nExperimentos Condicionalmente Aleatórios\nEm amostras de tamanho limitado ou dependendo de cenários específicos, a aleatorização simples pode, por acaso, resultar em um desequilíbrio em covariáveis entre os grupos. Esse desequilíbrio pode levar a um viés de seleção e comprometer a validade interna do experimento. Para mitigar esse risco e equilibrar as características importantes na amostra, podemos utilizar métodos de Aleatorização Condicional. Um método mais simples e comumente utilizado, é a estratificação por covariáveis, isto é, dividir a população em subgrupos com base em que cada proporção e características sejam divididas entre o grupo de controle e tratamento. Ainda sim, há diversos outros meios.\nElementos do Poder Estatístico\n\nNo contexto de estudos experimentai, ainda estaremos trabalhando com testes de hipóteses, pois de fato estamos atuando com cenários nas quais queremos estudar. Isto implica que estamos ainda sujeitos a cometer erros estatísticos ao tomar uma decisão sobre a hipótese nula H0.\nErros do Tipo I e Tipo II\n\nErro do Tipo I (Falso Positivo):\nOcorre quando rejeitamos a H0 quando ela é, na verdade, verdadeira. A probabilidade de cometer um Erro Tipo I é controlada pelo nível de significância α. Comumente o valor de α é utilizado em 0,05, o que significa que aceitamos 5% de chance de concluir erroneamente que há um efeito.\n\n[!tip]\nNeste contexto, seria concluir que o tratamento teve um efeito quando, na realidade, a diferença observada foi devida puramente ao acaso.\n\nErro do Tipo II (Falso Negativo):\nOcorre quando falhamos em rejeitar a H0 quando ela é, na verdade, falsa. A probabilidade de cometer um Erro Tipo II é controlado pelo poder de teste, 1−β.\n\n[!tip]\nNeste contexto, seria concluir que o tratamento não teve um efeito (ou que não houve diferença significativa) quando, na realidade, ele teve um efeito real na população.\n\nAnálise de Poder Estatístico\nÉ fundamental que façamos uma análise do poder, pois permite determinar o tamanho de amostra necessário para detectar um efeito de determinado tamanho com uma probabilidade aceitável. Os quatro termos inter-relacionados nesta análise são:\n\nTamanho da Amostra: O número de observações incluídas no estudo. Um aumento na amostra geralmente aumenta o Poder do Teste.\nNível de Significância α: Se for diminuído (ex: de 0,05 para 0,01), a chance de um Falso Positivo diminui, mas a exigência para rejeitar H0 é maior, o que, por sua vez, diminuindo a sensibilidade do Poder do Teste (aumentando β).\nPoder do Teste (1−β): O poder de teste é a sensibilidade do estudo. Geralmente, o poder do teste é fixado em 0,80 (ou 80%), o que significa que se um efeito real existir, o estudo tem 80% de chance de detectá-lo.\nTamanho do Efeito (Effect Size - Cohen’s D) ou Efeito Mínimo Detectável (Minimum Detectable Effect - MDE): O Tamanho do Efeito é a magnitude da diferença ou relacionamento de interesse na população. O MDE é o menor tamanho de efeito que o estudo está equipado para detectar com as configurações de amostra, nível de significância e Poder do teste.\n\nRelação com o MDE:\n\nSe o MDE for muito alto (ex: 15%), o estudo é muito &quot;grosseiro&quot; e pode falhar em detectar efeitos menores, mas clinicamente ou economicamente relevantes (ex: 2%), resultando em um aumento da probabilidade do Erro Tipo II.\nPara reduzir o MDE e, assim, aumentar a sensibilidade do estudo a efeitos menores, é necessário **aumentar o Tamanho da Amostra N.\n\nO MDE não deve ser um número arbitrário; ele deve ser o menor efeito que é economicamente ou clinicamente relevante para a sua área. A Análise de Poder a Priori deve usar este MDE junto com o Poder e o Alpha para calcular o tamanho de amostra mínimo necessário. Se o tamanho da amostra for inviável para o MDE de interesse, o estudo deve ser repensado.\n\n[!tip]\nSegundo Ron Kovahi, se o MDE for menor que 5%, dificilmente você irá detectá-lo com confiança, junto ao fato da quantidade de amostras necessárias para verificar. O ideal será entre 5% a 10%.",
		"tags": [ "note"]
},

{
		"title": "6. DAG",
		"date":"Thu Dec 25 2025 17:13:13 GMT+0000 (Coordinated Universal Time)",
		"url":"/path-for-the-true-and-brave/causalidade/6-dag/",
		"content": "DAG\nO Modelo Gráfico Acíclico Direcionado (DAG) é uma ferramenta visual e matemática essencial na moderna teoria da inferência causal, especialmente em contextos observacionais onde experimentos são inviáveis ou antiéticos. Seu propósito principal é tornar explícitas as suposições causais: identificar caminhos que geram confusão, indicar quais variáveis devem ser ajustadas e orientar estratégias de identificação, como caminhos backdoor.\nFundamentos Estruturais\n\nNós (Variáveis): Cada nó no gráfico representa uma variável aleatória. A estrutura do DAG é definida com base na Independência Condicional entre as variáveis, que é o conceito-chave da moderna inferência causal. Ele permite traduzir as relações causais em restrições estatísticas testáveis. Na teoria dos conjuntos, o conceito de Probabilidade Condicional P(B|A) – que define a relação entre conjuntos de eventos – é análogo algebricamente a correlação parcial r(X,Y)Z que é usada em algoritmos de aprendizado de estrutura causal, como o Inductive Causality.\nArestas (Relações →): As setas indicam a direcionalidade da causalidade. A→B significa que A é uma causa direta de B. O DAG representa a Causalidade Regular, focada em graus mensuráveis (gradação) de causalidade, diferentemente da Causalidade Estrita (classificação 0 ou 1).\nAciclicidade (Não Cíclico): É a regra fundamental. Não pode haver um ciclo fechado (por exemplo, A→B e B→A). Isso impõe uma ordem temporal e causal clara, garantindo que o modelo seja computável para inferência.\n\nObjetivos\n\nVisualizar caminhos entre tratamento D e desfecho Y: o DAG expõe todos os caminhos (causais e não causais) que conectam D e Y, permitindo identificar fontes potenciais de viés.\n\nIdentificação de variáveis de confusão: Conseguir localizar variáveis que são causas tanto de D quanto de Y e, portanto, que precisam ser consideradas ao estimar o efeito causal.\n\nAplicar o critério do backdoor: ele fornece uma regra gráfica para encontrar conjuntos de variáveis que, se condicionados, bloqueiam todos os caminhos não causais entre D e Y, permitindo identificar o efeito causal de D em Y.\n\nUm caminho backdoor é um caminho entre D e Y que começa com uma seta apontando para D (exemplo: D←V→Y). Se esse caminho não for bloqueado, ele causa viés de confounding.\nAo controlar (condicionar) a variável V neste exemplo, o caminho traseiro é bloqueado, e a associação restante entre D e Y pode ser interpretada como o efeito causal de D em Y.\n\n[!tip]\nIdentificação Causal via Backdoor: O objetivo do ajuste de backdoor é simular uma intervenção física (o operador do(x)) usando apenas dados observacionais. Ao bloquear os caminhos backdoor, eliminamos a &quot;contaminação&quot; das associações espúrias, permitindo que a correlação restante seja interpretada como o efeito causal puro, aproximando o estudo observacional dos resultados de um Experimento Controlado Aleatorizado (RCT).\n\nEm essência, enquanto o RCT tenta eliminar os vieses por meio da randomização no design do estudo, o DAG ajuda a identificar e bloquear os confoundings por meio de ajustes na análise dos dados observacionais.\nD-Separação\nA d‑separação é o critério gráfico que determina se um conjunto Z bloqueia todos os caminhos entre X e Y, implicando X⊥⊥Y|Z. Regras essenciais sobre bloqueio de um caminho:\n\nCadeia, garfo ou causa comum (X→V→Y ou X←V→Y): o caminho é bloqueado se o nó intermediário (B) estiver condicionado.\nUm colisor ou efeito comum (X→V←Y): o caminho é bloqueado se o colisor B NÃO for condicionado; condicionar o colisor (ou um de seus descendentes) abre o caminho (isto é, cria dependência).\n\nSe todo caminho entre X e Y for bloqueado por Z, então X e Y são d‑separados por Z no gráfico.\n\n[!tip]\nExemplo: A afirmação de que X e Y são d-separados por Z - X⊥⊥Y|Z - é testada em dados usando correlação parcial ou independência condicional. A correlação parcial entre X e Y dado Z, ρXY⋅Z, representa a correlação entre os resíduos de uma regressão de X em Z e os resíduos de uma regressão de Y em Z. Um valor próximo de zero para ρXY⋅Z corrobora a independência e, portanto, a d-separação.\n\nEstatística Psicobio II 2024 #24 - DAG II Directed Acyclic Graphs - d' separation; algoritmo PC e IC\n\nTermos de Classificação\n\nEstatística Psicobio II 2024 #25 - DAG III - Aplicações do DAG, Propensity Scores e diff-n-diff\nEm um DAG, as variáveis podem ser caracterizadas pela sua posição relativa à Exposiçãoe ao Desfecho. Abaixo os tipos mais relevantes e as ações práticas recomendadas.\nTipos de Variáveis\n\nConfundidor (confusão)\nUm ancestral tanto da exposição quanto do desfecho.\n\nCria um caminho não causal entre X e Y, distorcendo o verdadeiro efeito de X sobre Y.\nAção: É uma variável que devemos condicionar para fechar o caminho de confusão e obter uma estimativa não enviesada do efeito causal.\nEstrutura: X←V→Y\n\nMediador\nUm descendente da Exposição e um antecedente do Desfecho.\n\nFunção: Explica o mecanismo pelo qual X afeta Y, estando no caminho causal de interesse.\nAção: Não devemos condicionar a variável mediadora se nosso objetivo é estimar o efeito total de X sobre Y. Condicionar V nos daria apenas o efeito direto de X sobre Y.\nEstrutura: X→V→Y\n\nColisor\n\nUm descendente tanto da Exposição quanto do Desfecho\nFunção: Por si só, não cria viés. O viés é induzid apenas quando condicionamos (incluímos na análise) o Colisor.\nAção: Não devemos condicionar o colisor. Condicionar um Colisor abre um caminho de viés, levando ao fenômeno chamado viés de seleção ou viés do colisor.\nEstrutura: X→V←Y",
		"tags": ["24", "25", "note"]
},

{
		"title": "7. Regressão Linear",
		"date":"Thu Dec 25 2025 17:13:13 GMT+0000 (Coordinated Universal Time)",
		"url":"/path-for-the-true-and-brave/causalidade/7-regressao-linear/",
		"content": "Regressão Linear\nModelos de regressão linear têm ampla aplicabilidade na inferência causal. Pelo método dos mínimos quadrados ordinários (MQO), conseguimos estimar parâmetros que, sob suposições apropriadas, têm interpretação causal.\nDada uma relação simples Y ~ X + ε, podemos estimar o efeito de X sobre Y pelas estimativas MQO, β^0 e β^1.\n\n[!tip]\nO coeficiente β^0 pode ser interpretado como o valor esperado de Y quando X=0 (e quando todas as outras variáveis no modelo são zero).\n\nAtenção: essa interpretação só é útil quando X = 0 é um valor plausível/observado.\n\n[!tip]\nEm um estudo com grupo de controle e tratamento (X indica tratamento), β^0 é a média do grupo controle e β^1 é a diferença média (efeito médio) entre tratamento e controle — desde que as suposições de identificação sejam satisfeitas.\n\nO coeficiente β^1 representa a variação média esperada em Y resultante de um aumento unitário em X, mantendo constantes as demais covariáveis do modelo.\n\nSe X for a variável de tratamento e for contínua, β^1 é a variação média de Y associada a um aumento unitário em X (sob suposições causais).\nSe X for uma dummy de tratamento e as suposições de identificação forem plausíveis, β^1 pode ser interpretado como o Efeito Médio do Tratamento (ATE ou ATT dependendo da população condicionada). Se Y for binário e você usar um modelo linear de probabilidade, β^1 aproxima o efeito médio (ATE) sob ignorabilidade, mas tem limitações (valores previstos fora de [0,1], heterocedasticidade). Para resultados binários, usar regressão logística.\n\n[!tip] 💡\nÉ crucial controlar variáveis de confusão. Se omitirmos variáveis que influenciam tanto X quanto Y, seu efeito será absorvido no termo de erro e incorretamente atribuído a X, gerando viés de variável omitida. Em caso de dúvida sobre quais tipos de variáveis vale a pena controlar, veja este paper, se baseando no DAG: A Crash Course in Good and Bad Controls\n\nO Trade-off entre Viés e Variância\nEntretanto, condicionar (ou incluir) covariáveis irrelevantes ou em excesso no modelo pode introduzir um risco: o aumento da variância do estimador de β^1.\nO aumento na variância ocorre frequentemente devido à multicolinearidade e significa que as estimativas de β^1 serão menos precisas. Isso resulta em intervalos de confiança mais amplo, tornando mais difícil rejeitar a hipótese nula e obter um resultado estatisticamente significativo.\nTeorema Frisch‑Waugh‑Lovell\nOutra forma de observamos isso, é entendermos melhor o funcionamento do teorema Teorema Frisch-Waugh-Lovell (FWL).\nEle demonstra que o coeficiente de X em uma regressão múltipla Y ~ X + Z é igual ao coeficiente obtido ao regressar os resíduos de Y sobre Z nos resíduos de X sobre Z. Em termos práticos, isso significa que a contribuição de cada regressora pode ser entendida como a associação entre as partes de Y e X que não são explicadas por Z. Isto pode ser dividido em três etapas\n\nDesviesamento (Debiasing Step)\n\nRemover o viés das variáveis de controle Z da sua variável de interesse X.\nRegredimos a variável de tratamento X nas covariáveis de controle Z, (ex: X∼Z)\nColetamos os resíduos dessa regressão X~. Estes resíduos representam a parte de X que é ortogonal (não correlacionada) aos controles Z.\n\nRemoção de Ruído (Denoising Step)\n\nRemover o ruído das variáveis de controle Z da sua variável dependente Y.\nRegredimos a variável dependente Y nas mesmas covariáveis de controle Z, (ex: Y∼Z)\nColetamos os resíduos dessa regressão Y~. Estes resíduos representam a parte de Y que é independente dos controles Z.\n\nRegressão Final\n\nA estimativa final do efeito causal β^1 é obtida regredindo o resíduo da variável dependente no resíduo da variável de tratamento: Y~∼X~.\nO β^ obtido nesta regressão de resíduos é idêntico ao β^1 da regressão original Y∼X+Z.\n\nUma melhor explicação sobre este tema pode ser encontrada no livro Causal Inference in Python: Applying Causal Inference in the Tech Industry, de Matheus Facure.\nPara ver os exemplos via código, é só acessar aqui.\n\n[!tip]\nVale relembrarmos, que para atuação de dados categoricos - ou discretizações de valores númericos que queremos atuar como - necessitamos transformá-los como variável Dummy. Para cada coluna, é necessário transformá-lo em uma covariável de 0 ou 1. Assim, o modelo de Regressão irá comportar cada categoria como uma linha adversa, se comportando como uma categoria a parte ao outcome que queremos observar. Utilizando Pandas, podemos utilizar o pd.get_dummies. Via modelagem statsmodels, basta dentro da formula ao ols, inserirmos como outcome ~ C(Variable).\n\n[!tip]\nLembrete: a regressão linear assume que a relação entre as regressoras e o resultado (condicional) é linear. Se a relação verdadeira for não linear, a especificação linear pode provocar viés de especificação. É importante verificar se isso ocorre, especialmente entre a variável de tratamento e o desfecho; caso ocorra, podemos aplicar transformações adequadas, por exemplo: logaritmos, termos polinomiais, interações ou transformações multiplicativas.\n\nSpline\nNo contexto de variáveis de controle com relação não linear, podemos modelar via Spline. Desta forma, o modelo consegue se convergir, conseguindo observar melhor a intervenção.\nimport numpy as np\nimport pandas as pd\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\nfrom scipy.special import expit # Equivalente ao plogis (inverse logit)\nimport matplotlib.pyplot as plt\n\n# 1. Funções de Simulação ----\ndef sim_data(n=250, beta_trt=1.5, z1_mean=5, z1_sd=2,\nz2_size=1, z2_prob=0.5, z1_on_x=0.05,\nz2_on_x=0.2, z1_on_y=0.5, z2_on_y=0.3):\n\n# Criando o DataFrame\nz1 = np.random.normal(z1_mean, z1_sd, n)\nz2 = np.random.binomial(z2_size, z2_prob, n)\n\nprob = expit(z1_on_x * z1 + z2_on_x * z2)\nx = np.random.binomial(1, prob, n)\n\n# Gerando Y (Linear por padrão, vamos alterar depois)\ny = beta_trt * x + z1_on_y * z1 + z2_on_y * z2 + np.random.normal(0, 1, n)\n\nreturn pd.DataFrame({'x': x, 'y': y, 'z1': z1, 'z2': z2})\n\n# 2. Gerando Dados Não-Lineares ----\nnp.random.seed(456)\ndf = sim_data()\n# Alterando y para ter relação não-linear com z1 (z1^3 + z1)\ndf['y'] = 1.5 * df['x'] + (df['z1']**3) + df['z1'] + df['z2'] + np.random.normal(0, 1, 250)\n\n# 3. Ajustando Modelos ----\n\n# Modelo 1: Apenas termos lineares\nmod1 = smf.ols(&quot;y ~ x + z1 + z2&quot;, data=df).fit()\nprint(&quot;--- Modelo 1: Linear ---&quot;)\nprint(mod1.summary().tables[1])\n\n# Modelo 2: Usando Natural Splines (cr() ou bs())\n# O patsy usa cr() para cubics splines ou você pode importar splines.\n# Para Natural Splines igual ao R, usamos 'cr' ou instalamos dmetar/patsy extensões.\n# O termo cr(z1, df=4) é o mais próximo do ns(z1, 4)\nmod2 = smf.ols(&quot;y ~ x + cr(z1, df=4) + z2&quot;, data=df).fit()\nprint(&quot;\\n--- Modelo 2: Splines ---&quot;)\nprint(mod2.summary().tables[1])\n\n# 4. Verificação de Performance (Bonus) ----\n# Python não tem uma biblioteca idêntica ao 'performance' do R em um único comando,\n# mas podemos checar os resíduos manualmente.\n\ndef check_predictions(model, title):\nplt.figure(figsize=(8, 5))\nplt.hist(model.model.endog, alpha=0.5, label='Realidade', bins=30)\nplt.hist(model.fittedvalues, alpha=0.5, label='Predição', bins=30)\nplt.title(f&quot;Check Predictions: {title}&quot;)\nplt.legend()\nplt.show()\n\ncheck_predictions(mod1, &quot;Modelo Linear&quot;)\ncheck_predictions(mod2, &quot;Modelo com Splines&quot;)\n\nRegressão Linear como Modelo para Potenciais Outcome\nOutra possibilidade de utilizar a regressão linear, é atuar como um modelo de imputação de potenciais resultados. Isto quer dizer que conseguimos estimar os efeitos causais, seja ATE ou ATT, preechendo valores contrafactuais.\nA lógica reside na capacidade da regressão de modelar as funções de resultado potencial:E[Y0|X] e E[Y1|X].\nEfeito de Tratamento Médio (ATE)\n\n[!tip]\nRelembrando! O ATE é calculado como a diferença média entre o que toda a população teria se fosse tratada E^[Y1|Xi] e o que toda a população teria se não fosse tratada E^[Y0|Xi]\n\nATE=1N∑i(E^[Y1|Xi]−E^[Y0|Xi])\n\nOnde E^[Y0|Xi] e E^[Y1|Xi] são modelos de regressão ajustados, respectivamente, nas unidades de controle T=0 e nas unidades tratadas T=1.\n\nCálculo Simplificado com statsmodels\nEm um modelo de regressão linear que inclui covariáveis X, o estimador do ATE é equivalente ao coeficiente da variável de tratamento T.\nSe o seu modelo é Y=β0+β1T+β2X+ϵ, a estimativa de β^1 é o ATE.\nPython\nformula_ate = 'Y ~ T + X1 + X2'\nmodel_ate = smf.ols(formula_ate, data=data).fit()\nate_estimate = model_ate.params['T']\n\nEfeito Médio de Tratamento nos Tratados (ATT)\n\n[!tip] 💡\nRelembrando! O ATT é a diferença média entre o resultado observado para o grupo tratado Yi e o seu resultado contrafactual imputado E^[Y0|Xi]\nATT=1N1∑i:Ti=1(Yi−E^[Y0|Xi])\nIsto significa que usamos o grupo de controle T=0 para construir o modelo que prevê o resultado potencial Y0.\n\nCálculo Simplificado com statsmodels\nmodel_mu0 = smf.ols('Y ~ X1 + X2', data=data[data['T'] == 0]).fit()\nimputed_y0 = model_mu0.predict(data[data['T'] == 1]) # Imputar o contrafactual, isto é, usar model_mu0 para prever o Y_0 para as unidades do grupo tratado T=1.\natt_estimate = (data[data['T'] == 1]['Y'] - imputed_y0).mean()",
		"tags": [ "note"]
},

{
		"title": "8. Viés",
		"date":"Thu Dec 25 2025 17:13:13 GMT+0000 (Coordinated Universal Time)",
		"url":"/path-for-the-true-and-brave/causalidade/8-vies/",
		"content": "Viés\nO viés ocorre porque a variável de confusão cria uma associação espúria (falsa) entre o Tratamento (a Causa, A) e o Resultado (o Efeito, B). Isso acontece quando o Tratamento e o Resultado compartilham uma causa comum (a variável de confusão, C).\nEm outras palavras, a variável de confusão (C) influencia:\n\nA probabilidade de receber o Tratamento (C→A).\nO Resultado de interesse (C→B).\n\nGraficamente, a relação espúria é representada no DAG (Modelo Gráfico Acíclico Direcionado) como um caminho backdoor: A←C→B\nSem controlar adequadamente (ajustar ou condicionar) essa variável, a nossa estimativa do efeito de A em B incluirá o efeito indireto de C em B, fazendo parecer que A tem um efeito maior (ou menor) do que realmente tem.\nViés de seleção\nOcorre quando os participantes de um estudo são sistematicamente diferentes dos não participantes por questões que não podemos controlar completamente.\nEndogeneidade &amp; Viés de variável omitida\nA Endogeneidade é um problema estatístico que ocorre quando a variável de tratamento (ou preditor incluído) X1 é correlacionada com o termo de erro do modelo.\nO Viés de Variável Omitida é uma forma comum de endogeneidade. Ele acontece quando uma variável relevante X2 é omitida do modelo de regressão, resultando em estimativas enviesadas do efeito do tratamento X1. O viés ocorre se e somente se a variável omitida X2 satisfizer duas condições:\n\nAfeta o resultado Y\nTem correlação com a variável de tratamento X1\n\nIsto ocorre pois os efeitos das variáveis de confusão estarão correlacionadas com o termo de erro do modelo, pois o estimador de Mínimos Quadrados Ordinários (MQO) se torna viesado e inconsistente, o que significa que as estimativas dos coeficientes não representam o verdadeiro efeito causal entre as variáveis.\n\n[!tip]\nUma análise rápida de verificar uma variável de confusão sob isso é durante a análise exploratória utilizando pairplot da biblioteca Seaborn.\nNela, conseguiremos ver se há uma correlação forte das covariáveis com o tratamento.\nsns.pairplot(data[[&quot;T&quot;, &quot;C1&quot;, &quot;C2&quot;, &quot;C3&quot;]], diag_kind=&quot;hist&quot;)\n\nDerivação do Estimador de Mínimos Quadrados Ordinários (MQO)\nModelo verdadeiro Y=β0+β1X1+β2X2+u, onde E[u]=0 e Cov(u,X1)=Cov(u,X2)=0\nSuponha que estimemos por MQO apenas Y sobre X1 (isto é, omitimos X2). O estimador de MQO para o coeficiente de X1 na regressão simples é α1=Cov(Y,X1)Var(X1).\nSubstituindo o modelo verdadeiro em Cov(Y,X1): Cov(Y,X1)=Cov(β0+β1X1+β2X2+u,;X1)=β1Var(X1)+β2Cov(X2,X1)+Cov(u,X1)\nAssumindo (Cov(u,X1)=0), temos: α1=β1+β2Cov(X2,X1)Var(X1)\nPortanto, o valor esperado do estimador é E[α1]=β1+β2Cov(X2,X1)Var(X1).\nO termo adicional β2Cov(X2,X1)Var(X1) é o viés por omissão. Ele será diferente de zero sempre que:\n\nβ2≠0 (ou seja, X2 afeta Y) e\nCov(X2,X1)≠0 (ou seja, X2 está correlacionada com X1).\n\nEm outras palavras: se X2 é relevante para Y e está correlacionada com X1, então ao omiti-la o efeito de X2 é parcialmente atribuído a X1, enviesando α1.",
		"tags": [ "note"]
},

{
		"title": "9. Escore de Propensão",
		"date":"Thu Dec 25 2025 17:13:13 GMT+0000 (Coordinated Universal Time)",
		"url":"/path-for-the-true-and-brave/causalidade/9-escore-de-propensao/",
		"content": "Escore de Propensão\nNo contexto de inferência causal, podemos ter dois cenários: estudos experimentais, onde há controle da randomização por meio de RCTs e, por consequência, melhor controle dos confundidores; e estudos observacionais, onde não controlamos como os dados foram obtidos, podendo haver viés(es). Para esse último contexto, devemos, de alguma forma, simular a randomização. Em outras palavras, controlar vieses que possam prejudicar o estudo. Um dos métodos que podemos utilizar, o escore de propensão (Propensity Score), que serve para aproximar condições de randomização em estudos observacionais, nos quais a alocação do tratamento não é aleatória e os dados já foram coletados. Nesse cenário não há controle das diferenças entre os grupos de tratamento e controle, o que pode gerar viés por variáveis de confusão.\n\n[!tip]\nExemplos comuns para utilizarmos o escore de propensão:\n\nViés de Seleção: Pessoas que escolhem receber um tratamento são fundamentalmente diferentes daquelas que não o recebem.\n\nExemplo: Indivíduos mais saudáveis ou mais ricos podem ter maior acesso ou propensão a um novo medicamento.\n\nNoncompliance: Mesmo em ensaios clínicos, se houver falta de adesão total ao tratamento, o efeito causal (como o ATE ou ATT) calculado diretamente pode estar enviesado, comprometendo os resultados e sua interpretabilidade.\n\nA definição formal é:\ne(X)=P(T=1|X)Onde T é a variável de tratamento e X covariáveis.\nAo condicionarmos nas covariáveis, o escore de propensão controla as variáveis de confusão, ajudando a alcançarmos a independência condicional — o tratamento T torna-se independente do resultado potencial, desde que se condicione no escore de propensão, T⊥Yt|e(X).\n\n[!tip] 💡\nO Escore de Propensão é uma ferramenta também conhecida para redução de dimensionalidade. Em vez de ter que controlar dezenas de covariáveis X diretamente na análise de resultado, podemos simplesmente controlar o escore e(X).\n\n[!tip] 💡\nO conceito do Escore de Propensão é estritamente aplicado a tratamentos binários (discretizados ou dicotômicos: Sim/Não). Para tratamentos contínuos, um método utilizado é o Generalized Propensity Score (GPS), aonde modela envolta a densidade condicional, ao invés da probabilidade condicional.\n\nImportante destacar, que ainda sim, precisamos que as premissas de ignorabilidade, positividade e SUTVA devem ser respeitadas antes de aplicar. Relembrando que comentei sobre esse tema em <a class=\"internal-link\" target=\"\" data-note-icon=\"undefined\" href=\"/path-for-the-true-and-brave/causalidade/5-design-de-experimentos/\">5. Design de Experimentos</a>.\nPara utilizarmos o score de propensão, basta regredirmos a intervenção com suas covariáveis em uma regressão logística. Seu resultado, final, seria a probabilidade de uma unidade receber o tratamento condicional às covariáveis pré‑tratamento X.\nExemplo (Causal Inference in Python: Applying Causal Inference in the Tech Industry\nimport statsmodels.formula.api as smf\n\n# 1. Estimar o Escore de Propensão\nps_model = smf.logit(&quot;&quot;&quot;intervention ~\ntenure + last_engagement_score + department_score\n+ C(n_of_reports) + C(gender) + C(role)&quot;&quot;&quot;, data=df).fit(disp=0)\n\n# 2. Adicionar o Escore de Propensão como nova coluna\ndata_ps = df.assign(\npropensity_score = ps_model.predict(df),\n)\n\ndata_ps[[&quot;intervention&quot;, &quot;engagement_score&quot;, &quot;propensity_score&quot;]].head()\n\n# 3. Estimar o Efeito Causal usando o Escore de Propensão como covariável\nmodel = smf.ols(&quot;engagement_score ~ intervention + propensity_score&quot;,\ndata=data_ps).fit()\n\n# O coeficiente 'intervention' neste modelo representa o ATE ajustado pelo escore de propensão\nprint(&quot;ATE Ajustado por Escore de Propensão:&quot;, model.params[&quot;intervention&quot;])\n\nPonderação por Escore de Propensão Inverso\nUma vez tendo esse score, podemos estimar o efeito médio de tratamento. Uma das formas que podemos é por Ponderação por Score de Propensão Inverso (IPW).\nA ideia de IPW é reponderar a sua amostra para criar uma pseudo-população onde a distribuição das variáveis de confusão X é a mesma nos grupos de tratamento T=1 e controle T=0. Isto imita as condições de um ensaio aleatório. O peso W atribuído a cada indivíduo é o inverso da probabilidade de o indivíduo ter recebido o tratamento que realmente recebeu. Essa probabilidade é o Escore de Propensão e^(x). Utilizando desta forma, estimamos um ATE em uma população observacional e você quiser criar uma pseudo‑população em que o tratamento é independente das covariáveis observadas.\n\n[!tip]\nUnidades Incomuns (Alto Peso):\n\nUnidades que receberam um tratamento improvável (e.g., alto risco de rotatividade, mas não receberam o treino) recebem um peso alto.\n\nIsso os torna mais representativos da população em geral, essencialmente forçando um balanceamento da amostra.\n\nUnidades Comuns (Baixo Peso):\n\nUnidades que receberam um tratamento provável recebem um peso baixo.\n\nO peso para cada unidade Wi é calculado da seguinte forma, onde Ti é o tratamento real recebido:\nWi=1P(Ti|Xi)={1e^(xi)se Ti=111−e^(xi)se Ti=0\n[!tip] 💡\nAo dar um peso alto a unidades tratadas que parecem unidades de controle, e unidades de controle que parecem unidades tratadas, o método garante que o grupo de tratamento e o grupo de controle na pseudo-população sejam comparáveis.\n\nExemplo (Causal Inference in Python: Applying Causal Inference in the Tech Industry\néééEfeito Causal=(Média ponderada do resultadose todos fossem tratados)−(Média ponderada do resultadose ninguém fosse tratado)# 1. Calcular os pesos IPW para cada grupo\nweight_t = 1 / data_ps.query(&quot;intervention == 1&quot;)[&quot;propensity_score&quot;]\nweight_nt = 1 / (1 - data_ps.query(&quot;intervention == 0&quot;)[&quot;propensity_score&quot;])\n\n# 2. Obter os resultados (engagement_score) por grupo\nt1 = data_ps.query(&quot;intervention == 1&quot;)[&quot;engagement_score&quot;]\nt0 = data_ps.query(&quot;intervention == 0&quot;)[&quot;engagement_score&quot;]\n\n# 3. Estimar o Resultado Potencial Médio (E[Y^t])\ny1_num = sum(t1 * weight_t) # Numerador: Somatório (Y * W) para T=1\ny1_den = sum(weight_t) # Denominador: Somatório (W) para T=1\ny1 = y1_num / y1_den\n\ny0_num = sum(t0 * weight_nt) # Numerador: Somatório (Y * W) para T=0\ny0_den = sum(weight_nt) # Denominador: Somatório (W) para T=0\ny0 = y0_num / y0_den\n\nprint(&quot;E[Y1] (Tratado):&quot;, y1)\nprint(&quot;E[Y0] (Controle):&quot;, y0)\nprint(&quot;ATE:&quot;, y1 - y0)\n\nEstimativa Duplamente Robusta\nO Escore de Propensão e(X) e a Ponderação por Escore de Propensão Inverso (IPW) são ferramentas para controlar variáveis de confusão e simular a randomização em dados observacionais. O IPW, em particular, é um estimador baseado em design que se foca em balancear os grupos.\nEntretanto, uma preocupação comum em inferência causal é a especificação incorreta dos modelos. E se o modelo que usamos para calcular o Escore de Propensão estiver errado? Isso nos leva à busca por estimadores mais resilientes.\nO Conceito &quot;Duplamente Robusto&quot;\nUm estimador é considerado Duplamente Robusto (Double Robust - DR) se a estimativa do efeito causal for consistente (ou seja, convergirá para o verdadeiro efeito causal) se:\n\nO modelo para o Escore de Propensão estiver corretamente especificado.\nOU\nO modelo para o outcome potencial que estima estiver corretamente especificado.\n\nEm outras palavras, o estimador DR converge para o modelo que estiver correto. Isso confere uma vantagem e aumenta a confiança na estimativa final, pois você só precisa acertar em um dos dois modelos. A ideia central é que o estimador utiliza ambos os modelos - por exemplo, IPW + Regressão Logística - para construir um estimador para o resultado potencial.\nUm estimador DR popular para o resultado potencial médio sob tratamento pode ser escrito como:\nμtDR(μ^,e^)=1N∑i=1N[μ^t(Xi)+Ti−e^(Xi)e^(Xi)(Yi−μ^t(Xi))]Onde:\n\nYi é o resultado observado.\nTi é a variável de tratamento.\nμ^t(Xi) é a previsão do resultado Y pelo modelo, assumindo o tratamento t\ne^(Xi) é o Escore de Propensão.\n\nSe o Escore de Propensão estiver correto:\nO termo Ti−e^(Xi)e^(Xi) tenderá a zero na média, e o segundo termo todo se anulará.\nIsto deixa apenas o primeiro termo, 1N∑i=1Nμ^t(Xi), que converge para a estimativa do resultado do modelo. Neste caso, a estimativa DR se comporta como um estimador design-based.\nSe o modelo estiver correto:\nO segundo termo, (Yi−μ^t(Xi)), tenderá a zero na média, pois μ^t(Xi) é uma previsão precisa de Yi.\nA estimativa DR converge para um estimador outcome-based que se baseia primariamente no modelo.",
		"tags": [ "note"]
},

{
		"title": "Inferência Causal",
		"date":"Thu Dec 25 2025 17:13:13 GMT+0000 (Coordinated Universal Time)",
		"url":"/path-for-the-true-and-brave/causalidade/inferencia-causal/",
		"content": "<a class=\"internal-link\" target=\"\" data-note-icon=\"undefined\" href=\"/path-for-the-true-and-brave/causalidade/0-roadmap/\">0. Roadmap</a>\n<a class=\"internal-link\" target=\"\" data-note-icon=\"undefined\" href=\"/path-for-the-true-and-brave/causalidade/1-epifanias/\">1. Epifanias</a>\n<a class=\"internal-link\" target=\"\" data-note-icon=\"undefined\" href=\"/path-for-the-true-and-brave/causalidade/2-como-predicao-e-inferencia-causal-se-conversam/\">2. Como Predição e Inferência Causal se Conversam</a>\n<a class=\"internal-link\" target=\"\" data-note-icon=\"undefined\" href=\"/path-for-the-true-and-brave/causalidade/3-teorias-da-causalidade/\">3. Teorias da Causalidade</a>\n<a class=\"internal-link\" target=\"\" data-note-icon=\"undefined\" href=\"/path-for-the-true-and-brave/causalidade/4-escada-da-causacao/\">4. Escada da Causação</a>\n<a class=\"internal-link\" target=\"\" data-note-icon=\"undefined\" href=\"/path-for-the-true-and-brave/causalidade/5-design-de-experimentos/\">5. Design de Experimentos</a>\n<a class=\"internal-link\" target=\"\" data-note-icon=\"undefined\" href=\"/path-for-the-true-and-brave/causalidade/6-dag/\">6. DAG</a>\n<a class=\"internal-link\" target=\"\" data-note-icon=\"undefined\" href=\"/path-for-the-true-and-brave/causalidade/7-regressao-linear/\">7. Regressão Linear</a>\n<a class=\"internal-link\" target=\"\" data-note-icon=\"undefined\" href=\"/path-for-the-true-and-brave/causalidade/8-vies/\">8. Viés</a>\n<a class=\"internal-link\" target=\"\" data-note-icon=\"undefined\" href=\"/path-for-the-true-and-brave/causalidade/9-escore-de-propensao/\">9. Escore de Propensão</a>\n<a class=\"internal-link\" target=\"\" data-note-icon=\"undefined\" href=\"/path-for-the-true-and-brave/causalidade/10-efeitos-heterogeneos/\">10. Efeitos Heterogêneos</a>\n<a class=\"internal-link\" target=\"\" data-note-icon=\"undefined\" href=\"/path-for-the-true-and-brave/causalidade/12-double-machine-learning/\">12. Double Machine Learning</a>\n<a class=\"internal-link\" target=\"\" data-note-icon=\"undefined\" href=\"/path-for-the-true-and-brave/causalidade/13-guia-de-equivocos/\">13. Guia de Equívocos</a>\n<a class=\"internal-link\" target=\"\" data-note-icon=\"undefined\" href=\"/path-for-the-true-and-brave/causalidade/14-gen-ai/\">14. GenAI</a>",
		"tags": [ "note"]
},

{
		"title": "Digital Garden Home",
		"date":"Thu Dec 25 2025 17:13:13 GMT+0000 (Coordinated Universal Time)",
		"url":"/",
		"content": "<a class=\"internal-link\" target=\"\" data-note-icon=\"undefined\" href=\"/path-for-the-true-and-brave/causalidade/inferencia-causal/\">Inferência Causal</a>",
		"tags": [ "note","gardenEntry"]
}
]