[
{
		"title": "Digital Garden Home",
		"date":"Mon Jan 26 2026 12:43:12 GMT+0000 (Coordinated Universal Time)",
		"url":"/",
		"content": "<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/digital-garden/meu-modelo-conforme/text/meu-modelo-conforme/\">Meu Modelo Conforme</a>\n<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/digital-garden/path-for-the-true-and-brave/text/inferencia-causal/\">Inferência Causal</a>\nTinyshift",
		"tags": [ "note","gardenEntry"]
},

{
		"title": "1. Introdução",
		"date":"Mon Jan 26 2026 12:43:12 GMT+0000 (Coordinated Universal Time)",
		"url":"/digital-garden/meu-modelo-conforme/text/1-introducao/",
		"content": "Introdução\n\n[!note]\n&quot;The true measure of a man is not his intelligence or how high he rises in this freak establishment. No, the true measure of a man is this: how quickly can he respond to the needs of others and how much of himself he can give&quot; — Philip K. Dick\n\nOlá, meu nome é Lucas Leão, sou Cientista de Dados — ou pelo menos tento ser. Se você, assim como eu, já se sentiu estagnado e desejava se aperfeiçoar em alguma tecnologia ou teoria que só ouvia falar, saiba que estamos no mesmo barco. Para fins temporais, escrevo este texto em Dezembro 2023.\nDurante minha jornada criando modelos de Machine Learning, uma dúvida persistia: como posso ter mais confiança nos meus modelos? Não me entenda mal! Confio nas minhas habilidades, mas busco uma garantia extra na modelagem para evitar futuras dores de cabeça, tendo melhor noção sobre as incertezas das predições.\nSegundo o artigo Is there a role for statistics in artificial intelligence?, a quantificação de incerteza é frequentemente negligenciada em aplicações de inteligência artificial por dois motivos principais:\n\nFalsa crença de que &quot;Big Data&quot; automaticamente garante resultados exatos\nComplexidade dos métodos dificulta a criação de regiões de incerteza estatisticamente válidas\n\nNos últimos anos, surgiram diversas propostas para quantificar incerteza em modelos de Machine Learning e Deep Learning. No entanto, apenas o método de Previsão Conforme teve sua validade teórica comprovada, demonstrando intervalos de previsão que fornecem cobertura empírica efetiva para dados futuros — ou seja, um intervalo de previsão que de fato cobre valores futuros em (1 - α) das vezes.\nEste documento é um diário dessa jornada para explorar tanto a quantificação de incerteza quanto novos métodos de balanceamento de modelo. Nele, desenvolvi duas camadas adicionais ao modelo de RandomForestClassifier, atrelado ao meu objetivo de estudo. Se encontrar qualquer erro ou tiver sugestões de melhoria, por favor, mande-me um e-mail sem receio. Ficarei grato em revisar. Se estiver pensando em aplicar essa metodologia a outro problema, não hesite em me contatar. Valeu!\nGithub\n\nhttps://github.com/heylucasleao/tinycp",
		"tags": [ "note"]
},

{
		"title": "10. Classificador Conforme",
		"date":"Mon Jan 26 2026 12:43:12 GMT+0000 (Coordinated Universal Time)",
		"url":"/digital-garden/meu-modelo-conforme/text/10-classificador-conforme/",
		"content": "Classificador Conforme\nParabéns por chegar a este tópico. Agora, vamos explorar a síntese de todos os conceitos discutidos anteriormente e apresentar uma visão detalhada do modelo que criei. Certamente, pode haver conflitos conceituais. Caso ocorra, não tenha medo de me comunicar. Objetivo desse diário é demonstrar minha linha de pensamento, e como cheguei até aqui.\nO objetivo era desenvolver um modelo com alta adaptabilidade, flexibilidade e características específicas oferecidas pelo RandomForest, incluindo:\n\nCapacidade de processar dados de alta dimensionalidade e extrair correlações complexas.\nHabilidade de treinar modelos com dados de baixa frequência.\nRobustez no tratamento de conjuntos de dados desbalanceados.\nEficiência computacional, permitindo treinamento e inferência rápidas.\n\nAo incorporar a calibração conformal (Venn-Abers), o modelo alcança:\n\nRegulação precisa do score, transformando-o em uma medida verdadeiramente probabilística e mitigando riscos de overfitting.\nMaior confiabilidade nas previsões, essencial para aplicações críticas.\n\nA implementação da Previsão Conforme proporciona:\n\nAprimoramento significativo na interpretabilidade dos resultados do modelo.\nEstabelecimento de uma garantia de cobertura, permitindo controle preciso sobre a confiança do modelo.\nFlexibilidade na modelagem do intervalo de predição, adaptável a diferentes cenários.\nCapacidade de quantificar a incerteza das previsões.\n\nA integração de propriedades de Aprendizado Sensível ao Custo oferece:\n\nVersatilidade para lidar com diversos tipos de distribuições de dados.\nCalibração baseada no custo de erro e não somente performance.\nCapacidade de ajustar o modelo para minimizar custos em cenários assimétricos de erro.\n\nClassificador Conforme Binário\nUm diferencial que não mencionei é a utilização de uma ideia baseada nos artigos Venn Prediction for Survival Analysis e Efficient Venn predictors using random forests. Nessa abordagem, os dados não utilizados no treinamento de cada árvore, conhecidos como amostras OOB (Out-of-Bag), são empregados para gerar nossa cobertura. A ideia é que teremos uma representatividade populacional de cada arvore de decisão. Em teoria, isso elimina a necessidade de uma base de calibração separada. No entanto, neste caso, utilizo esses dados para outro propósito.\nÉ importante ressaltar também que transformo o conjunto de predições em uma única resposta: se o modelo tem certeza de que há apenas o rótulo verdadeiro ou não. Isso compromete a interpretabilidade do conjunto de predições do modelo. Conceitualmente, reconheço que isso pode ser questionável, mas o faço para obter flexibilidade na utilização do Aprendizado Sensível a Custo. Vale notar que internamente ainda é possível recuperar essa informação.\nCalibração do Valor α\nApós a criação do modelo conforme, ainda não há uma definição clara do valor α. Para determiná-lo, calibro para o melhor resultado da acurácia balanceada em um intervalo de 0.01 a 0.10. O objetivo é encontrar a melhor cobertura que permita ao modelo obter o menor custo de erro com uma garantia mínima de 90%. Haverá situações em que não há razão para reduzir α, possibilitando seu estreitamento, enquanto em outras, o modelo poderá ter uma eficiência melhor com um aumento desse valor.\n\n[!tip]\nAo unir os três tópicos e calibrar o α, estabelecemos um nível de significância que equilibra o custo entre falsos positivos e falsos negativos, evita overfitting e mantém uma distribuição representativa para a cobertura.\n\nAvaliação de Performance\nPara certificar que tudo ocorreu bem com o modelo, verifico seu performance com dados de validação utilizando uma função chamada evaluate. As métricas que ele retorna são:\n- &quot;total&quot;: A quantidade total de dados utilizados para avaliação.\n- &quot;alpha&quot;: O nível de significância estabelecido da cobertura.\n- &quot;empirical_coverage&quot;: A cobertura empírica dos conjuntos da Previsão Conforme.\n- &quot;one_c&quot;: A proporção de conjuntos de predição contendo exatamente um elemento.\n- &quot;avg_c&quot;: O tamanho médio dos conjuntos de predição.\n- &quot;empty&quot;: A proporção de conjuntos de predição vazios.\n- &quot;error&quot;: A taxa de erro de classificação.\n- &quot;log_loss&quot;: A perda logarítmica das predições.\n- &quot;ece&quot;: O erro de calibração esperado.\n- &quot;bm&quot;: O índice de informação do bookmaker.\n- &quot;mcc&quot;: O coeficiente de correlação de Matthews.\n- &quot;f1&quot;: O F1-Score\n- &quot;fpr&quot;: A taxa de falsos positivos.\n\nDistribuição Beta\n\nA distribuição Beta é uma distribuição de probabilidade contínua no intervalo [0, 1], ideal para observar e quantificar a incerteza na probabilidade do modelo. Sua função de densidade de probabilidade é definida por dois parâmetros α e β, que controlam a forma da distribuição e permitem modelar diferentes tipos de incerteza probabilística. É importante destacar que, devido ao rigor da Previsão Conforme, a cobertura segue naturalmente essa distribuição, assegurando a confiabilidade do modelo. Embora não seja estritamente necessário analisar a Beta especificamente para este fim, não discrimino o uso para análises posteriores, como nos testes A/B.\nReferência de meu Projeto\nhttps://github.com/HeyLucasLeao/cp-study/blob/master/cp.ipynb",
		"tags": [ "note"]
},

{
		"title": "11. Referências",
		"date":"Mon Jan 26 2026 12:43:12 GMT+0000 (Coordinated Universal Time)",
		"url":"/digital-garden/meu-modelo-conforme/text/11-referencias/",
		"content": "Referências\n\nInterpretable Uncertainty\nUnlocking Reliable Machine Learning: Conformal Prediction by Valery Manokhin\nDistribution-Free Uncertainty Quantification\nUncertainty Quantification: Enter Conformal Predictors\nUnderstanding, Generating, and Evaluating Prediction Intervals\nIntroduction To Conformal Prediction With Python: A Short Guide For Quantifying Uncertainty Of Machine Learning Models\nA Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification\nPractical Guide to Applied Conformal Prediction in Python: Learn and apply the best uncertainty frameworks to your industry applications\nUma Introdução Prática à Previsão Conforme\nCalibrando Modelos de Classificação Binária com Previsão Conforme\nAplicando Previsão Conforme em Modelos de Classificação\nHow to calibrate your classifier in an intelligent way using Venn-Abers Conformal Prediction\nWeek #4: Overview Of Conformal Predictors\nWeek #2: Intuition Behind Conformal Prediction\nWeek #1: Getting Started With Conformal Prediction For Classification\nConformal Prediction: Prediction with guaranteed performance\nIsotonic Regression : Another Level of Regression Method\nExpected Calibration Error (ECE): A Step-by-Step Visual Explanation\nConformal prediction for classification",
		"tags": ["4", "2", "1", "note"]
},

{
		"title": "12. Regressão",
		"date":"Mon Jan 26 2026 12:43:12 GMT+0000 (Coordinated Universal Time)",
		"url":"/digital-garden/meu-modelo-conforme/text/12-regressao/",
		"content": "Regressão\n\nUnd,erstanding, Generating, and Evaluating Prediction Intervals\nNa predição, estimamos resultados com base em dados históricos, assumindo que padrões passados podem nos ajudar a prever o futuro — sempre considerando um grau de incerteza. Na regressão, buscamos estimar um ponto específico. Por exemplo, na regressão linear, projetamos uma linha baseada em valores médios para obter o resultado desejado. Porém, estatisticamente, isso nos diz pouco: qual é o nível de incerteza do modelo? Que garantia temos de que minha casa realmente vale R$535.295?\nEm 1937, Jerzy Neyman introduziu o conceito de intervalos de confiança, argumentando que determinar um valor exato para um parâmetro populacional baseado em amostras tem utilidade limitada. É mais valioso estabelecer um intervalo de valores possíveis, com um nível de confiança definido de que o valor real esteja contido nele. Assim, podemos avaliar o grau de incerteza ao estimar um parâmetro. No contexto de previsão, este conceito é bastante relevante. A variabilidade e incerteza, sejam aleatórias ou epistêmicas, frequentemente dificultam a representação de todos os cenários possíveis. Por isso, quantificar a incerteza do modelo pode ser mais útil do que simplesmente fornecer um ponto médio. É aqui que entra a regressão quantílica: em vez de estimar um ponto médio, ela estima via quantil — o que é mais representativo para distribuições adversas de dados no dia a dia — permitindo-nos estimar duas previsões e utilizá-las como intervalo.\n\nLinear vs. Quantile Regression\n\nLinear vs. Quantile Regression\nEntretanto, a regressão quantílica não oferece garantia estatística de cobertura da previsão. Embora seja mais informativa, falta essa garantia formal. É nesse contexto que a previsão conforme se torna valiosa. Por exemplo, em vez de afirmar que minha casa vale R$535.295, posso apresentar um intervalo com 95% de confiança: entre R$515.629 e R$545.800. Mesmo sem um valor exato, tenho uma margem confiável do possível valor da casa e sei em qual faixa o modelo está seguro. Considere outro cenário: e se o intervalo fosse de R$480.000 a R$800.000? Tal amplitude indicaria claramente um problema no resultado. Seriam as características da minha casa que dificultam a previsão? A região onde moro influencia os preços? Ou o modelo está simplesmente incorreto? Todas essas análises se tornam possíveis ao examinar a amplitude do intervalo — algo que um valor pontual estimado jamais nos permitiria.\nApós a criação do método de Previsão Conforme para classificação na minha biblioteca, aprendi muito sobre o método e o tema em geral. Com isso, decidi expandir o projeto, oferecendo suporte contínuo à biblioteca. Para aprofundar meu entendimento, implementei dois métodos de regressão usando ICP simples via divisão de dados de treino e calibração: o ConformalizedRegression e o ConformalizedQuantileRegression.\n\nA diferença maior é que ConformalizedRegression aceita um modelo de regressão normal baseado no scikit-learn , e o ConformalizedQuantileRegression(CQR), que aceita modelos que preditam intervalos quantílicos, baseado no quantile-forest . A razão disso é que originalmente, a regressão conforme foi introduzida criando intervalos com a previsão estimada do modelo. O único problema que devido a forma desse treino, é que o modelo original não é capaz de ser tão adaptivo com a distribuição dos dados, tornando o intervalo da previsão menos abrangente. Para sanar isso, o ConformalizedQuantileRegressor se torna melhor para essas previsões, devido ao modelo utiliza ser um modelo quantil que predita um intervalo de previsão, identificando intervalos mais adaptativos entre os dados. E sim, ambos aceitam geração da cobertura baseado em Out-Of-Bag (OOB).\n\nTheoretical Foundations of Conformal Prediction",
		"tags": [ "note"]
},

{
		"title": "2. Antes de Começarmos…",
		"date":"Mon Jan 26 2026 12:43:12 GMT+0000 (Coordinated Universal Time)",
		"url":"/digital-garden/meu-modelo-conforme/text/2-antes-de-comecarmos/",
		"content": "Antes de começarmos...\nA Importância da Incerteza\nAntes de mais nada, queria compartilhar uma reflexão importante. Minha jornada com ciência de dados me fez perceber algo interessante: quanto mais me aprofundava nesse campo, mais distante ficava do pensamento estatístico tradicional. A razão? A estatística trabalha fundamentalmente com a ótica da incerteza e nossa compreensão das limitações dos resultados.\nSegundo o artigo Importance of being uncertain:\n\nA estatística nos ajuda a responder esta questão. Ela nos fornece uma maneira de modelar quantitativamente o papel do acaso em nossos experimentos e representar dados não como medições precisas, mas como estimativas com erro. Também nos mostra como o erro em valores de entrada se propaga através dos cálculos. A aplicação prática deste framework teórico é associar incerteza ao resultado dos experimentos e atribuir níveis de confiança a afirmações que generalizam além das observações.\n\nPercebi que estava sempre focando no acerto, e não no erro! Pode parecer uma reflexão simples, mas isso muda totalmente nosso paradigma diário: devemos buscar estar menos errados, não mais certos. É preciso aceitar viver sob a incerteza, reconhecendo o papel do erro. Altay Souza enfatiza esse conceito frequentemente em suas aulas de Estatística Aplicada à Psicobiologia, pela UNIFESP. Para entender mais esse entendimento, recomendo suas oito primeiras aulas — serão úteis para a vida inteira, prometo.\nDe volta aos Princípios\nAndrey Kolmogorov, matemático nascido no século XX, foi crucial para o desenvolvimento da ciência moderna. Suas contribuições inestimáveis abrangem desde a biologia, topologia e geologia até a teoria da probabilidade. Ele revolucionou nossa compreensão científica de tal forma que, sem suas descobertas, este artigo possivelmente nem existiria. Kolmogorov estabeleceu não apenas a definição matemática da probabilidade por meio de seus axiomas, mas também descreveu o Teorema Central do Limite. Seus axiomas não são meras construções matemáticas — são padrões fundamentais observados na natureza, comparáveis às leis da física como a gravidade. Assim como podemos observar e comprovar a gravidade empiricamente, os axiomas probabilísticos se manifestam em fenômenos naturais, da genética à mecânica quântica, demonstrando sua validade universal.\nA teoria da probabilidade de Kolmogorov marcou a matemática moderna ao estabelecer uma base axiomática rigorosa para seu estudo. Até seu trabalho em 1933, a teoria carecia de fundamento matemático formal. Com sua obra &quot;Fundamentos da Teoria da Probabilidade&quot;, ele unificou diferentes interpretações da probabilidade em uma única estrutura matemática coerente.\nSua abordagem revolucionária combinou a teoria dos conjuntos com a teoria da medida para definir probabilidade de forma matematicamente precisa. Essa formalização estabeleceu a teoria da probabilidade como um campo independente da matemática, permitindo representar eventos probabilísticos através de funções.\nSua contribuição vai além da formalização matemática — oferece um framework que permite modelar fenômenos aleatórios em diversos campos científicos, da física quântica à biologia molecular, economia e ciência da computação.\nPara fundamentar isso, ele estabeleceu três axiomas da teoria da probabilidade:\n\nNão-negatividade: A probabilidade de qualquer evento deve ser maior ou igual a zero.\n\nP(A)∈ℝ+\nNormalização: A probabilidade do espaço amostral total (Ω) é igual a 1.\n\nP(Ω)=1\nAditividade: Para eventos mutuamente exclusivos, a probabilidade da união é igual à soma das probabilidades individuais.\n\nP(A∪B)=P(A)+P(B)\n[!note]\nEstes axiomas são importantes porque:\n\nFornecem uma base matemática rigorosa para o cálculo de probabilidades\nPermitem derivar todas as outras regras e teoremas de probabilidade\nSão fundamentais para entender o Teorema Central do Limite\n\nCom base nesses axiomas, ele enunciou o Teorema do Limite Central, que demonstra:\n\nAo coletar múltiplas amostras de uma população e calcular suas médias, a distribuição dessas médias amostrais tende a uma distribuição normal, independentemente da distribuição original dos dados (sendo necessárias no mínimo 30 amostras para esta convergência, conforme seu experimento).\nA média dessas médias amostrais converge consistentemente para a verdadeira média populacional.\n\nIsso nos permite utilizar amostras para estimar parâmetros populacionais, eliminando a necessidade de dados censitários.\nPara ver a prova visual do TLC, basta clicar no link abaixo. Você perceberá que quanto mais amostras forem coletadas, mais a distribuição da amostra tenderá a uma normal, com sua média convergindo para a média da população.\nProbability Distributions\nEste conceito é um dos pilares para a inferências sobre populações a partir de amostras. Com isso, conseguimos criar intervalos de confiança.\nCaso queira saber mais sobre Kolmogorov, sugiro esse link.\nIntervalo de Confiança\nDesenvolvido por Jerzy Neyman em 1937, como parte de sua teoria de estimação por intervalos. Esta contribuição ofereceu uma alternativa mais robusta às estimativas pontuais.\nNeyman propôs que, ao invés de tentar adivinhar o valor exato de um parâmetro populacional, seria mais útil estabelecer um intervalo de valores prováveis, junto com um nível de confiança associado. Esta abordagem reconhece explicitamente a incerteza inerente à inferência estatística.\n\n[!tip]\nA interpretação correta de um intervalo de confiança de 95% é:\nSe repetíssemos o processo de amostragem muitas vezes e calculássemos o intervalo de confiança para cada amostra, aproximadamente 95% desses intervalos conteriam o verdadeiro parâmetro populacional.\n\nEsta interpretação frequentista é crucial para entender que o intervalo de confiança não nos diz a probabilidade de que o parâmetro populacional esteja dentro do intervalo calculado, mas sim a confiabilidade do método de construção do intervalo ao longo de múltiplas amostras. Uma boa representação visual do intervalo de confiança pode ser vista por aqui.\n\nIntervalo de Confiança da Média de Idade de Pacientes com Câncer Cervical\nÉ importante termos uma noção sobre os temas demonstrados pois são cruciais para a entendermos a Previsão Conforme. Nele, iremos quantificar a incerteza, melhorarmos nossa confiabilidade e interpretabilidade do modelo.",
		"tags": [ "note"]
},

{
		"title": "3. Probabilidade e Calibração de Modelo",
		"date":"Mon Jan 26 2026 12:43:12 GMT+0000 (Coordinated Universal Time)",
		"url":"/digital-garden/meu-modelo-conforme/text/3-probabilidade-e-calibracao-de-modelo/",
		"content": "Probabilidade e Calibração de Modelo\nA probabilidade do modelo é um conceito crucial na aprendizagem de máquina. Ela representa a confiança do modelo em suas previsões, oferecendo insights sobre seu desempenho e confiabilidade.\nA ideia em geral é que essa probabilidade, seja empírica, ou seja, refletindo que dados similares caem nesse percentual.\nImagine um modelo de visão computacional que verifica se as cerejas do café estão maduras o suficiente para colheita. Se separarmos todas as cerejas às quais o modelo atribuiu um score probabilístico de 0.80 e, manualmente, verificarmos que 40% delas estão realmente maduras, logo que o modelo está descalibrado. Isso poderá trazer risco a colheita, dando falsas expectativas e sendo imprevisivel seus resultados, demonstrando uma alta confiança. Em contra partida, a calibração quando bem feita oferece maior segurança de que o modelo se comportará adequadamente em um ambiente de produção, além de fornecer informações importantes sobre as incertezas do modelo, proporcionando previsibilidade para os stakeholders.\nIsto é bem exemplificado no artigo Calibration: the Achilles heel of predictiveanalytics:\n\nSe o algoritmo é usado para informar pacientes, estimativas de risco mal calibradas levam a falsas expectativas tanto para pacientes quanto para profissionais de saúde. Os pacientes podem tomar decisões pessoais antecipando um evento, ou sua ausência, que na verdade eram equivocadas. Por exemplo, considere um modelo de predição que prevê a chance de um tratamento de fertilização in vitro (FIV) resultar em um nascimento [14]. Independentemente do quão bem os modelos possam discriminar entre tratamentos que resultam em nascimento versus aqueles que não resultam, é claro que uma super ou subestimação da chance de nascimento torna os algoritmos clinicamente inaceitáveis. Por exemplo, uma forte superestimação da chance de nascimento após FIV daria falsas esperanças a casais que já estão passando por uma experiência estressante e emocional. Tratar um casal que, na realidade, tem um prognóstico favorável expõe a mulher desnecessariamente a possíveis efeitos colaterais prejudiciais, como a síndrome de hiperestimulação ovariana.\n\nProbability Calibration : Data Science Concepts\nNão é um problema novo\nGlenn W. Brier, meteorologista, enfrentou um problema similar em meados do século 20 com previsões do tempo. Como poderia avaliar a precisão de suas estimativas em relação ao que realmente acontecia? Foi assim que desenvolveu o &quot;Brier Score&quot;, uma métrica que avalia a precisão das previsões probabilísticas, comparando as probabilidades previstas com os resultados observados. Um score menor indica previsões mais precisas. Até os dias de hoje, é uma métrica essencial para entendermos o comportamento de nossas previsões.\nThe Brier Score Explained | Model Calibration\nOutra métrica utilizada nesse contexto é o Log Loss, que quantifica a incerteza na probabilidade das predições do modelo, comparando-as com os resultados reais. Utilizar essas duas métricas pode fornecer perspectivas diferentes sobre o desempenho do modelo.\nEm geral, modelos de ML não garantem boa calibração, ou seja, seu score probabilístico pode não representar realmente uma probabilidade. Isso é evidenciado na palestra de Guillaume Lemaitre, que também demonstra como técnicas populares de balanceamento podem prejudicar bastante essa calibração.\nUma forma de observar isso é através da curva de confiabilidade, que compara as probabilidades previstas pelo modelo com as frequências reais observadas dos eventos. Ela demonstra se o modelo está bem calibrado, confiante demais ou não. Para comparação, é criada uma linha diagonal perfeita que representa um modelo perfeitamente calibrado, onde as probabilidades previstas correspondem exatamente às frequências observadas. Se a curva de predição ficar abaixo da linha diagonal, significa que o modelo está confiante demais, prevendo probabilidades mais altas do que deveria em relação ao percentual real de ocorrências. Caso a curva fique acima da linha diagonal, sugere que o modelo está subestimando suas previsões, sendo menos confiante do que deveria.\n\nBMC Medical Informatics and Decision Making\nTendo isso em mente, vamos considerar um cenário: você está desenvolvendo um modelo de predição para identificar quando seu pedido no iFood pode resultar em uma experiência ruim. Para isso, você coletou 10 características de 100.000 pedidos (sim, você adora pedir comida!) ao longo de 5 anos. Ao analisar os dados, você percebeu que a distribuição é desbalanceada — apenas 20% dos registros indicam uma experiência negativa. Isso é um bom sinal, mas como seu modelo se comportaria com esse desbalanceamento? Você decide, então, experimentar quatro tipos de modelos:\n\nRandomForestClassifier (RF) sem nenhum tratamento nos dados\nBalancedRandomForestClassifier\nRF utilizando a técnica de Random Under-Sampling (RUS)\nRF utilizando a técnica de Synthetic Minority Over-sampling Technique (SMOTE)\nhttps://github.com/HeyLucasLeao/cp-study/blob/master/calibration_demo.ipynb\n\nFeito esses quatro modelos, se depara com isso:\nCurva de Confiabilidade\n\nRandomForestClassifier\n\nBalancedRandomForestClassifier\n\nRUS RandomForestClassifier\n\nSMOTE RandomForestClassifier\nO modelo sem tratamento do desbalanceamento de dados é, na verdade, melhor calibrado do que aqueles que utilizaram técnicas de reamostragem, como SMOTE, ROS ou RUS. Isto também é evidenciado em diversos, artigo, como por exemplo:\n\nThe harm of class imbalance corrections for risk prediction models: illustration and simulation using logistic regression\nThe harms of class imbalance corrections for machine learning based prediction models: a simulation study\nStop Oversampling for Class Imbalance Learning: A Critical Review\n\nAlém disso, observa-se que alguns modelos são naturalmente descalibrados após seu treinamento, independentemente do tratamento de dados. Conforme demonstrado no artigo Probabilistic Prediction in scikit-learn, é necessário adicionar um método de calibração para melhorar as estimativas.\nVenn-Abers\nNesse contexto, utilizo o Venn-Abers, um modelo de calibração que fornece um intervalo de probabilidade, auxiliando na interpretação e quantificação da incerteza na previsão de um modelo. Para obter as probabilidades, o método usa regressão isotônica para calibrar as previsões, aplicando-a duas vezes: primeiro assumindo que o rótulo verdadeiro é 0, depois assumindo que é 1. Esse processo gera duas funções de calibração, f0 e f1, que calculam os intervalos de probabilidade e representam os limites inferior e superior da probabilidade do rótulo ser 1. É possível também trabalhar com uma única probabilidade como resultado, que é o que faremos neste projeto. O artigo original sugere a fórmula:\np=p11−p0+p1Reamostragem\nConsiderando que a reamostragem prejudica a calibração do modelo, decidi abordar o problema das classes de outra maneira, preservando a distribuição original dos dados. É importante ressaltar também que o desbalanceamento por si só nem sempre prejudica o modelo — há arquiteturas pensadas nestes cenários, regularizando o viés. Durante anos, existiu uma concepção de que árvores de decisão, quando aplicadas em dados desbalanceados, inevitavelmente produziriam modelos enviesados para a classe majoritária. Entretanto, existem evidências de que árvores de decisão são capazes de lidar com esse cenário e, em algumas situações, podem até desenvolver uma tendência favorável à classe minoritária, com ajustes específicos. No caso do RandomForestClassifier, por exemplo, ajustamos o critério do modelo com base na proporção das classes, o que auxilia na generalização. Para um entendimento mais profundo, sugiro a leitura do artigo Towards understanding the bias in decision trees.",
		"tags": [ "note"]
},

{
		"title": "4. Previsão Conforme",
		"date":"Mon Jan 26 2026 12:43:12 GMT+0000 (Coordinated Universal Time)",
		"url":"/digital-garden/meu-modelo-conforme/text/4-previsao-conforme/",
		"content": "Previsão Conforme\nA melhor descrição que encontrei sobre o tema encontra-se no artigo Theoretical Foundations of Conformal Prediction, que descreve como:\n\nA previsão conforme é uma abordagem estatística para quantificação de incerteza onde as previsões do modelo são acompanhadas por um intervalo ou conjunto, comunicando o grau de confiabilidade em qualquer previsão, sem depender de pressupostos sobre a certeza do modelo.\n\nPortanto, é um framework de aprendizagem de máquina que permite quantificar incertezas e criar intervalos de predição. Isso possibilita melhores interpretações do modelo, maior segurança e garantias de probabilidade empírica nos resultados.\nSuas vantagens são:\n\nCobertura Garantida: As regiões de previsão oferecem garantias de cobertura para o resultado final.\nAgnosticismo de Modelo: É compatível com qualquer modelo ou área de Machine Learning.\nIndependência de Distribuição: As previsões conformes não pressupõem uma distribuição de probabilidade específica (Gaussiana, Gama, Poisson etc.), ampliando sua aplicabilidade.\nAusência de Retreino: Não é necessário reestimar o modelo após a previsão inicial.\nPredição Probabilística: Oferece previsões com medidas de confiança, permitindo controlar o nível de garantia do próprio modelo.\nFlexibilidade de Tamanho de Dados: A validade das previsões é mantida independentemente do tamanho do conjunto de dados. Contudo, um conjunto de dados pequeno para calibração gera menos valor se comparado a uma volumetria maior.\nEficiência Computacional: As previsões mantêm a eficiência computacional, sendo ideais para aplicações em tempo real e grandes conjuntos de dados.\n\nExistem dois tipos de categorias: Transductive Conformal Prediction (TCP) e Inductive Conformal Prediction (ICP).\nTransductive Conformal Prediction (TCP):\nO TCP foi o método original de Previsão Conforme. Sua característica principal é que, para cada novo ponto de dados, o modelo é treinado inteiramente para cada resultado possível. Por exemplo, em um modelo binário de classificação, o modelo será treinado uma vez para o valor 0 e outra para o valor 1, calculando um score de não conformidade para cada caso.\n\n[!tip]\nOu seja, o modelo irá ser treinado para cada rótulo e para cada ponto novo a ser testado!\n\nEsse processo garante alta precisão, pois considera toda a informação disponível para cada previsão. Este processo se assimila na técnica Jacknife, que faz uma é um processo de leave-one-out para estimação de variância e viés , aonde:\n\nRemove de forma **não **aleatória uma observação por vez do conjunto de dados\nCalcula a estatística de interesse com as observações restantes\nUtiliza essas estimativas para avaliar o variância e viés do estimador\n\nNo contexto da Previsão Conforme, esta abordagem tem como objetivo as estimativas de incerteza, embora⁠, em contra partida pode ser computacionalmente ineficiente dependendo da quantidade de dados tanto de treinamento, como para teste.\nInductive Conformal Prediction (ICP):\nO ICP foi desenvolvido como uma alternativa mais eficiente ao TCP. Nele treinamos uma única vez utilizando dados separados ao do treinamento do nosso modelo base. Com esse conjunto de dados de calibração, geramos um intervalo que são aplicados a novos dados para previsão.\nEmbora o TCP ofereça potencialmente maior precisão, o ICP é geralmente preferido em aplicações práticas devido à sua eficiência computacional, especialmente em cenários com a necessidade de previsões em tempo real.\nUma explicação visual sobre a diferença de ambos pode ser vista por aqui:\nUncertainty Quantification (3): From Full to Split Conformal Methods\nLogo, para este projeto, farei apenas o método ICP.\nCobertura Garantida\nPara compreender a garantia de cobertura, vamos analisar duas expressões matemáticas fundamentais:\nP(Yn+1∈C(Xn+1))≥1−αEla que a probabilidade do próximo valor Y estar contido no conjunto de predição C(Xn+1) é de pelo menos 1-α, onde α representa nossa taxa de erro desejada.\nC(Xn+1)={y∈Y:s(Xn+1,y)≤q^}Esta segunda expressão define o conjunto de predição utilizando um score de não-conformidade. Este score, calculado a partir de novos dados, é comparado com o quantil conforme (q̂), que estabelece nosso limiar para dados conformes. Em termos práticos, isso cria um conjunto de predição onde temos uma garantia probabilística de 1-α de que o próximo valor Y estará contido.\nPara que isso seja respeitado, devemos assumir que os dados respeitem a permutabilidase e que sejam dados independentes e identicamente distribuídos (i.i.d.), assegurando a validade estatística da cobertura.\nPermutabilidade\nO termo se refere à propriedade de uma sequência de variáveis aleatórias em que a ordem de aparecimento não afeta sua distribuição de probabilidade conjunta.\nEm termos mais simples, significa que os elementos de uma sequência podem ser reorganizados sem afetar suas propriedades probabilísticas fundamentais. Por exemplo:\nImagine uma urna com 3 bolas coloridas (vermelha, azul e verde) das quais você vai retirar uma a uma. Considere as seguintes sequências possíveis:\n\nSequência 1: (Vermelha, Azul, Verde)\nSequência 2: (Verde, Vermelha, Azul)\nSequência 3: (Azul, Verde, Vermelha)\n\nSe as bolas são retiradas aleatoriamente e recolocadas, a probabilidade de obter qualquer uma dessas sequências é idêntica. Isso demonstra que a sequência é permutável — você pode reorganizar os elementos e a distribuição de probabilidade permanece inalterada.\nEm resumo, para que a previsão conforme funcione adequadamente, os dados de calibração devem seguir a mesma distribuição dos dados que serão preditos no dia a dia. Podemos validar isso através de diferentes métodos: análise de cobertura empírica, que abordarei posteriormente, teste t de Student ou teste de Kolmogorov-Smirnov.",
		"tags": [ "note"]
},

{
		"title": "5. Treinamento",
		"date":"Mon Jan 26 2026 12:43:12 GMT+0000 (Coordinated Universal Time)",
		"url":"/digital-garden/meu-modelo-conforme/text/5-treinamento/",
		"content": "Treinamento\nNos meus projetos iniciais de carreira, como o de ansiedade e pandemia em época de Covid-19 ou o balanço sobre os dados e previsibilidade sobre a pandemia na região do Amazonas, eu acreditava que apenas gerar o F1 Score ou analisar o ROC-AUC resolveria todos os meus problemas. Porém, quando me deparava com novos dados, eu não sabia o que estava acontecendo. Percebi, tarde demais, que o modelo não estava calibrado!\n\nIntroduction To Conformal Prediction\nPara resolver esse problema, uma opção é transformar nosso modelo em um modelo conforme, que descrevi anteriormente. Eu até poderia ter parado apenas na camada de calibração Venn-Abers, que por si só já transforma nosso modelo em um conforme, mas a geração de cobertura nos dá outras interpretabilidades e possibilidades, que irei comentar no próximos tópicos.\n\n[!tip]\nNão há necessidade de termos uma modelo de calibração se quiser calibrar fazendo uma cobertura de previsão conforme. Apenas faço para melhorar integridade das probabilidades.\n\nDivisão de Dados\nVamos seguir este processo:\n\nDurante o treinamento, dividiremos os dados em três partes: dados de treinamento, calibração e validação.\n\nPor motivos de viés, não utilizamos a mesma massa de dados de treinamento do modelo para gerar o nosso ponto de corte para cobertura de dados conformes.\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\nX_train, X_calib, y_train, y_calib = train_test_split(X_train, y_train, test_size=0.25, random_state=42)\n\nPor conta de meu projeto, vou permanecer com RandomForestClassifier, mas pode ser qualquer um. A fim de simplicidade, deixarei também para termos apenas 2 classes de previsão.\n\nrf = RandomForestClassifier(random_state=42, n_jobs=-1)\nrf.fit(X_train, y_train)\n\nGrau de Incerteza\nPrecisamos tornar esse modelo conforme. Para isso, vamos estabelecer um limite máximo de incerteza do modelo para determinar se a classe predita é provavelmente a verdadeira.\nEsse grau de incerteza é chamado de score de não-conformidade. Existem várias maneiras de calculá-lo, mas para simplificar, usaremos o Hinge Loss, também conhecido como probabilidade inversa. Este score é calculado como 1 − P(y), onde P(y) é a predição do seu modelo. Podemos interpretá-lo como a distância entre a previsão do nosso modelo e a label verdadeira. Quanto mais próximo de 1, mais incerto é o resultado; quanto mais próximo de 0, mais certo.\nCobertura\nDurante o treinamento utilizamos esse score apenas para as probabilidades das classes verdadeiras, a fim de gerar um ponto de corte. Esse ponto separa novos dados que podem conter cada uma das classes em potencial. Chamamos isso de cobertura, pois garante com um grau de confiabilidade que a label verdadeira estará dentro do conjunto de predição. Abordaremos esse conceito com mais detalhes posteriormente.\n# Total de Dados\nn = len(X_calib)\n\n# Score do Modelo\ny_prob = model.predict_proba(X_calib)\n\n# Filtramos apenas para as probabilidades das labels verdadeiras\ny_prob = y_prob[np.arange(n),y_calib]\n\n# Hinge Loss\nnon_conformity_score = 1 - y_prob\n\nUma vez gerado, criaremos o q̂ , que é um ponto de corte baseado em medida de posição. Para todos os scores de não-conformidade, ordenamos seus valores do maior para o menor. Isso nos permite traçar um quantil baseado no nível de confiança, garantindo um percentual de cobertura.\nRecapitulando, o processo envolve:\n\nDefinir nosso nível de confiança α.\nGerar o q̂, que será o quantil (1 - α) desse score ordenado, do maior para o menor. Esse é o percentual de garantia. Por exemplo: com um α de 0.10, teremos um ponto de corte com 90% de garantia.\n\nn = len(nonconformity_score)\nalpha = 0.1\nq_level = np.ceil((n + 1) * (1 - alpha)) / n\nqhat = np.quantile(nonconformity_score, q_level, method=&quot;higher&quot;)\n\n[!tip]\nO q_level é necessário para ajustar a posição do quantil dentro do conjunto de dados finito, distribuindo adequadamente as posições dos quantis.\n\nCom todos os elementos gerados, podemos plotar o resultado. É importante lembrar que tudo abaixo desse q̂ tem cobertura garantida. Dessa forma, os 90% de cobertura significam que há a garantia de 90% para a classe verdadeira estar contida no conjunto de predição. É por essa razão que se utiliza o termo &quot;incerteza rigorosa&quot; para Previsão Conforme — existe uma probabilidade empírica por trás disso!\nfig = px.histogram(\nnonconformity_score,\ntitle=&quot;Score de Não Conformidade&quot;,\ncolor_discrete_sequence=[&quot;grey&quot;, &quot;orange&quot;],\nwidth=800,\nheight=400)\nfig.update_yaxes(title_text=&quot;Total&quot;)\nfig.update_xaxes(title_text=&quot;Score&quot;)\nfig.update_layout(legend=dict(title=&quot;Label&quot;))\nfig.add_vline(x=qhat, line_dash=&quot;dash&quot;, line_color=&quot;black&quot;, annotation_text=&quot;qhat&quot;, annotation_position=&quot;top&quot;)",
		"tags": [ "note"]
},

{
		"title": "6. Escoragem",
		"date":"Mon Jan 26 2026 12:43:12 GMT+0000 (Coordinated Universal Time)",
		"url":"/digital-garden/meu-modelo-conforme/text/6-escoragem/",
		"content": "Escoragem\nAnteriormente, geramos a cobertura para os conjuntos de previsão. Na verdade, o método que utilizamos é o mais tradicional, conhecido como cobertura marginal. Ele é excelente para situações em que se deseja atender à distribuição como um todo. Porém, dependendo do seu problema, sua adaptabilidade — ou seja, a capacidade de atender às classes específicas — pode não ser ideal. Não há certo ou errado; é preciso entender o que melhor atende ao seu problema. Existem diversos outros métodos, cada um com suas vantagens e desvantagens, como o RAPS, cobertura assímetrica e classe condicional, conhecida também como Mondrian.\n\nA Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification\n\nClasse Condicional\nA ideia da previsão é ter uma cobertura que tenha a mesma distribuição de dados passados, como dados futuros. Esse conceito é a permutabilidade. Isso significa que, não importa de que época o dado existe, ele irá ter a mesma distribuição de probabilidade. É importante entender isso, por duas razões:\n\nCaso haja mudança brusca e mudança na distribuição dos seus dados, a cobertura deverá ser gerada novamente, pois ela deixa de atender para o que foi proposto. Não há necessidade de retreino de modelo, mas sim para a cobertura.\nPor conta dessa premissa, também não é aconselhado, tampouco incentivado a fazer reamostragem de dados para não afetar a distribuição amostral dos dados. Para condições de dados desbalanceados, irei descrever como resolver no tópico Classificador Conforme, preservando a calibração do modelo.\n\nUm ponto que preciso dar ênfase, é que o uso de cobertura não gera apenas um único score como resultado, mas um conjunto de predições de todas as classes, podendo até todas as classes estarem na predição. Isso não é um bug! Modelos conformes que utilizam cobertura geram conjunto de respostas, sendo cada classe a ser testada dentro da cobertura.\n\nUnderstanding, Generating, and Evaluating Prediction Intervals\nPonto Estimado vs Intervalo\nNa previsão conforme, ainda é possível modelar um ponto estimado de duas maneiras:\n1. Venn-Abers (VA)\nO VA é um modelo de calibração de previsão conforme, ao qual oferece:\n2. P-valor dos NCScores\nPodemos estimar o p-valor dos scores de não-conformidade para cada classe predita.\nConsiderações Importantes\nEm ambos os cenários:\nInterpretação\n\nConfiança: Indica a probabilidade da classificação predita versus outras classes\nCredibilidade: Mostra o quão adequada é a previsão conforme para classificar a instância\n\nNão abordarei com profundidade estes dois métodos, mas tenha em mente a flexibilidade do framework.\n\n[!tip]\nÉ importante não confundir intervalos de predição com intervalos de confiança, pois são conceitualmente diferentes:\nO intervalo de confiança nos permite estimar, com determinado grau de certeza, onde um parâmetro populacional se encontra.\nJá o intervalo de predição nos permite estimar, também com um grau de certeza específico, onde o valor real de uma nova observação deve estar.\n\nCobertura\nUtilizar uma cobertura garantida de score de não conformidade pode nos ajudar a interpretar sobre diversos pontos:\n\nUncertainty Sets for Image Classifiers using Conformal Prediction\n\nEm um modelo de detecção de imagens, conseguimos saber quais labels estão sendo apresentadas para respectivas imagens, e quais têm quantificações aproximadas de incerteza.\nEm modelos de automação ou detecção, podemos solicitar analise humana aonde mais de uma label é detectada.\nEm um modelo de recomendação, é possível identificar similaridades entre produtos, sendo possível juntar ambos ou até ofertarem juntos.\n\ny_prob = rf.predict_proba(X_test)\nncscore = 1 - y_prob\n(ncscore &lt;= qhat).astype(int)\n\nAs possíveis respostas, poderão ser, pensando em um classificador binário:\n\n[0, 0]: Há garantia na probabilidade de que o dado escorado não compõe nenhuma classe.\n[1, 0]: Há garantia de que o dado compõe a classe ‘0’.\n[0, 1]: Há garantia de que o dado compõe a classe ‘1’.\n[1, 1]: Há garantia de que o dado compõem ambas as classes.\n\nO código para fazermos futuras escoragens é bem simples, a complexidade se dá aos fundamentos de chegarmos em um bom entendimento.\nSe ainda não ficou muito claro sobre o tema, antes de falarmos sobre validação e eficiência, sugiro seguir os exemplos de Christoph Molnar:\nWeek #1: Getting Started With Conformal Prediction For Classification",
		"tags": ["1", "note"]
},

{
		"title": "7. Validade e Eficiência",
		"date":"Mon Jan 26 2026 12:43:12 GMT+0000 (Coordinated Universal Time)",
		"url":"/digital-garden/meu-modelo-conforme/text/7-validade-e-eficiencia/",
		"content": "Validade e Eficiência\nAo tentar criar seu primeiro modelo de previsão conforme, você pode ter encontrado um desafio: muitos conjuntos de predição do seu modelo retorna todas as classes. Mas por que isso acontece?\nÀ medida que aumentamos o nível de cobertura (por exemplo, para 99%), os conjuntos de previsão conforme tendem a crescer. Isso ocorre porque o modelo precisa incluir mais classes para garantir que a verdadeira classe esteja no conjunto de previsão com a probabilidade desejada.\nEsse fenômeno está relacionado ao conceito de validade na previsão conforme. Ela assegura que a probabilidade de o conjunto de previsão conter a verdadeira classe seja, no mínimo, igual ao nível de confiança especificado. Por exemplo, com um nível de confiança de 99%, esperamos que o conjunto de previsão inclua a classe correta em pelo menos 99% dos casos.\nContudo, essa garantia pode resultar em conjuntos de previsão maiores, especialmente quando o nível de confiança é muito alto. Isso acontece porque o modelo precisa ser mais conservador em suas previsões para manter a garantia de cobertura.\nPor outro lado, pode também ocorrer o inverso, aonde ambos os valores não atendem à cobertura, tornando vazio o conjunto de predições. Isso pode ocorrer pois estamos mexendo em um intervalo gerado a partir de diversos valores, não apenas um ponto fixo. Imagine que chegue um dado bem diferente do que já foi visto em todo histórico dos dados.\nNo artigo Model-Agnostic Nonconformity Functions for Conformal Classification, foram criadas duas métricas de não-conformidade, AvgC e OneC, retratando as propriedades de **validade **e eficiência da cobertura, que nos auxiliam bastante a entender como nosso modelo está performando. Validade refere-se à quantidade média de rótulos sinalizados pelo modelo por conjunto de predições, enquanto eficiência é a proporção de conjuntos de predições com apenas um valor. Quanto menor o valor de validade, mais informação podemos extrair do modelo, pois o conjunto de predições fica menor. Por outro lado, quanto maior o score OneC, melhor é a capacidade do modelo de extrair informação do score de não conformidade, conseguindo ser mais específico em seu resultado.\nPodemos também ver as duas propriedades visualmente no link abaixo:\nUncertainty Quantification (1): Enter Conformal Predictors\nEm meu projeto pessoal, fiz um gráfico que plota ambos os scores baseados em diferentes níveis de α. Caso tenha curiosidade, o código está disponível em meu GitHub.\n\nOutras métricas que podem ser utilizadas para validação de modelo são:\nTotal de conjunto Vazios\n\nQuantas vezes o modelo emitiu um conjunto de predições vazias, não sendo informativo em seu resultado.\n\nTaxa de Erro\n\nMédia de conjunto de predições aonde o modelo errou em relação ao label original.\n\nCobertura Empírica\nÉ uma métrica que geramos para saber o quão temos a cobertura garantida no intervalo de predição em relação ao nível que foi modelado, em outras palavras, verificamos se, vamos supor, com um intervalo de 95% imposto à cobertura, temos aproximadamente 95% de garantia real sob ela. Caso ocorra de que esse valor seja relativamente inferior ao imposto, é possivel que o conceito de permutabilidade não esteja sendo atendida e toda modelagem precisa ser revisada!\nDentro dos meus modelos conformes no github há um código para geração dessa métrica, mas a lógica é o seguinte:\n\nA partir de uma massa de dados, gero o score de não-conformidade e seto um número arbitrário na qual vou iterar sob eles.\nA cada iteração, um percentual desses dados é selecionado de forma aleatória e posteriormente separados entre dado de calibração e teste, gerando o qhat baseado no alpha que modelei. Nesse caso, nosso alpha era 0.05.\nCalcula a média da cobertura dos dados selecionados para validação desta iteração.\nRepetimos o processo até o número de iterações seja atingido.\nPor fim tiramos a média de todas as coberturas geradas e comparamos com o valor modelado.\n\nHá uma ótima explicação sobre isso no link abaixo:\nA Tutorial on Conformal Prediction Part 2: Conditional Coverage and Diagnostics",
		"tags": [ "note"]
},

{
		"title": "8. Score de não-conformidade",
		"date":"Mon Jan 26 2026 12:43:12 GMT+0000 (Coordinated Universal Time)",
		"url":"/digital-garden/meu-modelo-conforme/text/8-score-de-nao-conformidade/",
		"content": "Score de não-conformidade\nVocê pode utilizar qualquer tipo de score de não-conformidade ou até mesmo criar um, mas deixarei documentado dois scores amplamente utilizados na área acadêmica.\nHinge Loss\nHinge, ou probabilidade inversa, refere-se ao quanto o modelo errou em relação ao rótulo verdadeiro. Seu cálculo se baseia em 1 − P(y), sendo P(y) a predição do seu modelo. O range vai de 0 a 1, onde 0 significa que o modelo está correto, e 1 indica que o modelo está completamente errado.\nMargin\nMargin refere-se à diferença entre a probabilidade da predição mais incorreta e a probabilidade correta. Valores menores ou iguais a zero indicam que o modelo tem certa confiança em relação à classe verdadeira, enquanto valores positivos representam uma incerteza em sua predição.",
		"tags": [ "note"]
},

{
		"title": "9. Aprendizado Sensível ao Custo",
		"date":"Mon Jan 26 2026 12:43:12 GMT+0000 (Coordinated Universal Time)",
		"url":"/digital-garden/meu-modelo-conforme/text/9-aprendizado-sensivel-ao-custo/",
		"content": "Aprendizado Sensível ao Custo\nO Aprendizado Sensível ao Custo é uma abordagem que busca otimizar decisões considerando os custos associados a diferentes tipos de erros. Diferentemente das abordagens tradicionais, onde os custos de erro são simétricos, esta abordagem lida com custos assimétricos — alguns erros podem ser mais custosos ou prejudiciais que outros. Esses erros podem ser de predição (Falsos Positivos ou Negativos) ou relacionados a regras de negócio, como fraudes ou aprovação de um serviço caro. A ideia central é minimizar o custo total das previsões, em vez de simplesmente maximizar a precisão.\nExemplo de Treinamento com Aprendizado Sensível ao Custo:\nConsidere um banco desenvolvendo um modelo para detectar transações fraudulentas. A matriz de custos poderia ser estruturada da seguinte forma:\n\nPrevisão \\ Real\nFraude\nNão Fraude\n\nFraude\n$0\n$50\n\nNão Fraude\n$1000\n$0\n\nNeste cenário:\n\nFalso Positivo (classificar uma transação legítima como fraude): Custa $50 à empresa devido à insatisfação do cliente.\nFalso Negativo (não detectar uma fraude real): Custa $1000 à empresa, representando o valor médio de uma transação fraudulenta.\nVerdadeiro Positivo e Verdadeiro Negativo: Não têm custos associados.\n\nLogo, o modelo treinado ajustaria seus parâmetros para minimizar o custo total. Isso pode resultar em aceitar mais falsos positivos para reduzir significativamente os falsos negativos mais custosos. Embora possa ter uma precisão geral ligeiramente menor, esse modelo seria mais eficaz em termos de redução de perdas financeiras para a empresa.\nDados Desbalanceados\nAlém disso, podemos aplicar essa metodologia para lidar com conjuntos de dados desbalanceados, onde uma classe é significativamente mais representada que outra. Atribuímos custos mais altos aos erros da classe menos representada, controlando assim a confiabilidade do modelo em relação às classes.\nPara implementar isso, primeiro criamos um peso para cada classe, proporcional ao volume de dados para treino. Simulando para duas classes:\nípeso-da-classe=total-de-dadostotal-de-classes×total-de-registros-da-classe-específicatotal_de_dados = 100\ntotal_da_classe_0 = len(y_train[y_train == 0]) # 90\nw1 = 100 / (2 * total_da_classe_0) #0.55\n\ntotal_da_classe_1 = len(y_train[y_train == 1]) # 10\nw2 = 100 / (2 * total_da_classe_1) #5\n\nrf = RandomForestClassifier()\nrf.fit(X_train, y_train, class_weight={0: 0.55, 1: 5})\n\nDesta forma, contabilizará os pesos das duas classes dentro da função de perda. Neste caso, dentro de gini, contabilizará os dois pesos.\nGini=1−W1∗Proportionc12−W2∗Proportionc22scikit-learn por padrão, possibilita já calcular esse peso, apenas incrementado o parametro como “balanced”.\nrf.fit(X_train, y_train, class_weight=&quot;balanced&quot;)\n\nHá outros métodos utilizando metadados mais específicos. Para mais informações, recomendo a palestra no EuroSciPy 2023.\nEuroSciPy 2023 - Get the best from your scikit-learn classifier\nAvaliação de Performance\nPrecisamos observar corretamente como nosso modelo atua no cenário do nosso problema. Para isso, é importante selecionar a melhor métrica para avaliação. Existe uma lista expressiva de opções. No contexto de classificação binária, irei abordar apenas as métricas que são de meu interesse.\nÉ importante destacar que todas essas métricas derivam da matriz de confusão, utilizando conceitos como Verdadeiro Positivo (VP), Falso Positivo (FP), Verdadeiro Negativo (VN) e Falso Negativo (FN).\n\n[!tip]\nSempre que precisar discutir ou revisar alguma métrica para adequá-la ao seu problema, sugiro fortemente consultar o guia disponibilizado pela Nannyml — vale a pena!\n\nF1-Score\nF1-Score é uma das métricas mais utilizadas para avaliar modelos. Seu cálculo é feito pela a média harmônica entre precisão e sensibilidade, fornecendo um único valor que equilibra ambas as métricas. Sua fórmula é:\nããF1=2×Precisão×SensibilidadePrecisão+SensibilidadeOnde:\n\nPrecisão = VP / (VP + FP)\nSensibilidade = VP / (VP + FN)\n\nÉ particularmente útil quando buscamos um equilíbrio entre precisão e sensibilidade. Um valor alto indica que o modelo possui tanto boa precisão quanto boa sensibilidade.\nEntretanto, o F1-Score não contabiliza os verdadeiros negativos e dá ênfase à classe positiva, o que o torna a ser enviesado. Para entendermos isso, precisamos voltar e falar de como ele surgiu e qual era o seu propósito inicial. O F1-Score foi desenvolvido por van Rijsbergen, em 1979, para avaliar sistemas de recuperação de informação, onde a precisão e sensibilidade tem maior grau de importância do que a predição correta de VN. Segundo o artigo Assessing Software Defection Prediction Performance: Why Using the Matthews Correlation Coefficient Matters, é exemplificado isso:\n\nEste domínio do problema é caracterizado por contagens muito grandes, e frequentemente desconhecidas, de VN. Considere, por exemplo, a recuperação de páginas web. Saber o número de páginas irrelevantes corretamente não recuperadas, ou seja, verdadeiros negativos, será tanto desafiador quanto pouco interessante. Isso chegaria a centenas de milhões, possivelmente mais. Infelizmente, aplicar F1 no contexto completamente diferente de predição de defeitos não é equivalente.\n\nIsso é bastante perceptível quando há um grau de importância nos Verdadeiros Negativos (VN) ou quando existe um desbalanceamento para a classe negativa. Nessas condições, a métrica pode mascarar a real performance do modelo. Tal fato é evidenciado também no artigo The advantages of the Matthews correlation coefficient (MCC) over F1 scoreand accuracy in binary classification evaluation, que demonstra cenários onde a métrica pode gerar uma confiança equivocada no modelo, sugerindo o uso de métricas alternativas que sejam mais representativas do contexto geral.\nPor exemplo, supondo que temos um modelo de detecção de indicativos de um paciente para uma doença muito comum:\n\nDados de Teste: 1000 pacientes\n980 pacientes (98%) têm a doença (positivos)\n20 pacientes (2%) não têm a doença (negativos)\n\nSe um modelo simplesmente classificar todos como positivos:\n\nF1-Score: 0.99\n\nCom essa métrica, não conseguimos avaliar se o modelo está superestimando os resultados ou simplesmente classificando todos os pacientes como doentes, mascarando assim problemas mais sérios. Por isso, recomenda-se utilizar métricas que ofereçam um contexto mais amplo e uma visão mais completa, considerando o peso de toda a matriz de confusão. Assim, abordarei a acurácia balanceada, uma normalização da métrica Bookmaker informedness (BM).\n\n[!tip]\nNão há problema em usar o F1-Score, porém é recomendável combiná-lo com outra métrica para obter um contexto maior do modelo.\n\nAcurácia Balanceada\nA partir delas podemos derivar uma métrica mais robusta para dados desbalanceados: a acurácia balanceada (BA). Seu diferencial é avaliar o desempenho do modelo considerando igualmente todas as classes, independentemente de sua frequência nos dados.\nA acurácia balanceada é calculada como a média aritmética entre sensibilidade e especificidade. Para um problema de classificação binária, a fórmula é:\náAcurácia Balanceada=12(VPVP+FN+VNVN+FP)Onde:\nA acurácia balanceada é útil em cenários onde as classes têm igual relevância, independentemente de sua distribuição nos dados.\nPor exemplo, imagine um sistema de controle de qualidade em uma fábrica de componentes críticos de aeronaves:\n\nVolumetria: 1.000 peças\n950 (95%) das peças são aprovadas no controle de qualidade\n5 (5%) das peças apresentam defeitos\n\nSe um modelo de detecção automática sempre aprovar as peças, teríamos:\n\nAcurácia normal: 95%\nAcurácia balanceada: 50%\n\nNeste caso, tanto aprovar uma peça defeituosa quanto rejeitar uma peça boa são igualmente críticos: o primeiro pode comprometer a segurança da aeronave, e o segundo representa um prejuízo financeiro significativo, pois são peças caras! Neste contexto em que os tipos de erros são igualmente importantes, é interessante considerarmos a acurácia balanceada.\nRetornando ao contexto original do problema — adaptar o modelo para dados possivelmente desbalanceados — e considerando que ambos os erros de classificação têm igual importância, a acurácia balanceada é mais adequada.\nAtualização de Projeto!\nApós revisão do meu projeto, resolvi fazer uma alteração na versão da biblioteca. Nela, utilizo a possibilidade de escolher entre duas métricas, Bookmaker Informedness (BM) ou Coeficiente de Correlação de Matthews (MCC).\nBookmaker Informedness\nO Bookmaker Informedness é outra métrica importante para avaliação de modelos, especialmente em cenários com classes desbalanceadas. Assim como a acurácia balanceada, ela busca fornecer uma avaliação mais robusta do desempenho do modelo. Na realidade, BA é uma normalização de BM.\nO BM é calculado como:\nBM=Sensibilidade+Especificidade−1Esta métrica:\n\nVaria de -1 a +1, onde +1 indica predição perfeita\n0 indica que o modelo não é melhor que escolhas aleatórias\nValores negativos indicam desempenho pior que aleatório\n\nO Bookmaker Informedness é particularmente útil quando as classes têm igual importância, independente de sua distribuição nos dados, como também é a única métrica para avaliar aleatoriedade da predição, demonstrado no artigo The Matthews correlation coefficient (MCC) is more reliable than balanced accuracy, bookmaker informedness, and markedness in two-class confusion matrix evaluation - BioData Mining\nCoeficiente de Correlação de Matthews\nO MCC é considerado uma das métricas mais completas para avaliação de classificadores binários, pois:\n\nConsidera todos os elementos da matriz de confusão (VP, VN, FP, FN)\nÉ especialmente útil para classes desbalanceadas\nFornece uma medida mais confiável mesmo quando as classes têm tamanhos muito diferentes\nEm caso de seu score alto, métricas como Brier Score, F1-Score, BM, ROC-AUC costumam apresentar bons resultados.\n\nA fórmula do MCC é:\nMCC=VP×VN−FP×FN(VP+FP)(VP+FN)(VN+FP)(VN+FN)O MCC tem as seguintes características:\n\nVaria de -1 a +1, similar ao Bookmaker Informedness\n+1 representa uma classificação perfeita\n0 indica desempenho equivalente a predições aleatórias\n-1 indica o pior desempenho possível\n\nO MCC é particularmente útil quando as classes têm igual importância, independentemente de sua distribuição nos dados. Diferentemente de outras métricas, existe uma extensa literatura que recomenda seu uso como padrão no campo da estatística para garantir maior rigor na avaliação dos modelos.\nPortanto, optou-se por utilizar tanto o MCC quanto o BM para avaliar os resultados.\n\n[!tip]\nComo o MCC considera tanto a prevalência dos dados positivos quanto o viés de quão provável o modelo prevê corretamente a base de dados, não é aconselhável utilizá-lo quando queremos comparar resultados entre diferentes bases de dados.\nPara esse cenário, é melhor utilizar BA ou BM.\n\nAprendizado Sensível a Custo versus Reamostragem\nUma diferença crucial é que, ao contrário dos métodos de undersampling ou oversampling, não modificamos a distribuição dos dados durante o treinamento. O modelo é treinado com a distribuição real dos dados disponíveis, alterando apenas a forma como aprende a partir deles. Isso traz uma vantagem especial quando precisamos estimar a precisão e probabilidade do modelo em um cenário real, pois a distribuição dos dados reflete fielmente a realidade.",
		"tags": ["0", "5", "note"]
},

{
		"title": "Meu Modelo Conforme",
		"date":"Mon Jan 26 2026 12:43:12 GMT+0000 (Coordinated Universal Time)",
		"url":"/digital-garden/meu-modelo-conforme/text/meu-modelo-conforme/",
		"content": "<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/digital-garden/meu-modelo-conforme/text/1-introducao/\"> 1. Introdução</a>\n<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/digital-garden/meu-modelo-conforme/text/2-antes-de-comecarmos/\">2. Antes de Começarmos…</a>\n<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/digital-garden/meu-modelo-conforme/text/3-probabilidade-e-calibracao-de-modelo/\">3. Probabilidade e Calibração de Modelo</a>\n<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/digital-garden/meu-modelo-conforme/text/4-previsao-conforme/\">4. Previsão Conforme</a>\n<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/digital-garden/meu-modelo-conforme/text/5-treinamento/\">5. Treinamento</a>\n<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/digital-garden/meu-modelo-conforme/text/6-escoragem/\">6. Escoragem</a>\n<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/digital-garden/meu-modelo-conforme/text/7-validade-e-eficiencia/\">7. Validade e Eficiência</a>\n<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/digital-garden/meu-modelo-conforme/text/8-score-de-nao-conformidade/\">8. Score de não-conformidade</a>\n<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/digital-garden/meu-modelo-conforme/text/9-aprendizado-sensivel-ao-custo/\">9. Aprendizado Sensível ao Custo</a>\n<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/digital-garden/meu-modelo-conforme/text/10-classificador-conforme/\">10. Classificador Conforme</a>\n<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/digital-garden/meu-modelo-conforme/text/11-referencias/\">11. Referências</a>\n<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/digital-garden/meu-modelo-conforme/text/12-regressao/\">12. Regressão</a>",
		"tags": [ "note"]
},

{
		"title": "0. Roadmap",
		"date":"Mon Jan 26 2026 12:43:12 GMT+0000 (Coordinated Universal Time)",
		"url":"/digital-garden/path-for-the-true-and-brave/text/0-roadmap/",
		"content": "Mês 1\n\nFree Tutorial - Causal AI in a Nutshell\nCausality, Decision Making &amp; Data Science (1 ~ 7)\nEstatística Psicobio II 2024 #23 - DAG I - Directed Acyclic Graphs - Princípios de Causalidade\nEstatística Psicobio II 2024 #24 - DAG II Directed Acyclic Graphs - d' separation; algoritmo PC e IC\nEstatística Psicobio II 2024 #25 - DAG III - Aplicações do DAG, Propensity Scores e diff-n-diff\n\nMês 2\n\nUniversidade de Dados - Robson Tigre\nCausal Inference in Python - (Cap I, II, III)\nCausal Inference in Python - Noncompliance &amp; Instruments\nTools for Causality\n\nMês 3\n\nEveryday causal inference\nThe Book of Why: The New Science of Cause and Effect\n\nNext Steps\n\nPanel Data (Cap. IV)\nCausal Discovery Inference\nOnline Controlled Experiments",
		"tags": ["23", "24", "25", "note"]
},

{
		"title": "1. Introdução",
		"date":"Mon Jan 26 2026 12:43:12 GMT+0000 (Coordinated Universal Time)",
		"url":"/digital-garden/path-for-the-true-and-brave/text/1-introducao/",
		"content": "Introdução\nE cá estamos Dezembro de 2025, semana de natal. Faz um tempo que não escrevo nada publicamente — na verdade até estava, concentrado em refinar o Tinyshift. O projeto cresceu bastante e estou bem feliz com o rumo que tomou, embora sei que ainda há muito o que fazer nele.\nNeste meio caminho, em epifanias, percebi algo. Quanto mais tempo trabalho em ciência de dados, mais certeza só tenho de uma coisa: eu sei absolutamente nada. Depois de tanto tempo estudando sob diversos temas, novamente senti que estava batendo em outro teto.\nNeste contexto, ficamos extremamente habituados em um escopo: associação. Quando digo isto, sempre pensamos em modelar sob forma de resultarmos na probabilidade de um acontecimento, de um número, ou de uma classe em relação a outros fatores. Isto começou a me pregar dois problemas:\n\nA primeira é que estamos sempre falando de padrões. Comportamentos de fraude, spam, itens comprados juntos. Isso é natural: nosso cérebro é feito para reconhecer padrões, desde a Era da Pedra. Para nossa sobrevivência, sempre ficamos habituados a isso. Mas padrões não são causa e efeito. Imagine o clássico dataset sobre vendas de sorvete com uma feature de ataques de tubarão. Ao observar os dados você encontra tem padrões, associações fortes de um com outro! Seria sensato recomendar que seu cliente corte relações com empresas de sorvete? Claro que não, ao menos pra mim! Ambas as variáveis podem ser influenciadas por um terceiro fator: a temperatura. No verão as pessoas vão mais à praia e compram mais sorvete — como também há mais chance de ataques. Isso é o que chamamos de correlação espúria. O mantra vale: associação não implica causalidade.\nA segunda questão é prática: um modelo de Machine Learning tradicional frequentemente entrega apenas uma probabilidade. Nós, humanos, tomamos decisões com base nesse número. Mas se nosso objetivo é orientar ações, por exemplo, reduzir churn, não basta saber quem tem maior probabilidade de churn; precisamos saber qual é o impacto de uma ação (uma promoção, atendimento diferenciado, cross-sell) sobre o churn. Quais ações causam mais impacto para diferentes perfis de cliente? Facure fala exatamente disso no podcast do Aleksander Molak. Em vez de modelar apenas a probabilidade, quero saber qual intervenção impacta mais e por quanto — ou seja, modelar sobre as regras de negócio, não só previsão.\n\nModelos preditivos podem induzir a decisões equivocadas quando o objetivo é agir no mundo. O propósito final de um modelo de ML é resolver um problema de negócio; mover o ponteiro é o que importa! Por isso, comecei a estudar formas de modelagem que foquem tomada de decisão: entender relações de causa e efeito para orientar intervenções eficazes. Assim, em vez de prever, posso estimar o impacto de prevenir clientes descontentes, quais fatores reduzem churn ou se um cross-sell aumenta a fidelidade.\nEstas anotações em Zettelkasten são o registro da minha jornada nessa selva que conheço tão pouco. Elas não são e nunca vão ser um guia prático, mas achei que seria bom disponibilizá-las como portfólio e para ajudar quem também gostaria de começar a ler ou discutir sobre o tema.\nAqui, escreverei apenas tópicos que me interessam, focando em dados observacionais e estudos transversais. Inferência Causal é gigante, então espere por lacunas nesse conteúdo. Mais importante: vamos ter um pouco de humildade epistêmica aqui, combinado?\n\n[!tip]\nEste documento não tem a pretensão de ser um ponto focal de ensinar, mas sim um registro pessoal de aprendizado. Escrever me ajuda a fixar o conteúdo e, ao torná-lo público, espero facilitar o caminho de quem também quer desbravar este tema, mas se sente perdido no início.\nComo ponto de partida, criei o <a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/digital-garden/path-for-the-true-and-brave/text/0-roadmap/\">0. Roadmap</a> detalhando o caminho que eu percorri. Como referências essenciais, recomendo acompanhar Robson Tigre e Matheus Facure — seus respectivos livros são excelentes e complementares.\nNote que alguns assuntos no roadmap se repetem ou são revisitados. Isso é intencional. Acredito que a fixação do conhecimento acontece através da:\n\nSíntese: Criar anotações próprias e explicar o assunto;\nPrática: Aplicar o que foi estudado;\nDiversidade: Consumir o mesmo tema por diferentes fontes e perspectivas.",
		"tags": [ "note"]
},

{
		"title": "10. Efeitos Heterogêneos",
		"date":"Mon Jan 26 2026 12:43:12 GMT+0000 (Coordinated Universal Time)",
		"url":"/digital-garden/path-for-the-true-and-brave/text/10-efeitos-heterogeneos/",
		"content": "Efeitos Heterogêneos\nNas análises anteriores, exploramos o ATE (Average Treatment Effect) sob uma perspectiva populacional (&quot;na média, o remédio funciona?&quot;). No entanto, a média pode esconder nuances cruciais. Em muitos cenários de negócio e ciência, o interesse real reside na personalização: entender como diferentes subgrupos reagem ao tratamento.\nPara capturar essa variabilidade, utilizamos o Efeito Médio de Tratamento Condicional (CATE).\nO objetivo do CATE é fundamentar a decisão nas características específicas (X) de cada unidade. Mudamos a pergunta de &quot;O tratamento funciona?&quot; para &quot;Para quem o tratamento funciona melhor?&quot;.\nMatematicamente:\nτ(x)=E[Yi(1)−Yi(0)∣Xi=x]Onde buscamos a diferença esperada entre os potenciais outcomes (Y1 e Y0), condicionada às características X.\nModelagem via Regressão Linear com Interação\nUma regressão linear simples (βD) estima apenas o efeito médio. Para flexibilizar o modelo e permitir heterogeneidade, introduzimostermos de interação entre a variável de tratamento (D) e as características (X).\nA equação assume a forma:\nçãyi=β0+β1Di⏟Efeito Base+β2Xi+β3(Di×Xi)⏟Interação+ϵi\n[!tip] Intuição Geométrica\nSem interação, as retas de regressão para o grupo Tratado e Controle seriam paralelas (mesma inclinação). O termo de interação β3 permite que as retas tenham inclinações diferentes. Se as retas não são paralelas, o efeito (a distância vertical entre elas) muda conforme X muda.\n\nDerivação do Efeito Marginal\nPara isolar o efeito do tratamento, derivamos a equação em relação a D:\n∂yi∂Di=β1+β3XiIsso prova matematicamente que o efeito não é mais constante (β1): ele agora é uma função linear das características do indivíduo (β1+β3Xi).\nAproximação por Diferença Finitas\nNa prática, como o modelo é linear, essa derivada pode ser calculada exatamente através da diferença entre duas predições. Usamos a definição de derivada onde o incremento (ϵ) é igual a 1 unidade:\nδyδD≈y^(D+1)−y^(t)Onde:\n\ny^(D+1) é a predição do modelo incrementando o tratamento original em uma unidade.\ny^(D) é a predição do modelo com os dados originais.\n\nExemplo (Causal Inference in Python: Applying Causal Inference in the Tech Industry\n\nimport statsmodels.formula.api as smf\n\n# 1. Definição das covariáveis (características que podem causar heterogeneidade)\nX = [&quot;C(month)&quot;, &quot;C(weekday)&quot;, &quot;is_holiday&quot;, &quot;competitors_price&quot;]\n\n# 2. Especificação do modelo com Interação # A sintaxe 'discounts * (X)'\n# Isso permite que o efeito do desconto mude conforme o mês, feriado ou preço do concorrente.\nregr_cate = smf.ols(f&quot;sales ~ discounts*({'+'.join(X)})&quot;,\ndata=data).fit()\n\n# 3. Estimativa do CATE (Efeito Médio de Tratamento Condicional)\n# Calculamos a diferença entre duas realidades hipotéticas para cada unidade:\n# Realidade A: O desconto atual + 1 unidade\n# Realidade B: O desconto atual\n# A diferença entre as predições isola o efeito marginal do desconto naquele contexto específico.\nols_cate_pred = (\nregr_cate.predict(data.assign(discounts=data[&quot;discounts&quot;]+1))\n-regr_cate.predict(data)\n)\n\nAvaliação de Modelos CATE\nDiferente de Machine Learning tradicional (onde temos o Y real para calcular RMSE ou Acurácia), na inferência causal nunca observamos o efeito real individual (não vemos Y1 e Y0 simultaneamente).\nEntão, como sabemos se o modelo é bom?\nA premissa é: Um bom modelo CATE consegue ordenar as unidades das mais sensíveis (maior efeito) para as menos sensíveis (menor efeito ou efeito negativo).\nUtilizamos métricas de &quot;Uplift&quot; para validar essa ordenação. Recomendo a leitura do capítulo 6 do livro Causal Inference in Python.\n\n[!note] Exemplos visuais\nRecomendo que observe os exemplos do livro junto com as anotações.\n\n1. Efeito por Quantil (Barplot)\nSegmentamos a base em quantis (ex: 10 grupos) ordenados pela predição do modelo (τ^). Calculamos o ATE dentro de cada grupo.\n\nSinal de Qualidade: Esperamos uma &quot;escada&quot; monotonicamente crescente. O 1º decil deve ter o menor ATE real estimado, e o último decil deve ter o maior.\n\n2. Curva de Efeito Cumulativo\nOrdenamos os dados do maior τ^ para o menor. Calculamos o efeito médio acumulado à medida que incluímos mais pessoas na amostra.\n\nDesvantagem: O início da curva tem poucas amostras (N pequeno), gerando alta variância e ruído (&quot;tremedeira&quot; no começo do gráfico).\n\n3. Curva de Ganho Cumulativo (Cumulative Gain)\nPara corrigir a variância, multiplicamos o efeito acumulado pela fração da população (k/N). Isso é análogo à curva ROC ou curva de Lorenz.\n\nEixo X: Porcentagem da população tratada (ordenada pelo modelo).\n\nEixo Y: Efeito acumulado &quot;Total&quot; (Ganho).\n\nLinha de Base (Random): Uma reta diagonal que liga (0,0) ao ATE total. Representa escolher pessoas aleatoriamente.\n\n[!note]\nCritério de Escolha (AUUC): O melhor modelo é aquele cuja curva &quot;embarriga&quot; mais para cima, distanciando-se da reta aleatória. Calculamos a Área Sob a Curva de Uplift (AUUC). Quanto maior a área, melhor o modelo consegue priorizar quem responde bem ao tratamento.",
		"tags": [ "note"]
},

{
		"title": "11. Variável Instrumental",
		"date":"Mon Jan 26 2026 12:43:12 GMT+0000 (Coordinated Universal Time)",
		"url":"/digital-garden/path-for-the-true-and-brave/text/11-variavel-instrumental/",
		"content": "Variável Instrumental\nExistem cenários em que é inviável controlar totalmente o viés de variável omitida U. Nestes casos, problemas comuns incluem:\n\nConfundimento Não Observado: A impossibilidade de coletar ou mensurar todas as variáveis de confusão que afetam tanto o tratamento quanto o resultado.\n\nNão-Adesão (Imperfect Compliance): A impossibilidade de garantir que todos os indivíduos designados ao grupo de tratamento efetivamente o recebam.\n\n[!tip] Nota: Compliance Refere-se à taxa de adesão, ou seja, o percentual de indivíduos que efetivamente seguiram o tratamento conforme a designação inicial.\n\nNestes cenários, a variável não observada U exerce influência sobre o tratamento D e o resultado Y, enviesando as estimativas de OLS (Mínimos Quadrados Ordinários):\nD←U→YA solução é utilizar uma Variável Instrumental Z, que atua como uma fonte de variação exógena para D:\nZ→D←U→YA abordagem de IV isola a variação em D que é induzida exclusivamente por Z, &quot;limpando&quot; a influência de U.\nPremissas\nPara que o estimador de IV seja consistente e identifique o efeito causal, quatro premissas devem ser satisfeitas:\n\nRelevância: O instrumento Z deve ter uma correlação forte com o tratamento D. Se o instrumento for &quot;fraco&quot;, as estimativas serão imprecisas e enviesadas.\n\nComo verificar: No Primeiro Estágio, avalia-se a Estatística F. A regra de bolso clássica sugere que F&gt;10 para descartar instrumentos fracos.\n\nExogeneidade / Independência: O instrumento Z deve ser &quot;tão bom quanto aleatório&quot;. Ele não pode estar correlacionado com nenhuma variável omitida (U) no modelo do resultado.\n\nComo verificar: Não há teste estatístico direto (pois U não é observado). Depende de argumentação teórica e desenho do estudo.\n\nRestrição de Exclusão: O instrumento Z deve afetar o outcome Y única e exclusivamente através do tratamento D. Não pode existir um caminho direto Z→Y.\n\nDesafio: Requer conhecimento e embasamento no domínio de negócio a ser tratado.\n\nMonotonicidade: O instrumento deve afetar todos os indivíduos na mesma direção. No contexto de experimentos, isso significa que não existem &quot;desafiadores&quot; (defiers) — pessoas que fazem exatamente o oposto do que o instrumento sugere.\n\n[!Abstract] Assista\nComo lidar com endogeniedade? | Entenda as Variáveis Instrumentais\n\nAplicações Principais\n\nCorreção de Experimentos (RCTs): Para lidar com imperfect compliance. Quando Z é a oferta aleatória do tratamento e D é o uso efetivo. Como a oferta é aleatória, ela serve como um instrumento perfeito para o uso.\n\n[!abstract] Leitura Recomendada\nSome ways to measure effects with imperfect compliance\n\nEstudos Observacionais: Quando não houve randomização e suspeita-se de endogeneidade. O instrumento funciona como um &quot;experimento natural&quot;, introduzindo uma aleatoriedade na atribuição de D que o pesquisador não pôde controlar.\n\nO instrumento provoca um choque exógeno em D, gerando uma variação &quot;limpa&quot; (independente de U).\nEstágios e o Estimador de Wald\nO efeito causal Local Average Treatment Effect (LATE) via IV pode ser calculado através da decomposição em dois estágios:\n\nPrimeiro Estágio (Impacto no Tratamento):\nRegredimos o tratamento D no instrumento Z. O coeficiente π representa a taxa de adesão ou a força do instrumento.\nD=α1+πZ+e1\n\nForma Reduzida (Intenção de Tratar - ITT):\nRegredimos o resultado Y diretamente no instrumento Z. O coeficiente γ mostra o efeito causal da atribuição (oferta) do instrumento sobre o resultado.\nY=α2+γZ+e2\n\nCálculo do LATE (Estimador de Wald):\nO efeito causal do tratamento em quem foi afetado pelo instrumento é a razão entre a Forma Reduzida e o Primeiro Estágio:\n\náβIV=Efeito de Z em Y (Forma Reduzida)Efeito de Z em D (Primeiro Estágio)=γπimport statsmodels.formula.api as smf\n\n# 1. Primeiro Estágio: Efeito de Z em D\n# O coeficiente de Z aqui é a taxa de adesão\nfirst_stage = smf.ols('D ~ Z', data=df).fit()\nden = first_stage.params['Z']\n\n# 2. Forma Reduzida: Efeito de Z em Y\n# O coeficiente de Z aqui é o ITTE\nreduced_form = smf.ols('Y ~ Z', data=df).fit()\nnum = reduced_form.params['Z']\n\n# Cálculo do Wald, ou LATE\nwald_estimator_sm = num / den\n\nprint(f&quot;Numerador (ITTE): {num}&quot;)\nprint(f&quot;Denominador (Compliance): {den}&quot;)\nprint(f&quot;Efeito Causal (Wald): {wald_estimator_sm}&quot;)\n\nMínimos Quadrados em Dois Estágios (2SLS)\nO método 2SLS é a generalização do estimador de Wald para casos com múltiplos instrumentos ou variáveis de controle (X).\n\nPrimeiro Estágio (Purificação de D):\nProjeta-se o tratamento D sobre o instrumento Z e controles X para obter os valores preditos D^.\nD^=α^+π^Z+ϕ^X\n\nSegundo Estágio (Estimação Causal):\nRegride-se Y sobre os valores &quot;limpos&quot; D^ e os controles X.\nY=β0+β2SLSD^+β1X+ε\n\nA intuição aqui é a decomposição da variância. A variável de tratamento original D possui dois componentes de variação:\n\nUma parte endógena, correlacionada com U\nUma parte exógena, induzida pelo instrumento Z\n\nAo rodarmos o primeiro estágio e calcularmos D^, estamos isolando apenas a variação em D que é explicada por Z. Como Z é não correlacionado com U, D^ também será independente de U.\nPortanto, o segundo estágio utiliza uma versão &quot;limpa&quot; do tratamento. Ao regredir Y em D^, eliminamos a contaminação do viés de seleção, permitindo que o OLS estime o efeito causal verdadeiro.\nfrom linearmodels.iv import IV2SLS\n\n# Fórmula: Y ~ Controles + [Endogeno ~ Instrumento]\n# O &quot;1&quot; representa a constante (intercepto)\nformula = 'Y ~ 1 + X + [D ~ Z]'\n\nmodel = IV2SLS.from_formula(formula, df)\nresult = model.fit()\n\nprint(result)\n\n[!tip] 2SLS vs. DoubleML (DML)\nO 2SLS assume relações lineares entre as covariáveis e o resultado. Se houver não-linearidades complexas, o uso de Double Machine Learning (DML) com variáveis instrumentais é preferível para remover o viés de forma mais robusta.\n\n[!abstract] Leitura Recomendada\nTwo-stage least squares: from the Wald estimator to regression",
		"tags": [ "note"]
},

{
		"title": "12. Double Machine Learning",
		"date":"Mon Jan 26 2026 12:43:12 GMT+0000 (Coordinated Universal Time)",
		"url":"/digital-garden/path-for-the-true-and-brave/text/12-double-machine-learning/",
		"content": "Double Machine Learning\n\nDouble ML: Causal Inference based on ML\nO Double Machine Learning (DML) representa uma metodologia moderna, situando-se na interseção entre a econometria e o Machine Learning (ML).\nPara entendermos DML, vamos revisitar o Teorema de Frisch-Waugh-Lovell (FWL). Na regressão linear clássica, o FWL nos diz que podemos estimar o efeito de um tratamento D sobre o outcome Y em duas etapas:\n\n&quot;Limpando&quot; Y das covariáveis X (pegando os resíduos).\n&quot;Limpando&quot; D das covariáveis X (pegando os resíduos).\nRegredindo os resíduos de Y contra os resíduos de D.\n\nO DML generaliza essa ideia. Em vez de usar regressão linear para &quot;limpar&quot; os dados, usamos modelos de ML.\n\n[!note] Artigos Sobre\n\nUplift Modeling Notebook\nDemand Elasticity Notebook\n\nPor que não usar apenas ML direto?\n&quot;Por que não apenas jogar Y, D e X em um XGBoost e olhar o feature importance ou SHAP?&quot;\nO problema reside no Viés de Regularização. Modelos de ML são desenhados para prever bem, não para estimar parâmetros. Eles usam regularização (Lasso, profundidade de árvore, dropout) para evitar overfitting.\n\nAo fazer isso, eles &quot;encolhem&quot; os coeficientes das variáveis de confusão.\nEsse viés na estimativa de g(X) contamina a estimativa do efeito de tratamento θ.\n\nO DML resolve isso através da Ortogonalização, separando a etapa de previsão (ML) da etapa de inferência.\nOs 4 Pilares\n\nFramework Não-Paramétrico: Flexibilidade total para usar Random Forests, Gradient Boosting ou Redes Neurais para modelar as variáveis de controle (X), capturando não-linearidades complexas automaticamente.\n\nRedução de Viés: Resolve o viés de regularização mencionado acima, garantindo que o erro de predição do modelo de ML não interfira no coeficiente de tratamento.\n\nInferência Estatística Válida: É matematicamente difícil calcular p-valores de uma &quot;caixa preta&quot;. O DML transforma o problema final em uma regressão linear simples sobre resíduos, recuperando a capacidade de calcular intervalos de confiança e significância clássicos (n-consistent).\n\nEficiência Estatística: O estimador converge rapidamente à medida que a amostra n cresce, comportando-se tão bem quanto uma regressão linear paramétrica, mesmo usando ML complexo &quot;por trás das cortinas&quot;.\n\nAlgoritmos\nRegressão Parcialmente Linear (PLR)\nAssumimos um processo gerador de dados onde o efeito de D é linear e aditivo, mas as confusas (X) são complexas:\nãY=Dθ⏟Linear+g(X)⏟Não-Linear+UD=m(X)+VOnde θ é o efeito causal, g(X) é a função de confusão do outcome e m(X) é a função do tratamento.\nO Processo de Ortogonalização\n\nEstimar Outcome (Y): Usamos um modelo de ML para estimar E[Y|X] (chamaremos de l(X)) e calculamos o resíduo:\nY~=Y−l^(X)\n\nEstimar Tratamento (D): Usamos outro modelo de ML para estimar m(X) (similar a um Propensity Score) e calculamos o resíduo:\nD~=D−m^(X)\n\nRegressão Final: Uma regressão linear simples (OLS) dos resíduos:\nY~=θD~+ϵ\n\n[!tip] Intuição dos Resíduos\nAo usarmos Y~ e D~, estamos trabalhando apenas com a variação que não é explicada por X. Isso isola a relação exógena entre D e Y.\n\nPor que &quot;Parcialmente Linear&quot;?\nO nome vem da estrutura da equação principal (Y=Dθ+g(X)+U). Ela é híbrida: possui um componente paramétrico linear (Dθ) para o tratamento, que queremos interpretar, e um componente não-paramétrico (g(X)) para as covariáveis, que queremos apenas controlar flexivelmente.\nModelo de Regressão Interativa (IRM)\nEnquanto a PLR assume que o tratamento apenas desloca o resultado de forma constante (aditiva), o IRM assume que o efeito do tratamento depende das características do indivíduo. Focamos aqui em tratamentos binários (D∈{0,1}).\náY=g0(X)⏟Baseline+D⋅(g1(X)−g0(X))⏟Efeito Variável τ(X)+UD=m(X)+VOnde:\n\ng0(X)=E[Y|X,D=0]: O outcome esperado para o grupo de controle.\n\ng1(X)=E[Y|X,D=1]: O outcome esperado para o grupo tratado.\n\nτ(X): O Efeito Causal Condicional (CATE), que varia conforme X.\n\nm(X): A probabilidade de tratamento (Propensity Score).\n\nO Processo de Estimação (AIPW)\nDiferente da PLR que usa uma regressão única nos resíduos, o IRM utiliza a estrutura de Augmented Inverse Probability Weighting (AIPW) para garantir robustez.\n\nEstimar os Potenciais Outcomes (g0,g1): Treinamos modelos de ML separados para aprender a curva de Y nos tratados e nos não-tratados.\n\nEstimar o Tratamento (m): Treinamos um classificador de ML para prever a probabilidade de receber o tratamento (Propensity Score).\n\nCombinação Duplamente Robusta: O algoritmo combina essas previsões para criar um &quot;score&quot; pseudo-outcome para cada indivíduo, que é então projetado nas variáveis X ou agregado para obter o ATE.\n\nψ(W)=g1(X)−g0(X)+D(Y−g1(X))m(X)−(1−D)(Y−g0(X))1−m(X)\n[!tip] A Propriedade de Dupla Robustez\nO estimador AIPW possui a mesma propriedade descrita sobre Estimador Duplamente Robusto: para ele convergir para o valor correto, apenas um dos dois modelos precisa estar bem especificado.\n\nSe o modelo de propensity m(X) for preciso (mesmo que g(X) seja ruim), o estimador funciona.\n\nSe o modelo de outcome g(X) for preciso (mesmo que m(X) seja ruim), o estimador funciona.\n\nPor que &quot;Interativo&quot;?\nO nome vem do termo de interação na equação estrutural. Na PLR, as curvas de Y(0) e Y(1) são paralelas (efeito fixo). No IRM, permitimos que as variáveis X interajam com D. Isso significa que as curvas podem ter inclinações diferentes, se cruzar ou divergir, permitindo identificar para quem o tratamento funciona (CATE) e para quem não funciona.\nPremissas Importantes\nÉ fundamental refrisar que esse método não é &quot;bala de prata&quot;. A validade causal ainda depende das premissas anteriores:\n\nIgnorabilidade: Y(d)⊥D|X. Ou seja, todas as variáveis de confusão relevantes foram incluídas em X. É importante refrisarmos isso que é assumido que foi capturando todos os confounders relevantes. Na prática, não temos como saber por exato, mas uma boa construção é importante.\nDomínio sob regra de negócio: Para toda a inferência causal, aqui não muda. Por mais complexo que nosso modelo possa ser, ele sempre será limitado relativo a tomada de decisão às escolhas de variáveis. Um bom DAG construído ainda é necessário, para evitar qualquer viés sob o resultado.\nQualidade de dados: por mais que o DoubleML é focado para estudos observacionais, aonde não controlamos variáveis de confusão e não temos uma randomização controlada, ele ainda pode sofrer com dados ruins. Se a extração tiver algum viés forte, problemas com campos, o resultado dele vai ser ineficiente para estimar causalidade.\nPositividade: Para valores de X relevantes, deve haver variação no tratamento (a probabilidade de tratamento P(D|X) não deve ser nem 0 nem 1 estritos, como também valores extremos).\nRegularidade: Os estimadores de ML devem convergir suficientemente rápido. O uso de Cross-Fitting é crucial para evitar viés de overfitting e garantir a validade assintótica.\n\nO Perigo no Overfitting\nMesmo com a ortogonalização, se o modelo de ML decorar os dados (overfitting), os resíduos serão artificialmente pequenos, enviesando o θ, eliminando a variação necessária para encontrarmos o efeito causal.\nPor conta disso, a prática padrão é utilizar o Cross-Fitting:\n\nSelecionamos K possíveis folds.\nNo K1, separamos os dados por exemplo em &quot;Treino&quot; e &quot;Hold-out&quot;.\nO modelo é treinado apenas na base de Treino, e utilizamos os dados para calcular o resíduo do Hold-Out.\nAgora, retreinamos o modelo com outro K fold, até que todos os dados tenham seus resíduos calculados.\n\nAssim, mesmo que o modelo aprenda nos dados de treino, ele não terá &quot;visto&quot; os dados de hold-out. Isso garante que os resíduos mantenham um ruído real e a variabilidade honesta necessária.\n\nDouble Machine Learning for Causal Inference: A Practical Guide | by Mohamed Hmamouch | Medium\nImplementação Prática: Calculando ATE e CATE com Python\nVamos utilizar a biblioteca DoubleML para aplicar os conceitos acima.\n1. Calculando o ATE\nPara o ATE, assumimos um efeito constante e usamos o modelo PLR.\nimport numpy as np\nimport pandas as pd\nfrom doubleml import DoubleMLData, DoubleMLPLR\nfrom sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n\n# --- Configuração dos Dados ---\n# Suponha que temos um DataFrame 'df' com:\n# 'y': Outcome, 'd': Tratamento binário, 'X1'...'X5': Covariáveis\ndata_dml = DoubleMLData(df,\ny_col='y',\nd_cols='d',\nx_cols=[f'X{i}' for i in range(5)])\n\n# --- Definindo os Modelos (Learners) ---\n# Modelo para prever Y (Outcome)\nml_l = RandomForestRegressor(n_estimators=100, max_depth=5)\n# Modelo para prever D (Propensity Score)\nml_m = RandomForestClassifier(n_estimators=100, max_depth=5)\n\n# --- Estimando ATE com Cross-Fitting ---\ndml_plr = DoubleMLPLR(data_dml,\nml_l=ml_l,\nml_m=ml_m,\nn_folds=3) # 3-fold Cross-Fitting\n\ndml_plr.fit()\nprint(dml_plr.summary)\n\nO resultado coef no sumário será o nosso τ (ATE), livre do viés das covariáveis.\n2. Calculando o CATE\nSe quisermos saber como o efeito varia de acordo com as características da pessoa (X), usamos o Interactive Regression Model (IRM). Em vez de calcular um número único, projetamos o efeito causal nas covariáveis usando um Preditor Linear.\nfrom doubleml import DoubleMLIRM\n\n# --- Usando IRM para permitir interações ---\n# ml_g prevê E[Y|X, D] e ml_m prevê E[D|X]\nml_g = RandomForestRegressor(n_estimators=100, max_depth=5)\nml_m = RandomForestClassifier(n_estimators=100, max_depth=5)\n\ndml_irm = DoubleMLIRM(data_dml,\nml_g=ml_g,\nml_m=ml_m,\nn_folds=3)\n\ndml_irm.fit()\n\n# --- Projetando a Heterogeneidade (CATE) ---\n# &quot;Como o efeito causal varia linearmente com as features X?&quot;\ncate_res = dml_irm.cate(basis=df[[f'X{i}' for i in range(5)]])\n\nprint(cate_res)\n\nInterpretando o CATE: Se no resultado do cate_res o coeficiente de uma variável (ex: X1: Idade) for positivo e significante, indica que o tratamento é mais eficaz quanto maior for a idade do indivíduo.\n\n[!note] Relembrando!\nPLR: Assume que o efeito do tratamento (θ) entra de forma aditiva e linear (não interage complexamente com X na equação estrutural). É ideal para tratamentos contínuos (ex: preço, dosagem).\nIRM: É desenhado especificamente para tratamentos binários. Permite interações completas entre o tratamento e as covariáveis, sendo mais robusto para heterogeneidade. Utiliza o estimador AIPW (Augmented Inverse Probability Weighting) por trás dos panos, que possui a propriedade de Dupla Robustez (Doubly Robust).\n\nIntroduction to Causal Machine Learning with DoubleML for Python\n3. Calculando o GATE (Group Average Treatment Effect)\nEnquanto o CATE busca o efeito individual (que pode possuir alto ruído estatístico), o GATE busca o efeito médio em um subgrupo específico.\nA biblioteca DoubleML oferece um método dedicado .gate() para cada grupo. Para utilizá-lo, precisamos passar um DataFrame onde as colunas representam os grupos (indicadores binários/dummies).\n\n[!tip] Nota\nPodemos calcular o GATE agregando as estimativas do CATE. Filtramos as unidades que pertencem ao grupo de interesse e tiramos a média dos seus efeitos causais estimados (τ^(x)).\n\nMatematicamente:\nτGATE=E[τ^(x)∣x∈Grupo]# --- Passo 1: Definir os Grupos de Interesse ---\n# Vamos criar, por exemplo, dois grupos baseados na variável X1 (ex: Idade normalizada)\n# Grupo 0: X1 &lt;= 0.5\n# Grupo 1: X1 &gt; 0.5\ngroups = pd.DataFrame({\n'Grupo_Baixo_X1': df['X1'] &lt;= 0.5,\n'Grupo_Alto_X1': df['X1'] &gt; 0.5\n})\n\n# --- Passo 2: Calcular o GATE via DoubleML ---\n# O método gate() ajusta uma regressão linear dos resíduos contra essas variáveis de grupo\ngate_res = dml_irm.gate(groups=groups)\n\nprint(gate_res)\n\n# --- Passo 3: Analisar os Intervalos de Confiança ---\n# Verificamos se o intervalo de 95% cruza o zero ou se os grupos se sobrepõem\nprint(gate_res.confint())\n\nEssa abordagem é poderosa para decisões de negócio estratégicas, onde não podemos personalizar para cada indivíduo, mas podemos criar políticas para segmentos (ex: Região Norte vs. Sul).\n\nCaracterística\nCATE (Conditional Average Treatment Effect)\nGATE (Group Average Treatment Effect)\n\nDefinição\nEfeito do tratamento para um indivíduo (ou unidade) com características exatas X.\nMédia dos efeitos de tratamento para um subgrupo específico da população.\n\nNível de Granularidade\nMicro (Individual / Personalizado).\nMacro (Segmento / Cluster).\n\nNotação Matemática\nτ(x)=E[Y(1)−Y(0)∣X=x]\nτGATE=E[τ(x)∣x∈Grupo]\n\nPergunta de Negócio\n&quot;Qual desconto devo dar para este cliente específico agora?&quot;\n&quot;A campanha funciona melhor na Região Sul ou na Região Norte?&quot;\n\nEstabilidade Estatística\nBaixa. Sofre com alta variância e ruído, pois n=1 (ou muito pequeno) para aquele X.\nAlta. O ruído individual tende a se cancelar na média do grupo, gerando estimativas mais robustas.\n\nNo DoubleML\nResultado da projeção do efeito nas features (via dml_irm.cate() ou BLP).\nCalculado tirando a média das predições do CATE filtradas por um subconjunto do DataFrame.\n\nAplicação Principal\nPersonalização de produto, Medicina de precisão, Recomendação dinâmica.\nDefinição de estratégia, Política pública, Decisão de portfólio.\n\nDoubleML com Variáveis Instrumentais (IV)\nDiferente do DoubleML padrão (que limpa X apenas de Y e D), no cenário com Variável Instrumental nós precisamos limpar a influência das covariáveis (X) de três lugares: do Resultado (Y), do Tratamento (D) e do Instrumento (Z).\nSimulando o DoubleMLPIV para ter uma ideia, o processo envolve 3 modelos de Machine Learning e uma regressão IV 2SLS final.\nPremissas\n\nY depende de X,D,U.\nD depende de X,Z,U.\nZ depende de X\n\n1. Previsão\nPrimeiro, usamos ML para prever Y, D e Z usando apenas as covariáveis X. O objetivo é capturar toda a variação explicada por variáveis de confusão.\n\nModelo 1 (q(X)): Prever Y usando X.\nModelo 2 (m(X)): Prever D usando X.\nModelo 3 (r(X)): Prever Z usando X.\n\n2. Ortogonalização Tripla\nSubtraímos as previsões dos valores reais.\n\nY~=Y−Y^ML (Variação no outcome não explicada por X)\nD~=D−D^ML (Variação no tratamento não explicada por X)\nZ~=Z−Z^ML (Variação no instrumento não explicada por X)\n\n3. Estágio Final (2SLS nos Resíduos)\nUsamos os resíduos do instrumento (Z~) para instrumentar os resíduos do tratamento (D~) e explicar os resíduos do resultado (Y~).\nimport numpy as np\nimport pandas as pd\nimport statsmodels.api as sm\nfrom sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n\n# --- 1. Gerando Dados Fictícios (Endógenos) ---\nnp.random.seed(42)\nn = 1000\n# X afeta tudo (confusão)\nX = np.random.normal(0, 1, (n, 3))\n# Z (instrumento) afeta D, mas também depende de X\nZ = 0.5*X[:,0] + np.random.normal(0, 1, n)\n# U (não observado) afeta D e Y\nU = np.random.normal(0, 1, n)\n# D (tratamento) depende de X, Z e U (viés)\nD = 0.5*Z + 0.5*X[:,0] + U + np.random.normal(0, 0.5, n)\n# Y (outcome) depende de D, X e U. Efeito real de D é 2.0\nY = 2.0*D + X[:,0] + U + np.random.normal(0, 0.5, n)\n\ndf = pd.DataFrame({'Y': Y, 'D': D, 'Z': Z})\nX_cols = pd.DataFrame(X, columns=['X1', 'X2', 'X3'])\n\n# --- 2. Fase de Machine Learning ---\n# Treinamos modelos para capturar a influência de X em Y, D e Z\n\n# a) Prever Y dado X\nmodel_y = RandomForestRegressor(max_depth=5).fit(X_cols, df['Y'])\ny_hat = model_y.predict(X_cols)\ny_res = df['Y'] - y_hat # Resíduo Y (Ortogonalizado)\n\n# b) Prever D dado X\nmodel_d = RandomForestRegressor(max_depth=5).fit(X_cols, df['D'])\nd_hat = model_d.predict(X_cols)\nd_res = df['D'] - d_hat # Resíduo D (Ortogonalizado)\n\n# c) Prever Z dado X (Essencial para DoubleMLPIV!)\nmodel_z = RandomForestRegressor(max_depth=5).fit(X_cols, df['Z'])\nz_hat = model_z.predict(X_cols)\nz_res = df['Z'] - z_hat # Resíduo Z (Ortogonalizado)\n\n# --- 3. 2SLS clássico ---\n# y_res ~ beta * d_res (instrumentado por z_res)\n\n# 1º Estágio Manual: Regredir d_res contra z_res\nstage1 = sm.OLS(d_res, sm.add_constant(z_res)).fit()\nd_res_hat = stage1.predict() # Variação de D limpa de X e induzida por Z limpo\n\n# 2º Estágio Manual: Regredir y_res contra o predito do 1º estágio\nstage2 = sm.OLS(y_res, sm.add_constant(d_res_hat)).fit()\n\nTratamentos Contínuos\nPara essas condições, utilizamos o PLR, mas com uma abordagem conceitualmente um pouco diferente, mas ainda podemos utilizar o DoubleML.\n1. ATE\nSe você quer saber &quot;Qual é a elasticidade média do preço na demanda?&quot;, a PLR padrão que vimos antes resolve perfeitamente.\n\nModelo de Outcome l(X): Regressão (Random Forest Regressor, XGBoost Regressor).\n\nModelo de Tratamento m(X): Regressão (não Classificação!). Aqui estimamos E[D|X] (ex: qual o preço esperado para um produto com essas características).\n\nFinal: Regressão linear dos resíduos.\n\nA intuição é: &quot;Depois de remover o efeito das características do produto, se eu subo o preço em R$1 (resíduo), quanto cai a venda (resíduo)?&quot;\n\n2. Efeito Heterogêneo / CATE\nE se você quiser saber: &quot;A sensibilidade ao preço muda dependendo da renda do cliente?&quot;\nAqui a equação muda. Não assumimos mais um θ fixo, mas sim uma função θ(X):\nY=D⋅θ(X)+g(X)+UPara resolver isso com DML em tratamentos contínuos, mantemos a estrutura da PLR, mas alteramos a etapa final.\nO Processo Adaptado\n\nOrtogonalização:\n\nLimpamos Y usando ML (Yres=Y−E^[Y|X]).\n\nLimpamos D usando ML (Dres=D−E^[D|X]).\n\nEstimação do CATE (A Mudança):\n\nEm vez de fazer OLS(Y_res ~ D_res), nós projetamos a relação sobre as variáveis X.\n\nBasicamente, rodamos uma regressão onde o coeficiente de Dres interage com X.\n\nYres≈θ(X)⋅DresExemplo\nImagine que queremos ver a elasticidade-preço ( e como ela varia por renda e idade.\nfrom doubleml import DoubleMLPLR\nfrom sklearn.ensemble import RandomForestRegressor\n\n# Nota: Para tratamento contínuo, AMBOS os modelos devem ser Regressores\nml_l = RandomForestRegressor() # Prever Vendas (Outcome)\nml_m = RandomForestRegressor() # Prever Preço (Tratamento Contínuo)\n\n# 1. Ajustar o PLR\ndml_plr = DoubleMLPLR(data_dml,\nml_l=ml_l,\nml_m=ml_m,\nn_folds=3)\ndml_plr.fit()\n\n# O 'coef' aqui é a elasticidade MÉDIA (ATE)\nprint(f&quot;Elasticidade Média: {dml_plr.coef}&quot;)\n\n# 2. Estimando CATE (Heterogeneidade)\n# Queremos saber: A elasticidade depende da Renda (X1)?\n# O método cate() faz uma regressão dos resíduos: Y_res ~ alpha + beta_1 * D_res * X1\ncate_res = dml_plr.cate(basis=df[['X1']])\n\nprint(cate_res)",
		"tags": [ "note"]
},

{
		"title": "13. GenAI e Causalidade",
		"date":"Mon Jan 26 2026 12:43:12 GMT+0000 (Coordinated Universal Time)",
		"url":"/digital-garden/path-for-the-true-and-brave/text/13-gen-ai-e-causalidade/",
		"content": "GenAI e Causalidade\nÉ fundamental salientar que os modelos de linguagem de grande escala (LLMs) não capturam, por si só, relações intrínsecas de causalidade. Existem desafios documentados de raciocínio (reasoning) em modelos não determinísticos e, para fins de inferência causal, essas ferramentas não substituem os conceitos e frameworks consolidados da econometria e estatística.\nNo episódio do podcast Free Will, LLMs &amp; Intelligence| Judea Pearl Ep 21 | CausalBanditsPodcast.com, Judea Pearl faz uma analogia na qual confiar exclusivamente em um LLM para causalidade é como ler um livro de receitas escrito por alguém que nunca cozinhou, mas que leu todos os livros de culinária existentes. O modelo replica instruções sem compreender a &quot;química&quot; — por exemplo, por que o fermento faz o bolo crescer. Pearl argumenta que os LLMs não aprendem modelos causais diretamente do ambiente, mas sim &quot;copiam&quot; os modelos mentais dos autores dos textos de treinamento. O resultado é o que ele chama de uma &quot;salada de associações&quot; ou &quot;rumores sobre modelos causais&quot;, sugerindo que devemos tratar o modelo como uma nova &quot;caixa preta&quot; para experimentação, e não como uma fonte de verdade causal.\nEm paralelo com a analogia de Pearl, Emre Kıcıman, no episódio Open Source Causal AI &amp; The Generative Revolution | Emre Kıcıman Ep 16, expressa ceticismo sobre a capacidade atual dos LLMs de raciocinar causalmente. Ele observa que, embora seja possível que eventualmente aprendam modelos causais, os LLMs atuais modelam principalmente a linguagem, e não o mundo físico. Kıcıman aponta que, mesmo quando modelos como o Sora parecem simular a física, eles frequentemente realizam simulações locais aproximadas que podem &quot;cortar caminho&quot; para satisfazer um comando criativo, como criar ondas em uma xícara de café onde, logicamente, elas não deveriam existir.\nApesar dessas limitações, Kıcıman argumenta que os LLMs são valiosos para complementar a especialização humana, oferecendo suporte tecnológico ao:\n\nPropor mecanismos causais plausíveis que um pesquisador pode ter deixado passar;\n\nCriticar suposições e sugerir onde é necessária maior validação;\n\nAliviar o fardo de &quot;começar do zero&quot; para especialistas no domínio.\n\nExemplos práticos dessa colaboração já existem. O artigo Mining Causality: AI-Assisted Search for Instrumental Variables, por exemplo, propõe agentes que auxiliam na busca de variáveis instrumentais através de etapas estruturadas de prompt e validação. No campo das ferramentas, a biblioteca PyWhyLLM é um projeto experimental desenhado para integrar essas capacidades diretamente no fluxo de trabalho de análise causal, fazendo parte do ecossistema PyWhy (que inclui o DoWhy). Outra iniciativa relevante é o Causal LLM Agent, desenvolvido pelo laboratório Jinesis da Universidade de Toronto.\n\n[!tip] Causal Reasoning\nCaso tenha interesse para linhas de pesquisa como o Causal LLM Agent, sugiro observar o trabalho de Zhijing Jing, sua linha de pesquisa é voltada a este tema.\n\nAtualmente, os LLMs não são capazes em extrair com segurança os mecanismos causais, mas podem ser utilizados como um parceiro colaborativo. Eles ajudam a preencher a lacuna entre o conhecimento de domínio necessário para compreendê-los. Ao usar essas ferramentas, pesquisadores podem tratar o modelo como um instrumento para a descoberta e crítica causal, enquanto deixam a criticidade, estimativa final e a tomada de decisão para o pesquisador. É importante refrisar que eles não devem ser utilizados para terceirizar decisões críticas, nem para substituir o conhecimento de domínio. Seu uso exige rigor, documentação e, crucialmente, revisão por especialistas humanos. Como sugerido pela tradição de Fisher, a interpretação final e a atribuição de efeitos causais são responsabilidades inalienáveis do pesquisador. Quanto maior o impacto da decisão, maior deve ser o rigor da análise humana sobre a saída da máquina.",
		"tags": [ "note"]
},

{
		"title": "14. Boas Práticas",
		"date":"Mon Jan 26 2026 12:43:12 GMT+0000 (Coordinated Universal Time)",
		"url":"/digital-garden/path-for-the-true-and-brave/text/14-boas-praticas/",
		"content": "Boas Práticas\n\n[!citation] Citação\nThe basic steps as we stated them are step one is you have to realize that your data is the result from an experiment. So you have to describe the experiment which generated the data and then with that you can also start describing the kind of the causal question you have. - Mark van der Laan\n\nToda inferência causal sustenta-se em dois pilares fundamentais: premissas e resultados.\nAs premissas devem ser declaradas explicitamente e rigorosamente respeitadas. Caso haja suspeita de violação ou impossibilidade de validação completa de alguma delas, é preferível que essa limitação seja apontada e elucidada no estudo, em vez de ofuscada. Um estudo honesto, que respeita tanto o método científico quanto o leitor, mantém seu valor mesmo com limitações declaradas.\nResultados e hipóteses exigem seriedade e cronologia. As hipóteses devem ser formuladas antes do estudo (pré-registro), e não ajustadas a posteriori para se adequarem aos dados observados. Modelar resultados baseando-se em hipóteses criadas após a análise é uma prática problemática (HARKing), pois aumenta o risco de detectar padrões espúrios e induzir a tomadas de decisão equivocadas.\nPortanto, um escopo de boas práticas deve focar na leitura crítica dos resultados, visando responder perguntas de causa e efeito que impactam a unidade de estudo. Para auxiliar, o artigo abaixo é uma referência que estabelece um fluxo de trabalho e recomendações de validação utilizando modelos de Machine Learning (ML) para prever resultados de tratamentos com segurança:\n\nCausal machine learning for predicting treatment outcomes\nAlém disso, a estruturação do processo é de suma vital. O trabalho A Causal Roadmap, por exemplo, busca rigor metodológico. Ele estabelece um roteiro de sete etapas para gerar evidências de alta qualidade em dados do mundo real (RWE), guiando desde a formulação da pergunta até a estimativa do efeito:\n\nA Causal Roadmap for Generating High-Quality Real-World Evidence\nÉ importante pontuar que no artigo esclarece a importância do pesquisador em utilizar frameworks rigorosos, citando como exemplo Target Trial Emulation (TTE), que exige a especificação explícita de quatro componentes:\n\nPopulação: Quem seria elegível para o ensaio?\nEstratégias de Tratamento: Quais as intervenções exatas a comparar?\nAtribuição e Seguimento: Como e por quanto tempo os grupos são monitorizados?\nOutcome: Qual o outcome definido à priori?\n\nPara facilitar a identificação da abordagem adequada, deixei um infográfico dinâmico para me ajudar, mas utilize com ressalvas, acredito em suma ser limitado. Se você utiliza ferramentas de GenAI, há o PyWhyLLM como assistente para exploração, ou o Causal LLM Agent citados anteriormente em <a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/digital-garden/path-for-the-true-and-brave/text/13-gen-ai-e-causalidade/\">13. GenAI e Causalidade</a>.\nEquívocos\nEmbora possamos utilizar algoritmos preditivos em análises causais, as abordagens divergem em objetivos e interpretação. Modelos causais exigem maior maturidade teórica para identificar o efeito de uma intervenção, indo além da correlação.\nAbaixo, listo equívocos que podem surgir durante a construção de um modelo causal:\n1. Assumir causalidade em dados observacionais sem critério\nObservações empíricas que mostram associação entre duas variáveis não permitem, por si só, concluir causalidade. A associação pode ser fruto de confusão, causalidade reversa ou mera coincidência.\n\nExemplo: As vendas de sorvete e o número de afogamentos aumentam simultaneamente; a temperatura (variável omitida) é a causa comum de ambos.\nComo evitar: Sempre observe a construção do DAG, procure fontes de variação plausivelmente exógenas, use desenho experimental quando possível, e declare explicitamente as premissas necessárias para qualquer interpretação causal.\n\n2. Acreditar que a Randomização resolve todos os problemas\nEnsaios aleatorizados reduzem vieses de seleção na atribuição do tratamento, mas não* garantem validade externa automática, ausência de vieses de medição, ou ausência de não‑compliance, perdas de seguimento e efeitos indiretos.\n\nExemplo: Um experimento onde muitos participantes do grupo de tratamento desistem (attrition) gera estimativas enviesadas.\nComo evitar: Monitore a adesão e perdas de seguimento; considere estimadores como Variáveis Instrumentais para lidar com a não-conformidade.\n\n3. Controlar o máximo de variáveis possível\nDiferente do mundo preditivo, onde &quot;mais dados costumam ser melhor&quot;, na causalidade, incluir certas variáveis pode introduzir viés. Controlar mediadores ou colisores pode distorcer o efeito real.\n\nPonto Chave: Um alto R2 ou poder preditivo não implica poder causal. Incluir um colisor pode gerar uma correlação espúria onde não existe causalidade.\nComo evitar: Utilize o critério de Backdoor no seu DAG para decidir quais variáveis devem (e quais não podem) ser controladas.\n\n4. Substituir o pensamento causal por modelos complexos\nModelos de Machine Learning altamente flexíveis podem prever o outcome com precisão, mas não explicam o que aconteceria sob uma intervenção. A complexidade do algoritmo não valida a suposição causal.\n\nComo evitar: Combine ML com frameworks causais (como Double Machine Learning), documente as premissas e realize análises de sensibilidade.\n\n5. Ignorar a Heterogeneidade do Efeito\nAssumir que o efeito causal é o mesmo para todos os indivíduos (homogeneidade) pode mascarar resultados importantes.\n\nExemplo: Um desconto que aumenta as vendas para jovens, mas reduz o valor da marca para clientes premium.\nComo evitar: Estime efeitos heterogêneos (CATE - Conditional Average Treatment Effect) e discuta os limites da generalização dos resultados.\n\n6. Tratar o P-valor como prova de causalidade\nA significância estatística quantifica apenas a incerteza amostral sob um modelo específico; ela não valida suas suposições causais. Um efeito estatisticamente significativo (p&lt;0,05) não elimina explicações alternativas, como variáveis de confusão ou viés de seleção.\n\nO Trade-off: Isso está ligado ao equilíbrio entre Viés e Variância, que comentei anteriormente. Um modelo pode ter variância baixa (estimativas precisas/p-valor baixo), mas estar altamente enviesado por não considerar a estrutura causal correta.\nMagnitude vs. Significância: Um tamanho de efeito grande ou um alto nível de significância não garantem benefícios práticos ou validade causal. Em grandes bases de dados (Big Data), quase qualquer correlação irrelevante pode se tornar &quot;estatisticamente significativa&quot;, mesmo sem qualquer sentido causal. Uma variável com alto poder causal pode apresentar um p-valor alto (não significante) se a amostra for pequena ou a variância for elevada. Não confunda precisão estatística com relevância causal.\n\nComo evitar:\n\nFoque na magnitude do efeito e nos Intervalos de Confiança, que mostram a incerteza de forma mais transparente.\nPriorize a robustez do desenho do estudo em vez da busca por p-valores baixos.\nCombine a evidência estatística com argumentos teóricos e testes de sensibilidade.",
		"tags": [ "note"]
},

{
		"title": "2. Predição & Inferência Causal",
		"date":"Mon Jan 26 2026 12:43:12 GMT+0000 (Coordinated Universal Time)",
		"url":"/digital-garden/path-for-the-true-and-brave/text/2-predicao-and-inferencia-causal/",
		"content": "Predição &amp; Inferência Causal\nModelagem preditiva e inferência causal possuem propósitos distintos. Enquanto modelos de Machine Learning focam em estimar um outcome futuro (como a probabilidade de churn), a inferência causal busca entender os resultados potenciais de uma intervenção (como o quanto uma promoção evitaria esse churn).\nÉ crucial distinguir essas abordagens: prever a probabilidade de um evento não é o mesmo que saber como alterá-lo. A predição prioriza a precisão da estimativa baseada em associações. Já a causalidade foca no mecanismo e na relação entre variáveis, sendo essencial para quantificar o impacto de tratamentos e guiar decisões estratégicas. Em outras palavras e exemplificando por regressão linear, um focamos no R2 e outro na estimativa do β que não esteja enviesada.\n\n[!Abstract] Leitura Recomendada\nA note about R-squared\n\nAlém disso, a inferência causal permite observar efeitos heterogêneos, ou seja, como o impacto de um tratamento varia entre diferentes subgrupos. Isso possibilita uma personalização mais eficiente, direcionando intervenções para onde elas trazem maiores benefícios, conforme escrevi em <a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/digital-garden/path-for-the-true-and-brave/text/10-efeitos-heterogeneos/\">10. Efeitos Heterogêneos</a>.\n\n[!tip] Comparação\nPredição: otimiza acurácia. Boa para segmentação, detecção de anomalias e priorização (ex.: identificar clientes em risco).\nInferência causal: estima efeitos de intervenções e responde “o que acontece se eu fizer X?”. Essencial para tomar decisões que mudam o mundo.\n\nMixtape Sessions: Foundation of Causality\n\n[!tip] Citação\nI always try to explain managers that they need Causal Machine Learning by saying, &quot;well you have correlation and here you want more causation and these are your technical problems and maybe it never really worked.&quot;\nI've been testing that for a couple of years. My current way is to simply explain it with like a crystal ball: Does a manager really want to have one crystal ball telling what the future will be like?\nA manager wants to change the future, so they don't want a crystal ball, rather they want to have crystal balls. One for decision A, the second for decision B and then they can look into the future how certain decisions will improve outcomes and they can pick the decision that works best for their company. - Stefan Feuerriegel",
		"tags": [ "note"]
},

{
		"title": "3. Teorias da Causalidade",
		"date":"Mon Jan 26 2026 12:43:12 GMT+0000 (Coordinated Universal Time)",
		"url":"/digital-garden/path-for-the-true-and-brave/text/3-teorias-da-causalidade/",
		"content": "Teorias da Causalidade\nA causalidade é um conceito complexo, abordado por pensadores como Aristóteles, David Hume, e Kant, com contribuições mais recentes de economistas como Angus Deaton e estatísticos. Em diversas áreas, há uma variabilidade de definições dela.\nPara o contexto da estatística e da modelagem de dados, a abordagem mais relevante é a Causalidade Regular (diferente da Causalidade Estrita de Descartes, que se baseia em leis naturais). A Causalidade Regular foca em eventos probabilísticos em vez de determinísticos, dando um foco grande em probabilidade condicional. Essa linha de pensamento foi inicialmente influenciada por ideias de Hans Reichenbach e John Stuart Mill, evoluindo para o que é hoje reconhecido como a moderna teoria da inferência causal, impulsionada por Judea Pearl e seu trabalho com Modelos Gráficos Acíclicos Direcionados (DAGs). Outros nomes, como Susan Haack e Deborah Mayo, também trouxeram contribuições importantes para a filosofia da causalidade e da estatística.\nNeste modelo, a causalidade é definida por três aspectos principais:\n\nDirecionalidade: A relação de causa e efeito é estruturada graficamente, indicando que o evento A causa o evento B (A→B).\nTemporalidade: A causalidade é expressa em termos de probabilidades condicionais – a probabilidade de um evento, dado que o outro já ocorreu. No entanto, o conceito estatístico fundamental aqui é a probabilidade de a causa A ocorrer, dado o efeito B, se e somente se A for a causa. Em termos de probabilidades condicionais, o que é crucial é a comparação entre P(B|A) e P(B|¬A) (a probabilidade do efeito B ocorrer na presença da causa A versus na sua ausência).\nReprodutibilidade (ou Invariância): Para ser considerada causal, a relação observada entre os eventos deve ser invariante, ou seja, consistentemente reproduzida sob as mesmas condições e em diferentes contextos relevantes.\n\n[!tip] Nota\nA Independência Condicional é a chave da inferência causal. Ela permite distinguir relações causais genuínas de simples associações estatísticas, identificando se a relação entre dois eventos desaparece ao condicionar uma terceira variável (a variável de confusão).\n\n[!tip] Nota\nAs variáveis de confusão (ou variáveis confundidoras, ou confounders) são variáveis que exercem influência tanto na causa quanto no efeito em estudo.\nÉ crucial identificar e controlar essas variáveis, pois a sua presença afeta diretamente a validade da inferência causal, levando a estimativas enviesadas do verdadeiro efeito, causando o que chamamos de associação espúria.\n\nDefinição de Causalidade, Causação e Associação\nComo falei, existe uma definição ampla sobre causalidade, a qual varia conforme a área de atuação. Essa pluralidade de conceitos é bem representada no artigo The Representation of Causality and Causation with Ontologies: A Systematic Literature Review, que demonstra como as definições mudam ao longo da literatura. Para o escopo probabilístico em que atuaremos, adotaremos uma perspectiva mais próxima à de Judea Pearl.\nCausalidade é a relação direcional de causa e efeito entre entidades, variáveis ou eventos. Já a causação refere-se ao mecanismo ou ação pela qual a causa produz o efeito. Ambos os conceitos envolvem direcionalidade, temporalidade e influência — a ideia de que um elemento efetivamente gera uma alteração no outro.\nEm contraste, a associação é a mera relação estatística entre duas variáveis. É fundamental não confundirmos com causalidade. Por definição, a associação pode incluir vieses, enquanto a causação busca isolar relações diretas. Assim, duas variáveis podem não ter influência direta entre si, mas parecerem relacionadas por serem influenciadas por uma variável externa não mapeada (lembremos da relação espúria). Nesses casos, há associação, mas não há nexo causal direto.\n\n[!tip] Citação\nCausal inference is the science of inferring causation from association and understanding when and why they differ. - Matheus Facure\n\nProblema Fundamental da Inferência Causal\nO Problema Fundamental da Inferência Causal reside na impossibilidade de observar simultaneamente, na mesma unidade, o resultado factual e o resultado contrafactual .\nPara quantificar o efeito causal de um tratamento, seria necessário calcular a diferença entre esses dois resultados. No entanto, uma única unidade (seja um indivíduo, evento ou variável) só pode existir em um único estado (tratado ou não tratado) em um dado momento.\nEm essência, a quantificação exata exigiria um universo paralelo onde a unidade pudesse ser observada em condições idênticas, mas sob estados de tratamento opostos. Dado que isso é logisticamente impossível, o problema é considerado o obstáculo central da inferência causal.\nDefinição Formal\nPara formalizar a causalidade, utilizamos a notação de Resultados Potenciais, fundamental para o entendimento do que constitui um efeito causal versus uma associação.\n1. Notação Básica\nAntes de equacionar o problema, definimos as variáveis para uma unidade i:\n\nDi: A variável de tratamento (Binária: 1 se tratado, 0 se controle).\nYi: O outcome observado (o que realmente aconteceu).\nY1i: O potencial outcome se a unidade tivesse sido tratada.\nY0i: O potencial outcome se a unidade não tivesse sido tratada.\n\n[!tip] A Realidade Observada\nDevido ao Problema Fundamental da Inferência Causal, nós observamos apenas um dos estados. O resultado observado é definido como:\nYi=DiY1i+(1−Di)Y0i\n2. Decomposição\nA equação fundamental é:\nçãçéE[Y|D=1]−E[Y|D=0]⏟Associação (Diferença Observada)=E[Y1−Y0|D=1]⏟ATT (Efeito Causal)+{E[Y0|D=1]−E[Y0|D=0]}⏟ViésATT (Average Treatment Effect on the Treated)\nRepresenta o efeito causal para o grupo que foi tratado. É a diferença entre o que aconteceu com eles (Y1) e o que teria acontecido se eles não tivessem sido tratados (Y0, o contrafactual).\n\nViés:\nEste é o termo crítico. Ele compara o estado basal (Y0) dos dois grupos.E[Y0|D=1]−E[Y0|D=0]Em outras palavras: &quot;Mesmo sem o tratamento, o grupo tratado já seria diferente do grupo de controle?&quot;. Se esse termo for diferente de zero, temos um viés.\n\n3. Identificação Causal (Exchangeability)\nPara que a Associação seja igual à Causalidade, o termo de Viés deve ser nulo. Isso ocorre quando:\nE[Y0|D=1]=E[Y0|D=0]Significa que o resultado do grupo de controle (Y0|D=0) é um substituto perfeito para o contrafactual do grupo tratado (Y0|D=1). Em termos práticos, os grupos devem ser comparáveis antes do tratamento.\n\n[!tip] Exemplo Intuitivo\nImagine testar um remédio em um hospital (D=1) versus pessoas na rua (D=0).\n\nAssociação: As pessoas no hospital têm saúde pior (Y) que as da rua.\nViés: O grupo tratado (T=1) já teria uma saúde basal (Y0) pior, mesmo sem remédio.\nConclusão: E[Y0|D=1]≠E[Y0|D=0]. O viés de seleção é negativo, mascarando o possível efeito positivo do remédio.\n\nMastering Mostly Harmless Econometrics - Part 1",
		"tags": [ "note"]
},

{
		"title": "4. Escada da Causação",
		"date":"Mon Jan 26 2026 12:43:12 GMT+0000 (Coordinated Universal Time)",
		"url":"/digital-garden/path-for-the-true-and-brave/text/4-escada-da-causacao/",
		"content": "Escada da Causação\nPara Alan Turing, a inteligência de uma máquina era definida pelo comportamento. O Teste de Turing estabelecia que, se uma máquina pudesse replicar o comportamento humano a ponto de se tornar indistinguível de uma pessoa, ela seria considerada inteligente. No entanto, para Judea Pearl, essa visão foca no sintoma, não na causa.\nEm sua obra The Book of Why, Pearl argumenta que a verdadeira inteligência não reside na capacidade de imitar padrões, mas na habilidade de compreender as relações de causa e efeito. Para organizar essa transição de pensamento para um conceito causal, Pearl propôs o que chama de Escada da Causação: um framework que divide a capacidade de entendimento em três níveis evolutivos.\n1. Primeiro Degrau: Associação (Ver)\nA associação é o nível mais básico e comum, fundamentado na observação. Trata-se de detectar padrões e regularidades: “Se eu vejo A, qual a probabilidade de ver B?”. É o domínio da estatística tradicional, da regressão e do aprendizado de máquina atual.\nNeste degrau, apenas replicamos o que observamos por meio da correlação. É um comportamento primitivo que encontramos no dia a dia: um bebê aprendendo associações, ou uma coruja que observa o ruído na mata e o associa ao alimento sem precisar entender a anatomia do rato. Nossos ancestrais também operavam aqui ao aprenderem que certos cogumelos eram venenosos; se o consumo era seguido de morte, criava-se a associação. A inteligência artificial atual por exemplo é excelente neste degrau, mas ela apenas &quot;vê&quot; o mundo sem compreender os mecanismos por trás dele.\n2. Segundo Degrau: Intervenção (Fazer)\nA intervenção vai além da observação passiva, ela envolve a manipulação ativa de variáveis para observar novos resultados (outcomes). Aqui, não basta observar o meio, é preciso intervir nele para responder perguntas do tipo: &quot;O que acontecerá se eu fizer X?&quot;.\nUm exemplo clássico é o estudo de impacto de medicamentos. Não basta analisar dados de pessoas que já tomam o remédio por conta própria, precisamos de um grupo de controle e uma intervenção direta para isolar efeitos adversos e entender o impacto real. É o nível dos experimentos controlados e Testes A/B. A intervenção é superior à associação porque mudar o que existe gera informações que os dados passivos não conseguem fornecer: ver fumaça nos dá uma probabilidade de fogo, mas fazer fumaça é uma ação que altera o sistema. Questões de intervenção não podem ser respondidas apenas com dados observacionais como Big Data ou redes neurais profundas se não houver um modelo que modifique a ação que observamos.\n3. Terceiro Degrau: Contrafactuais (Imaginar)\nSe a associação é sobre ver e a intervenção é sobre fazer, o contrafactual é sobre imaginar. Este é o topo da escada e a característica que nos define como seres humanos. Ele lida com o &quot;E se?&quot;: a capacidade de olharmos para o passado, criarmos um universo paralelo em nossa mente e comparar o que ocorreu com o que poderia ter ocorrido sob condições diferentes.\nDiferente dos degraus anteriores, o contrafactual não pode ser respondido apenas com dados atuais ou experimentos presentes, pois o evento já passou. É um exercício de retrospectiva e rigor lógico. Utilizamos essa habilidade em diversas áreas:\n\nMedicina: &quot;O paciente faleceu. Ele teria sobrevivido se tivéssemos administrado o antibiótico antes?&quot;\n\nNegócios: &quot;Tivemos 1.000 vendas. Quantas teríamos feito se não tivéssemos oferecido o cupom?&quot;\n\nJustiça e Ética: &quot;O réu teria evitado o acidente se tivesse feito a manutenção dos freios?&quot;\n\nEste nível permite o aprendizado profundo e a atribuição de responsabilidade, sendo o pilar fundamental para uma inteligência que compreende, de fato, o funcionamento do mundo.",
		"tags": [ "note"]
},

{
		"title": "5. Design de Experimentos",
		"date":"Mon Jan 26 2026 12:43:12 GMT+0000 (Coordinated Universal Time)",
		"url":"/digital-garden/path-for-the-true-and-brave/text/5-design-de-experimentos/",
		"content": "Design de Experimentos\nNa introdução ao seu trabalho The Design of Experiments, Ronald Fisher demonstrou preocupação com a falta de clareza e rigor metodológico em experimentos. Ele notou que a ausência de um design experimental robusto poderia levar a:\n\nDificuldade de Interpretação: O leitor e, por vezes, o próprio cientista, poderiam ter interpretações diferentes sobre os resultados, levando a conclusões não suportadas pelos dados ou que poderiam ter ocorrido por acaso (chance), mesmo que a hipótese fosse falsa.\nCarência Estrutural (Design): Falhas lógicas e estruturais tornam o experimento fundamentalmente incorreto, muitas vezes devido a controles inadequados ou à ausência de uma comparação válida.\n\nExperimentos mal projetados resultam em desperdício de recursos (tempo e dinheiro) e em decisões estratégicas equivocadas. Em um cenário de tomada de decisão, é imprescindível sermos cautelosos e rigorosos para manter o controle sobre a inferência.\nFisher propôs um método para trazer facilidade e confiança à experimentação, baseando-se em três pilares:\n\nRandomização: Garante que características não observáveis se distribuam igualmente entre os grupos, eliminando viés de seleção.\n\nControle: Isola o efeito do tratamento de fatores externos (ruído).\n\nReplicação: Reduz o erro experimental e aumenta a precisão da estimativa.\n\nExperimentos Aleatorizados\nPara contornar o Problema Fundamental da Inferência Causal, suprir a carência de design de experimentos e controlar o viés de variável omitida, recorre-se a métodos de pesquisa como o Experimento Aleatorizado.\nO experimento aleatorizado, ou ensaio clínico randomizado (RCT), é um procedimento no qual as unidades de uma amostra populacional são alocadas de forma aleatória (randomizada) ao grupo de tratamento ou ao grupo de controle.\nA randomização é crucial, pois:\n\nElimina vieses de seleção e confusão.\nCria grupos estatisticamente comparáveis (balanceados).\n\nAo garantir que a única diferença sistemática esperada entre os grupos seja a aplicação do tratamento, a randomização permite que a diferença observacional nos resultados seja interpretada como uma estimativa válida do efeito causal médio do tratamento na população.\n\n[!tip] Lembre-se: O Conceito do Contrafactual\nAo criarmos dois grupos estatisticamente idênticos na média, o grupo de controle representa uma foto do &quot;futuro que não aconteceu&quot; para o grupo tratado. Isso torna plausível responder a perguntas contrafactuais: &quot;O que teria acontecido se não tivéssemos aplicado a mudança?&quot;\n\nLecture 3 – The Magic of Randomized Control Trials\n\nLecture 3 – The Magic of Randomized Control Trials\n\n[!Abstract] Leitura Recomendada\nThe impact of computer usage on academic performance: Evidence from a randomized trial at the United States Military Academy\n\nPremissas\nMolak, em conversa com Thanos Vlontzos enfatiza que nunca nos livramos totalmente das premissas. Todo modelo, causal ou não, repousa sobre suposições; o objetivo não é eliminá‑las, mas escolher aquelas com as quais podemos conviver e torná‑las explícitas. Segundo ele, o problema não é ter premissas iniciais, e sim esquecê‑las: uma suposição negligenciada pode fazer um projeto parecer perfeito na superfície, mas esconder uma &quot;mancha enorme&quot; que, mais tarde, causará problemas. Isso vale tanto para estudos experimentais quanto especialmente para estudos observacionais. As premissas que devemos respeitar são:\n\nSUTVA (Stable Unit Treatment Value Assumption)\n- Consistência: O tratamento é bem definido; o outcome observado para uma unidade sob o tratamento D é igual ao resultado potencial Y(D).\n- Sem interferência: O tratamento de uma unidade não afeta o resultado de outra (sem spillovers/efeitos indiretos).\nIgnorabilidade / Unconfoundedness / Exchangeability\n- Os resultados potenciais são independentes da atribuição do tratamento, condicional às covariáveis observadas: {Y(0),Y(1)}⊥D|X. Em RCTs ideais, a randomização garante ignorabilidade por definição.\nPositividade / Overlap\n- Para todo valor de X considerado, há probabilidade estritamente positiva de receber cada condição: 0&lt;P(T=1|X)&lt;1. Sem positividade, não é possível comparar contrafactuais em certas subpopulações.\nControle de confundidores\n- Em estudos observacionais: Medir e ajustar os confundidores (regressão, propensity scores, IPW, etc.).\n- Em RCTs: Projetar estratificação quando necessário para garantir balanceamento e ajustar para covariáveis na análise para melhorar a precisão (redução de variância).\nAmeaças pós-randomização\n- Não-adesão (noncompliance), perda amostral diferencial (attrition), contaminação e mediadores induzidos pelo tratamento podem reintroduzir viés de seleção.\n\nPontos de Atenção\n\nValidade Interna:\n\nDefinição: Refere-se à confiança de que o efeito observado no resultado é causado unicamente pela manipulação do tratamento (variável independente) e não por fatores externos, vieses ou erros de condução. Um experimento tem alta validade interna se pudermos afirmar com certeza que o tratamento causou a mudança no resultado.\nAmeaças: Seleção dos participantes, mudanças naturais ao longo do tempo, eventos externos durante o experimento e mortalidade/perda amostral.\n\nValidação Externa: Trata-se da capacidade de generalizar os resultados do experimento para a população mais ampla ou para outros ambientes e contextos. Se os resultados só se aplicam à amostra específica estudada, a validade externa é baixa.\n\nAmeaças: Interação entre seleção e tratamento (o efeito só existe no grupo específico selecionado) e efeitos de laboratório (condições artificiais que não refletem o mundo real).\n\nValidade de Construto\n\nDefinição: Refere-se à adequação das medidas. Garante que as variáveis operacionais (como você mede ou manipula algo) realmente representam os construtos teóricos (os conceitos abstratos estudados).\nEm outras palavras: É a certeza de que o experimento está medindo aquilo que se propôs a medir.\nPonto de Atenção:\n\nDeve-se garantir que as métricas realmente capturem a essência dos conceitos (ex: satisfação do cliente, motivação).\nAmeaças Comuns:\n\nSub-representação do Construto: A métrica é incompleta e não captura a totalidade do conceito.\nVariância de Métodos Irrelevantes: A medição é contaminada por fatores alheios ao conceito de interesse.\n\nEfeito Spillover (Violação da SUTVA):\n\nOcorre quando o tratamento aplicado ao Grupo de Tratamento afeta, indiretamente, o Grupo de Controle (ou vice-versa). O tratamento &quot;vaza&quot; ou a informação/benefício se espalha.\n\nExemplos:\n\nUm participante do controle aprende sobre a nova funcionalidade com um amigo do tratamento.\nUm participante do grupo de controle aprende sobre a nova funcionalidade com um amigo do grupo de tratamento (contaminação).\nA mudança de preço em uma loja (tratamento) altera a demanda de uma loja vizinha (controle).\nEm experimentos geográficos, a intervenção em uma área afeta a área contígua.\n\nImplicação: Se houver spillover, o grupo de controle deixa de ser uma linha de base pura, comprometendo a validade interna. A estimativa do efeito será enviesada.\nMitigação: Usar clusters/agrupamentos distantes (geográfica ou socialmente) ou implementar cegamento rigoroso.\n\nAnálise de Poder Estatístico e Tamanho de Amostra\n\nNo contexto de estudos experimentais, a inferência nunca é absoluta; ela é probabilística. Ao tomarmos uma decisão sobre rejeitar ou não a Hipótese Nula (H0), estamos sujeitos a cometer erros. O &quot;Poder Estatístico&quot; é, fundamentalmente, uma medida de nossa capacidade de evitar um desses erros: o de não ver algo que realmente existe.\n1. A Matriz de Decisão (Erros Tipo I e II)\nA melhor forma de visualizar os riscos é através da matriz de decisão. Imagine que existe uma &quot;Verdade Universal&quot; (que não conhecemos) e uma &quot;Decisão do Cientista&quot; (baseada nos dados).\n\nErro do Tipo I (α - Falso Positivo): É o risco de afirmar que o tratamento funciona quando ele é inócuo. É controlado pelo Nível de Significância. Ocorre quando rejeitamos a H0 quando ela é, na verdade, verdadeira.\n\nErro do Tipo II (β - Falso Negativo): É o risco de dizer que &quot;não houve mudança&quot;, quando na verdade o tratamento funcionou. Ocorre quando falhamos em rejeitar a H0 quando ela é, na verdade, falsa.\n\nPoder do Teste (1−β): É a probabilidade de não cometer o Erro Tipo II. Se o Poder é 80%, significa que, se o tratamento for eficaz, temos 80% de chance de detectá-lo.\n\n2. Os 4 Pilares da Análise de Poder\nA Análise de Poder (Power Analysis) descreve o equilíbrio matemático entre quatro variáveis interdependentes. Se você fixar três delas, a quarta pode ser determinada.\n\nTamanho da Amostra (n): A quantidade de unidades no experimento.\n\nRelação: Quanto maior o n, menor o erro padrão e maior o Poder.\n\nNível de Significância (α): O critério de rigor para o &quot;falso positivo&quot;.\n\nRelação: Ser mais rigoroso (ex: baixar α de 5% para 1%) torna mais difícil rejeitar a nula, o que diminui o Poder (aumenta o risco de Falso Negativo).\n\nTamanho do Efeito / MDE (δ): A magnitude da diferença que queremos detectar.\n\nRelação: Efeitos grandes são &quot;fáceis&quot; de ver (ex: um aumento de 50% na conversão). Efeitos minúsculos exigem mais amostra.\n\nPoder Estatístico (1−β): A sensibilidade do teste.\n\n[!example] A Analogia da Rede de Pesca\nImagine que você quer pescar peixes em um lago.\n\nTamanho do Efeito: É o tamanho do peixe. Peixes grandes são fáceis de pegar; peixes pequenos escapam facilmente.\n\nTamanho da Amostra: É o tamanho da sua rede. Uma rede maior cobre mais área.\n\nSignificância (α): É a chance de você puxar uma bota velha e achar que é um peixe.\n\nPoder: É a probabilidade de, havendo um peixe no lago, ele acabar na sua rede.\n\nSe você quer pegar peixes muito pequenos (MDE baixo) com alta certeza (Alto Poder), você precisará de uma rede gigantesca (Amostra Alta).\n\n3. Efeito Mínimo Detectável (MDE)\nO MDE representa a menor mudança que vale a pena detectar. Ele estará atrelado a decisão de negócio e o custo para rodar um experimento.\n\nMDE e ROI: Se implementar uma nova feature custa $1 milhão, um aumento de 0.1% na receita pode não pagar o custo. Logo, seu experimento não precisa ter sensibilidade para detectar 0.1%. Você deve configurá-lo para detectar o ponto de breakeven.\n\nO Perigo do MDE Baixo: Querer detectar efeitos ínfimos exige amostras exponenciais.\n\nO Perigo do MDE Alto: Se você configura o estudo para detectar apenas aumentos gigantes, e seu tratamento gera um ganho sólido de 5%, seu teste dirá que &quot;não houve diferença significativa&quot; (Erro Tipo II), e você descartará uma ideia vencedora. Dificilmente sob ótica de mercado, teremos saltos grandes de efeito de uma feature nova ou novos produtos, por exemplo.\n\n[!tip] A Regra de Kohavi\nSegundo Ron Kohavi (ex-VP do Airbnb e Microsoft), se o seu MDE for menor que 5%, dificilmente seu experimento detectará efeitos significativos com confiança. Idealmente, podemos projetar entre 5% a 10% de efeito.\n\n[!Abstract] Leitura Recomendada\nMinimum Detectable Effect (MDE) and Cohen’s d\n\nElementos fundamentais do desenho experimental\n\n[!Abstract] Leitura Recomendada\nFormulating a well-defined causal question\n\nPara responder a uma pergunta de pesquisa com objetivo causal, é imperativo definir, de forma precisa e mensurável, os componentes estruturais do estudo. A ausência de definições rigorosas torna a inferência ambígua e sujeita a interpretações contraditórias.\n1. Tratamento (Di)\nRefere-se à intervenção ou exposição que está sendo investigada.\n\nDefinição Operacional: Descreva exatamente o que constitui &quot;receber o tratamento&quot;. Evite ambiguidades. Por exemplo, em vez de &quot;receber um cupom&quot;, especifique &quot;receber um cupom de 10% de desconto via e-mail às 09:00&quot;.\n\nEscopo e Intensidade: O tratamento é binário (D∈{0,1}), contínuo (ex: dose de um medicamento) ou multivalorado (ex: variações A/B/C)?\n\nConsistência e SUTVA: A definição deve ser clara o suficiente para garantir que não existam múltiplas versões ocultas do tratamento que afetem o resultado de formas diferentes, violando SUTVA. Se duas pessoas recebem Di=1, elas devem ter recebido essencialmente a mesma intervenção.\n\n2. Potenciais Outcomes (Yi(0),Yi(1))\nOs potenciais outcomes representam os resultados teóricos que a unidade i apresentaria sob cada condição de tratamento.\n\nMensurabilidade: Como o outcome observado Yi será coletado? Temos dados confiáveis para mensurar o estado contrafactual, seja via desenho experimental (RCT) ou métodos observacionais?\n\nDefinição da Métrica: Especifique a métrica exata e a janela temporal.\n\nExemplo: &quot;Conversão&quot; é vago. &quot;Compra confirmada (Y&gt;0) no período de 7 dias após a exposição&quot; é preciso.\n\nTransformações: Defina previamente se usará a métrica bruta, logaritmo, ou taxas.\n\nValidade de Construto: A métrica escolhida realmente representa o conceito que queremos estudar? Uma definição robusta minimiza o erro de medição e garante que estamos capturando o fenômeno de interesse.\n\n3. Unidade de Observação (Ui)\nDefine a entidade fundamental sobre a qual o tratamento é aplicado e o desfecho é medido.\n\nNível de Agregação: Quem é a unidade experimental? Um usuário individual, uma sessão de navegador, uma loja física ou um município?\n\nAlinhamento Tratamento-Unidade: É crucial verificar se a unidade de análise coincide com a unidade de randomização/tratamento.\n\nInterferência: A escolha da unidade afeta a probabilidade de interferência entre unidades? É preciso observar para não violar a SUTVA.\n\nValidade Externa: As características das unidades observadas na amostra permitem generalizar os resultados para a população-alvo?\n\n4. Estimand (O parâmetro de interesse)\nO Estimand é a quantidade teórica exata que queremos estimar. Ele guia todo o desenho do estudo e o cálculo do tamanho da amostra.\n\nDefinição do Parâmetro: O que queremos descobrir?\n\nATE (Average Treatment Effect): O efeito médio para toda a população. E[Y(1)−Y(0)].\n\nATT (Average Treatment Effect on the Treated): O efeito médio apenas para quem de fato recebeu o tratamento.\n\nCATE (Conditional Average Treatment Effect): O efeito médio para um subgrupo específico (heterogeneidade).\n\nMecanismo de Atribuição\n\n[!tip] Citação\nI think it's wrong to think any causality comes only in the modeling part. It comes in the entire system building process:\n\nFrom the data collection (thinking about which parameters come into play);\nObviously the data modeling;\nAnd then to actually making it robust and serving it to the End Customer.\n\nSo this is, for example, a very crucial point: Gathering correct data, especially in the medical field, is extremely hard and extremely crucial. - Thanos Vlontzos\n\nO mecanismo de atribuição é o processo (conhecido ou desconhecido) que determina quais unidades recebem o tratamento e quais recebem o controle. Formalmente, ele descreve a lei de probabilidade condicional P(W|X,Y(0),Y(1)) que governa a alocação do tratamento W.\nEm um RCT, este mecanismo é controlado e conhecido (ex: moeda, sorteio). Em estudos observacionais, ele é desconhecido e precisa ser estimado. Essa estimativa é justamente o cálculo da probabilidade de receber o tratamento P(W=1|X), valor que chamamos de Escore de Propensão, ao qual nos permite rebalancear os grupos e validar se as premissas de identificação foram respeitadas.\nProblemas com Experimentos Aleatorizados\nEm um RCT, os participantes são distribuídos aleatoriamente para o grupo de tratamento ou controle. Essa randomização visa equilibrar todas as variáveis de confusão (tanto as conhecidas quanto as desconhecidas) entre os grupos, permitindo que qualquer diferença observada no resultado seja atribuída, com alta confiança, à intervenção (causa).\nEmbora seja o padrão de ouro na metodologia experimental, ele não oferece uma garantia absoluta de causalidade, pois a randomização inicial é apenas o primeiro passo. A causalidade pode ser comprometida por vieses pós-randomização que surgem durante a execução do estudo. Problemas como a desigualdade de características entre os participantes, perda ou até abandono podem prejudicar o resultado para uma generalização dos resultados.\nAlém das limitações metodológicas na condução do estudo, o RCT é inviável ou antiético em inúmeros cenários de pesquisa causal. Existem fenômenos de interesse (como o efeito de eventos raros, exposições de longuíssimo prazo, ou variáveis não manipuláveis, como o status socioeconômico) onde a aleatoriedade é inatingível. Mais gravemente, a randomização é antiética em exposições que são sabidamente prejudiciais. Por exemplo, seria moralmente inaceitável randomizar uma população para forçar um grupo a fumar a fim de analisar as chances de câncer de pulmão.\nPortanto, em contextos onde a intervenção não pode ser controlada por um RCT devido a impedimentos éticos ou práticos, os pesquisadores devem recorrer a outras ferramentas, como também é possível aplicar outros tipos de amostragens.\n\n[!Abstract] Leitura Recomendada\nHow to run experiments that actually answer your questions\nCommon experimental pitfalls and how to avoid them",
		"tags": [ "note"]
},

{
		"title": "6. DAG",
		"date":"Mon Jan 26 2026 12:43:12 GMT+0000 (Coordinated Universal Time)",
		"url":"/digital-garden/path-for-the-true-and-brave/text/6-dag/",
		"content": "DAG\nO Modelo Gráfico Acíclico Direcionado (DAG) é uma ferramenta visual e matemática essencial na inferência causal moderna. Ele é crucial em contextos observacionais, onde experimentos controlados (RCTs) são inviáveis ou antiéticos. Seu propósito principal é explicitar suposições causais, pois permite identificar caminhos de confusão, determinar quais variáveis ajustar e orientar estratégias de identificação.\n1. Fundamentos Estruturais\n\nNós (Variáveis): Cada nó representa uma variável aleatória. A estrutura é definida pela Independência Condicional. O DAG traduz relações causais em restrições estatísticas testáveis.\n\n[!note]\nAlgebricamente, a Probabilidade Condicional P(B|A) na teoria dos conjuntos é análoga à correlação parcial r(X,Y)|Z usada em algoritmos de descoberta causal (como o Inductive Causality).\n\nArestas (Relações →): Indicam a direção da causalidade. A→B implica que A causa B. O DAG foca na Causalidade Regular (graus mensuráveis de influência) em vez da Causalidade Estrita determinística.\n\nAciclicidade (Não Cíclico): É a regra fundamental. Não pode haver um ciclo fechado (por exemplo, A→B e B→A). Isso impõe uma ordem temporal e causal clara, garantindo que o modelo seja computável para inferência.\n\n2. A Mecânica: D-Separação\nA d-separação (&quot;d&quot; de direcional) é o critério gráfico que determina se um fluxo de informação entre duas variáveis está bloqueado ou aberto. Se todas as trilhas entre D e Y são bloqueadas por um conjunto Z, dizemos que D⊥⊥Y|Z.\nRegras de Bloqueio de Caminho:\n\nCadeia (D→Z→Y) ou Garfo (D←Z→Y):\n\nO caminho está aberto por padrão.\nO caminho é bloqueado se condicionarmos (controlarmos) o nó intermediário Z.\n\nColisor (D→Z←Y):\n\nO caminho está bloqueado por padrão (as setas colidem).\nO caminho é aberto se condicionarmos o colisor Z (ou qualquer descendente dele). Isso cria uma dependência espúria.\n\n[!tip] Validação com Dados\nA d-separação teórica (D⊥⊥Y|Z) deve refletir uma independência estatística nos dados. Testamos isso verificando se a correlação parcial entre D e Y dado Z (ρDY⋅Z) é próxima de zero.\nUma explicação de correlação parcial pode ser vista via Mastering Mostly Harmless Econometrics - Part 2 a partir de 1:08:30.\n\nEstatística Psicobio II 2024 #24 - DAG II Directed Acyclic Graphs - d' separation; algoritmo PC e IC\n\n3. Identificação e Critério Backdoor\nO objetivo final é isolar o efeito causal de D em Y, eliminando vieses.\n\nCaminho Backdoor (Porta dos Fundos): Qualquer caminho entre D e Y que começa com uma seta apontando para D (ex: D←V→Y). Isso representa uma causa comum que gera correlação não-causal, que é a variável de confusão.\n\nCritério Backdoor: Para identificar o efeito causal, devemos selecionar um conjunto de variáveis que, ao serem condicionadas, bloqueiam todos os caminhos backdoor sem abrir novos caminhos (como colisor).\n\n[!note] Analogia: DAG vs. RCT\nEnquanto o Experimento Randomizado (RCT) elimina vieses pelo design (randomização quebra as setas chegando em D), o DAG permite eliminar vieses na análise, simulando uma intervenção (do(D)) através do ajuste estatístico correto.\n\n4. Classificação de Variáveis e Seleção de Controles\nClassificar a variável corretamente é vital para saber se ela é um &quot;Bom Controle&quot; ou um &quot;Mau Controle&quot;.\nA. Confounder (Confusão / Causa Comum)\nAncestral comum da exposição (D) e do desfecho (Y).\n\nEstrutura: D←V→Y\nProblema: Cria um caminho não-causal, enviesando a estimativa.\nAção: Condicionar (Controlar). Devemos fechar essa porta para limpar o efeito.\n\nB. Mediador\nDescendente da exposição e ancestral do desfecho. Está no caminho causal.\n\nEstrutura: D→V→Y\nFunção: Explica como D afeta Y.\nAção: NÃO Condicionar (se o objetivo é o efeito total). Controlar o mediador bloqueia o fluxo causal legítimo (overcontrol bias).\n\nC. Colisor\nDescendente comum da exposição e do desfecho.\n\nEstrutura: D→V←Y\nProblema: Por natureza, ele já bloqueia o caminho.\nAção: NÃO Condicionar. Se controlarmos o colisor, abrimos o caminho e criamos o Viés de Seleção (ou Viés de Colisor).\n\n5. Boas Práticas e Leituras\nO sucesso da inferência causal depende mais do desenho e das suposições teóricas (o DAG) do que da modelagem estatística em si. Definir &quot;bons&quot; e &quot;maus&quot; controles é a chave para evitar paradoxos estatísticos.\n\n[!abstract] Leituras Recomendadas\n\nCausal assumptions: Think first, regress later\nA Crash Course in Good and Bad Controls\nVídeos de Apoio:\n\nMastering Mostly Harmless Econometrics - Part 2 (Minuto 1:08:30 - Correlação Parcial)\nEstatística Psicobio II - d-separation &amp; Algoritmo PC",
		"tags": ["24", "note"]
},

{
		"title": "7. Regressão Linear",
		"date":"Mon Jan 26 2026 12:43:12 GMT+0000 (Coordinated Universal Time)",
		"url":"/digital-garden/path-for-the-true-and-brave/text/7-regressao-linear/",
		"content": "Regressão Linear\n\n[!Abstract] Leitura Recomendada\nLinear regression: our go-to tool\n\nOs modelos de regressão linear são ferramentas fundamentais na inferência causal. Utilizando o método dos Mínimos Quadrados Ordinários (MQO), é possível estimar parâmetros que, sob as suposições corretas de identificação, possuem uma interpretação causal direta.\nConsiderando uma relação linear simples Y∼X+ε, estimamos o efeito de X sobre Y através dos coeficientes β^0 e β^1.\n1. O Intercepto (β^0)\nO coeficiente β^0 representa o valor esperado de Y quando X=0 (assumindo que todas as outras covariáveis do modelo também sejam zero).\n\nPonto de Atenção: Essa interpretação matemática só possui valor prático se X=0 for um cenário plausível ou observado nos dados (ex: idade = 0 pode não fazer sentido em certas análises laborais).\n\n[!tip] Interpretação em Experimentos\nEm estudos com grupos de Controle e Tratamento (onde X é uma dummy indicando o tratamento), β^0 representa a média do grupo de controle. Consequentemente, β^1 captura a diferença média entre os grupos (efeito do tratamento).\n\n2. O Coeficiente de Interesse (β^1)\nO coeficiente β^1 isola a variação média esperada em Y dada uma alteração em X, mantendo constantes as demais variáveis do modelo (ceteris paribus). A interpretação varia conforme a natureza de X:\n\nSe X for contínua: β^1 é a variação média em Y associada a um aumento de uma unidade em X.\n\nSe X for binária (Dummy de Tratamento): β^1 é interpretado como o Efeito Médio do Tratamento (ATE ou ATT, dependendo da população condicionada).\n\n[!tip] Variáveis Categóricas e Dummies\nPara utilizar dados categóricos (strings ou categorias numéricas) em uma regressão, é necessário transformá-los em variáveis binárias (Dummies).\n\nImplementação:\n\nPandas: Utilize pd.get_dummies(df, columns=['Var'], drop_first=True).\n\nStatsmodels: Na fórmula, basta envolver a variável com C(): outcome ~ C(Variavel).\n\nAtenção (Armadilha da Dummy): Para uma variável com N categorias, devemos criar apenas N−1 colunas de dummies. Se incluirmos todas as N colunas junto com o intercepto, criamos multicolinearidade perfeita (redundância).\n\nInterpretação: A categoria omitida torna-se a Categoria de Referência. Os coeficientes das outras dummies representam a diferença média em relação a essa categoria base (quando todas as dummies são 0).\n\n3. Termo de Interação\nMuitas vezes, a suposição de que o efeito de X sobre Y é constante para todos é muito forte. Para capturar como o efeito varia dependendo de uma terceira variável Z, incluímos um termo de interação (produto) no modelo:\nY=β0+β1X+β2Z+β3(X⋅Z)+εNeste modelo, o efeito de X sobre Y não é mais apenas β1. O efeito marginal de X passa a depender do valor de Z:\nΔYΔX=β1+β3ZA interpretação dos coeficientes muda:\n\nβ1 (Efeito Principal de X): Representa o efeito de X sobre Y apenas quando Z=0. Não é mais o efeito médio global.\n\nβ3 (Coeficiente de Interação): Representa o quanto o efeito de X muda para cada unidade adicional de Z.\n\nSe Z for uma variável binária (ex: Z=1 para Mulheres, Z=0 para Homens) e X for o tratamento, então β3 é a diferença de efeito do tratamento entre mulheres e homens, por exemplo.\n\n[!TIP] Lembrete\nAo incluir uma interação X⋅Z, sempre inclua as variáveis originais X e Z no modelo separadamente. Omitir β1 ou β2 força o intercepto ou a inclinação a passar pela origem de forma artificial, enviesando a estimativa da interação.\n\nO Trade-off entre Viés e Variância\n\n[!Abstract] Leitura Recomendada\nCausal Inference in Python: Applying Causal Inference — Part II, Cap. Frisch-Waugh-Lovell Theorem and Orthogonalization, pág. 106\n\nCondicionar covariáveis irrelevantes ou em excesso no modelo pode introduzir um risco: o aumento da variância do estimador de β^1.\nO aumento na variância ocorre frequentemente devido à multicolinearidade e significa que as estimativas de β^1 serão menos precisas. Isso resulta em intervalos de confiança mais amplo, tornando mais difícil rejeitar a hipótese nula e obter um resultado estatisticamente significativo.\nTeorema Frisch‑Waugh‑Lovell\nOutra forma de observamos isso, é entendermos melhor o funcionamento do teorema Teorema Frisch-Waugh-Lovell (FWL).\nEle demonstra que o coeficiente de X em uma regressão múltipla Y ~ X + Z é igual ao coeficiente obtido ao regressar os resíduos de Y sobre Z nos resíduos de X sobre Z. Em termos práticos, isso significa que a contribuição de cada regressora pode ser entendida como a associação entre as partes de Y e X que não são explicadas por Z. Isto pode ser dividido em três etapas\n\nDesviesamento (Debiasing Step)\n\nRemover o viés das variáveis de controle Z da sua variável de interesse X.\nRegredimos a variável de tratamento X nas covariáveis de controle Z, (ex: X∼Z)\nColetamos os resíduos dessa regressão X~. Estes resíduos representam a parte de X que é ortogonal (não correlacionada) aos controles Z.\n\nRemoção de Ruído (Denoising Step)\n\nRemover o ruído das variáveis de controle Z da sua variável dependente Y.\nRegredimos a variável dependente Y nas mesmas covariáveis de controle Z, (ex: Y∼Z)\nColetamos os resíduos dessa regressão Y~. Estes resíduos representam a parte de Y que é independente dos controles Z.\n\nRegressão Final\n\nA estimativa final do efeito causal β^1 é obtida regredindo o resíduo da variável dependente no resíduo da variável de tratamento: Y~∼X~.\nO β^ obtido nesta regressão de resíduos é idêntico ao β^1 da regressão original Y∼X+Z.\n\nPara ver exemplos via código, é só acessar aqui.\n\n[!tip] Lembrete\nA regressão linear assume que a relação entre as regressoras e o resultado (condicional) é linear. Se a relação verdadeira for não linear, a especificação linear pode provocar viés de especificação. É importante verificar se isso ocorre, especialmente entre a variável de tratamento e o desfecho; caso ocorra, podemos aplicar transformações adequadas, por exemplo: logaritmos, termos polinomiais, interações ou transformações multiplicativas.\n\nRegressão Linear como Modelo para Potenciais Outcome\nOutra possibilidade de utilizar a regressão linear, é atuar como um modelo de imputação de potenciais resultados. Isto quer dizer que conseguimos estimar os efeitos causais, seja ATE ou ATT, preechendo valores contrafactuais.\nA lógica reside na capacidade da regressão de modelar as funções de resultado potencial:E[Y0|X] e E[Y1|X].\nEfeito de Tratamento Médio (ATE)\n\n[!tip] Lembrete\nO ATE é calculado como a diferença média entre o que toda a população teria se fosse tratada E^[Y1|Xi] e o que toda a população teria se não fosse tratada E^[Y0|Xi]\n\nATE=1N∑i(E^[Y1|Xi]−E^[Y0|Xi])\n\nOnde E^[Y0|Xi] e E^[Y1|Xi] são modelos de regressão ajustados, respectivamente, nas unidades de controle T=0 e nas unidades tratadas T=1.\n\nCálculo Simplificado com statsmodels\nEm um modelo de regressão linear que inclui covariáveis X, o estimador do ATE é equivalente ao coeficiente da variável de tratamento D.\nSe o seu modelo é Y=β0+β1D+β2X+ϵ, a estimativa de β^1 é o ATE.\nPython\nformula_ate = 'Y ~ D + X1 + X2'\nmodel_ate = smf.ols(formula_ate, data=data).fit()\nate_estimate = model_ate.params['D']\n\nEfeito Médio de Tratamento nos Tratados (ATT)\n\n[!tip] Lembrete\nO ATT é a diferença média entre o resultado observado para o grupo tratado Yi e o seu resultado contrafactual imputado E^[Y0|Xi]\nATT=1N1∑i:Di=1(Yi−E^[Y0|Xi])\nIsto significa que usamos o grupo de controle D=0 para construir o modelo que prevê o resultado potencial Y0.\n\nCálculo Simplificado com statsmodels\nmodel_mu0 = smf.ols('Y ~ X1 + X2', data=data[data['D'] == 0]).fit()\nimputed_y0 = model_mu0.predict(data[data['D'] == 1]) # Imputar o contrafactual, isto é, usar model_mu0 para prever o Y_0 para as unidades do grupo tratado T=1.\natt_estimate = (data[data['D'] == 1]['Y'] - imputed_y0).mean()",
		"tags": [ "note"]
},

{
		"title": "8. Viés",
		"date":"Mon Jan 26 2026 12:43:12 GMT+0000 (Coordinated Universal Time)",
		"url":"/digital-garden/path-for-the-true-and-brave/text/8-vies/",
		"content": "Viés\nO viés ocorre porque a variável de confusão cria uma associação espúria (falsa) entre o Tratamento (a Causa, A) e o Resultado (o Efeito, B). Isso acontece quando o Tratamento e o Resultado compartilham uma causa comum (a variável de confusão, C).\nEm outras palavras, a variável de confusão (C) influencia:\n\nA probabilidade de receber o Tratamento (C→A).\nO Resultado de interesse (C→B).\n\nGraficamente, a relação espúria é representada no DAG (Modelo Gráfico Acíclico Direcionado) como um caminho backdoor: A←C→B\nSem controlar adequadamente (ajustar ou condicionar) essa variável, a nossa estimativa do efeito de A em B incluirá o efeito indireto de C em B, fazendo parecer que A tem um efeito maior (ou menor) do que realmente tem.\nViés de seleção\nSurge quando a amostra analisada não representa fielmente a população de interesse, devido a um critério de seleção (implícito ou explícito) que correlaciona a probabilidade de receber o Tratamento com o próprio Resultado. Esse fenômeno pode ocorrer tanto na etapa de coleta de dados quanto na divisão dos grupos, comprometendo a validade interna e externa das estimativas. Por essa razão, é fundamental dedicar atenção ao <a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/digital-garden/path-for-the-true-and-brave/text/5-design-de-experimentos/\">5. Design de Experimentos</a> e ao mecanismo de atribuição, garantindo que o processo de entrada no estudo não introduza correlações artificiais que invalidem a inferência causal.\nExemplos\n\nAutoseleção: Quando o indivíduo decide se quer participar ou não do tratamento. Pessoas que se voluntariam para um programa de treinamento profissional podem ser mais motivadas do que as que não se voluntariam. Se a &quot;motivação&quot; afeta o salário final, comparar voluntários com não-voluntários enviesará o efeito do treinamento.\n\nViés de Atrito: Comum em estudos longitudinais. Se os participantes que abandonam o estudo são sistematicamente diferentes dos que ficam (ex: em um teste de medicamento, os que sentem muitos efeitos colaterais desistem), a análise final será feita apenas sobre os &quot;sobreviventes&quot;, distorcendo o efeito real.\n\nTruncamento Incidental: Ocorre quando observamos o resultado Y apenas para uma subamostra selecionada. O exemplo clássico é a &quot;Equação de Salários de Heckman&quot;: só observamos o salário de quem decide trabalhar. Se a decisão de trabalhar estiver correlacionada com habilidades não observadas, a média salarial da amostra não representa a média da população.\n\nFormalização\nPara que a estimativa do efeito causal seja válida, precisamos que a atribuição do tratamento seja independente dos resultados potenciais (Independência). O viés de seleção quebra essa premissa:\n(Y1,Y0)⊥̸D∣S=1Onde S=1 indica que o indivíduo faz parte da amostra observada. Isso implica que:\n\nE[Y0|D=1,S=1]≠E[Y0|D=0,S=1]\n\nOu seja, mesmo na ausência do tratamento, o grupo que foi &quot;selecionado&quot; para o tratamento teria um desempenho diferente do grupo de controle devido a características inerentes à seleção.\nViés de variável omitida (OVB) &amp; Endogeneidade\n\n[!Abstract] Leitura Recomendada\nThe anatomy of omitted variable bias\n\nA Endogeneidade ocorre quando uma variável explicativa em um modelo de regressão é correlacionada com o termo de erro (ϵ).\nO OVB é uma das formas mais frequentes de endogeneidade. Ele surge quando omitimos do modelo uma variável Xomitida que deveria estar presente. Para que essa omissão gere viés no coeficiente da variável de tratamento D, duas condições devem ser atendidas simultaneamente:\n\nRelevância para o Outcome: A variável omitida deve ser um determinante de Y.\n\nCorrelação com o Tratamento: A variável omitida deve estar correlacionada com a variável de tratamento D.\n\nImpacto no Modelo\nQuando essas condições são atendidas, o efeito da variável omitida é &quot;capturado&quot; pelo termo de erro, tornando-o correlacionado com o tratamento. Matematicamente, o viés pode ser expressado como:\nBias=βomitida⋅δDXOnde βomitida é o efeito da variável omitida sobre Y, e δDX resulta da regressão da variável omitida contra o tratamento. Como consequência, o estimador de MQO torna-se viesado e inconsistente, falhando em capturar o verdadeiro efeito causal.\n\n[!tip] Nota\nUma análise rápida de verificar uma variável de confusão sob isso é durante a análise exploratória utilizando pairplot da biblioteca Seaborn.\nNela, conseguiremos ver se há uma correlação forte das covariáveis com o tratamento.\nsns.pairplot(data[[&quot;T&quot;, &quot;C1&quot;, &quot;C2&quot;, &quot;C3&quot;]], diag_kind=&quot;hist&quot;)\n\nDerivação do Estimador de Mínimos Quadrados Ordinários (MQO)\nModelo verdadeiro Y=β0+β1X1+β2X2+u, onde E[u]=0 e Cov(u,X1)=Cov(u,X2)=0\nSuponha que estimemos por MQO apenas Y sobre X1 (isto é, omitimos X2). O estimador de MQO para o coeficiente de X1 na regressão simples é α1=Cov(Y,X1)Var(X1).\nSubstituindo o modelo verdadeiro em Cov(Y,X1):\nCov(Y,X1)=Cov(β0+β1X1+β2X2+u,X1)=β1Var(X1)+β2Cov(X2,X1)+Cov(u,X1)Assumindo (Cov(u,X1)=0), temos: α1=β1+β2Cov(X2,X1)Var(X1)\nPortanto, o valor esperado do estimador é E[α1]=β1+β2Cov(X2,X1)Var(X1).\nO termo adicional β2Cov(X2,X1)Var(X1) é o viés por omissão. Ele será diferente de zero sempre que:\n\nβ2≠0 (ou seja, X2 afeta Y) e\nCov(X2,X1)≠0 (ou seja, X2 está correlacionada com X1).\n\nEm outras palavras: se X2 é relevante para Y e está correlacionada com X1, então ao omiti-la o efeito de X2 é parcialmente atribuído a X1, enviesando α1.\n\n[!tip] Exemplo\nPodemos ver uma representação de OVB e como avaliar variáveis de controle em uma regressão a partir da aula ministrada em Mastering Mostly Harmless Econometrics - Part 2, a partir de 01:14:00.",
		"tags": [ "note"]
},

{
		"title": "9. Escore de Propensão",
		"date":"Mon Jan 26 2026 12:43:12 GMT+0000 (Coordinated Universal Time)",
		"url":"/digital-garden/path-for-the-true-and-brave/text/9-escore-de-propensao/",
		"content": "Escore de Propensão\nEm inferência causal distinguimos dois cenários: estudos experimentais, nos quais o pesquisador controla o mecanismo de atribuição - por exemplo, usando RCT - e conhece as probabilidades de receber o tratamento; e estudos observacionais, nos quais a alocação não é controlada e pode haver vieses por confusão. Em estudos observacionais precisamos, de certa forma, “simular” a randomização para reduzir vieses decorrentes de diferenças nas covariáveis pré‑tratamento entre tratados e controles.\nA definição formal é:\ne(X)=P(D=1|X)Onde D é a variável de tratamento e X covariáveis.\nAo condicionarmos nas covariáveis, o escore de propensão controla as variáveis de confusão, ajudando a alcançarmos a independência condicional — o tratamento D torna-se independente do resultado potencial, desde que se condicione no escore de propensão, ⟂Y(0),Y(1)⟂D|e(X).\n\n[!tip] Cenários comuns\n\nViés de Seleção: Pessoas que escolhem receber um tratamento são fundamentalmente diferentes daquelas que não o recebem.\n\nExemplo: Indivíduos mais saudáveis ou mais ricos podem ter maior acesso ou propensão a um novo medicamento.\n\nNoncompliance: Mesmo em ensaios clínicos, se houver falta de adesão total ao tratamento, o efeito causal (como o ATE ou ATT) calculado diretamente pode estar enviesado, comprometendo os resultados e sua interpretabilidade.\n\n[!tip] Nota\nO conceito do Escore de Propensão é estritamente aplicado a tratamentos binários (discretizados ou dicotômicos: Sim/Não). Para tratamentos contínuos, um método utilizado é o Generalized Propensity Score (GPS), aonde modela envolta a densidade condicional, ao invés da probabilidade condicional.\n\nImportante destacar, que ainda sim, precisamos que as premissas de ignorabilidade, positividade e SUTVA devem ser respeitadas antes de aplicar. Relembrando que comentei sobre esse tema em <a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/digital-garden/path-for-the-true-and-brave/text/5-design-de-experimentos/\">5. Design de Experimentos</a>.\nPara utilizarmos o score de propensão, basta regredirmos a intervenção com suas covariáveis em modelo probabilístico, como a regressão logística. Seu resultado, final, seria a probabilidade de uma unidade receber o tratamento condicional dado às covariáveis pré‑tratamento X.\nExemplo (Causal Inference in Python: Applying Causal Inference in the Tech Industry)\nimport statsmodels.formula.api as smf\n\n# 1. Estimar o Escore de Propensão\nps_model = smf.logit(&quot;&quot;&quot;intervention ~\ntenure + last_engagement_score + department_score\n+ C(n_of_reports) + C(gender) + C(role)&quot;&quot;&quot;, data=df).fit(disp=0)\n\n# 2. Adicionar o Escore de Propensão como nova coluna\ndata_ps = df.assign(\npropensity_score = ps_model.predict(df),\n)\n\ndata_ps[[&quot;intervention&quot;, &quot;engagement_score&quot;, &quot;propensity_score&quot;]].head()\n\n# 3. Estimar o Efeito Causal usando o Escore de Propensão como covariável\nmodel = smf.ols(&quot;engagement_score ~ intervention + propensity_score&quot;,\ndata=data_ps).fit()\n\n# O coeficiente 'intervention' neste modelo representa o ATE ajustado pelo escore de propensão\nprint(&quot;ATE Ajustado por Escore de Propensão:&quot;, model.params[&quot;intervention&quot;])\n\nPonderação por Escore de Propensão Inverso\nUma vez tendo esse score, podemos estimar o efeito médio de tratamento. Uma das formas que podemos é por Ponderação por Score de Propensão Inverso (IPW).\nA ideia de IPW é reponderar a sua amostra para criar uma pseudo-população onde a distribuição das variáveis de confusão X é a mesma nos grupos de tratamento D=1 e controle D=0. Isto imita as condições de um ensaio aleatório. O peso W atribuído a cada indivíduo é o inverso da probabilidade de o indivíduo ter recebido o tratamento que realmente recebeu. Essa probabilidade é o Escore de Propensão e^(x). Utilizando desta forma, estimamos um ATE em uma população observacional e você quiser criar uma pseudo‑população em que o tratamento é independente das covariáveis observadas.\n\n[!tip] Exemplo\nUnidades Incomuns (Alto Peso):\n\nUnidades que receberam um tratamento improvável (e.g., alto risco de rotatividade, mas não receberam o treino) recebem um peso alto.\n\nIsso os torna mais representativos da população em geral, essencialmente forçando um balanceamento da amostra.\n\nUnidades Comuns (Baixo Peso):\n\nUnidades que receberam um tratamento provável recebem um peso baixo.\n\nO peso para cada unidade Wi é calculado da seguinte forma, onde Di é o tratamento real recebido:\nWi=1P(Di|Xi)={1e^(xi)se Di=111−e^(xi)se Di=0\n[!tip] Nota\nAo dar um peso alto a unidades tratadas que parecem unidades de controle, e unidades de controle que parecem unidades tratadas, o método garante que o grupo de tratamento e o grupo de controle na pseudo-população sejam comparáveis.\n\nExemplo (Causal Inference in Python: Applying Causal Inference in the Tech Industry\néééEfeito Causal=(Média ponderada do resultadose todos fossem tratados)−(Média ponderada do resultadose ninguém fosse tratado)# 1. Calcular os pesos IPW para cada grupo\nweight_t = 1 / data_ps.query(&quot;intervention == 1&quot;)[&quot;propensity_score&quot;]\nweight_nt = 1 / (1 - data_ps.query(&quot;intervention == 0&quot;)[&quot;propensity_score&quot;])\n\n# 2. Obter os resultados (engagement_score) por grupo\nt1 = data_ps.query(&quot;intervention == 1&quot;)[&quot;engagement_score&quot;]\nt0 = data_ps.query(&quot;intervention == 0&quot;)[&quot;engagement_score&quot;]\n\n# 3. Estimar o Resultado Potencial Médio (E[Y^t])\ny1_num = sum(t1 * weight_t) # Numerador: Somatório (Y * W) para T=1\ny1_den = sum(weight_t) # Denominador: Somatório (W) para T=1\ny1 = y1_num / y1_den\n\ny0_num = sum(t0 * weight_nt) # Numerador: Somatório (Y * W) para T=0\ny0_den = sum(weight_nt) # Denominador: Somatório (W) para T=0\ny0 = y0_num / y0_den\n\nprint(&quot;E[Y1] (Tratado):&quot;, y1)\nprint(&quot;E[Y0] (Controle):&quot;, y0)\nprint(&quot;ATE:&quot;, y1 - y0)\n\nEstimativa Duplamente Robusta\nO Escore de Propensão e(X) e a Ponderação por Escore de Propensão Inverso (IPW) são ferramentas para controlar variáveis de confusão e simular a randomização em dados observacionais. O IPW, em particular, é um estimador baseado em design que se foca em balancear os grupos.\nEntretanto, uma preocupação comum em inferência causal é a especificação incorreta dos modelos. E se o modelo que usamos para calcular o Escore de Propensão estiver errado? Isso nos leva à busca por estimadores mais resilientes.\nO Conceito &quot;Duplamente Robusto&quot;\nUm estimador é considerado Duplamente Robusto (Double Robust - DR) se a estimativa do efeito causal for consistente (ou seja, convergirá para o verdadeiro efeito causal) se:\n\nO modelo para o Escore de Propensão estiver corretamente especificado.\nOU\nO modelo para o outcome potencial que estima estiver corretamente especificado.\n\nEm outras palavras, o estimador DR converge para o modelo que estiver correto. Isso confere uma vantagem e aumenta a confiança na estimativa final, pois você só precisa acertar em um dos dois modelos. A ideia central é que o estimador utiliza ambos os modelos - por exemplo, IPW + Regressão Logística - para construir um estimador para o resultado potencial.\nUm estimador DR popular para o resultado potencial médio sob tratamento pode ser escrito como:\nμtDR(μ^,e^)=1N∑i=1N[μ^t(Xi)+Di−e^(Xi)e^(Xi)(Yi−μ^t(Xi))]Onde:\n\nYi é o resultado observado.\nDi é a variável de tratamento.\nμ^t(Xi) é a previsão do resultado Y pelo modelo, assumindo o tratamento t\ne^(Xi) é o Escore de Propensão.\n\nSe o Escore de Propensão estiver correto:\nO termo Di−e^(Xi)e^(Xi) tenderá a zero na média, e o segundo termo todo se anulará.\nIsto deixa apenas o primeiro termo, 1N∑i=1Nμ^t(Xi), que converge para a estimativa do resultado do modelo. Neste caso, a estimativa DR se comporta como um estimador design-based.\nSe o modelo estiver correto:\nO segundo termo, (Yi−μ^t(Xi)), tenderá a zero na média, pois μ^t(Xi) é uma previsão precisa de Yi.\nA estimativa DR converge para um estimador outcome-based que se baseia primariamente no modelo.",
		"tags": [ "note"]
},

{
		"title": "Inferência Causal",
		"date":"Mon Jan 26 2026 12:43:12 GMT+0000 (Coordinated Universal Time)",
		"url":"/digital-garden/path-for-the-true-and-brave/text/inferencia-causal/",
		"content": "<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/digital-garden/path-for-the-true-and-brave/text/0-roadmap/\">0. Roadmap</a>\n<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/digital-garden/path-for-the-true-and-brave/text/1-introducao/\">1. Introdução</a>\n<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/digital-garden/path-for-the-true-and-brave/text/2-predicao-and-inferencia-causal/\">2. Predição &amp; Inferência Causal</a>\n<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/digital-garden/path-for-the-true-and-brave/text/3-teorias-da-causalidade/\">3. Teorias da Causalidade</a>\n<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/digital-garden/path-for-the-true-and-brave/text/4-escada-da-causacao/\">4. Escada da Causação</a>\n<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/digital-garden/path-for-the-true-and-brave/text/5-design-de-experimentos/\">5. Design de Experimentos</a>\n<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/digital-garden/path-for-the-true-and-brave/text/6-dag/\">6. DAG</a>\n<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/digital-garden/path-for-the-true-and-brave/text/7-regressao-linear/\">7. Regressão Linear</a>\n<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/digital-garden/path-for-the-true-and-brave/text/8-vies/\">8. Viés</a>\n<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/digital-garden/path-for-the-true-and-brave/text/9-escore-de-propensao/\">9. Escore de Propensão</a>\n<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/digital-garden/path-for-the-true-and-brave/text/10-efeitos-heterogeneos/\">10. Efeitos Heterogêneos</a>\n<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/digital-garden/path-for-the-true-and-brave/text/11-variavel-instrumental/\">11. Variável Instrumental</a>\n<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/digital-garden/path-for-the-true-and-brave/text/12-double-machine-learning/\">12. Double Machine Learning</a>\n<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/digital-garden/path-for-the-true-and-brave/text/13-gen-ai-e-causalidade/\">13. GenAI e Causalidade</a>\n<a class=\"internal-link\" target=\"\" data-note-icon=\"\" href=\"/digital-garden/path-for-the-true-and-brave/text/14-boas-praticas/\">14. Boas Práticas</a>",
		"tags": [ "note"]
}
]