<!doctype html>
<html lang="pt-br">
<head>
<title>14. Boas Práticas</title>
<meta name="viewport" content="width=device-width,initial-scale=1">
<script async type="module">import mermaid from"https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs"</script>
<script async src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.25.0/prism.min.js" integrity="sha512-hpZ5pDCF2bRCweL5WoA0/N1elet1KYL5mx3LP555Eg/0ZguaHawxNvEjF6O3rufAChs16HVNhEc6blF/rZoowQ==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
<script async src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.25.0/plugins/autoloader/prism-autoloader.min.js" integrity="sha512-sv0slik/5O0JIPdLBCR2A3XDg/1U3WuDEheZfI/DI5n8Yqc3h5kjrnr46FGBNiUAJF7rE4LHKwQ/SoSLRKAxEA==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
<script async src="https://cdn.jsdelivr.net/npm/lucide@0.115.0/dist/umd/lucide.min.js"></script>
<script>window.addEventListener("load",(()=>{document.querySelectorAll(".callout").forEach((e=>{const t=getComputedStyle(e).getPropertyValue("--callout-icon"),l=t&&t.trim().replace(/^lucide-/,"");if(l){const t=e.querySelector(".callout-title");if(t){const e=document.createElement("div"),c=document.createElement("i");e.appendChild(c),c.setAttribute("icon-name",l),e.setAttribute("class","callout-icon"),t.insertBefore(e,t.firstChild)}}})),lucide.createIcons(),Array.from(document.querySelectorAll(".callout.is-collapsible")).forEach((e=>{e.querySelector(".callout-title").addEventListener("click",(t=>{e.classList.contains("is-collapsed")?e.classList.remove("is-collapsed"):e.classList.add("is-collapsed")}))}))}))</script>
<script async src="https://fastly.jsdelivr.net/npm/force-graph@1.43.0/dist/force-graph.min.js"></script>
<script async src="https://fastly.jsdelivr.net/npm/@alpinejs/persist@3.11.1/dist/cdn.min.js"></script>
<script src="https://fastly.jsdelivr.net/npm/alpinejs@3.11.1/dist/cdn.min.js" async></script>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.25.0/themes/prism-okaidia.min.css" integrity="sha512-mIs9kKbaw6JZFfSuo+MovjU+Ntggfoj8RwAmJbVXQ5mkAX5LlgETQEweFPI18humSPHymTb5iikEOKWF7I8ncQ==" crossorigin="anonymous" referrerpolicy="no-referrer" async>
<script src="https://fastly.jsdelivr.net/npm/whatwg-fetch@3.6.2/dist/fetch.umd.min.js" crossorigin="anonymous" referrerpolicy="no-referrer" async></script>
<link href="/styles/digital-garden-base.css" rel="stylesheet">
<link href="/styles/obsidian-base.css" rel="stylesheet">
<link href="/styles/_theme.e86f9391.css" rel="stylesheet">
<link href="/styles/custom-style.css" rel="stylesheet">
<link rel="icon" href="/favicon.ico" sizes="any">
<link rel="icon" href="/favicon.svg" type="image/svg+xml">
<link rel="apple-touch-icon" href="/apple-touch-icon.png">
<link rel="manifest" href="/manifest.webmanifest">
<style></style>
</head>
<body class="theme-dark markdown-preview-view markdown-rendered markdown-preview-section">
<nav class="navbar">
<div class="navbar-inner">
<a href="/" style="text-decoration:none">
<h1 style="margin:15px!important">Hey, Lucas Leão!</h1>
</a>
</div>
</nav>
<main class="content cm-s-obsidian">
<header>
<div class="header-meta">
</div>
</header>
<h1 id="boas-praticas" tabindex="-1">Boas Práticas</h1>
<div class="callout" data-callout="citation"><div class="callout-title"><div class="callout-title-inner"> Citação<br></div></div>
<div class="callout-content">
<p>
The basic steps as we stated them are step one is you have to realize that your data is the result from an experiment. So you have to describe the experiment which generated the data and then with that you can also start describing the kind of the causal question you have. - <a href="https://youtu.be/qr5JolEAuJU?list=PLhKKv6iMja4p5FbJIgzTOE67E1M6c8lnB&amp;t=1" target="_blank" class="external-link">Mark van der Laan</a></p>
</div></div>
<p>Toda inferência causal sustenta-se em dois pilares fundamentais: <strong>premissas</strong> e <strong>resultados</strong>.</p>
<p>As premissas devem ser declaradas explicitamente e rigorosamente respeitadas. Caso haja suspeita de violação ou impossibilidade de validação completa de alguma delas, é preferível que essa limitação seja apontada e elucidada no estudo, em vez de ofuscada. Um estudo honesto, que respeita tanto o método científico quanto o leitor, mantém seu valor mesmo com limitações declaradas.</p>
<p>Resultados e hipóteses exigem seriedade e cronologia. As hipóteses devem ser formuladas <strong>antes</strong> do estudo (pré-registro), e não ajustadas <em>a posteriori</em> para se adequarem aos dados observados. Modelar resultados baseando-se em hipóteses criadas após a análise é uma prática problemática (<em>HARKing</em>), pois aumenta o risco de detectar padrões espúrios e induzir a tomadas de decisão equivocadas.</p>
<p>Portanto, um escopo de boas práticas deve focar na leitura crítica dos resultados, visando responder perguntas de causa e efeito que impactam a unidade de estudo. Para auxiliar, o artigo abaixo é uma referência que estabelece um fluxo de trabalho e recomendações de validação utilizando modelos de Machine Learning (ML) para prever resultados de tratamentos com segurança:</p>
<p><picture src="/img/user/digital-garden/path-for-the-true-and-brave/assets/boas_praticas_1.png" alt="boas_praticas_1.png"><source media="(max-width:480px)" srcset="/img/optimized/JWwO5u8noz-355.webp" type="image/webp">
<source media="(max-width:480px)" srcset="/img/optimized/JWwO5u8noz-355.jpeg">
<img class="" src="/img/user/digital-garden/path-for-the-true-and-brave/assets/boas_praticas_1.png" alt="boas_praticas_1.png" width=""></picture><br>
<em><a href="https://arxiv.org/abs/2410.08770" target="_blank" class="external-link">Causal machine learning for predicting treatment outcomes</a></em></p>
<p>Além disso, a estruturação do processo é de suma vital. O trabalho <em>A Causal Roadmap</em>, por exemplo, busca rigor metodológico. Ele estabelece um roteiro de sete etapas para gerar evidências de alta qualidade em dados do mundo real (RWE), guiando desde a formulação da pergunta até a estimativa do efeito:</p>
<p><picture src="/img/user/digital-garden/path-for-the-true-and-brave/assets/boas_praticas_2.png" alt="boas_praticas_2.png"><source media="(max-width:480px)" srcset="/img/optimized/MjxguYb2gh-401.webp" type="image/webp">
<source media="(max-width:480px)" srcset="/img/optimized/MjxguYb2gh-401.jpeg">
<img class="" src="/img/user/digital-garden/path-for-the-true-and-brave/assets/boas_praticas_2.png" alt="boas_praticas_2.png" width=""></picture><br>
<em><a href="https://arxiv.org/abs/2305.06850" target="_blank" class="external-link">A Causal Roadmap for Generating High-Quality Real-World Evidence</a></em></p>
<p>É importante pontuar que no artigo, esclarece a importância do pesquisador em utilizar frameworks, como Target Trial Emulation (TTE), que força a serem especificos, em quatro componentes:</p>
<ol>
<li>Quem é o público alvo na população?</li>
<li>Qual a definição de estratégia para o tratamento?</li>
<li>Quanto tempo durará o experimento?</li>
<li>Qual a definição clara de outcome?</li>
</ol>
<p>Para facilitar a identificação da abordagem adequada, deixei um <a href="https://heylucasleao.github.io/html-files/infografico_causal.html" target="_blank" class="external-link">infográfico dinâmico</a> para me ajudar para mim, mas utilize com ressalvas, acredito em suma ser limitado. Se você utiliza ferramentas de GenAI, há o <a href="https://github.com/py-why/pywhyllm" target="_blank" class="external-link">PyWhyLLM</a> como assistente para exploração, ou o <a href="https://cais-web.vercel.app/" target="_blank" class="external-link">Causal LLM Agent</a>.</p>
<h1 id="equivocos" tabindex="-1">Equívocos</h1>
<p>Embora possamos utilizar algoritmos preditivos em análises causais, as abordagens divergem em objetivos e interpretação. Modelos causais exigem maior maturidade teórica para identificar o efeito de uma intervenção, indo além da correlação.</p>
<p>Abaixo, listo equívocos que podem surgir durante a construção de um modelo causal:</p>
<h3 id="1-assumir-causalidade-em-dados-observacionais-sem-criterio" tabindex="-1">1. Assumir causalidade em dados observacionais sem critério</h3>
<p>Observações empíricas que mostram associação entre duas variáveis não permitem, por si só, concluir causalidade. A associação pode ser fruto de confusão, causalidade reversa ou mera coincidência.</p>
<ul>
<li><strong>Exemplo:</strong> As vendas de sorvete e o número de afogamentos aumentam simultaneamente; a temperatura (variável omitida) é a causa comum de ambos.</li>
<li>Como evitar: Sempre observe a construção do DAG, procure fontes de variação plausivelmente exógenas, use desenho experimental quando possível, e declare explicitamente as premissas necessárias para qualquer interpretação causal.</li>
</ul>
<h3 id="2-acreditar-que-a-randomizacao-resolve-strong-todos-strong-os-problemas" tabindex="-1">2. Acreditar que a Randomização resolve <strong>todos</strong> os problemas</h3>
<p>Ensaios aleatorizados reduzem vieses de seleção na atribuição do tratamento, mas <strong>não</strong>* garantem validade externa automática, ausência de vieses de medição, ou ausência de não‑compliance, perdas de seguimento e efeitos indiretos.</p>
<ul>
<li>Exemplo: Um experimento onde muitos participantes do grupo de tratamento desistem (attrition) gera estimativas enviesadas.</li>
<li>Como evitar: Monitore a adesão e perdas de seguimento; considere estimadores como Variáveis Instrumentais para lidar com a não-conformidade.</li>
</ul>
<h3 id="3-controlar-o-maximo-de-variaveis-possivel" tabindex="-1">3. Controlar o máximo de variáveis possível</h3>
<p>Diferente do mundo preditivo, onde &quot;mais dados costumam ser melhor&quot;, na causalidade, incluir certas variáveis pode <strong>introduzir</strong> viés. Controlar mediadores ou colisores pode distorcer o efeito real.</p>
<ul>
<li>Ponto Chave: Um alto <mjx-container class="MathJax" jax="SVG" style="direction:ltr;position:relative"><svg style="overflow:visible;min-height:1px;min-width:1px;vertical-align:-.048ex" xmlns="http://www.w3.org/2000/svg" width="2.705ex" height="1.934ex" role="img" focusable="false" viewBox="0 -833.9 1195.6 854.9" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msup"><g data-mml-node="mi"><path data-c="1D445" d="M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z" style="stroke-width:3"></path></g><g data-mml-node="mn" transform="translate(792,363) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" style="stroke-width:3"></path></g></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline" style="top:0;left:0;clip:rect(1px,1px,1px,1px);-webkit-touch-callout:none;-webkit-user-select:none;-khtml-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;position:absolute;padding:1px 0 0 0;border:0;display:block;width:auto;overflow:hidden"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mi>R</mi><mn>2</mn></msup></math></mjx-assistive-mml></mjx-container> ou poder preditivo não implica poder causal. Incluir um colisor pode gerar uma correlação espúria onde não existe causalidade.</li>
<li>Como evitar: Utilize o critério de Backdoor no seu DAG para decidir quais variáveis devem (e quais não podem) ser controladas.</li>
</ul>
<h3 id="4-substituir-o-pensamento-causal-por-modelos-complexos" tabindex="-1">4. Substituir o pensamento causal por modelos complexos</h3>
<p>Modelos de Machine Learning altamente flexíveis podem prever o <em>outcome</em> com precisão, mas não explicam o que aconteceria sob uma intervenção. A complexidade do algoritmo não valida a suposição causal.</p>
<ul>
<li>Como evitar: Combine ML com frameworks causais (como Double Machine Learning), documente as premissas e realize análises de sensibilidade.</li>
</ul>
<h3 id="5-ignorar-a-heterogeneidade-do-efeito" tabindex="-1">5. Ignorar a Heterogeneidade do Efeito</h3>
<p>Assumir que o efeito causal é o mesmo para todos os indivíduos (homogeneidade) pode mascarar resultados importantes.</p>
<ul>
<li>Exemplo: Um desconto que aumenta as vendas para jovens, mas reduz o valor da marca para clientes premium.</li>
<li>Como evitar: Estime efeitos heterogêneos (CATE - Conditional Average Treatment Effect) e discuta os limites da generalização dos resultados.</li>
</ul>
<h3 id="6-tratar-o-p-valor-como-prova-de-causalidade" tabindex="-1">6. Tratar o P-valor como prova de causalidade</h3>
<p>A significância estatística quantifica apenas a incerteza amostral sob um modelo específico; ela <strong>não valida</strong> suas suposições causais. Um efeito estatisticamente significativo (<mjx-container class="MathJax" jax="SVG" style="direction:ltr;position:relative"><svg style="overflow:visible;min-height:1px;min-width:1px;vertical-align:-.439ex" xmlns="http://www.w3.org/2000/svg" width="8.555ex" height="1.946ex" role="img" focusable="false" viewBox="0 -666 3781.2 860" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z" style="stroke-width:3"></path></g><g data-mml-node="mo" transform="translate(780.8,0)"><path data-c="3C" d="M694 -11T694 -19T688 -33T678 -40Q671 -40 524 29T234 166L90 235Q83 240 83 250Q83 261 91 266Q664 540 678 540Q681 540 687 534T694 519T687 505Q686 504 417 376L151 250L417 124Q686 -4 687 -5Q694 -11 694 -19Z" style="stroke-width:3"></path></g><g data-mml-node="mn" transform="translate(1836.6,0)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" style="stroke-width:3"></path></g><g data-mml-node="mo" transform="translate(2336.6,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z" style="stroke-width:3"></path></g><g data-mml-node="mn" transform="translate(2781.2,0)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" style="stroke-width:3"></path><path data-c="35" d="M164 157Q164 133 148 117T109 101H102Q148 22 224 22Q294 22 326 82Q345 115 345 210Q345 313 318 349Q292 382 260 382H254Q176 382 136 314Q132 307 129 306T114 304Q97 304 95 310Q93 314 93 485V614Q93 664 98 664Q100 666 102 666Q103 666 123 658T178 642T253 634Q324 634 389 662Q397 666 402 666Q410 666 410 648V635Q328 538 205 538Q174 538 149 544L139 546V374Q158 388 169 396T205 412T256 420Q337 420 393 355T449 201Q449 109 385 44T229 -22Q148 -22 99 32T50 154Q50 178 61 192T84 210T107 214Q132 214 148 197T164 157Z" transform="translate(500,0)" style="stroke-width:3"></path></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline" style="top:0;left:0;clip:rect(1px,1px,1px,1px);-webkit-touch-callout:none;-webkit-user-select:none;-khtml-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;position:absolute;padding:1px 0 0 0;border:0;display:block;width:auto;overflow:hidden"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>p</mi><mo>&lt;</mo><mn>0</mn><mo>,</mo><mn>05</mn></math></mjx-assistive-mml></mjx-container>) não elimina explicações alternativas, como variáveis de confusão ou viés de seleção.</p>
<ul>
<li><strong>O Trade-off:</strong> Isso está ligado ao equilíbrio entre Viés e Variância, que comentei anteriormente. Um modelo pode ter variância baixa (estimativas precisas/p-valor baixo), mas estar altamente enviesado por não considerar a estrutura causal correta.</li>
<li><strong>Magnitude vs. Significância:</strong> Um tamanho de efeito grande ou um alto nível de significância não garantem benefícios práticos ou validade causal. Em grandes bases de dados (Big Data), quase qualquer correlação irrelevante pode se tornar &quot;estatisticamente significativa&quot;, mesmo sem qualquer sentido causal. Uma variável com alto poder causal pode apresentar um <mjx-container class="MathJax" jax="SVG" style="direction:ltr;position:relative"><svg style="overflow:visible;min-height:1px;min-width:1px;vertical-align:-.439ex" xmlns="http://www.w3.org/2000/svg" width="1.138ex" height="1.439ex" role="img" focusable="false" viewBox="0 -442 503 636" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z" style="stroke-width:3"></path></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline" style="top:0;left:0;clip:rect(1px,1px,1px,1px);-webkit-touch-callout:none;-webkit-user-select:none;-khtml-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;position:absolute;padding:1px 0 0 0;border:0;display:block;width:auto;overflow:hidden"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>p</mi></math></mjx-assistive-mml></mjx-container>-valor alto (não significante) se a amostra for pequena ou a variância for elevada. <strong>Não confunda precisão estatística com relevância causal.</strong></li>
</ul>
<p><strong>Como evitar:</strong></p>
<ul>
<li>Foque na magnitude do efeito e nos <strong>Intervalos de Confiança</strong>, que mostram a incerteza de forma mais transparente.</li>
<li>Priorize a robustez do desenho do estudo em vez da busca por <mjx-container class="MathJax" jax="SVG" style="direction:ltr;position:relative"><svg style="overflow:visible;min-height:1px;min-width:1px;vertical-align:-.439ex" xmlns="http://www.w3.org/2000/svg" width="1.138ex" height="1.439ex" role="img" focusable="false" viewBox="0 -442 503 636" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z" style="stroke-width:3"></path></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline" style="top:0;left:0;clip:rect(1px,1px,1px,1px);-webkit-touch-callout:none;-webkit-user-select:none;-khtml-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;position:absolute;padding:1px 0 0 0;border:0;display:block;width:auto;overflow:hidden"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>p</mi></math></mjx-assistive-mml></mjx-container>-valores baixos.</li>
<li>Combine a evidência estatística com argumentos teóricos e testes de sensibilidade.</li>
</ul>
</main>
<script>window.location.hash&&document.getElementById(window.location.hash.slice(1)).classList.add("referred"),window.addEventListener("hashchange",(e=>{const t=e.oldURL.split("#");t[1]&&document.getElementById(t[1]).classList.remove("referred");const n=e.newURL.split("#");n[1]&&document.getElementById(n[1]).classList.add("referred")}),!1);const url_parts=window.location.href.split("#"),url=url_parts[0],referrence=url_parts[1];document.querySelectorAll(".cm-s-obsidian > *[id]").forEach((function(e){e.ondblclick=function(e){const t=url+"#"+e.target.id;navigator.clipboard.writeText(t)}}))</script>
<script src="https://fastly.jsdelivr.net/npm/luxon@3.2.1/build/global/luxon.min.js"></script>
<script defer="defer">TIMESTAMP_FORMAT="MMM dd, yyyy h:mm a",document.querySelectorAll(".human-date").forEach((function(e){date=e.getAttribute("data-date")||e.innerText,parsed_date=luxon.DateTime.fromISO(date),null!=parsed_date.invalid&&(parsed_date=luxon.DateTime.fromSQL(date)),null!=parsed_date.invalid&&(parsed_date=luxon.DateTime.fromHTML(date)),e.innerHTML=parsed_date.toFormat(TIMESTAMP_FORMAT)}))</script>
<script>lucide.createIcons({attrs:{class:["svg-icon"]}})</script>
</body>
</html>
