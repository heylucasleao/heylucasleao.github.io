<!doctype html>
<html lang="pt-br">
<head>
<title>3. Probabilidade e Calibração de Modelo</title>
<meta name="viewport" content="width=device-width,initial-scale=1">
<script async type="module">import mermaid from"https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs"</script>
<script async src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.25.0/prism.min.js" integrity="sha512-hpZ5pDCF2bRCweL5WoA0/N1elet1KYL5mx3LP555Eg/0ZguaHawxNvEjF6O3rufAChs16HVNhEc6blF/rZoowQ==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
<script async src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.25.0/plugins/autoloader/prism-autoloader.min.js" integrity="sha512-sv0slik/5O0JIPdLBCR2A3XDg/1U3WuDEheZfI/DI5n8Yqc3h5kjrnr46FGBNiUAJF7rE4LHKwQ/SoSLRKAxEA==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
<script async src="https://cdn.jsdelivr.net/npm/lucide@0.115.0/dist/umd/lucide.min.js"></script>
<script>window.addEventListener("load",(()=>{document.querySelectorAll(".callout").forEach((e=>{const t=getComputedStyle(e).getPropertyValue("--callout-icon"),l=t&&t.trim().replace(/^lucide-/,"");if(l){const t=e.querySelector(".callout-title");if(t){const e=document.createElement("div"),c=document.createElement("i");e.appendChild(c),c.setAttribute("icon-name",l),e.setAttribute("class","callout-icon"),t.insertBefore(e,t.firstChild)}}})),lucide.createIcons(),Array.from(document.querySelectorAll(".callout.is-collapsible")).forEach((e=>{e.querySelector(".callout-title").addEventListener("click",(t=>{e.classList.contains("is-collapsed")?e.classList.remove("is-collapsed"):e.classList.add("is-collapsed")}))}))}))</script>
<script async src="https://fastly.jsdelivr.net/npm/force-graph@1.43.0/dist/force-graph.min.js"></script>
<script async src="https://fastly.jsdelivr.net/npm/@alpinejs/persist@3.11.1/dist/cdn.min.js"></script>
<script src="https://fastly.jsdelivr.net/npm/alpinejs@3.11.1/dist/cdn.min.js" async></script>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.25.0/themes/prism-okaidia.min.css" integrity="sha512-mIs9kKbaw6JZFfSuo+MovjU+Ntggfoj8RwAmJbVXQ5mkAX5LlgETQEweFPI18humSPHymTb5iikEOKWF7I8ncQ==" crossorigin="anonymous" referrerpolicy="no-referrer" async>
<script src="https://fastly.jsdelivr.net/npm/whatwg-fetch@3.6.2/dist/fetch.umd.min.js" crossorigin="anonymous" referrerpolicy="no-referrer" async></script>
<link href="/styles/digital-garden-base.css" rel="stylesheet">
<link href="/styles/obsidian-base.css" rel="stylesheet">
<link href="/styles/_theme.962a3ae4.css" rel="stylesheet">
<link href="/styles/custom-style.css" rel="stylesheet">
<link rel="icon" href="/favicon.ico" sizes="any">
<link rel="icon" href="/favicon.svg" type="image/svg+xml">
<link rel="apple-touch-icon" href="/apple-touch-icon.png">
<link rel="manifest" href="/manifest.webmanifest">
<style></style>
</head>
<body class="theme-dark markdown-preview-view markdown-rendered markdown-preview-section">
<nav class="navbar">
<div class="navbar-inner">
<a href="/" style="text-decoration:none">
<h1 style="margin:15px!important">Hey, Lucas Leão!</h1>
</a>
</div>
</nav>
<main class="content cm-s-obsidian">
<header>
<div class="header-meta">
</div>
</header>
<h1 id="probabilidade-e-calibracao-de-modelo" tabindex="-1">Probabilidade e Calibração de Modelo</h1>
<p>A probabilidade do modelo é um conceito crucial na aprendizagem de máquina. Ela representa a confiança do modelo em suas previsões, oferecendo insights sobre seu desempenho e confiabilidade.</p>
<p>A ideia em geral é que essa probabilidade, seja empírica, ou seja, refletindo que dados similares caem nesse percentual.</p>
<p>Imagine um modelo de visão computacional que verifica se as cerejas do café estão maduras o suficiente para colheita. Se separarmos todas as cerejas às quais o modelo atribuiu um score probabilístico de 0.80 e, manualmente, verificarmos que 40% delas estão realmente maduras, logo que o modelo está descalibrado. Isso poderá trazer risco a colheita, dando falsas expectativas e sendo imprevisivel seus resultados, demonstrando uma alta confiança. Em contra partida, a calibração quando bem feita oferece maior segurança de que o modelo se comportará adequadamente em um ambiente de produção, além de fornecer informações importantes sobre as incertezas do modelo, proporcionando previsibilidade para os stakeholders.</p>
<p>Isto é bem exemplificado no artigo <a href="https://bmcmedicine.biomedcentral.com/articles/10.1186/s12916-019-1466-7" target="_blank" class="external-link">Calibration: the Achilles heel of predictiveanalytics</a>:</p>
<blockquote>
<p>Se o algoritmo é usado para informar pacientes, estimativas de risco mal calibradas levam a falsas expectativas tanto para pacientes quanto para profissionais de saúde. Os pacientes podem tomar decisões pessoais antecipando um evento, ou sua ausência, que na verdade eram equivocadas. Por exemplo, considere um modelo de predição que prevê a chance de um tratamento de fertilização in vitro (FIV) resultar em um nascimento [<a href="https://bmcmedicine.biomedcentral.com/articles/10.1186/s12916-019-1466-7#ref-CR14" target="_blank" class="external-link">14</a>]. Independentemente do quão bem os modelos possam discriminar entre tratamentos que resultam em nascimento versus aqueles que não resultam, é claro que uma super ou subestimação da chance de nascimento torna os algoritmos clinicamente inaceitáveis. Por exemplo, uma forte superestimação da chance de nascimento após FIV daria falsas esperanças a casais que já estão passando por uma experiência estressante e emocional. Tratar um casal que, na realidade, tem um prognóstico favorável expõe a mulher desnecessariamente a possíveis efeitos colaterais prejudiciais, como a síndrome de hiperestimulação ovariana.</p>
</blockquote>
<p><a href="https://www.youtube.com/watch?v=AunotauS5yI" target="_blank" class="external-link">Probability Calibration : Data Science Concepts</a></p>
<h2 id="nao-e-um-problema-novo" tabindex="-1">Não é um problema novo</h2>
<p>Glenn W. Brier, meteorologista, enfrentou um problema similar em meados do século 20 com previsões do tempo. Como poderia avaliar a precisão de suas estimativas em relação ao que realmente acontecia? Foi assim que desenvolveu o &quot;Brier Score&quot;, uma métrica que avalia a precisão das previsões probabilísticas, comparando as probabilidades previstas com os resultados observados. Um score menor indica previsões mais precisas. Até os dias de hoje, é uma métrica essencial para entendermos o comportamento de nossas previsões.</p>
<p><a href="https://www.youtube.com/watch?v=BiaebXlgfNQ" target="_blank" class="external-link">The Brier Score Explained | Model Calibration</a></p>
<p>Outra métrica utilizada nesse contexto é o Log Loss, que quantifica a incerteza na probabilidade das predições do modelo, comparando-as com os resultados reais. Utilizar essas duas métricas pode fornecer perspectivas diferentes sobre o desempenho do modelo.</p>
<p>Em geral, modelos de ML <strong>não</strong> garantem boa calibração, ou seja, seu score probabilístico pode não representar realmente uma probabilidade. Isso é evidenciado na <a href="https://youtu.be/6YnhoCfArQo" target="_blank" class="external-link">palestra</a> de <a href="https://www.linkedin.com/in/guillaume-lemaitre-b9404939/" target="_blank" class="external-link">Guillaume Lemaitre</a>, que também demonstra como técnicas populares de balanceamento podem prejudicar bastante essa calibração.</p>
<p>Uma forma de observar isso é através da curva de confiabilidade, que compara as probabilidades previstas pelo modelo com as frequências reais observadas dos eventos. Ela demonstra se o modelo está bem calibrado, confiante demais ou não. Para comparação, é criada uma linha diagonal perfeita que representa um modelo perfeitamente calibrado, onde as probabilidades previstas correspondem exatamente às frequências observadas. Se a curva de predição ficar abaixo da linha diagonal, significa que o modelo está confiante demais, prevendo probabilidades mais altas do que deveria em relação ao percentual real de ocorrências. Caso a curva fique acima da linha diagonal, sugere que o modelo está subestimando suas previsões, sendo menos confiante do que deveria.</p>
<p><picture src="/img/user/digital-garden/meu-modelo-conforme/assets/image.png" alt="image.png|BMC Medical Informatics and Decision Making"><source media="(max-width:480px)" srcset="/img/optimized/ndb4a9n9pt-500.webp" type="image/webp">
<source media="(max-width:480px)" srcset="/img/optimized/ndb4a9n9pt-500.jpeg">
<source media="(max-width:1920px)" srcset="/img/optimized/ndb4a9n9pt-644.webp" type="image/webp"><source media="(max-width:1920px)" srcset="/img/optimized/ndb4a9n9pt-644.jpeg"><img class="" src="/img/user/digital-garden/meu-modelo-conforme/assets/image.png" alt="image.png|BMC Medical Informatics and Decision Making" width=""></picture><br>
<a href="https://www.researchgate.net/figure/Reliability-curve-calibration-plot-of-the-model-output-probabilities-on-the-test-set_fig3_329597860" target="_blank" class="external-link">BMC Medical Informatics and Decision Making</a></p>
<p>Tendo isso em mente, vamos considerar um cenário: você está desenvolvendo um modelo de predição para identificar quando seu pedido no iFood pode resultar em uma experiência ruim. Para isso, você coletou 10 características de 100.000 pedidos (sim, você adora pedir comida!) ao longo de 5 anos. Ao analisar os dados, você percebeu que a distribuição é desbalanceada — apenas 20% dos registros indicam uma experiência negativa. Isso é um bom sinal, mas como seu modelo se comportaria com esse desbalanceamento? Você decide, então, experimentar quatro tipos de modelos:</p>
<ol>
<li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html" target="_blank" class="external-link">RandomForestClassifier (RF) sem nenhum tratamento nos dados</a></li>
<li><a href="https://imbalanced-learn.org/stable/references/generated/imblearn.ensemble.BalancedRandomForestClassifier.html" target="_blank" class="external-link">BalancedRandomForestClassifier</a></li>
<li>RF utilizando a técnica de <a href="https://imbalanced-learn.org/stable/references/generated/imblearn.under_sampling.RandomUnderSampler.html" target="_blank" class="external-link">Random Under-Sampling (RUS)</a></li>
<li>RF utilizando a técnica de Synthetic Minority <a href="https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SMOTE.html" target="_blank" class="external-link">Over-sampling Technique (SMOTE)</a><br>
<a href="https://github.com/HeyLucasLeao/cp-study/blob/master/calibration_demo.ipynb" target="_blank" class="external-link">https://github.com/HeyLucasLeao/cp-study/blob/master/calibration_demo.ipynb</a></li>
</ol>
<p>Feito esses quatro modelos, se depara com isso:</p>
<h2 id="curva-de-confiabilidade" tabindex="-1">Curva de Confiabilidade</h2>
<p><picture src="/img/user/digital-garden/meu-modelo-conforme/assets/vanilla_rf.png" alt="vanilla_rf.png|RandomForestClassifier"><source media="(max-width:480px)" srcset="/img/optimized/rjEdwspSdG-500.webp" type="image/webp">
<source media="(max-width:480px)" srcset="/img/optimized/rjEdwspSdG-500.jpeg">
<source media="(max-width:1920px)" srcset="/img/optimized/rjEdwspSdG-700.webp" type="image/webp"><source media="(max-width:1920px)" srcset="/img/optimized/rjEdwspSdG-700.jpeg"><img class="" src="/img/user/digital-garden/meu-modelo-conforme/assets/vanilla_rf.png" alt="vanilla_rf.png|RandomForestClassifier" width=""></picture><br>
RandomForestClassifier</p>
<p><picture src="/img/user/digital-garden/meu-modelo-conforme/assets/balanced_rf.png" alt="balanced_rf.png|BalancedRandomForestClassifier"><source media="(max-width:480px)" srcset="/img/optimized/MtFySKw_Yc-500.webp" type="image/webp">
<source media="(max-width:480px)" srcset="/img/optimized/MtFySKw_Yc-500.jpeg">
<source media="(max-width:1920px)" srcset="/img/optimized/MtFySKw_Yc-700.webp" type="image/webp"><source media="(max-width:1920px)" srcset="/img/optimized/MtFySKw_Yc-700.jpeg"><img class="" src="/img/user/digital-garden/meu-modelo-conforme/assets/balanced_rf.png" alt="balanced_rf.png|BalancedRandomForestClassifier" width=""></picture><br>
BalancedRandomForestClassifier</p>
<p><picture src="/img/user/digital-garden/meu-modelo-conforme/assets/rus_rf.png" alt="rus_rf.png|RUS RandomForestClassifier"><source media="(max-width:480px)" srcset="/img/optimized/FrAscgSc7a-500.webp" type="image/webp">
<source media="(max-width:480px)" srcset="/img/optimized/FrAscgSc7a-500.jpeg">
<source media="(max-width:1920px)" srcset="/img/optimized/FrAscgSc7a-700.webp" type="image/webp"><source media="(max-width:1920px)" srcset="/img/optimized/FrAscgSc7a-700.jpeg"><img class="" src="/img/user/digital-garden/meu-modelo-conforme/assets/rus_rf.png" alt="rus_rf.png|RUS RandomForestClassifier" width=""></picture><br>
RUS RandomForestClassifier</p>
<p><picture src="/img/user/digital-garden/meu-modelo-conforme/assets/smote_rf.png" alt="smote_rf.png|SMOTE RandomForestClassifier"><source media="(max-width:480px)" srcset="/img/optimized/3UWNN7FEgY-500.webp" type="image/webp">
<source media="(max-width:480px)" srcset="/img/optimized/3UWNN7FEgY-500.jpeg">
<source media="(max-width:1920px)" srcset="/img/optimized/3UWNN7FEgY-700.webp" type="image/webp"><source media="(max-width:1920px)" srcset="/img/optimized/3UWNN7FEgY-700.jpeg"><img class="" src="/img/user/digital-garden/meu-modelo-conforme/assets/smote_rf.png" alt="smote_rf.png|SMOTE RandomForestClassifier" width=""></picture><br>
SMOTE RandomForestClassifier<br>
O modelo sem tratamento do desbalanceamento de dados é, na verdade, melhor calibrado do que aqueles que utilizaram técnicas de reamostragem, como SMOTE, ROS ou RUS. Isto também é evidenciado em diversos, artigo, como por exemplo:</p>
<ul>
<li><a href="https://doi.org/10.1093/jamia/ocac093" target="_blank" class="external-link">The harm of class imbalance corrections for risk prediction models: illustration and simulation using logistic regression</a></li>
<li><a href="https://arxiv.org/abs/2404.19494" target="_blank" class="external-link">The harms of class imbalance corrections for machine learning based prediction models: a simulation study</a></li>
<li><a href="https://arxiv.org/abs/2202.03579" target="_blank" class="external-link">Stop Oversampling for Class Imbalance Learning: A Critical Review</a></li>
</ul>
<p>Além disso, observa-se que alguns modelos são naturalmente descalibrados após seu treinamento, independentemente do tratamento de dados. Conforme demonstrado no artigo <a href="https://www.diva-portal.org/smash/record.jsf?dswid=5765&amp;pid=diva2%3A1603345&amp;c=1&amp;searchType=SIMPLE&amp;language=en&amp;query=2%3A1603345&amp;af=%5B%5D&amp;aq=%5B%5B%5D%5D&amp;aq2=%5B%5B%5D%5D&amp;aqe=%5B%5D&amp;noOfRows=50&amp;sortOrder=author_sort_asc&amp;sortOrder2=title_sort_asc&amp;onlyFullText=false&amp;sf=all" target="_blank" class="external-link">Probabilistic Prediction in scikit-learn</a>, é necessário adicionar um método de calibração para melhorar as estimativas.</p>
<h3 id="venn-abers" tabindex="-1">Venn-Abers</h3>
<p>Nesse contexto, utilizo o <a href="https://youtu.be/TK37Db3WHYI?t=2344" target="_blank" class="external-link">Venn-Abers</a>, um modelo de calibração que fornece um intervalo de probabilidade, auxiliando na interpretação e quantificação da incerteza na previsão de um modelo. Para obter as probabilidades, o método usa <a href="https://www.youtube.com/watch?v=TEbLUhHqLgE" target="_blank" class="external-link">regressão isotônica</a> para calibrar as previsões, aplicando-a duas vezes: primeiro assumindo que o rótulo verdadeiro é 0, depois assumindo que é 1. Esse processo gera duas funções de calibração, f0 e f1, que calculam os intervalos de probabilidade e representam os limites inferior e superior da probabilidade do rótulo ser 1. É possível também trabalhar com uma única probabilidade como resultado, que é o que faremos neste projeto. O artigo original sugere a fórmula:</p>
<mjx-container class="MathJax" jax="SVG" display="true" style="direction:ltr;display:block;text-align:center;margin:1em 0;position:relative"><svg style="overflow:visible;min-height:1px;min-width:1px;vertical-align:-1.991ex" xmlns="http://www.w3.org/2000/svg" width="16.065ex" height="4.52ex" role="img" focusable="false" viewBox="0 -1118 7100.6 1998" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z" style="stroke-width:3"></path></g><g data-mml-node="mo" transform="translate(780.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z" style="stroke-width:3"></path></g><g data-mml-node="mfrac" transform="translate(1836.6,0)"><g data-mml-node="msub" transform="translate(2162.2,676)"><g data-mml-node="mi"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z" style="stroke-width:3"></path></g><g data-mml-node="mn" transform="translate(536,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" style="stroke-width:3"></path></g></g><g data-mml-node="mrow" transform="translate(220,-686)"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" style="stroke-width:3"></path></g><g data-mml-node="mo" transform="translate(722.2,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z" style="stroke-width:3"></path></g><g data-mml-node="msub" transform="translate(1722.4,0)"><g data-mml-node="mi"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z" style="stroke-width:3"></path></g><g data-mml-node="mn" transform="translate(536,-150) scale(0.707)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" style="stroke-width:3"></path></g></g><g data-mml-node="mo" transform="translate(2884.2,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z" style="stroke-width:3"></path></g><g data-mml-node="msub" transform="translate(3884.4,0)"><g data-mml-node="mi"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z" style="stroke-width:3"></path></g><g data-mml-node="mn" transform="translate(536,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" style="stroke-width:3"></path></g></g></g><rect width="5024" height="60" x="120" y="220"></rect></g></g></g></svg><mjx-assistive-mml unselectable="on" display="block" style="top:0;left:0;clip:rect(1px,1px,1px,1px);-webkit-touch-callout:none;-webkit-user-select:none;-khtml-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;position:absolute;padding:1px 0 0 0;border:0;display:block;overflow:hidden;width:100%"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mi>p</mi><mo>=</mo><mfrac><msub><mi>p</mi><mn>1</mn></msub><mrow><mn>1</mn><mo>−</mo><msub><mi>p</mi><mn>0</mn></msub><mo>+</mo><msub><mi>p</mi><mn>1</mn></msub></mrow></mfrac></math></mjx-assistive-mml></mjx-container><h3 id="reamostragem" tabindex="-1">Reamostragem</h3>
<p>Considerando que a reamostragem prejudica a calibração do modelo, decidi abordar o problema das classes de outra maneira, preservando a distribuição original dos dados. É importante ressaltar também que o desbalanceamento por si só nem sempre prejudica o modelo — há arquiteturas pensadas nestes cenários, regularizando o viés. Durante anos, existiu uma concepção de que árvores de decisão, quando aplicadas em dados desbalanceados, inevitavelmente produziriam modelos enviesados para a classe majoritária. Entretanto, existem evidências de que árvores de decisão são capazes de lidar com esse cenário e, em algumas situações, podem até desenvolver uma tendência favorável à classe minoritária, com ajustes específicos. No caso do RandomForestClassifier, por exemplo, ajustamos o critério do modelo com base na proporção das classes, o que auxilia na generalização. Para um entendimento mais profundo, sugiro a leitura do artigo <a href="https://arxiv.org/abs/2501.04903" target="_blank" class="external-link">Towards understanding the bias in decision trees</a>.</p>
</main>
<script>window.location.hash&&document.getElementById(window.location.hash.slice(1)).classList.add("referred"),window.addEventListener("hashchange",(e=>{const t=e.oldURL.split("#");t[1]&&document.getElementById(t[1]).classList.remove("referred");const n=e.newURL.split("#");n[1]&&document.getElementById(n[1]).classList.add("referred")}),!1);const url_parts=window.location.href.split("#"),url=url_parts[0],referrence=url_parts[1];document.querySelectorAll(".cm-s-obsidian > *[id]").forEach((function(e){e.ondblclick=function(e){const t=url+"#"+e.target.id;navigator.clipboard.writeText(t)}}))</script>
<script src="https://fastly.jsdelivr.net/npm/luxon@3.2.1/build/global/luxon.min.js"></script>
<script defer="defer">TIMESTAMP_FORMAT="MMM dd, yyyy h:mm a",document.querySelectorAll(".human-date").forEach((function(e){date=e.getAttribute("data-date")||e.innerText,parsed_date=luxon.DateTime.fromISO(date),null!=parsed_date.invalid&&(parsed_date=luxon.DateTime.fromSQL(date)),null!=parsed_date.invalid&&(parsed_date=luxon.DateTime.fromHTML(date)),e.innerHTML=parsed_date.toFormat(TIMESTAMP_FORMAT)}))</script>
<script>lucide.createIcons({attrs:{class:["svg-icon"]}})</script>
</body>
</html>
